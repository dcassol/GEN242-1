





















































































[{"body":"\nOverview This course introduces algorithms, statistical methods and data analysis programming routines relevant for genome biology. It consists of three main components: lectures, hands-on practicals and student course projects. The lecture topics cover databases, sequence (NGS) analysis, phylogenetics, comparative genomics, genome-wide profiling methods, network biology and more. The hands-on practicals include homework assignments and course projects focusing on data analysis programming of next generation genome data using command-line tools on a computer cluster and the programming environment R. Depending on student interests, one or more specialty topics may be included, such as the analysis of single cell (e.g. scRNA-Seq) experiments, multi-omics data, or the development of web-based analysis tools (e.g. Shiny Apps).\nWho should take this class? Students with a strong interest and motivation in acquiring the skills required for mastering the computational aspects of modern genome research. The class is mainly targeting graduate students but senior undergraduate students are welcome to enroll as well. The main audience of this class usually includes students from bioscience, biomedical and bioengineering programs as well as CS and statistics students with interest in computational biology.\nCan I audit this class? It is possible to audit this class. However, due to the emphasis on active participation in practicals and course projects, students usually learn much more if they enroll into the class rather than auditing it in a passive manner.\nCode of conduct and DEI standards The instructors, organizers and participants of this class are committed to create and maintain an environment in which everyone can learn and thrive in ways inclusive of their diverse backgrounds and identities. All teaching material, activities, virtual or face-to-face interactions related to this course are intended to provide a harassment-free experience for everyone, regardless of age, body size, visible or invisible disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, caste, color, religion, or sexual identity and orientation. For additional information about this important topic please visit the website of UCR’s Office of Diversity, Equity \u0026 Inclusion (DEI).\n","categories":"","description":"","excerpt":"\nOverview This course introduces algorithms, statistical methods and …","ref":"/about/introduction/","tags":"","title":"Introduction"},{"body":"  GitHub in GEN242  Note, this class will make heavy use of GitHub Homework assignments will be submitted to private GitHub repositories: one repository for each student Course projects will also use private GitHub repositories: one repository for each course project (shared among students of each project) Each student will need a personal GitHub account. They can be created here. GitHub provides an unlimited number of free public repositories to each user. Via GitHub Education students can sign up for free private GitHub accounts (see here). All private GitHub accounts required for this class will be provided by the instructor via GitHub Classroom For beginners this quick guide may be useful  What are Git and GitHub?  Git is a distributed version control system similar to SVN GitHub is an online social coding service based on Git Combined Git/GitHub: environment for version control and social coding  Installing Git  Install on Windows, OS X and Linux When using it from RStudio, it needs to find the Git executable  Git Basics from Command-Line Also try interactive git tutorial.\n  Finding help from command-line\ngit \u003ccommand\u003e --help    Initialize a directory as a Git repository\ngit init    Add specific files to Git repository (staging area)\ngit add myfile    Add all files recursively\nTo ignore specific files (e.g. temp files), list them in a .gitignore file in your repository’s root directory. Regular expressions are supported. See here for more details.\ngit add -A :/    After editing file(s) in your repos, record a snapshot of the staging area\ngit commit -am \"some edits\"    GitHub Basics from Command-Line   Generate a new remote repository on GitHub online or use hub command-line wrapper for this. To avoid errors with the online method, do not initialize the new repository with README, license, or .gitignore files. You can add these files after your project has been pushed to GitHub.\ngit remote add origin https://github.com/\u003cuser_name\u003e/\u003crepos_name\u003e.git    Push updates to remote. Next time one can just use git push\ngit push -u origin master    Clone existing remote repository\ngit clone https://github.com/\u003cuser_name\u003e/\u003crepos_name\u003e.git    Before working on project, update local git repos\ngit pull    Make changes and recommit local to remote\ngit commit -am \"some edits\"; git push -u origin master    Exercise Run the following git/github excercise from the command-line.\ngit clone https://github.com/\u003cuser or org\u003e/\u003crepo name\u003e cd \u003crepo name\u003e git pull touch test # Creates empty file for testing git add -A git commit -am \"some edits\" git push -u origin master ##-\u003e Edit test file online and then run `git pull` to inspect changes  Online file upload This could be useful for new users who want to upload their homework assignments to GitHub but are not familiar enough with the command-line yet.\n Press Create new file button on your repository. Under the file path window add required subdirectory structure and a dummy file name (e.g. Homework/HW1/dummy.txt) After this press Upload files and upload any file (e.g. homework) to the newly create directory. After this the initial dummy file can be deleted. The latter is necessary since empty directories are not visible on GitHub.  Using GitHub from RStudio   After installing Git (see here), set path to Git executable in Rstudio:\n Tools \u003e Global Options \u003e Git/SVN    If needed, log in to GitHub account and create repository. Use option Initialize this repository with a README.\n  Clone repository by copying \u0026 pasting URL from repository into RStudio’s ‘Clone Git Repository’ window:\n File \u003e New Project \u003e Version Control \u003e Git \u003e Provide URL    Now do some work (e.g. add an R script), commit and push changes as follows:\n Tools \u003e Version Control \u003e Commit    Check files in staging area and press Commit Button\n  To commit changes to GitHub, press Push Button\n  Shortcuts to automate above routines are here\n  To resolve password issues, follow instructions here.\n  ","categories":"","description":"","excerpt":"  GitHub in GEN242  Note, this class will make heavy use of GitHub …","ref":"/manuals/github/github/","tags":"","title":"GitHub Introduction"},{"body":"  GitHub in GEN242  Note, this class will make heavy use of GitHub Homework assignments will be submitted and graded on GitHub Classroom Course projects will also use private GitHub repositories: one repository for each course project (shared among students of each project) Each student will need a personal GitHub account. They can be created here. GitHub provides an unlimited number of free public repositories to each user. Via GitHub Education students can sign up for an extended number of free private GitHub accounts (see here). For beginners this quick guide may be useful  What are Git and GitHub?  Git is a version control system similar to SVN GitHub is an online social coding service based on Git Combined Git/GitHub: environment for version control and social coding  Installing Git  Install on Windows, OS X and Linux When using it from RStudio, it needs to find the Git executable  Git Basics from Command-Line Also try interactive git tutorial.\n  Finding help from command-line\ngit \u003ccommand\u003e --help    Initialize a directory as a Git repository\ngit init    Add specific files to Git repository (staging area)\ngit add myfile    Add all files recursively\nTo ignore specific files (e.g. temp files), list them in a .gitignore file in your repository’s root directory. Regular expressions are supported. See here for more details.\ngit add -A :/    After editing file(s) in your repos, record a snapshot of the staging area\ngit commit -am \"some edits\"    GitHub Basics from Command-Line   Generate a new remote repository on GitHub online or use hub or GitHub CLI command-line wrappers for this. To avoid errors with the online method, do not initialize the new repository with README, license, or .gitignore files. You can add these files after your project has been pushed to GitHub.\ngit remote add origin https://github.com/\u003cuser_name\u003e/\u003crepos_name\u003e.git    Push updates to remote. Next time one can just use git push\ngit push -u origin master    Clone existing remote repository\ngit clone https://github.com/\u003cuser_name\u003e/\u003crepos_name\u003e.git    Before working on project, update local git repos\ngit pull    Make changes and recommit local to remote\ngit commit -am \"some edits\"; git push -u origin master    Exercise Run the following git/github excercise from the command-line. Do this after creating a GitHub repos according to the instructions above or online as outlined here.\ngit clone https://github.com/\u003cuser or org\u003e/\u003crepo name\u003e cd \u003crepo name\u003e git pull touch test # Creates empty file for testing git add test # or use '-A' for all git commit -am \"some edits\" git push ##-\u003e Edit test file online and then run `git pull` to inspect changes  Online file upload Useful for new users who want to upload their homework assignments to GitHub but are not familiar enough with the command-line yet.\n Press Add file button on your repository, and then Upload files. Under the file path window add required subdirectory structure and a dummy file name (e.g. Homework/HW1/dummy.txt) After this press Upload files and upload any file (e.g. homework) to the newly create directory. After this the initial dummy file can be deleted. The latter is necessary since empty directories are not visible on GitHub.  Using GitHub from RStudio   After installing Git (see here), set path to Git executable in Rstudio:\n Tools \u003e Global Options \u003e Git/SVN    If needed, log in to GitHub account and create repository. Use option Initialize this repository with a README.\n  Clone repository by copying \u0026 pasting URL from repository into RStudio’s ‘Clone Git Repository’ window:\n File \u003e New Project \u003e Version Control \u003e Git \u003e Provide URL    Now do some work (e.g. add an R script), commit and push changes as follows:\n Tools \u003e Version Control \u003e Commit    Check files in staging area and press Commit Button\n  To commit changes to GitHub, press Push Button\n  Shortcuts to automate above routines are here\n  To resolve password issues, follow instructions here.\n  ","categories":"","description":"","excerpt":"  GitHub in GEN242  Note, this class will make heavy use of GitHub …","ref":"/tutorials/github/github/","tags":"","title":"GitHub Introduction"},{"body":"Course title Data Analysis in Genome Biology GEN242 - Spring 2021\nPrintable syllabus See Google Doc version here.\nInstructor Name: Thomas Girke Email: thomas.girke@ucr.edu Office location: virtual via Zoom Office hour: Tue 4:30 - 5:30 PM \u0026 Fri 4:00 - 5:00 PM Zoom URL: privately shared\nTA Name: Le Zhang Email: le.zhang001@email.ucr.edu Office location: virtual via Zoom Office hour: Tue 11:00 - 12:00 PM Zoom URL: privately shared\nDescription Introduction to algorithms, statistical methods and data analysis programming routines relevant for genome biology. The class consists of three main components: lectures, hands-on practicals and student course projects. The lecture topics cover databases, sequence (NGS) analysis, phylogenetics, comparative genomics, genome-wide profiling methods, network biology and more. The hands-on practicals include homework assignments and course projects focusing on data analysis programming of next generation genome data using command-line tools on a computer cluster and the programming environment R. Credit: 4 units (2x 1.5 hours lectures, 1 hour discussion)\nObjectives of course  Acquire understanding of algorithms used in bioinformatics Obtain hands-on experience in large scale data analysis.  Prerequisites The main prerequisite for this course is a strong interest in acquiring the skills required for mastering the computational aspects of modern genome research.\nStructure of course Two lectures per week (1.5 hours each) plus one discussion section (1 hour). During the first weeks the discussion section will be used for data analysis tutorials using Linux command-line tools and R.\nTime Lecture: Tue/Thu 2:00-3:20 PM Discussion: Thu 3:30-4:20 PM\nLocation Online via video conferencing software\nGrading  Homework assignments: 40% Scientific paper presentation: 20% Course project presentations: 20% Final project report: 20%  Additional details about the grading system are provided in this table (see both tabs).\nGrading policy: Given the diverse educational background of the students in GEN242, all assignments are designed to be solvable by students from both experimental and quantitative disciplines, including those with no or only limited prior experience in programming and/or data modeling. The weight of each of the four gradable components in this class is given above in percent. (1) The homeworks include 8-10 assignments throughout the class. They cover algorithms and data analysis programming problems using the R language. The grading of these assignments is mainly based on correctness, reproducibility and reusability of the analysis code. (2-4) Students will work on a Challenge Project (individually or in group) addressing a specific data analysis problem in genome data sciences. As part of their project, students will present a scientific paper (2) closely related to their project (see reading list for details). The results of the Challenge Projects (3) will be presented and discussed by each student at the end of the course. In addition, each student will write a detailed analysis report (4) of the assigned course project. The latter will be written in the style of a scientific publication and should include a detailed description of the results including all analysis code to fully reproduce the project results followed by a critical discussion of the outcomes. The grading of both the paper and project presentations (2-3) includes anonymous feedback from all students as well as the instructor, where understanding of the material, clarity of the oral presentations and critical thinking are the main grading criteria. The final project reports (4) will be graded by the instructor with an emphasis on scientific and coding accuracy, overall understanding of the topic, as well as reproducibility of the results.\nMaterials needed Students are expected to bring to each class meeting a laptop with a functional wireless connection and a recent internet browser version (e.g. Firefox, Chrome or Safari) preinstalled. Tablet computers with mobile operating systems are not suitable for running the required software. User accounts on a research computer cluster will be provided at the beginning of the course. To log in to the cluster, students also need to install a terminal application for their operating system (e.g. iTerm2 on OS X, and PuTTY or MobaXterm on Windows) as well as a file exchange software such as FileZilla. In addition, a recent version of R and RStudio should be installed on each laptop.\nIf possible students may want to attend class sessions from a monitor setup with either one large monitor (wide enough to display several windows) or two separate monitors. This allows simultaneous viewing of presentations on one screen and following along hands-on practicals on the other screen.\nSchedule Note: this schedule is from a previous offering of this class. The final schedule will be released during the first two weeks to include student suggestions.\n   Week Topic     Week 1 Course Introduction    Databases and Software for Genome Biology    Discussion: Introduction to Linux and HPC    Reading: A1, T1, T2   Week 2 Sequencing Technologies    Discussion: Introduction to R    Reading: A2-A4, T3   Week 3 Sequence Alignments and Searching    Multiple Sequence Alignments    Discussion: Programming in R    Reading: A5-A6, T4   Week 4 Short Read Alignment Algorithms    Discussion: Basics of NGS Analysis    Reading: A7-A10, T5   Week 5 Gene Expression Analysis using Microarrays and RNA-Seq    Discussion: NGS Workflow Overview; RNA-Seq Analysis    Reading: A11-A15, T6-T7   Week 6 Analysis of ChIP-Seq and VAR-Seq Experiments    Discussion: ChIP-Seq and VAR-Seq Analysis    Reading: A16-A18, T8-T9   Week 7 Students present publication related to their chosen course project    Discussion: Q\u0026A about papers    Reading: A19-A23   Week 8 Clustering algorithms    Pathway and GO annotation systems    Discussion: Gene Set Enrichment Analysis    Reading: A24-A26, T6 (Sec 3.14-3.15), T10   Week 9 Genome and Transcriptome Assembly Algorithms    Profile HMMs for Protein Family Modeling    Introduction to Phylogenetics    Discussion: Graphics and Data Visualization    Reading: A27-A29, T11   Week 10 Final presentations of student data analysis projects    Discussion: Tips and tricks for efficient data analysis programming    Reading: A30-A31, T3 (Sec 12,13-17)    Reading list Note: this reading list is from a previous offering of this class. The list will be finalized during the first two weeks to include student suggestions.\nJournal articles A1. Huber W, Carey VJ, Gentleman R, Anders S, Carlson M, Carvalho BS, Bravo HC, Davis S, Gatto L, Girke T, et al (2015) Orchestrating high-throughput genomic analysis with Bioconductor. Nat Methods 12: 115–121\nA2. Metzker, M. L., Jan 2010. Sequencing technologies - the next generation. Nat Rev Genet 11 (1), 31–46.\nA3. Needleman SB, Wunsch CD (1970) A general method applicable to the search for similarities in the amino acid sequence of two proteins. J Mol Biol 48, 443-453.\nA4. Smith TF, Waterman MS (1981) Identification of common molecular subsequences. J Mol Biol 147, 195-197.\nA5. Corpet F (1988) Multiple sequence alignment with hierarchical clustering. Nucleic Acids Res 16, 10881-90.\nA6. Altschul, S. F., Gish, W., Miller, W., Myers, E. W., Lipman, D. J., Oct 1990. Basic local alignment search tool. J Mol Biol 215 (3), 403–410.\nA7. Li, H, Durbin, R (2009) Fast and accurate short read alignment with Burrows-Wheeler transform. Bioinformatics, 25: 1754-1760.\nA8. Dobin, A., Davis, C.A., Schlesinger, F., Drenkow, J., Zaleski, C., Jha, S., Batut, P., Chaisson, M., Gingeras, T.R., 2012. STAR: ultrafast universal RNA-seq aligner. Bioinformatics 29, 15–21.\nA9. Langmead, B, Salzberg, S L (2012) Fast gapped-read alignment with Bowtie 2. Nat Methods, 9: 357-359.\nA10. Kim D, Langmead B, Salzberg SL (2015) HISAT: a fast spliced aligner with low memory requirements. Nat Methods 12: 357–360\nA11. Bray NL, Pimentel H, Melsted P, Pachter L (2016) Near-optimal probabilistic RNA-seq quantification. Nat Biotechnol. doi: 10.1038/nbt.3519\nA12. Love MI, Huber W, Anders S (2014) Moderated estimation of fold change and dispersion for RNA-seq data with DESeq2. Genome Biol 15: 550\nA13. Zhou X, Lindsay H, Robinson MD (2014) Robustly detecting differential expression in RNA sequencing data using observation weights. Nucleic Acids Res 42: e91\nA14. Anders, S, Reyes, A, Huber, W (2012) Detecting differential usage of exons from RNA-seq data. Genome Res, 22: 2008-2017.\nA15. Soneson, C, Delorenzi, M (2013) A comparison of methods for differential expression analysis of RNA-seq data. BMC Bioinformatics, 14: 91-91.\nA16. Zhang Y, Liu T, Meyer CA, Eeckhoute J, Johnson DS, Bernstein BE, Nussbaum C, Myers RM, Brown M, Li W, et al (2008) Model-based analysis of ChIP-Seq (MACS). Genome Biol. doi: 10.1186/gb-2008-9-9-r137\nA17. Wilbanks EG, Facciotti MT (2010) Evaluation of algorithm performance in ChIP-seq peak detection. PLoS One. doi: 10.1371/journal.pone.0011471.\nA18. Landt et al. (2012) ChIP-seq guidelines and practices of the ENCODE and modENCODE consortia. Genome Res, 22: 1813-1831.\nA19. McLeay, Robert C, and Timothy L Bailey. 2010. “Motif Enrichment Analysis: A Unified Framework and an Evaluation on ChIP Data.” BMC Bioinformatics 11: 165.\nA20. Machanick, P, Bailey, T L (2011) MEME-ChIP: motif analysis of large DNA datasets. Bioinformatics, 27: 1696-1697.\nA21. Tompa, M, N Li, T L Bailey, G M Church, B De Moor, E Eskin, A V Favorov, et al. 2005. “Assessing Computational Tools for the Discovery of Transcription Factor Binding Sites.” Nature Biotechnology 23 (1): 137–44.\nA22. DePristo MA, Banks E, Poplin R, Garimella KV, Maguire JR, Hartl C, Philippakis AA, del Angel G, Rivas MA, Hanna M, et al (2011) A framework for variation discovery and genotyping using next-generation DNA sequencing data. Nat Genet 43: 491–498.\nA23. Shihab HA, Rogers MF, Gough J, Mort M, Cooper DN, Day INM, Gaunt TR, Campbell C (2015) An integrative approach to predicting the functional effects of non-coding and coding sequence variation. Bioinformatics 31: 1536–1543.\nA24. Raymond JW, Blankley CJ, Willett P (2003) Comparison of chemical clustering methods using graph- and fingerprint-based similarity measures. J Mol Graph Model 21: 421–433.\nA25. Subramanian A, Tamayo P, Mootha VK, Mukherjee S, Ebert BL, Gillette MA, Paulovich A, Pomeroy SL, Golub TR, Lander ES, et al (2005) Gene set enrichment analysis: a knowledge-based approach for interpreting genome-wide expression profiles. Proc Natl Acad Sci U S A 102: 15545–15550.\nA26. Ashburner M, Ball CA, Blake JA, Botstein D, Butler H, Cherry JM, Davis AP, Dolinski K, Dwight SS, Eppig JT, et al (2000) Gene ontology: tool for the unification of biology. The Gene Ontology Consortium. Nat Genet 25: 25–29.\nA27. Zyla J, Marczyk M, Domaszewska T, Kaufmann SHE, Polanska J, Weiner J (2019) Gene set enrichment for reproducible science: comparison of CERNO and eight other algorithms. Bioinformatics 35: 5146–5154\nA28. Alkan, C, Sajjadian, S, Eichler, E E (2011) Limitations of next-generation genome sequence assembly. Nat Methods, 8: 61-65.\nA29. Eddy SR (1998) Profile hidden Markov models. Bioinformatics 14: 755–763.\nA30. Grabherr, M G, Haas, B J, Yassour, M, Levin, J Z, Thompson, D A, Amit, I, Adiconis, X, Fan, L, Raychowdhury, R, Zeng, Q, Chen, Z, Mauceli, E, Hacohen, N, Gnirke, A, Rhind, N, di Palma, F, Birren, B W, Nusbaum, C, Lindblad-Toh, K, Friedman, N, Regev, A (2011) Full-length transcriptome assembly from RNA-Seq data without a reference genome. Nat Biotechnol, 29: 644-652.\nA31. Zeitouni, B, Boeva, V, Janoueix-Lerosey, I, Loeillet, S, Legoix-ne, P, Nicolas, A, Delattre, O, Barillot, E (2010) SVDetect: a tool to identify genomic structural variations from paired-end and mate-pair sequencing data. Bioinformatics, 26: 1895-1896.\nA32. Ronquist F, Teslenko M, van der Mark P, Ayres DL, Darling A, Höhna S, Larget B, Liu L, Suchard MA, Huelsenbeck JP (2012) MrBayes 3.2: efficient Bayesian phylogenetic inference and model choice across a large model space. Syst Biol 61: 539–542.\nTutorials T1. GitHub Introduction\nT2. Introduction to Computer Clusters and Linux\nT3. Introduction to R\nT4. Programming in R\nT5. NGS Analysis Basics\nT6. NGS Workflows\nT7. RNA-Seq Workflow\nT8. ChIP-Seq Workflow\nT9. VAR-Seq Workflow\nT10. Unsupervised Learning\nT11. Data Visualization\nBooks Note: there is no need to purchase any books for this course as most reading material will be based on journal articles!\nGeneral Jonathan Pevsner (2009) Bioinformatics and Functional Genomics. Wiley-Blackwell; 2nd Edition, 992 pages.\nAlgorithms Jones N and Pevzner P (2004) An Introduction to Bioinformatics Algorithms. MIT Press, Massachusetts, 435 pages.\nSequence Analysis Durbin, R, Eddy, S, Krogh, A, Mitchison, G. (1998) Biological Sequence Analysis: Probabilistic Models of Proteins and Nucleic Acids. Cambridge University Press, UK, 356 pages.\nParida L (2008) Pattern Discovery in Bioinformatics: Theory \u0026 Algorithms. CRC Press, London, 526 pages.\nProfiling Bioinformatics Gentleman, R, Carey, V, Dudoit, S, Irizarry, R, Huber, W (2005) Bioinformatics and Computational Biology Solutions Using R and Bioconductor. Springer, New York, 473 pages.\nPhylogenetics Felsenstein, J (2004) Inferring Phylogenies. Sinauer, Massachusetts, 664 pages.\nParadis (2006) Analysis of Phylogenetics and Evolution with R. Springer, New York, 211 pages.\n","categories":"","description":"","excerpt":"Course title Data Analysis in Genome Biology GEN242 - Spring 2021 …","ref":"/about/syllabus/","tags":"","title":"Syllabus - GEN242"},{"body":"  HPCC Cluster Overview The HPCC Cluster (formerly called biocluster) is a shared research computing system available at UCR. The HPCC website is available here.\nWhat Is a Computer Cluster?   A computer cluster is an assembly of CPU units, so called computer nodes that work together to perform many computations in parallel. To achieve this, an internal network (e.g. Infiniband interconnect) connects the nodes to a larger unit, while a head node controls the load and traffic across the entire system.\n  Usually, users log into the head node to submit their computer requests via srun to a queuing system provided by resource management and scheduling software, such as SGE, Slurm or TORQUE/MAUI. The queuing system distributes the processes to the computer nodes in a controlled fashion.\n  Because the head node controls the entire system, users should never run computing jobs on the head node directly!\n  For code testing purposes, one can log into one of the nodes with srun --pty bash -l and run jobs interactively. Alternatively, one can log into the test node owl via ssh.\n  Hardware Infrastructure Computer nodes  Over 4,500 CPU cores 48 AMD computer nodes, each with 64 CPU cores and 512GB RAM 40 Intel computer nodes, each with 32 CPU cores and 512GB RAM 6 high-memory nodes, each 32 CPU cores and 1024GB RAM 12 GPU nodes, each with 5,000 cuda cores  Interconnect  FDR IB @56Gbs  Storage  Parallel GPFS storage system with 2.1 PB usable space Backup of same architecture and similar amount  User traffic  Computing tasks need to be submitted via srun HPCC Cluster headnode only for login, not for computing tasks! Monitor cluster activity: squeue or jobMonitor (qstatMonitor)  Manuals  HPCC Cluster Manual Linux Manual  Linux Basics Log into HPCC Cluster  Login command on OS X or Linux  ssh -XY user@cluster.hpcc.ucr.edu  Type password\n  Windows: provide same information in a terminal application like Putty or MobaXterm. Here is an annimated usage introduction for MobaXterm.\n Host name: cluster.hpcc.ucr.edu User name: … Password: …    Important Linux Commands Finding help\nman \u003cprogram_name\u003e  List content of current directory\nls  Print current working directory\npwd  Search in files and directories\ngrep  Word count\nwc  Create directory\nmkdir  Delete files and directories\nrm  Move and rename files\nmv  Copy files from internet to pwd\nwget  Viewing files\nless  File Exchange GUI applications\n Windows: WinSCP Mac OS X: CyberDuck Win/OS X/Linux: FileZilla  SCP command-line tool\nscp file user@remotehost:/home/user/ # From local to remote scp user@remotehost:/home/user/file . # From remote to local  STD IN/OUT/ERR, Redirect \u0026 Wildcards Wildcard * to specify many files\nfile.*  Redirect ls output to file\nls \u003e file  Specify file as input to command\ncommand \u003c myfile  Append output of command to file\ncommand \u003e\u003e myfile  Pipe STDOUT of one command to another command\ncommand1 | command2  Turn off progress info\ncommand \u003e /dev/null  Pipe output of grep to wc\ngrep pattern file | wc  Print STDERR to file\ngrep pattern nonexistingfile 2 \u003e mystderr  Homework Assignment (HW2) See HW2 page here.\nPermissions and ownership List directories and files\nls -al  The previous command shows something like this for each file/dir: drwxrwxrwx. The meaning of this syntax is as follows:\n d: directory rwx: read, write and execute permissions, respectively  first triplet: user permissions (u) second triplet: group permissions (g) third triplet: world permissions (o)    Example for assigning write and execute permissions to user, group and world\nchmod ugo+rx my_file   + causes the permissions selected to be added - causes them to be removed = causes them to be the only permissions that the file has.  When performing the same operation on many files with subdirectories then one can use -R for recursive behavior.\nchmod -R ugo+rx my_dir  Since directories have to be executable the capital X option can be useful which applies only to directories but not to files. The following will assign drwxr-xr-x to directories and -rw-r--r-- to files and hidden files.\nchmod -R ugo-x,u+rwX,go+rX,go-w ./* ./.[!.]*  Syntax for changing user \u0026 group ownership\nchown \u003cuser\u003e:\u003cgroup\u003e \u003cfile or dir\u003e  Symbolic Links Symbolic links are short nicknames to files and directories that save typing of their full paths.\nln -s original_filename new_nickname  Software and module system  Over 750 software tools are currently installed on HPCC Cluster Most common research databases used in bioinformatics are available Support of most common programming languages used in research computing A module system is used to facilitate the management of software tools. This includes any number of versions of each software. New software install requests can be sent to support@hpcc.ucr.edu. To use software manged under the module system, users need to learn using some basic commands. The most common commands are listed below.  Print available modules\nmodule avail  Print available modules starting with R\nmodule avail R  Load default module R\nmodule load R  Load specific module R version\nmodule load R/3.2.2  List loaded modules\nmodule list  Unload module R\nmodule unload R  Unload specific module R\nmodule unload R/3.2.3-dev  Big data storage Each user account on HPCC Cluster comes only with 20GB of disk space. Much more disk space is available in a dedicated bigdata directory. How much space depends on the subscription of each user group. The path of bigdata and bigdata-shared is as follows:\n /bigdata/labname/username /bigdata/labname/shared  All lab members share the same bigdata pool. The course number gen242 is used as labname for user accounts adminstered under GEN242.\nThe disk usage of home and bigdata can be monitored on the HPCC Cluster Dashboard.\nQueuing system: Slurm HPCC Cluster uses Slurm as queuing and load balancing system. To control user traffic, any type of compute intensive jobs need to be submitted via the sbatch or srun (see below) to the computer nodes. Much more detailed information on this topic can be found on these sites:\n UCR HPCC Manual Slurm Documentation Torque/Slurm Comparison Switching from Torque to Slurm Slurm Quick Start Tutorial  Job submission with sbatch Print information about queues/partitions available on a cluster.\nsinfo  Compute jobs are submitted with sbatch via a submission script (here script_name.sh).\nsbatch script_name.sh  The following sample submission script (script_name.sh) executes an R script named my_script.R.\n#!/bin/bash -l #SBATCH --nodes=1 #SBATCH --ntasks=1 #SBATCH --cpus-per-task=1 #SBATCH --mem-per-cpu=1G #SBATCH --time=1-00:15:00 # 1 day and 15 minutes #SBATCH --mail-user=useremail@address.com #SBATCH --mail-type=ALL #SBATCH --job-name=\"some_test\" #SBATCH -p batch # Choose queue/parition from: intel, batch, highmem, gpu, short Rscript my_script.R  Interactive session: logs user into node\nsrun --pty bash -l  Interactive session with specific resource requests\nsrun --x11 --partition=short --mem=2gb --cpus-per-task 4 --ntasks 1 --time 1:00:00 --pty bash -l  STDOUT and STDERROR of jobs will be written to files named slurm-\u003cjobid\u003e.out or to custom a file specified under #SBATCH --output in the submission script.\nMonitoring jobs with squeue List all jobs in queue\nsqueue  List jobs of a specific user\nsqueue -u \u003cuser\u003e  Print more detailed information about a job\nscontrol show job \u003cJOBID\u003e  Custom command to summarize and visualize cluster activity\njobMonitor  Deleting and altering jobs Delete a single job\nscancel -i \u003cJOBID\u003e  Delete all jobs of a user\nscancel -u \u003cusername\u003e  Delete all jobs of a certain name\nscancel --name \u003cmyJobName\u003e  Altering jobs with scontrol update. The below example changes the walltime (\u003cNEW_TIME\u003e) of a specific job (\u003cJOBID\u003e).\nscontrol update jobid=\u003cJOBID\u003e TimeLimit=\u003cNEW_TIME\u003e  Resource limits Resourse limits for users can be viewed as follows.\nsacctmgr show account $GROUP format=Account,User,Partition,GrpCPUs,GrpMem,GrpNodes --ass | grep $USER  Similarly, one can view the limits of the group a user belongs to.\nsacctmgr show account $GROUP format=Account,User,Partition,GrpCPUs,GrpMem,GrpNodes,GrpTRES%30 --ass | head -3  Text/code editors The following list includes examples of several widely used code editors.\n Vi/Vim/Neovim: Non-graphical (terminal-based) editor. Vi is guaranteed to be available on any system. Vim and Nvim (Neovim) are the improved versions of vi. Emacs: Non-graphical or window-based editor. You still need to know keystroke commands to use it. Installed on all Linux distributions and on most other Unix systems. Pico: Simple terminal-based editor available on most versions of Unix. Uses keystroke commands, but they are listed in logical fashion at bottom of screen. Nano: A simple terminal-based editor which is default on modern Debian systems. Atom: Modern text editor developed by GitHub project.  Why does it matter? To work efficiently on remote systems like a computer cluster, it is essential to learn how to work in a pure command-line interface. GUI environments like RStudio and similar coding environments are not suitable for this. In addition, there is a lot of value of knowing how to work in an environment that is not restricted to a specific programming language. Therefore, this class embraces RStudio where it is useful, but for working on remote systems like HPCC Cluster, it uses Nvim and Tmux. Both are useful for many programming languages. Combinded with the nvim-r plugin they also provide a powerful command-line working environment for R. The following provides a brief introduction to this environment.\nVim overview The following opens a file (here myfile) with nvim (or vim)\nnvim myfile.txt # for neovim (or 'vim myfile.txt' for vim)  Once you are in Nvim, there are three main modes: normal, insert and command mode. The most important commands for switching between the three modes are:\n i: The i key brings you from the normal mode to the insert mode. The latter is used for typing. Esc: The Esc key brings you from the insert mode back to the normal mode. :: The : key starts the command mode at the bottom of the screen.  Use the arrow keys to move your cursor in the text. Using Fn Up/Down key allows to page through the text quicker. In the following command overview, all commands starting with : need to be typed in the command mode. All other commands are typed in the normal mode after pushing the Esc key.\nImportant modifier keys to control vim/nvim\n :w: save changes to file. If you are in editing mode you have to hit Esc first. :q: quit file that has not been changed :wq: save and quit file :!q: quit file without saving any changes  Useful resources for learning vim/nvim  Interactive Vim Tutorial Official Vim Documentation HPCC Linux Manual  Nvim-R-Tmux essentials Terminal-based Working Environment for R: Nvim-R-Tmux.\n Nvim-R-Tmux IDE for R Basics Tmux is a terminal multiplexer that allows to split terminal windows and to detach/reattach to existing terminal sessions. Combinded with the nvim-r plugin it provides a powerful command-line working environment for R where users can send code from a script to the R console or command-line. Both tmux and the nvim-r plugin need to be installed on a system. On HPCC Cluster both are configured in each user account. If this is not the case then follow the quick configuration instructions given in the following subsection.\nQuick configuration in user accounts of UCR’s HPCC Skip these steps if Nvim-R-Tmux is already configured in your account. Or follow the detailed instructions to install Nvim-R-Tmux from scratch on your own system.\n Log in to your user account on HPCC and execute install_nvimRtmux. Alternatively, follow these step-by-step install commands. To enable the nvim-R-tmux environment, log out and in again. Follow usage instructions of next section.  Basic usage of Nvim-R-Tmux The official and much more detailed user manual for Nvim-R is available here. The following gives a short introduction into the basic usage of Nvim-R-Tmux:\n1. Start tmux session (optional)\nNote, running Nvim from within a tmux session is optional. Skip this step if tmux functionality is not required (e.g. reattaching to sessions on remote systems).\ntmux # starts a new tmux session tmux a # attaches to an existing session  2. Open nvim-connected R session\nOpen a *.R or *.Rmd file with nvim and intialize a connected R session with \\rf. This command can be remapped to other key combinations, e.g. uncommenting lines 10-12 in .config/nvim/init.vim will remap it to the F2 key. Note, the resulting split window among Nvim and R behaves like a split viewport in nvim or vim meaning the usage of Ctrl-w w followed by i and Esc is important for navigation.\nnvim myscript.R # or *.Rmd file  3. Send R code from nvim to the R pane\nSingle lines of code can be sent from nvim to the R console by pressing the space bar. To send several lines at once, one can select them in nvim’s visual mode and then hit the space bar. Please note, the default command for sending code lines in the nvim-r-plugin is \\l. This key binding has been remapped in the provided .config/nvim/init.vim file to the space bar. Most other key bindings (shortcuts) still start with the \\ as LocalLeader, e.g. \\rh opens the help for a function/object where the curser is located in nvim. More details on this are given below.\nImportant keybindings for nvim The main advantages of Neovim compared to Vim are its better performance and its built-in terminal emulator facilitating the communication among Neovim and interactive programming environments such as R. Since the Vim and Neovim environments are managed independently, one can run them in parallel on the same system without interfering with each other. The usage of Neovim is almost identical to Vim.\nNvim commands\n \\rf: opens vim-connected R session. If you do this the first time in your user account, you might be asked to create an R directory under ~/. If so approve this action by pressing y. spacebar: sends code from vim to R; here remapped in init.vim from default \\l :split or :vsplit: splits viewport (similar to pane split in tmux) gz: maximizes size of viewport in normal mode (similar to Tmux’s Ctrl-a z zoom utility) Ctrl-w w: jumps cursor to R viewport and back; toggle between insert (i) and command (Esc) mode is required for navigation and controlling the environment. Ctrl-w r: swaps viewports Ctrl-w =: resizes splits to equal size :resize \u003c+5 or -5\u003e: resizes height by specified value :vertical resize \u003c+5 or -5\u003e: resizes width by specified value Ctrl-w H or Ctrl-w K: toggles between horizontal/vertical splits Ctrl-spacebar: omni completion for R objects/functions when nvim is in insert mode. Note, this has been remapped in init.vim from difficult to type default Ctrl-x Ctrl-o. :h nvim-R: opens nvim-R’s user manual; navigation works the same as for any Vim/Nvim help document :Rhelp fct_name: opens help for a function from nvim’s command mode with text completion support Ctrl-s and Ctrl-x: freezes/unfreezes vim (some systems)  Important keybindings for tmux Pane-level commands\n Ctrl-a %: splits pane vertically Ctrl-a \": splits pane horizontally Ctrl-a o: jumps cursor to next pane Ctrl-a Ctrl-o: swaps panes Ctrl-a \u003cspace bar\u003e: rotates pane arrangement Ctrl-a Alt \u003cleft or right\u003e: resizes to left or right Ctrl-a Esc \u003cup or down\u003e: resizes to left or right  Window-level comands\n Ctrl-a n: switches to next tmux window Ctrl-a Ctrl-a: switches to previous tmux window Ctrl-a c: creates a new tmux window Ctrl-a 1: switches to specific tmux window selected by number  Session-level comands\n Ctrl-a d: detaches from current session Ctrl-a s: switch between available tmux sesssions $ tmux new -s \u003cname\u003e: starts new session with a specific name $ tmux ls: lists available tmux session(s) $ tmux attach -t \u003cid\u003e: attaches to specific tmux session $ tmux attach: reattaches to session $ tmux kill-session -t \u003cid\u003e: kills a specific tmux session Ctrl-a : kill-session: kills a session from tmux command mode that can be initiated with Ctrl-a :  Nvim IDEs for other languages For other languages, such as Bash, Python and Ruby, one can use the vimcmdline plugin for nvim (or vim). To install it, one needs to copy from the vimcmdline resository the directories ftplugin, plugin and syntax and their files to ~/.config/nvim/. For user accounts of UCR’s HPCC, the above install script install_nvimRtmux includes the install of vimcmdline (since 09-Jun-18).\nThe usage of vimcmdline is very similar to nvim-R. To start a connected terminal session, one opens with nvim a code file with the extension of a given language (e.g. *.sh for Bash or *.py for Python), while the corresponding interactive interpreter session is initiated by pressing the key sequence \\s (corresponds to \\rf under nvim-R). Subsequently, code lines can be sent with the space bar. More details are available here.\n","categories":"","description":"","excerpt":"  HPCC Cluster Overview The HPCC Cluster (formerly called biocluster) …","ref":"/manuals/linux/linux/","tags":"","title":"Introduction to HPCC Cluster and Linux"},{"body":"  HPCC Cluster Overview The HPCC Cluster (formerly called biocluster) is a shared research computing system available at UCR. The HPCC website is available here.\nWhat Is a Computer Cluster?   A computer cluster is an assembly of CPU units, so called computer nodes that work together to perform many computations in parallel. To achieve this, an internal network (e.g. Infiniband interconnect) connects the nodes to a larger unit, while a head node controls the load and traffic across the entire system.\n  Usually, users log into the head node to submit their computer requests via srun to a queuing system provided by resource management and scheduling software, such as SGE, Slurm or TORQUE/MAUI. The queuing system distributes the processes to the computer nodes in a controlled fashion.\n  Because the head node controls the entire system, users should never run computing jobs on the head node directly!\n  For code testing purposes, one can log into one of the nodes with srun --pty bash -l and run jobs interactively. Alternatively, one can log into the test node owl via ssh.\n  Hardware Infrastructure Computer nodes  Over 8,000 CPU cores 130 Intel, AMD and GPU nodes 32-128 CPU cores per node 256-1,024 GB of RAM per node 12 GPU nodes, each with total of over 80,000 cuda cores  Interconnect  FDR IB @56Gbs  Storage  Parallel GPFS storage system with 3.0 PB usable space File system scales to over 50 PB Backup of same architecture and similar amount  User traffic  Computing tasks need to be submitted via sbatch or srun HPCC Cluster headnode only for login, not for computing tasks! Monitor cluster activity: squeue or jobMonitor (qstatMonitor)  Manuals  HPCC Cluster Manual Linux Manual  Linux Basics Log into HPCC Cluster  Login command on OS X or Linux  ssh -XY user@cluster.hpcc.ucr.edu  Type password\n  Windows: provide same information in a terminal application like Putty or MobaXterm. Here is an annimated usage introduction for MobaXterm.\n Host name: cluster.hpcc.ucr.edu User name: … Password: …    Important Linux Commands Finding help\nman \u003cprogram_name\u003e  List content of current directory\nls  Print current working directory\npwd  Search in files and directories\ngrep  Word count\nwc  Create directory\nmkdir  Delete files and directories\nrm  Move and rename files\nmv  Copy files from internet to pwd\nwget  Viewing files\nless  File Exchange GUI applications\n Windows: WinSCP Mac OS X: CyberDuck Win/OS X/Linux: FileZilla  SCP: via command-line (Manual)\nAdvantages of this method include: batch up/downloads and ease of automation.\nscp file user@remotehost:/home/user/ # From local to remote scp user@remotehost:/home/user/file . # From remote to local  RSYNC: via command-line (Manual)\nAdvantages of this method include: same as SCP plus differential update options and viewing of directory content.\nPrint (view) content of remote directory\nrsync user@remotehost:~/somedirectory/*  Download directory or file(s)\nrsync -avzhe ssh user@remotehost:~/somedirectory . # -a: recursive archive mode (thus -r not required), also preserves permissions, time stamps, etc # -v: verbose # -z: compress data during transfer # -h: print messages in human-readable format # -e: specifies transfer protocol; using ssh here provides encryption during transfer # --delete: files that were deleted on source will be deleted also in backup-destination # -n: for testing use this dry-run option, but drop '-e ssh' in this case  Upload directory or file(s)\nrsync -avzhe ssh somedirectory user@hostname:~/  STD IN/OUT/ERR, Redirect \u0026 Wildcards Wildcard * to specify many files\nfile.*  Redirect ls output to file\nls \u003e file  Specify file as input to command\ncommand \u003c myfile  Append output of command to file\ncommand \u003e\u003e myfile  Pipe STDOUT of one command to another command\ncommand1 | command2  Turn off progress info\ncommand \u003e /dev/null  Pipe output of grep to wc\ngrep pattern file | wc  Print STDERR to file\ngrep pattern nonexistingfile 2 \u003e mystderr  Homework Assignment (HW2) See HW2 page here.\nPermissions and ownership List directories and files\nls -al  The previous command shows something like this for each file/dir: drwxrwxrwx. The meaning of this syntax is as follows:\n d: directory rwx: read, write and execute permissions, respectively  first triplet: user permissions (u) second triplet: group permissions (g) third triplet: world permissions (o)    Example for assigning write and execute permissions to user, group and world\nchmod ugo+rx my_file   + causes the permissions selected to be added - causes them to be removed = causes them to be the only permissions that the file has.  When performing the same operation on many files with subdirectories then one can use -R for recursive behavior.\nchmod -R ugo+rx my_dir  Since directories have to be executable the capital X option can be useful which applies only to directories but not to files. The following will assign drwxr-xr-x to directories and -rw-r--r-- to files and hidden files.\nchmod -R ugo-x,u+rwX,go+rX,go-w ./* ./.[!.]*  Syntax for changing user \u0026 group ownership\nchown \u003cuser\u003e:\u003cgroup\u003e \u003cfile or dir\u003e  Symbolic Links Symbolic links are short nicknames to files and directories that save typing of their full paths.\nln -s original_filename new_nickname  Software and module system  Over 2,000 software tools are currently installed on HPCC Cluster Custom installs in user accounts via various mechanisms, e.g. environment management systems such as conda Most common research databases used in bioinformatics are available Support of most common programming languages used in research computing A module system is used to facilitate the management of software tools. This includes any number of versions of each software. New software install requests can be sent to support@hpcc.ucr.edu. To use software manged under the module system, users need to learn using some basic commands. The most common commands are listed below.  Print available modules\nmodule avail  Print available modules starting with R\nmodule avail R  Load default module R\nmodule load R  Load specific module R version\nmodule load R/3.2.2  List loaded modules\nmodule list  Unload module R\nmodule unload R  Unload specific module R\nmodule unload R/3.2.3-dev  Big data storage Each user account on HPCC Cluster comes only with 20GB of disk space. Much more disk space is available in a dedicated bigdata directory. How much space depends on the subscription of each user group. The path of bigdata and bigdata-shared is as follows:\n /bigdata/labname/username /bigdata/labname/shared  All lab members share the same bigdata pool. The course number gen242 is used as labname for user accounts adminstered under GEN242 (here /bigdata/gen242/shared).\nThe disk usage of home and bigdata can be monitored on the HPCC Cluster Dashboard.\nQueuing system: Slurm HPCC Cluster uses Slurm as queuing and load balancing system. To control user traffic, any type of compute intensive jobs need to be submitted via the sbatch or srun (see below) to the computer nodes. Much more detailed information on this topic can be found on these sites:\n UCR HPCC Manual Slurm Documentation Torque/Slurm Comparison Switching from Torque to Slurm Slurm Quick Start Tutorial  Job submission with sbatch Print information about queues/partitions available on a cluster.\nsinfo  Compute jobs are submitted with sbatch via a submission script (here script_name.sh).\nsbatch script_name.sh  The following sample submission script (script_name.sh) executes an R script named my_script.R.\n#!/bin/bash -l #SBATCH --nodes=1 #SBATCH --ntasks=1 #SBATCH --cpus-per-task=1 #SBATCH --mem-per-cpu=1G #SBATCH --time=1-00:15:00 # 1 day and 15 minutes #SBATCH --mail-user=useremail@address.com #SBATCH --mail-type=ALL #SBATCH --job-name=\"some_test\" #SBATCH -p batch # Choose queue/parition from: intel, batch, highmem, gpu, short Rscript my_script.R  Interactive session: logs user into node\nsrun --pty bash -l  Interactive session with specific resource requests\nsrun --x11 --partition=short --mem=2gb --cpus-per-task 4 --ntasks 1 --time 1:00:00 --pty bash -l  STDOUT and STDERROR of jobs will be written to files named slurm-\u003cjobid\u003e.out or to custom a file specified under #SBATCH --output in the submission script.\nMonitoring jobs with squeue List all jobs in queue\nsqueue  List jobs of a specific user\nsqueue -u \u003cuser\u003e  Print more detailed information about a job\nscontrol show job \u003cJOBID\u003e  Custom command to summarize and visualize cluster activity\njobMonitor  Deleting and altering jobs Delete a single job\nscancel -i \u003cJOBID\u003e  Delete all jobs of a user\nscancel -u \u003cusername\u003e  Delete all jobs of a certain name\nscancel --name \u003cmyJobName\u003e  Altering jobs with scontrol update. The below example changes the walltime (\u003cNEW_TIME\u003e) of a specific job (\u003cJOBID\u003e).\nscontrol update jobid=\u003cJOBID\u003e TimeLimit=\u003cNEW_TIME\u003e  Resource limits Resourse limits for users can be viewed as follows.\nsacctmgr show account $GROUP format=Account,User,Partition,GrpCPUs,GrpMem,GrpNodes --ass | grep $USER  Similarly, one can view the limits of the group a user belongs to.\nsacctmgr show account $GROUP format=Account,User,Partition,GrpCPUs,GrpMem,GrpNodes,GrpTRES%30 --ass | head -3  Text/code editors The following list includes examples of several widely used code editors.\n Vi/Vim/Neovim: Non-graphical (terminal-based) editor. Vi is guaranteed to be available on any system. Vim and Nvim (Neovim) are the improved versions of vi. Emacs: Non-graphical or window-based editor. You still need to know keystroke commands to use it. Installed on all Linux distributions and on most other Unix systems. Pico: Simple terminal-based editor available on most versions of Unix. Uses keystroke commands, but they are listed in logical fashion at bottom of screen. Nano: A simple terminal-based editor which is default on modern Debian systems. Atom: Modern text editor developed by GitHub project.  Why does it matter? To work efficiently on remote systems like a computer cluster, it is essential to learn how to work in a pure command-line interface. GUI environments like RStudio and similar coding environments are not suitable for this. In addition, there is a lot of value of knowing how to work in an environment that is not restricted to a specific programming language. Therefore, this class embraces RStudio where it is useful, but for working on remote systems like HPCC Cluster, it uses Nvim and Tmux. Both are useful for many programming languages. Combinded with the nvim-r plugin they also provide a powerful command-line working environment for R. The following provides a brief introduction to this environment.\nVim overview The following opens a file (here myfile) with nvim (or vim)\nnvim myfile.txt # for neovim (or 'vim myfile.txt' for vim)  Once you are in Nvim, there are three main modes: normal, insert and command mode. The most important commands for switching between the three modes are:\n i: The i key brings you from the normal mode to the insert mode. The latter is used for typing. Esc: The Esc key brings you from the insert mode back to the normal mode. :: The : key starts the command mode at the bottom of the screen.  Use the arrow keys to move your cursor in the text. Using Fn Up/Down key allows to page through the text quicker. In the following command overview, all commands starting with : need to be typed in the command mode. All other commands are typed in the normal mode after pushing the Esc key.\nImportant modifier keys to control vim/nvim\n :w: save changes to file. If you are in editing mode you have to hit Esc first. :q: quit file that has not been changed :wq: save and quit file :!q: quit file without saving any changes  Useful resources for learning vim/nvim  Interactive Vim Tutorial Official Vim Documentation HPCC Linux Manual  Nvim-R-Tmux essentials Terminal-based Working Environment for R: Nvim-R-Tmux.\n Nvim-R-Tmux IDE for R Basics Tmux is a terminal multiplexer that allows to split terminal windows and to detach/reattach to existing terminal sessions. Combinded with the nvim-r plugin it provides a powerful command-line working environment for R where users can send code from a script to the R console or command-line. Both tmux and the nvim-r plugin need to be installed on a system. On HPCC Cluster both are configured in each user account. If this is not the case then follow the quick configuration instructions given in the following subsection.\nQuick configuration in user accounts of UCR’s HPCC Skip these steps if Nvim-R-Tmux is already configured in your account. Or follow the detailed instructions to install Nvim-R-Tmux from scratch on your own system.\n Log in to your user account on HPCC and execute install_nvimRtmux. Alternatively, follow these step-by-step install commands. To enable the nvim-R-tmux environment, log out and in again. Follow usage instructions of next section.  Basic usage of Nvim-R-Tmux The official and much more detailed user manual for Nvim-R is available here. The following gives a short introduction into the basic usage of Nvim-R-Tmux:\n1. Start tmux session (optional)\nNote, running Nvim from within a tmux session is optional. Skip this step if tmux functionality is not required (e.g. reattaching to sessions on remote systems).\ntmux # starts a new tmux session tmux a # attaches to an existing session  2. Open nvim-connected R session\nOpen a *.R or *.Rmd file with nvim and intialize a connected R session with \\rf. This command can be remapped to other key combinations, e.g. uncommenting lines 10-12 in .config/nvim/init.vim will remap it to the F2 key. Note, the resulting split window among Nvim and R behaves like a split viewport in nvim or vim meaning the usage of Ctrl-w w followed by i and Esc is important for navigation.\nnvim myscript.R # or *.Rmd file  3. Send R code from nvim to the R pane\nSingle lines of code can be sent from nvim to the R console by pressing the space bar. To send several lines at once, one can select them in nvim’s visual mode and then hit the space bar. Please note, the default command for sending code lines in the nvim-r-plugin is \\l. This key binding has been remapped in the provided .config/nvim/init.vim file to the space bar. Most other key bindings (shortcuts) still start with the \\ as LocalLeader, e.g. \\rh opens the help for a function/object where the curser is located in nvim. More details on this are given below.\nImportant keybindings for nvim The main advantages of Neovim compared to Vim are its better performance and its built-in terminal emulator facilitating the communication among Neovim and interactive programming environments such as R. Since the Vim and Neovim environments are managed independently, one can run them in parallel on the same system without interfering with each other. The usage of Neovim is almost identical to Vim.\nNvim commands\n \\rf: opens vim-connected R session. If you do this the first time in your user account, you might be asked to create an R directory under ~/. If so approve this action by pressing y. spacebar: sends code from vim to R; here remapped in init.vim from default \\l :split or :vsplit: splits viewport (similar to pane split in tmux) gz: maximizes size of viewport in normal mode (similar to Tmux’s Ctrl-a z zoom utility) Ctrl-w w: jumps cursor to R viewport and back; toggle between insert (i) and command (Esc) mode is required for navigation and controlling the environment. Ctrl-w r: swaps viewports Ctrl-w =: resizes splits to equal size :resize \u003c+5 or -5\u003e: resizes height by specified value :vertical resize \u003c+5 or -5\u003e: resizes width by specified value Ctrl-w H or Ctrl-w K: toggles between horizontal/vertical splits Ctrl-spacebar: omni completion for R objects/functions when nvim is in insert mode. Note, this has been remapped in init.vim from difficult to type default Ctrl-x Ctrl-o. :h nvim-R: opens nvim-R’s user manual; navigation works the same as for any Vim/Nvim help document :Rhelp fct_name: opens help for a function from nvim’s command mode with text completion support Ctrl-s and Ctrl-x: freezes/unfreezes vim (some systems)  Important keybindings for tmux Pane-level commands\n Ctrl-a %: splits pane vertically Ctrl-a \": splits pane horizontally Ctrl-a o: jumps cursor to next pane Ctrl-a Ctrl-o: swaps panes Ctrl-a \u003cspace bar\u003e: rotates pane arrangement Ctrl-a Alt \u003cleft or right\u003e: resizes to left or right Ctrl-a Esc \u003cup or down\u003e: resizes to left or right  Window-level comands\n Ctrl-a n: switches to next tmux window Ctrl-a Ctrl-a: switches to previous tmux window Ctrl-a c: creates a new tmux window Ctrl-a 1: switches to specific tmux window selected by number  Session-level comands\n Ctrl-a d: detaches from current session Ctrl-a s: switch between available tmux sesssions $ tmux new -s \u003cname\u003e: starts new session with a specific name $ tmux ls: lists available tmux session(s) $ tmux attach -t \u003cid\u003e: attaches to specific tmux session $ tmux attach: reattaches to session $ tmux kill-session -t \u003cid\u003e: kills a specific tmux session Ctrl-a : kill-session: kills a session from tmux command mode that can be initiated with Ctrl-a :  Nvim IDEs for other languages For other languages, such as Bash, Python and Ruby, one can use the vimcmdline plugin for nvim (or vim). To install it, one needs to copy from the vimcmdline resository the directories ftplugin, plugin and syntax and their files to ~/.config/nvim/. For user accounts of UCR’s HPCC, the above install script install_nvimRtmux includes the install of vimcmdline (since 09-Jun-18).\nThe usage of vimcmdline is very similar to nvim-R. To start a connected terminal session, one opens with nvim a code file with the extension of a given language (e.g. *.sh for Bash or *.py for Python), while the corresponding interactive interpreter session is initiated by pressing the key sequence \\s (corresponds to \\rf under nvim-R). Subsequently, code lines can be sent with the space bar. More details are available here.\n","categories":"","description":"","excerpt":"  HPCC Cluster Overview The HPCC Cluster (formerly called biocluster) …","ref":"/tutorials/linux/linux/","tags":"","title":"Introduction to HPCC Cluster and Linux"},{"body":"Detailed course schedule Note: this schedule is preliminary and subject to changes.\n ","categories":"","description":"","excerpt":"Detailed course schedule Note: this schedule is preliminary and …","ref":"/about/schedule/","tags":"","title":"Course Schedule"},{"body":"       document.addEventListener(\"DOMContentLoaded\", function() { document.querySelector(\"h1\").className = \"title\"; });  document.addEventListener(\"DOMContentLoaded\", function() { var links = document.links; for (var i = 0, linksLength = links.length; i Overview What is R? R is a powerful statistical environment and programming language for the analysis and visualization of data. The associated Bioconductor and CRAN package repositories provide many additional R packages for statistical data analysis for a wide array of research areas. The R software is free and runs on all common operating systems.\nWhy Using R?  Complete statistical environment and programming language Efficient functions and data structures for data analysis Powerful graphics Access to fast growing number of analysis packages Most widely used language in bioinformatics Is standard for data mining and biostatistical analysis Technical advantages: free, open-source, available for all OSs  Books and Documentation  simpleR - Using R for Introductory Statistics (John Verzani, 2004) - URL Bioinformatics and Computational Biology Solutions Using R and Bioconductor (Gentleman et al., 2005) - URL More on this see “Finding Help” section in UCR Manual - URL  R Working Environments    R Projects and Interfaces  Some R working environments with support for syntax highlighting and utilities to send code to the R console:\n RStudio: excellent choice for beginners (Cheat Sheet) Basic R code editors provided by Rguis gedit, Rgedit, RKWard, Eclipse, Tinn-R, Notepad++, NppToR Vim-R-Tmux: R working environment based on vim and tmux Emacs (ESS add-on package)  Example: RStudio New integrated development environment (IDE) for R. Highly functional for both beginners and advanced.\n   RStudio IDE  Some userful shortcuts: Ctrl+Enter (send code), Ctrl+Shift+C (comment/uncomment), Ctrl+1/2 (switch window focus)\nExample: Nvim-R-Tmux Terminal-based Working Environment for R: Nvim-R-Tmux.\n   Nvim-R-Tmux IDE for R  R Package Repositories  CRAN (\u003e11,000 packages) general data analysis - URL Bioconductor (\u003e1,100 packages) bioscience data analysis - URL Omegahat (\u003e90 packages) programming interfaces - URL  Installation of R Packages   Install R for your operating system from CRAN.\n  Install RStudio from RStudio.\n  Install CRAN Packages from R console like this:\ninstall.packages(c(\"pkg1\", \"pkg2\")) install.packages(\"pkg.zip\", repos=NULL)    Install Bioconductor packages as follows:\nif (!requireNamespace(\"BiocManager\", quietly = TRUE)) install.packages(\"BiocManager\") # Installs BiocManager if not available yet BiocManager::version() # Reports Bioconductor version BiocManager::install(c(\"pkg1\", \"pkg2\")) # Installs packages specified under \"pkg1\"    For more details consult the Bioc Install page and BiocInstaller package.\n  Getting Around Startup and Closing Behavior   Starting R: The R GUI versions, including RStudio, under Windows and Mac OS X can be opened by double-clicking their icons. Alternatively, one can start it by typing R in a terminal (default under Linux).\n  Startup/Closing Behavior: The R environment is controlled by hidden files in the startup directory: .RData, .Rhistory and .Rprofile (optional).\n  Closing R:\n  q()  Save workspace image? [y/n/c]:   Note: When responding with y, then the entire R workspace will be written to the .RData file which can become very large. Often it is sufficient to just save an analysis protocol in an R source file. This way one can quickly regenerate all data sets and objects.  Navigating directories Create an object with the assignment operator \u003c- or =\nobject \u003c- ...  Instead of the assignment operator one can use the assign function\nassign(\"x\", function(arguments))  List objects in current R session\nls()  Return content of current working directory\ndir()  Return path of current working directory\ngetwd()  Change current working directory\nsetwd(\"/home/user\")  Basic Syntax General R command syntax\nobject \u003c- function_name(arguments) object \u003c- object[arguments]  Finding help\n?function_name  Load a library/package\nlibrary(\"my_library\")  List functions defined by a library\nlibrary(help=\"my_library\")  Load library manual (PDF or HTML file)\nvignette(\"my_library\")  Execute an R script from within R\nsource(\"my_script.R\")  Execute an R script from command-line (the first of the three options is preferred)\n$ Rscript my_script.R $ R CMD BATCH my_script.R $ R --slave \u003c my_script.R  Data Types Numeric data Example: 1, 2, 3, ...\nx \u003c- c(1, 2, 3) x  ## [1] 1 2 3  is.numeric(x)  ## [1] TRUE  as.character(x)  ## [1] \"1\" \"2\" \"3\"  Character data Example: \"a\", \"b\", \"c\", ...\nx \u003c- c(\"1\", \"2\", \"3\") x  ## [1] \"1\" \"2\" \"3\"  is.character(x)  ## [1] TRUE  as.numeric(x)  ## [1] 1 2 3  Complex data Example: mix of both\nc(1, \"b\", 3)  ## [1] \"1\" \"b\" \"3\"  Logical data Example: TRUE of FALSE\nx \u003c- 1:10 \u003c 5 x  ## [1] TRUE TRUE TRUE TRUE FALSE FALSE FALSE FALSE FALSE FALSE  !x  ## [1] FALSE FALSE FALSE FALSE TRUE TRUE TRUE TRUE TRUE TRUE  which(x) # Returns index for the 'TRUE' values in logical vector  ## [1] 1 2 3 4  Data Objects Object types Vectors (1D) Definition: numeric or character\nmyVec \u003c- 1:10; names(myVec) \u003c- letters[1:10] myVec \u003c- setNames(1:10, letters[1:10]) # Same as above in single step myVec[1:5]  ## a b c d e ## 1 2 3 4 5  myVec[c(2,4,6,8)]  ## b d f h ## 2 4 6 8  myVec[c(\"b\", \"d\", \"f\")]  ## b d f ## 2 4 6  Factors (1D) Definition: vectors with grouping information\nfactor(c(\"dog\", \"cat\", \"mouse\", \"dog\", \"dog\", \"cat\"))  ## [1] dog cat mouse dog dog cat ## Levels: cat dog mouse  Matrices (2D) Definition: two dimensional structures with data of same type\nmyMA \u003c- matrix(1:30, 3, 10, byrow = TRUE) class(myMA)  ## [1] \"matrix\" \"array\"  myMA[1:2,]  ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] ## [1,] 1 2 3 4 5 6 7 8 9 10 ## [2,] 11 12 13 14 15 16 17 18 19 20  myMA[1, , drop=FALSE]  ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] ## [1,] 1 2 3 4 5 6 7 8 9 10  Data Frames (2D) Definition: two dimensional objects with data of variable types\nmyDF \u003c- data.frame(Col1=1:10, Col2=10:1) myDF[1:2, ]  ## Col1 Col2 ## 1 1 10 ## 2 2 9  Arrays Definition: data structure with one, two or more dimensions\nLists Definition: containers for any object type\nmyL \u003c- list(name=\"Fred\", wife=\"Mary\", no.children=3, child.ages=c(4,7,9)) myL  ## $name ## [1] \"Fred\" ## ## $wife ## [1] \"Mary\" ## ## $no.children ## [1] 3 ## ## $child.ages ## [1] 4 7 9  myL[[4]][1:2]  ## [1] 4 7  Functions Definition: piece of code\nmyfct \u003c- function(arg1, arg2, ...) { function_body }  Subsetting of data objects (1.) Subsetting by positive or negative index/position numbers\nmyVec \u003c- 1:26; names(myVec) \u003c- LETTERS myVec[1:4]  ## A B C D ## 1 2 3 4  (2.) Subsetting by same length logical vectors\nmyLog \u003c- myVec \u003e 10 myVec[myLog]  ## K L M N O P Q R S T U V W X Y Z ## 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26  (3.) Subsetting by field names\nmyVec[c(\"B\", \"K\", \"M\")]  ## B K M ## 2 11 13  (4.) Subset with $ sign: references a single column or list component by its name\niris$Species[1:8]  ## [1] setosa setosa setosa setosa setosa setosa setosa setosa ## Levels: setosa versicolor virginica  Important Utilities Combining Objects The c function combines vectors and lists\nc(1, 2, 3)  ## [1] 1 2 3  x \u003c- 1:3; y \u003c- 101:103 c(x, y)  ## [1] 1 2 3 101 102 103  iris$Species[1:8]  ## [1] setosa setosa setosa setosa setosa setosa setosa setosa ## Levels: setosa versicolor virginica  The cbind and rbind functions can be used to append columns and rows, respecively.\nma \u003c- cbind(x, y) ma  ## x y ## [1,] 1 101 ## [2,] 2 102 ## [3,] 3 103  rbind(ma, ma)  ## x y ## [1,] 1 101 ## [2,] 2 102 ## [3,] 3 103 ## [4,] 1 101 ## [5,] 2 102 ## [6,] 3 103  Accessing Dimensions of Objects Length and dimension information of objects\nlength(iris$Species)  ## [1] 150  dim(iris)  ## [1] 150 5  Accessing Name Slots of Objects Accessing row and column names of 2D objects\nrownames(iris)[1:8]  ## [1] \"1\" \"2\" \"3\" \"4\" \"5\" \"6\" \"7\" \"8\"  colnames(iris)  ## [1] \"Sepal.Length\" \"Sepal.Width\" \"Petal.Length\" \"Petal.Width\" \"Species\"  Return name field of vectors and lists\nnames(myVec)  ## [1] \"A\" \"B\" \"C\" \"D\" \"E\" \"F\" \"G\" \"H\" \"I\" \"J\" \"K\" \"L\" \"M\" \"N\" \"O\" \"P\" \"Q\" \"R\" \"S\" \"T\" \"U\" \"V\" \"W\" \"X\" ## [25] \"Y\" \"Z\"  names(myL)  ## [1] \"name\" \"wife\" \"no.children\" \"child.ages\"  Sorting Objects The function sort returns a vector in ascending or descending order\nsort(10:1)  ## [1] 1 2 3 4 5 6 7 8 9 10  The function order returns a sorting index for sorting an object\nsortindex \u003c- order(iris[,1], decreasing = FALSE) sortindex[1:12]  ## [1] 14 9 39 43 42 4 7 23 48 3 30 12  iris[sortindex,][1:2,]  ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 14 4.3 3.0 1.1 0.1 setosa ## 9 4.4 2.9 1.4 0.2 setosa  sortindex \u003c- order(-iris[,1]) # Same as decreasing=TRUE  Sorting multiple columns\niris[order(iris$Sepal.Length, iris$Sepal.Width),][1:2,]  ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 14 4.3 3.0 1.1 0.1 setosa ## 9 4.4 2.9 1.4 0.2 setosa  Operators and Calculations Comparison Operators Comparison operators: ==, !=, \u003c, \u003e, \u003c=, \u003e=\n1==1  ## [1] TRUE  Logical operators: AND: \u0026, OR: |, NOT: !\nx \u003c- 1:10; y \u003c- 10:1 x \u003e y \u0026 x \u003e 5  ## [1] FALSE FALSE FALSE FALSE FALSE TRUE TRUE TRUE TRUE TRUE  Basic Calculations To look up math functions, see Function Index here\nx + y  ## [1] 11 11 11 11 11 11 11 11 11 11  sum(x)  ## [1] 55  mean(x)  ## [1] 5.5  apply(iris[1:6,1:3], 1, mean)  ## 1 2 3 4 5 6 ## 3.333333 3.100000 3.066667 3.066667 3.333333 3.666667  Reading and Writing External Data Import of tabular data Import of a tab-delimited tabular file\nmyDF \u003c- read.delim(\"myData.xls\", sep=\"\\t\")  Import of Excel file. Note: working with tab- or comma-delimited files is more flexible and preferred.\nlibrary(gdata) myDF \u003c- read.xls\"myData.xls\")  Import of Google Sheets. The following example imports a sample Google Sheet from here. Detailed instructions for interacting from R with Google Sheets with the required googlesheets package are here.\nlibrary(\"googlesheets\"); library(\"dplyr\"); library(knitr) gs_auth() # Creates authorizaton token (.httr-oauth) in current directory if not present sheetid \u003c-\"1U-32UcwZP1k3saKeaH1mbvEAOfZRdNHNkWK2GI1rpPM\" gap \u003c- gs_key(sheetid) mysheet \u003c- gs_read(gap, skip=4) myDF \u003c- as.data.frame(mysheet) myDF  Export of tabular data write.table(myDF, file=\"myfile.xls\", sep=\"\\t\", quote=FALSE, col.names=NA)  Line-wise import myDF \u003c- readLines(\"myData.txt\")  Line-wise export writeLines(month.name, \"myData.txt\")  Export R object mylist \u003c- list(C1=iris[,1], C2=iris[,2]) # Example to export saveRDS(mylist, \"mylist.rds\")  Import R object mylist \u003c- readRDS(\"mylist.rds\")  Copy and paste into R On Windows/Linux systems\nread.delim(\"clipboard\")  On Mac OS X systems\nread.delim(pipe(\"pbpaste\"))  Copy and paste from R On Windows/Linux systems\nwrite.table(iris, \"clipboard\", sep=\"\\t\", col.names=NA, quote=F)  On Mac OS X systems\nzz \u003c- pipe('pbcopy', 'w') write.table(iris, zz, sep=\"\\t\", col.names=NA, quote=F) close(zz)  Homework 3A Homework 3A: Object Subsetting Routines and Import/Export\nUseful R Functions Unique entries Make vector entries unique with unique\nlength(iris$Sepal.Length)  ## [1] 150  length(unique(iris$Sepal.Length))  ## [1] 35  Count occurrences Count occurrences of entries with table\ntable(iris$Species)  ## ## setosa versicolor virginica ## 50 50 50  Aggregate data Compute aggregate statistics with aggregate\naggregate(iris[,1:4], by=list(iris$Species), FUN=mean, na.rm=TRUE)  ## Group.1 Sepal.Length Sepal.Width Petal.Length Petal.Width ## 1 setosa 5.006 3.428 1.462 0.246 ## 2 versicolor 5.936 2.770 4.260 1.326 ## 3 virginica 6.588 2.974 5.552 2.026  Intersect data Compute intersect between two vectors with %in%\nmonth.name %in% c(\"May\", \"July\")  ## [1] FALSE FALSE FALSE FALSE TRUE FALSE TRUE FALSE FALSE FALSE FALSE FALSE  Merge data frames Join two data frames by common field entries with merge (here row names by.x=0). To obtain only the common rows, change all=TRUE to all=FALSE. To merge on specific columns, refer to them by their position numbers or their column names.\nframe1 \u003c- iris[sample(1:length(iris[,1]), 30), ] frame1[1:2,]  ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 72 6.1 2.8 4.0 1.3 versicolor ## 45 5.1 3.8 1.9 0.4 setosa  dim(frame1)  ## [1] 30 5  my_result \u003c- merge(frame1, iris, by.x = 0, by.y = 0, all = TRUE) dim(my_result)  ## [1] 150 11  dplyr Environment Modern object classes and methods for handling data.frame like structures are provided by the dplyr and data.table packages. The following gives a short introduction to the usage and functionalities of the dplyr package. More detailed tutorials on this topic can be found here:\n dplyr: A Grammar of Data Manipulation Introduction to dplyr Tutorial on dplyr Cheatsheet for Joins from Jenny Bryan Tibbles Intro to data.table package Big data with dplyr and data.table Fast lookups with dplyr and data.table  Installation The dplyr environment has evolved into an ecosystem of packages. To simplify package management, one can install and load the entire collection via the tidyverse package. For more details on tidyverse see here.\ninstall.packages(\"tidyverse\")  Construct a tibble (tibble) library(tidyverse) as_tibble(iris) # coerce data.frame to tibble tbl  ## # A tibble: 150 x 5 ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cfct\u003e ## 1 5.1 3.5 1.4 0.2 setosa ## 2 4.9 3 1.4 0.2 setosa ## 3 4.7 3.2 1.3 0.2 setosa ## 4 4.6 3.1 1.5 0.2 setosa ## 5 5 3.6 1.4 0.2 setosa ## 6 5.4 3.9 1.7 0.4 setosa ## 7 4.6 3.4 1.4 0.3 setosa ## 8 5 3.4 1.5 0.2 setosa ## 9 4.4 2.9 1.4 0.2 setosa ## 10 4.9 3.1 1.5 0.1 setosa ## # … with 140 more rows  Alternative functions producing the same result include as_data_frame and tbl_df:\nas_data_frame(iris) tbl_df(iris)  Reading and writing tabular files While the base R read/write utilities can be used for data.frames, best time performance with the least amount of typing is achieved with the export/import functions from the readr package. For very large files the fread function from the data.table package achieves the best time performance.\nImport with readr Import functions provided by readr include:\n read_csv(): comma separated (CSV) files read_tsv(): tab separated files read_delim(): general delimited files read_fwf(): fixed width files read_table(): tabular files where colums are separated by white-space. read_log(): web log files  Create a sample tab delimited file for import\nwrite_tsv(iris, \"iris.txt\") # Creates sample file  Import with read_tsv\niris_df \u003c- read_tsv(\"iris.txt\") # Import with read_tbv from readr package iris_df  ## # A tibble: 150 x 5 ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cchr\u003e ## 1 5.1 3.5 1.4 0.2 setosa ## 2 4.9 3 1.4 0.2 setosa ## 3 4.7 3.2 1.3 0.2 setosa ## 4 4.6 3.1 1.5 0.2 setosa ## 5 5 3.6 1.4 0.2 setosa ## 6 5.4 3.9 1.7 0.4 setosa ## 7 4.6 3.4 1.4 0.3 setosa ## 8 5 3.4 1.5 0.2 setosa ## 9 4.4 2.9 1.4 0.2 setosa ## 10 4.9 3.1 1.5 0.1 setosa ## # … with 140 more rows  To import Google Sheets directly into R, see here.\nFast table import with fread The fread function from the data.table package provides the best time performance for reading large tabular files into R.\nlibrary(data.table) iris_df \u003c- as_data_frame(fread(\"iris.txt\")) # Import with fread and conversion to tibble iris_df  ## # A tibble: 150 x 5 ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cchr\u003e ## 1 5.1 3.5 1.4 0.2 setosa ## 2 4.9 3 1.4 0.2 setosa ## 3 4.7 3.2 1.3 0.2 setosa ## 4 4.6 3.1 1.5 0.2 setosa ## 5 5 3.6 1.4 0.2 setosa ## 6 5.4 3.9 1.7 0.4 setosa ## 7 4.6 3.4 1.4 0.3 setosa ## 8 5 3.4 1.5 0.2 setosa ## 9 4.4 2.9 1.4 0.2 setosa ## 10 4.9 3.1 1.5 0.1 setosa ## # … with 140 more rows  Note: to ignore lines starting with comment signs, one can pass on to fread a shell command for preprocessing the file. The following example illustrates this option.\nfread(\"grep -v '^#' iris.txt\")  Export with readr Export function provided by readr inlcude\n write_delim(): general delimited files write_csv(): comma separated (CSV) files write_excel_csv(): excel style CSV files write_tsv(): tab separated files  For instance, the write_tsv function writes a data.frame or tibble to a tab delimited file with much nicer default settings than the base R write.table function.\nwrite_tsv(iris_df, \"iris.txt\")  Column and row binds The equivalents to base R’s rbind and cbind are bind_rows and bind_cols, respectively.\nbind_cols(iris_df, iris_df)  ## # A tibble: 150 x 10 ## Sepal.Length...1 Sepal.Width...2 Petal.Length...3 Petal.Width...4 Species...5 Sepal.Length...6 ## \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cchr\u003e \u003cdbl\u003e ## 1 5.1 3.5 1.4 0.2 setosa 5.1 ## 2 4.9 3 1.4 0.2 setosa 4.9 ## 3 4.7 3.2 1.3 0.2 setosa 4.7 ## 4 4.6 3.1 1.5 0.2 setosa 4.6 ## 5 5 3.6 1.4 0.2 setosa 5 ## 6 5.4 3.9 1.7 0.4 setosa 5.4 ## 7 4.6 3.4 1.4 0.3 setosa 4.6 ## 8 5 3.4 1.5 0.2 setosa 5 ## 9 4.4 2.9 1.4 0.2 setosa 4.4 ## 10 4.9 3.1 1.5 0.1 setosa 4.9 ## # … with 140 more rows, and 4 more variables: Sepal.Width...7 \u003cdbl\u003e, Petal.Length...8 \u003cdbl\u003e, ## # Petal.Width...9 \u003cdbl\u003e, Species...10 \u003cchr\u003e  bind_rows(iris_df, iris_df)  ## # A tibble: 300 x 5 ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cchr\u003e ## 1 5.1 3.5 1.4 0.2 setosa ## 2 4.9 3 1.4 0.2 setosa ## 3 4.7 3.2 1.3 0.2 setosa ## 4 4.6 3.1 1.5 0.2 setosa ## 5 5 3.6 1.4 0.2 setosa ## 6 5.4 3.9 1.7 0.4 setosa ## 7 4.6 3.4 1.4 0.3 setosa ## 8 5 3.4 1.5 0.2 setosa ## 9 4.4 2.9 1.4 0.2 setosa ## 10 4.9 3.1 1.5 0.1 setosa ## # … with 290 more rows  Extract column as vector The subsetting operators [[ and $can be used to extract from a tibble single columns as vector.\niris_df[[5]][1:12]  ## [1] \"setosa\" \"setosa\" \"setosa\" \"setosa\" \"setosa\" \"setosa\" \"setosa\" \"setosa\" \"setosa\" \"setosa\" ## [11] \"setosa\" \"setosa\"  iris_df$Species[1:12]  ## [1] \"setosa\" \"setosa\" \"setosa\" \"setosa\" \"setosa\" \"setosa\" \"setosa\" \"setosa\" \"setosa\" \"setosa\" ## [11] \"setosa\" \"setosa\"  Important dplyr functions  filter() and slice() arrange() select() and rename() distinct() mutate() and transmute() summarise() sample_n() and sample_frac()  Slice and filter functions Filter function filter(iris_df, Sepal.Length \u003e 7.5, Species==\"virginica\")  ## # A tibble: 6 x 5 ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cchr\u003e ## 1 7.6 3 6.6 2.1 virginica ## 2 7.7 3.8 6.7 2.2 virginica ## 3 7.7 2.6 6.9 2.3 virginica ## 4 7.7 2.8 6.7 2 virginica ## 5 7.9 3.8 6.4 2 virginica ## 6 7.7 3 6.1 2.3 virginica  Base R code equivalent iris_df[iris_df[, \"Sepal.Length\"] \u003e 7.5 \u0026 iris_df[, \"Species\"]==\"virginica\", ]  ## # A tibble: 6 x 5 ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cchr\u003e ## 1 7.6 3 6.6 2.1 virginica ## 2 7.7 3.8 6.7 2.2 virginica ## 3 7.7 2.6 6.9 2.3 virginica ## 4 7.7 2.8 6.7 2 virginica ## 5 7.9 3.8 6.4 2 virginica ## 6 7.7 3 6.1 2.3 virginica  Including boolean operators filter(iris_df, Sepal.Length \u003e 7.5 | Sepal.Length \u003c 5.5, Species==\"virginica\")  ## # A tibble: 7 x 5 ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cchr\u003e ## 1 7.6 3 6.6 2.1 virginica ## 2 4.9 2.5 4.5 1.7 virginica ## 3 7.7 3.8 6.7 2.2 virginica ## 4 7.7 2.6 6.9 2.3 virginica ## 5 7.7 2.8 6.7 2 virginica ## 6 7.9 3.8 6.4 2 virginica ## 7 7.7 3 6.1 2.3 virginica  Subset rows by position dplyr approach\nslice(iris_df, 1:2)  ## # A tibble: 2 x 5 ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cchr\u003e ## 1 5.1 3.5 1.4 0.2 setosa ## 2 4.9 3 1.4 0.2 setosa  Base R code equivalent\niris_df[1:2,]  ## # A tibble: 2 x 5 ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cchr\u003e ## 1 5.1 3.5 1.4 0.2 setosa ## 2 4.9 3 1.4 0.2 setosa  Subset rows by names Since tibbles do not contain row names, row wise subsetting via the [,] operator cannot be used. However, the corresponding behavior can be achieved by passing to select a row position index obtained by basic R intersect utilities such as match.\nCreate a suitable test tibble\ndf1 \u003c- bind_cols(data_frame(ids1=paste0(\"g\", 1:10)), as_data_frame(matrix(1:40, 10, 4, dimnames=list(1:10, paste0(\"CA\", 1:4))))) df1  ## # A tibble: 10 x 5 ## ids1 CA1 CA2 CA3 CA4 ## \u003cchr\u003e \u003cint\u003e \u003cint\u003e \u003cint\u003e \u003cint\u003e ## 1 g1 1 11 21 31 ## 2 g2 2 12 22 32 ## 3 g3 3 13 23 33 ## 4 g4 4 14 24 34 ## 5 g5 5 15 25 35 ## 6 g6 6 16 26 36 ## 7 g7 7 17 27 37 ## 8 g8 8 18 28 38 ## 9 g9 9 19 29 39 ## 10 g10 10 20 30 40  dplyr approach\nslice(df1, match(c(\"g10\", \"g4\", \"g4\"), df1$ids1))  ## # A tibble: 3 x 5 ## ids1 CA1 CA2 CA3 CA4 ## \u003cchr\u003e \u003cint\u003e \u003cint\u003e \u003cint\u003e \u003cint\u003e ## 1 g10 10 20 30 40 ## 2 g4 4 14 24 34 ## 3 g4 4 14 24 34  Base R equivalent\ndf1_old \u003c- as.data.frame(df1) rownames(df1_old) \u003c- df1_old[,1] df1_old[c(\"g10\", \"g4\", \"g4\"),]  ## ids1 CA1 CA2 CA3 CA4 ## g10 g10 10 20 30 40 ## g4 g4 4 14 24 34 ## g4.1 g4 4 14 24 34  Sorting with arrange Row-wise ordering based on specific columns\ndplyr approach\narrange(iris_df, Species, Sepal.Length, Sepal.Width)  ## # A tibble: 150 x 5 ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cchr\u003e ## 1 4.3 3 1.1 0.1 setosa ## 2 4.4 2.9 1.4 0.2 setosa ## 3 4.4 3 1.3 0.2 setosa ## 4 4.4 3.2 1.3 0.2 setosa ## 5 4.5 2.3 1.3 0.3 setosa ## 6 4.6 3.1 1.5 0.2 setosa ## 7 4.6 3.2 1.4 0.2 setosa ## 8 4.6 3.4 1.4 0.3 setosa ## 9 4.6 3.6 1 0.2 setosa ## 10 4.7 3.2 1.3 0.2 setosa ## # … with 140 more rows  For ordering descendingly use desc() function\narrange(iris_df, desc(Species), Sepal.Length, Sepal.Width)  ## # A tibble: 150 x 5 ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cchr\u003e ## 1 4.9 2.5 4.5 1.7 virginica ## 2 5.6 2.8 4.9 2 virginica ## 3 5.7 2.5 5 2 virginica ## 4 5.8 2.7 5.1 1.9 virginica ## 5 5.8 2.7 5.1 1.9 virginica ## 6 5.8 2.8 5.1 2.4 virginica ## 7 5.9 3 5.1 1.8 virginica ## 8 6 2.2 5 1.5 virginica ## 9 6 3 4.8 1.8 virginica ## 10 6.1 2.6 5.6 1.4 virginica ## # … with 140 more rows  Base R code equivalent\niris_df[order(iris_df$Species, iris_df$Sepal.Length, iris_df$Sepal.Width), ]  ## # A tibble: 150 x 5 ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cchr\u003e ## 1 4.3 3 1.1 0.1 setosa ## 2 4.4 2.9 1.4 0.2 setosa ## 3 4.4 3 1.3 0.2 setosa ## 4 4.4 3.2 1.3 0.2 setosa ## 5 4.5 2.3 1.3 0.3 setosa ## 6 4.6 3.1 1.5 0.2 setosa ## 7 4.6 3.2 1.4 0.2 setosa ## 8 4.6 3.4 1.4 0.3 setosa ## 9 4.6 3.6 1 0.2 setosa ## 10 4.7 3.2 1.3 0.2 setosa ## # … with 140 more rows  iris_df[order(iris_df$Species, decreasing=TRUE), ]  ## # A tibble: 150 x 5 ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cchr\u003e ## 1 6.3 3.3 6 2.5 virginica ## 2 5.8 2.7 5.1 1.9 virginica ## 3 7.1 3 5.9 2.1 virginica ## 4 6.3 2.9 5.6 1.8 virginica ## 5 6.5 3 5.8 2.2 virginica ## 6 7.6 3 6.6 2.1 virginica ## 7 4.9 2.5 4.5 1.7 virginica ## 8 7.3 2.9 6.3 1.8 virginica ## 9 6.7 2.5 5.8 1.8 virginica ## 10 7.2 3.6 6.1 2.5 virginica ## # … with 140 more rows  Select columns with select Select specific columns\nselect(iris_df, Species, Petal.Length, Sepal.Length)  ## # A tibble: 150 x 3 ## Species Petal.Length Sepal.Length ## \u003cchr\u003e \u003cdbl\u003e \u003cdbl\u003e ## 1 setosa 1.4 5.1 ## 2 setosa 1.4 4.9 ## 3 setosa 1.3 4.7 ## 4 setosa 1.5 4.6 ## 5 setosa 1.4 5 ## 6 setosa 1.7 5.4 ## 7 setosa 1.4 4.6 ## 8 setosa 1.5 5 ## 9 setosa 1.4 4.4 ## 10 setosa 1.5 4.9 ## # … with 140 more rows  Select range of columns by name\nselect(iris_df, Sepal.Length : Petal.Width)  ## # A tibble: 150 x 4 ## Sepal.Length Sepal.Width Petal.Length Petal.Width ## \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e ## 1 5.1 3.5 1.4 0.2 ## 2 4.9 3 1.4 0.2 ## 3 4.7 3.2 1.3 0.2 ## 4 4.6 3.1 1.5 0.2 ## 5 5 3.6 1.4 0.2 ## 6 5.4 3.9 1.7 0.4 ## 7 4.6 3.4 1.4 0.3 ## 8 5 3.4 1.5 0.2 ## 9 4.4 2.9 1.4 0.2 ## 10 4.9 3.1 1.5 0.1 ## # … with 140 more rows  Drop specific columns (here range)\nselect(iris_df, -(Sepal.Length : Petal.Width))  ## # A tibble: 150 x 1 ## Species ## \u003cchr\u003e ## 1 setosa ## 2 setosa ## 3 setosa ## 4 setosa ## 5 setosa ## 6 setosa ## 7 setosa ## 8 setosa ## 9 setosa ## 10 setosa ## # … with 140 more rows  Renaming columns with rename dplyr approach\nrename(iris_df, new_col_name = Species)  ## # A tibble: 150 x 5 ## Sepal.Length Sepal.Width Petal.Length Petal.Width new_col_name ## \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cchr\u003e ## 1 5.1 3.5 1.4 0.2 setosa ## 2 4.9 3 1.4 0.2 setosa ## 3 4.7 3.2 1.3 0.2 setosa ## 4 4.6 3.1 1.5 0.2 setosa ## 5 5 3.6 1.4 0.2 setosa ## 6 5.4 3.9 1.7 0.4 setosa ## 7 4.6 3.4 1.4 0.3 setosa ## 8 5 3.4 1.5 0.2 setosa ## 9 4.4 2.9 1.4 0.2 setosa ## 10 4.9 3.1 1.5 0.1 setosa ## # … with 140 more rows  Base R code approach\ncolnames(iris_df)[colnames(iris_df)==\"Species\"] \u003c- \"new_col_names\"  Obtain unique rows with distinct dplyr approach\ndistinct(iris_df, Species, .keep_all=TRUE)  ## # A tibble: 3 x 5 ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cchr\u003e ## 1 5.1 3.5 1.4 0.2 setosa ## 2 7 3.2 4.7 1.4 versicolor ## 3 6.3 3.3 6 2.5 virginica  Base R code approach\niris_df[!duplicated(iris_df$Species),]  ## # A tibble: 3 x 5 ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cchr\u003e ## 1 5.1 3.5 1.4 0.2 setosa ## 2 7 3.2 4.7 1.4 versicolor ## 3 6.3 3.3 6 2.5 virginica  Add columns mutate The mutate function allows to append columns to existing ones.\nmutate(iris_df, Ratio = Sepal.Length / Sepal.Width, Sum = Sepal.Length + Sepal.Width)  ## # A tibble: 150 x 7 ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species Ratio Sum ## \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cchr\u003e \u003cdbl\u003e \u003cdbl\u003e ## 1 5.1 3.5 1.4 0.2 setosa 1.46 8.6 ## 2 4.9 3 1.4 0.2 setosa 1.63 7.9 ## 3 4.7 3.2 1.3 0.2 setosa 1.47 7.9 ## 4 4.6 3.1 1.5 0.2 setosa 1.48 7.7 ## 5 5 3.6 1.4 0.2 setosa 1.39 8.6 ## 6 5.4 3.9 1.7 0.4 setosa 1.38 9.3 ## 7 4.6 3.4 1.4 0.3 setosa 1.35 8 ## 8 5 3.4 1.5 0.2 setosa 1.47 8.4 ## 9 4.4 2.9 1.4 0.2 setosa 1.52 7.3 ## 10 4.9 3.1 1.5 0.1 setosa 1.58 8 ## # … with 140 more rows  transmute The transmute function does the same as mutate but drops existing columns\ntransmute(iris_df, Ratio = Sepal.Length / Sepal.Width, Sum = Sepal.Length + Sepal.Width)  ## # A tibble: 150 x 2 ## Ratio Sum ## \u003cdbl\u003e \u003cdbl\u003e ## 1 1.46 8.6 ## 2 1.63 7.9 ## 3 1.47 7.9 ## 4 1.48 7.7 ## 5 1.39 8.6 ## 6 1.38 9.3 ## 7 1.35 8 ## 8 1.47 8.4 ## 9 1.52 7.3 ## 10 1.58 8 ## # … with 140 more rows  bind_cols The bind_cols function is the equivalent of cbind in base R. To add rows, use the corresponding bind_rows function.\nbind_cols(iris_df, iris_df)  ## # A tibble: 150 x 10 ## Sepal.Length...1 Sepal.Width...2 Petal.Length...3 Petal.Width...4 Species...5 Sepal.Length...6 ## \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cchr\u003e \u003cdbl\u003e ## 1 5.1 3.5 1.4 0.2 setosa 5.1 ## 2 4.9 3 1.4 0.2 setosa 4.9 ## 3 4.7 3.2 1.3 0.2 setosa 4.7 ## 4 4.6 3.1 1.5 0.2 setosa 4.6 ## 5 5 3.6 1.4 0.2 setosa 5 ## 6 5.4 3.9 1.7 0.4 setosa 5.4 ## 7 4.6 3.4 1.4 0.3 setosa 4.6 ## 8 5 3.4 1.5 0.2 setosa 5 ## 9 4.4 2.9 1.4 0.2 setosa 4.4 ## 10 4.9 3.1 1.5 0.1 setosa 4.9 ## # … with 140 more rows, and 4 more variables: Sepal.Width...7 \u003cdbl\u003e, Petal.Length...8 \u003cdbl\u003e, ## # Petal.Width...9 \u003cdbl\u003e, Species...10 \u003cchr\u003e  Summarize data Summary calculation on single column\nsummarize(iris_df, mean(Petal.Length))  ## # A tibble: 1 x 1 ## `mean(Petal.Length)` ## \u003cdbl\u003e ## 1 3.76  Summary calculation on many columns\nsummarize_all(iris_df[,1:4], mean)  ## # A tibble: 1 x 4 ## Sepal.Length Sepal.Width Petal.Length Petal.Width ## \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e ## 1 5.84 3.06 3.76 1.20  Summarize by grouping column\nsummarize(group_by(iris_df, Species), mean(Petal.Length))  ## # A tibble: 3 x 2 ## Species `mean(Petal.Length)` ## \u003cchr\u003e \u003cdbl\u003e ## 1 setosa 1.46 ## 2 versicolor 4.26 ## 3 virginica 5.55  Aggregate summaries\nsummarize_all(group_by(iris_df, Species), mean)  ## # A tibble: 3 x 5 ## Species Sepal.Length Sepal.Width Petal.Length Petal.Width ## \u003cchr\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e ## 1 setosa 5.01 3.43 1.46 0.246 ## 2 versicolor 5.94 2.77 4.26 1.33 ## 3 virginica 6.59 2.97 5.55 2.03  Note: group_by does the looping for the user similar to aggregate or tapply.\nMerging tibbles The dplyr package provides several join functions for merging tibbles by a common key column similar to the merge function in base R. These *_join functions include:\n inner_join(): returns join only for rows matching among both tibbles full_join(): returns join for all (matching and non-matching) rows of two tibbles left_join(): returns join for all rows in first tibble right_join(): returns join for all rows in second tibble anti_join(): returns for first tibble only those rows that have no match in the second one  Sample tibbles to illustrate *.join functions.\ndf1 \u003c- bind_cols(data_frame(ids1=paste0(\"g\", 1:10)), as_data_frame(matrix(1:40, 10, 4, dimnames=list(1:10, paste0(\"CA\", 1:4))))) df1  ## # A tibble: 10 x 5 ## ids1 CA1 CA2 CA3 CA4 ## \u003cchr\u003e \u003cint\u003e \u003cint\u003e \u003cint\u003e \u003cint\u003e ## 1 g1 1 11 21 31 ## 2 g2 2 12 22 32 ## 3 g3 3 13 23 33 ## 4 g4 4 14 24 34 ## 5 g5 5 15 25 35 ## 6 g6 6 16 26 36 ## 7 g7 7 17 27 37 ## 8 g8 8 18 28 38 ## 9 g9 9 19 29 39 ## 10 g10 10 20 30 40  df2 \u003c- bind_cols(data_frame(ids2=paste0(\"g\", c(2,5,11,12))), as_data_frame(matrix(1:16, 4, 4, dimnames=list(1:4, paste0(\"CB\", 1:4))))) df2  ## # A tibble: 4 x 5 ## ids2 CB1 CB2 CB3 CB4 ## \u003cchr\u003e \u003cint\u003e \u003cint\u003e \u003cint\u003e \u003cint\u003e ## 1 g2 1 5 9 13 ## 2 g5 2 6 10 14 ## 3 g11 3 7 11 15 ## 4 g12 4 8 12 16  Inner join inner_join(df1, df2, by=c(\"ids1\"=\"ids2\"))  ## # A tibble: 2 x 9 ## ids1 CA1 CA2 CA3 CA4 CB1 CB2 CB3 CB4 ## \u003cchr\u003e \u003cint\u003e \u003cint\u003e \u003cint\u003e \u003cint\u003e \u003cint\u003e \u003cint\u003e \u003cint\u003e \u003cint\u003e ## 1 g2 2 12 22 32 1 5 9 13 ## 2 g5 5 15 25 35 2 6 10 14  Left join left_join(df1, df2, by=c(\"ids1\"=\"ids2\"))  ## # A tibble: 10 x 9 ## ids1 CA1 CA2 CA3 CA4 CB1 CB2 CB3 CB4 ## \u003cchr\u003e \u003cint\u003e \u003cint\u003e \u003cint\u003e \u003cint\u003e \u003cint\u003e \u003cint\u003e \u003cint\u003e \u003cint\u003e ## 1 g1 1 11 21 31 NA NA NA NA ## 2 g2 2 12 22 32 1 5 9 13 ## 3 g3 3 13 23 33 NA NA NA NA ## 4 g4 4 14 24 34 NA NA NA NA ## 5 g5 5 15 25 35 2 6 10 14 ## 6 g6 6 16 26 36 NA NA NA NA ## 7 g7 7 17 27 37 NA NA NA NA ## 8 g8 8 18 28 38 NA NA NA NA ## 9 g9 9 19 29 39 NA NA NA NA ## 10 g10 10 20 30 40 NA NA NA NA  Right join right_join(df1, df2, by=c(\"ids1\"=\"ids2\"))  ## # A tibble: 4 x 9 ## ids1 CA1 CA2 CA3 CA4 CB1 CB2 CB3 CB4 ## \u003cchr\u003e \u003cint\u003e \u003cint\u003e \u003cint\u003e \u003cint\u003e \u003cint\u003e \u003cint\u003e \u003cint\u003e \u003cint\u003e ## 1 g2 2 12 22 32 1 5 9 13 ## 2 g5 5 15 25 35 2 6 10 14 ## 3 g11 NA NA NA NA 3 7 11 15 ## 4 g12 NA NA NA NA 4 8 12 16  Full join full_join(df1, df2, by=c(\"ids1\"=\"ids2\"))  ## # A tibble: 12 x 9 ## ids1 CA1 CA2 CA3 CA4 CB1 CB2 CB3 CB4 ## \u003cchr\u003e \u003cint\u003e \u003cint\u003e \u003cint\u003e \u003cint\u003e \u003cint\u003e \u003cint\u003e \u003cint\u003e \u003cint\u003e ## 1 g1 1 11 21 31 NA NA NA NA ## 2 g2 2 12 22 32 1 5 9 13 ## 3 g3 3 13 23 33 NA NA NA NA ## 4 g4 4 14 24 34 NA NA NA NA ## 5 g5 5 15 25 35 2 6 10 14 ## 6 g6 6 16 26 36 NA NA NA NA ## 7 g7 7 17 27 37 NA NA NA NA ## 8 g8 8 18 28 38 NA NA NA NA ## 9 g9 9 19 29 39 NA NA NA NA ## 10 g10 10 20 30 40 NA NA NA NA ## 11 g11 NA NA NA NA 3 7 11 15 ## 12 g12 NA NA NA NA 4 8 12 16  Anti join anti_join(df1, df2, by=c(\"ids1\"=\"ids2\"))  ## # A tibble: 8 x 5 ## ids1 CA1 CA2 CA3 CA4 ## \u003cchr\u003e \u003cint\u003e \u003cint\u003e \u003cint\u003e \u003cint\u003e ## 1 g1 1 11 21 31 ## 2 g3 3 13 23 33 ## 3 g4 4 14 24 34 ## 4 g6 6 16 26 36 ## 5 g7 7 17 27 37 ## 6 g8 8 18 28 38 ## 7 g9 9 19 29 39 ## 8 g10 10 20 30 40  For additional join options users want to cosult the *_join help pages.\nChaining To simplify chaining of serveral operations, dplyr provides the %\u003e% operator, where x %\u003e% f(y) turns into f(x, y). This way one can pipe together multiple operations by writing them from left-to-right or top-to-bottom. This makes for easy to type and readable code.\nExample 1 Series of data manipulations and export\nread_tsv(\"iris.txt\") %\u003e% # Import with read_tbv from readr package as_tibble() %\u003e% # Declare tibble to use select(Sepal.Length:Species) %\u003e% # Select columns filter(Species==\"setosa\") %\u003e% # Filter rows by some value arrange(Sepal.Length) %\u003e% # Sort by some column mutate(Subtract=Petal.Length - Petal.Width) # Calculate and append  ## # A tibble: 50 x 6 ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species Subtract ## \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cchr\u003e \u003cdbl\u003e ## 1 4.3 3 1.1 0.1 setosa 1 ## 2 4.4 2.9 1.4 0.2 setosa 1.2 ## 3 4.4 3 1.3 0.2 setosa 1.1 ## 4 4.4 3.2 1.3 0.2 setosa 1.1 ## 5 4.5 2.3 1.3 0.3 setosa 1 ## 6 4.6 3.1 1.5 0.2 setosa 1.3 ## 7 4.6 3.4 1.4 0.3 setosa 1.10 ## 8 4.6 3.6 1 0.2 setosa 0.8 ## 9 4.6 3.2 1.4 0.2 setosa 1.2 ## 10 4.7 3.2 1.3 0.2 setosa 1.1 ## # … with 40 more rows  # write_tsv(\"iris.txt\") # Export to file, omitted here to show result  Example 2 Series of summary calculations for grouped data (group_by)\niris_df %\u003e% # Declare tibble to use group_by(Species) %\u003e% # Group by species summarize(Mean_Sepal.Length=mean(Sepal.Length), Max_Sepal.Length=max(Sepal.Length), Min_Sepal.Length=min(Sepal.Length), SD_Sepal.Length=sd(Sepal.Length), Total=n())  ## # A tibble: 3 x 6 ## Species Mean_Sepal.Length Max_Sepal.Length Min_Sepal.Length SD_Sepal.Length Total ## \u003cchr\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cint\u003e ## 1 setosa 5.01 5.8 4.3 0.352 50 ## 2 versicolor 5.94 7 4.9 0.516 50 ## 3 virginica 6.59 7.9 4.9 0.636 50  Example 3 Combining dplyr chaining with ggplot\niris_df %\u003e% group_by(Species) %\u003e% summarize_all(mean) %\u003e% reshape2::melt(id.vars=c(\"Species\"), variable.name = \"Samples\", value.name=\"Values\") %\u003e% ggplot(aes(Samples, Values, fill = Species)) + geom_bar(position=\"dodge\", stat=\"identity\")  SQLite Databases SQLite is a lightweight relational database solution. The RSQLite package provides an easy to use interface to create, manage and query SQLite databases directly from R. Basic instructions for using SQLite from the command-line are available here. A short introduction to RSQLite is available here.\nLoading data into SQLite databases The following loads two data.frames derived from the iris data set (here mydf1 and mydf2) into an SQLite database (here test.db).\nlibrary(RSQLite) unlink(\"test.db\") # Delete any existing test.db mydb \u003c- dbConnect(SQLite(), \"test.db\") # Creates database file test.db mydf1 \u003c- data.frame(ids=paste0(\"id\", seq_along(iris[,1])), iris) mydf2 \u003c- mydf1[sample(seq_along(mydf1[,1]), 10),] dbWriteTable(mydb, \"mydf1\", mydf1) dbWriteTable(mydb, \"mydf2\", mydf2)  List names of tables in database dbListTables(mydb)  ## [1] \"mydf1\" \"mydf2\"  Import table into data.frame dbGetQuery(mydb, 'SELECT * FROM mydf2')  ## ids Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 1 id111 6.5 3.2 5.1 2.0 virginica ## 2 id106 7.6 3.0 6.6 2.1 virginica ## 3 id117 6.5 3.0 5.5 1.8 virginica ## 4 id61 5.0 2.0 3.5 1.0 versicolor ## 5 id50 5.0 3.3 1.4 0.2 setosa ## 6 id123 7.7 2.8 6.7 2.0 virginica ## 7 id60 5.2 2.7 3.9 1.4 versicolor ## 8 id92 6.1 3.0 4.6 1.4 versicolor ## 9 id32 5.4 3.4 1.5 0.4 setosa ## 10 id84 6.0 2.7 5.1 1.6 versicolor  Query database dbGetQuery(mydb, 'SELECT * FROM mydf1 WHERE \"Sepal.Length\" \u003c 4.6')  ## ids Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 1 id9 4.4 2.9 1.4 0.2 setosa ## 2 id14 4.3 3.0 1.1 0.1 setosa ## 3 id39 4.4 3.0 1.3 0.2 setosa ## 4 id42 4.5 2.3 1.3 0.3 setosa ## 5 id43 4.4 3.2 1.3 0.2 setosa  Join tables The two tables can be joined on the shared ids column as follows.\ndbGetQuery(mydb, 'SELECT * FROM mydf1, mydf2 WHERE mydf1.ids = mydf2.ids')  ## ids Sepal.Length Sepal.Width Petal.Length Petal.Width Species ids Sepal.Length ## 1 id32 5.4 3.4 1.5 0.4 setosa id32 5.4 ## 2 id50 5.0 3.3 1.4 0.2 setosa id50 5.0 ## 3 id60 5.2 2.7 3.9 1.4 versicolor id60 5.2 ## 4 id61 5.0 2.0 3.5 1.0 versicolor id61 5.0 ## 5 id84 6.0 2.7 5.1 1.6 versicolor id84 6.0 ## 6 id92 6.1 3.0 4.6 1.4 versicolor id92 6.1 ## 7 id106 7.6 3.0 6.6 2.1 virginica id106 7.6 ## 8 id111 6.5 3.2 5.1 2.0 virginica id111 6.5 ## 9 id117 6.5 3.0 5.5 1.8 virginica id117 6.5 ## 10 id123 7.7 2.8 6.7 2.0 virginica id123 7.7 ## Sepal.Width Petal.Length Petal.Width Species ## 1 3.4 1.5 0.4 setosa ## 2 3.3 1.4 0.2 setosa ## 3 2.7 3.9 1.4 versicolor ## 4 2.0 3.5 1.0 versicolor ## 5 2.7 5.1 1.6 versicolor ## 6 3.0 4.6 1.4 versicolor ## 7 3.0 6.6 2.1 virginica ## 8 3.2 5.1 2.0 virginica ## 9 3.0 5.5 1.8 virginica ## 10 2.8 6.7 2.0 virginica  Graphics in R Advantages  Powerful environment for visualizing scientific data Integrated graphics and statistics infrastructure Publication quality graphics Fully programmable Highly reproducible Full LaTeX and Markdown support via knitr and R markdown Vast number of R packages with graphics utilities  Documentation for R Graphics General\n Graphics Task Page - URL R Graph Gallery - URL R Graphical Manual - URL Paul Murrell’s book R (Grid) Graphics - URL  Interactive graphics\n rggobi` (GGobi) - URL iplots - URL Open GL (rgl) - URL  Graphics Environments Viewing and saving graphics in R\n On-screen graphics postscript, pdf, svg jpeg, png, wmf, tiff, …  Four major graphic environments\n Low-level infrastructure   R Base Graphics (low- and high-level) grid: Manual  High-level infrastructure \\begin{itemize}   lattice: Manual, Intro, Book ggplot2: Manual, Intro, Book  Base Graphics: Overview Important high-level plotting functions\n plot: generic x-y plotting barplot: bar plots boxplot: box-and-whisker plot hist: histograms pie: pie charts dotchart: cleveland dot plots image, heatmap, contour, persp: functions to generate image-like plots qqnorm, qqline, qqplot: distribution comparison plots pairs, coplot: display of multivariant data  Help on graphics functions\n ?myfct ?plot ?par  Preferred Object Types  Matrices and data frames Vectors Named vectors  Scatter Plots Basic Scatter Plot Sample data set for subsequent plots\nset.seed(1410) y \u003c- matrix(runif(30), ncol=3, dimnames=list(letters[1:10], LETTERS[1:3]))  Plot data\nplot(y[,1], y[,2])  All pairs pairs(y)  With labels plot(y[,1], y[,2], pch=20, col=\"red\", main=\"Symbols and Labels\") text(y[,1]+0.03, y[,2], rownames(y))  More examples Print instead of symbols the row names\nplot(y[,1], y[,2], type=\"n\", main=\"Plot of Labels\") text(y[,1], y[,2], rownames(y))  Usage of important plotting parameters\ngrid(5, 5, lwd = 2) op \u003c- par(mar=c(8,8,8,8), bg=\"lightblue\") plot(y[,1], y[,2], type=\"p\", col=\"red\", cex.lab=1.2, cex.axis=1.2, cex.main=1.2, cex.sub=1, lwd=4, pch=20, xlab=\"x label\", ylab=\"y label\", main=\"My Main\", sub=\"My Sub\") par(op)  __Important arguments_\n mar: specifies the margin sizes around the plotting area in order: c(bottom, left, top, right) col: color of symbols pch: type of symbols, samples: example(points) lwd: size of symbols cex.*: control font sizes For details see ?par  Add regression line plot(y[,1], y[,2]) myline \u003c- lm(y[,2]~y[,1]); abline(myline, lwd=2)  summary(myline)  ## ## Call: ## lm(formula = y[, 2] ~ y[, 1]) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.40357 -0.17912 -0.04299 0.22147 0.46623 ## ## Coefficients: ## Estimate Std. Error t value Pr(\u003e|t|) ## (Intercept) 0.5764 0.2110 2.732 0.0258 * ## y[, 1] -0.3647 0.3959 -0.921 0.3839 ## --- ## Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ## ## Residual standard error: 0.3095 on 8 degrees of freedom ## Multiple R-squared: 0.09589, Adjusted R-squared: -0.01712 ## F-statistic: 0.8485 on 1 and 8 DF, p-value: 0.3839  Log scale Same plot as above, but on log scale\nplot(y[,1], y[,2], log=\"xy\")  Add a mathematical expression plot(y[,1], y[,2]); text(y[1,1], y[1,2], expression(sum(frac(1,sqrt(x^2*pi)))), cex=1.3)  Homework 3B Homework 3B: Scatter Plots\nLine Plots Single data set plot(y[,1], type=\"l\", lwd=2, col=\"blue\")  Many Data Sets Plots line graph for all columns in data frame y. The split.screen function is used in this example in a for loop to overlay several line graphs in the same plot.\nsplit.screen(c(1,1))  ## [1] 1  plot(y[,1], ylim=c(0,1), xlab=\"Measurement\", ylab=\"Intensity\", type=\"l\", lwd=2, col=1) for(i in 2:length(y[1,])) { screen(1, new=FALSE) plot(y[,i], ylim=c(0,1), type=\"l\", lwd=2, col=i, xaxt=\"n\", yaxt=\"n\", ylab=\"\", xlab=\"\", main=\"\", bty=\"n\") }  close.screen(all=TRUE)  Bar Plots Basics barplot(y[1:4,], ylim=c(0, max(y[1:4,])+0.3), beside=TRUE, legend=letters[1:4]) text(labels=round(as.vector(as.matrix(y[1:4,])),2), x=seq(1.5, 13, by=1) + sort(rep(c(0,1,2), 4)), y=as.vector(as.matrix(y[1:4,]))+0.04)  Error Bars bar \u003c- barplot(m \u003c- rowMeans(y) * 10, ylim=c(0, 10)) stdev \u003c- sd(t(y)) arrows(bar, m, bar, m + stdev, length=0.15, angle = 90)  Histograms hist(y, freq=TRUE, breaks=10)  Density Plots plot(density(y), col=\"red\")  Pie Charts pie(y[,1], col=rainbow(length(y[,1]), start=0.1, end=0.8), clockwise=TRUE) legend(\"topright\", legend=row.names(y), cex=1.3, bty=\"n\", pch=15, pt.cex=1.8, col=rainbow(length(y[,1]), start=0.1, end=0.8), ncol=1)  Color Selection Utilities Default color palette and how to change it\npalette()  ## [1] \"black\" \"#DF536B\" \"#61D04F\" \"#2297E6\" \"#28E2E5\" \"#CD0BBC\" \"#F5C710\" \"gray62\"  palette(rainbow(5, start=0.1, end=0.2)) palette()  ## [1] \"#FF9900\" \"#FFBF00\" \"#FFE600\" \"#F2FF00\" \"#CCFF00\"  palette(\"default\")  The gray function allows to select any type of gray shades by providing values from 0 to 1\ngray(seq(0.1, 1, by= 0.2))  ## [1] \"#1A1A1A\" \"#4D4D4D\" \"#808080\" \"#B3B3B3\" \"#E6E6E6\"  Color gradients with colorpanel function from gplots library`\nlibrary(gplots) colorpanel(5, \"darkblue\", \"yellow\", \"white\")  ## [1] \"#00008B\" \"#808046\" \"#FFFF00\" \"#FFFF80\" \"#FFFFFF\"  Much more on colors in R see Earl Glynn’s color chart here\nSaving Graphics to File After the pdf() command all graphs are redirected to file test.pdf. Works for all common formats similarly: jpeg, png, ps, tiff, …\npdf(\"test.pdf\") plot(1:10, 1:10) dev.off()  Generates Scalable Vector Graphics (SVG) files that can be edited in vector graphics programs, such as InkScape.\nlibrary(\"RSvgDevice\") devSVG(\"test.svg\") plot(1:10, 1:10) dev.off()  Homework 3C Homework 3C: Bar Plots\nAnalysis Routine Overview The following exercise introduces a variety of useful data analysis utilities in R.\nAnalysis Routine: Data Import   Step 1: To get started with this exercise, direct your R session to a dedicated workshop directory and download into this directory the following sample tables. Then import the files into Excel and save them as tab delimited text files.\n MolecularWeight_tair7.xls TargetP_analysis_tair7.xls    Import the tables into R\nImport molecular weight table\nmy_mw \u003c- read.delim(file=\"MolecularWeight_tair7.xls\", header=T, sep=\"\\t\") my_mw[1:2,]  Import subcelluar targeting table\nmy_target \u003c- read.delim(file=\"TargetP_analysis_tair7.xls\", header=T, sep=\"\\t\") my_target[1:2,]  Online import of molecular weight table\nmy_mw \u003c- read.delim(file=\"http://faculty.ucr.edu/~tgirke/Documents/R_BioCond/Samples/MolecularWeight_tair7.xls\", header=T, sep=\"\\t\") my_mw[1:2,]  ## Sequence.id Molecular.Weight.Da. Residues ## 1 AT1G08520.1 83285 760 ## 2 AT1G08530.1 27015 257  Online import of subcelluar targeting table\nmy_target \u003c- read.delim(file=\"http://faculty.ucr.edu/~tgirke/Documents/R_BioCond/Samples/TargetP_analysis_tair7.xls\", header=T, sep=\"\\t\") my_target[1:2,]  ## GeneName Loc cTP mTP SP other ## 1 AT1G08520.1 C 0.822 0.137 0.029 0.039 ## 2 AT1G08530.1 C 0.817 0.058 0.010 0.100  Merging Data Frames  Step 2: Assign uniform gene ID column titles  colnames(my_target)[1] \u003c- \"ID\" colnames(my_mw)[1] \u003c- \"ID\"   Step 3: Merge the two tables based on common ID field  my_mw_target \u003c- merge(my_mw, my_target, by.x=\"ID\", by.y=\"ID\", all.x=T)   Step 4: Shorten one table before the merge and then remove the non-matching rows (NAs) in the merged file  my_mw_target2a \u003c- merge(my_mw, my_target[1:40,], by.x=\"ID\", by.y=\"ID\", all.x=T) # To remove non-matching rows, use the argument setting 'all=F'. my_mw_target2 \u003c- na.omit(my_mw_target2a) # Removes rows containing \"NAs\" (non-matching rows).   Homework 3D: How can the merge function in the previous step be executed so that only the common rows among the two data frames are returned? Prove that both methods - the two step version with na.omit and your method - return identical results. Homework 3E: Replace all NAs in the data frame my_mw_target2a with zeros.  Filtering Data  Step 5: Retrieve all records with a value of greater than 100,000 in ‘MW’ column and ‘C’ value in ‘Loc’ column (targeted to chloroplast).  query \u003c- my_mw_target[my_mw_target[, 2] \u003e 100000 \u0026 my_mw_target[, 4] == \"C\", ] query[1:4, ]  ## ID Molecular.Weight.Da. Residues Loc cTP mTP SP other ## 219 AT1G02730.1 132588 1181 C 0.972 0.038 0.008 0.045 ## 243 AT1G02890.1 136825 1252 C 0.748 0.529 0.011 0.013 ## 281 AT1G03160.1 100732 912 C 0.871 0.235 0.011 0.007 ## 547 AT1G05380.1 126360 1138 C 0.740 0.099 0.016 0.358  dim(query)  ## [1] 170 8   Homework 3F: How many protein entries in the my_mw_target data frame have a MW of greater then 4,000 and less then 5,000. Subset the data frame accordingly and sort it by MW to check that your result is correct.  String Substitutions  Step 6: Use a regular expression in a substitute function to generate a separate ID column that lacks the gene model extensions. \u003c\u003clabel=Exercise 4.7, eval=TRUE, echo=TRUE, keep.source=TRUE\u003e\u003e=  my_mw_target3 \u003c- data.frame(loci=gsub(\"\\\\..*\", \"\", as.character(my_mw_target[,1]), perl = TRUE), my_mw_target) my_mw_target3[1:3,1:8]  ## loci ID Molecular.Weight.Da. Residues Loc cTP mTP SP ## 1 AT1G01010 AT1G01010.1 49426 429 _ 0.10 0.090 0.075 ## 2 AT1G01020 AT1G01020.1 28092 245 * 0.01 0.636 0.158 ## 3 AT1G01020 AT1G01020.2 21711 191 * 0.01 0.636 0.158   Homework 3G: Retrieve those rows in my_mw_target3 where the second column contains the following identifiers: c(\"AT5G52930.1\", \"AT4G18950.1\", \"AT1G15385.1\", \"AT4G36500.1\", \"AT1G67530.1\"). Use the %in% function for this query. As an alternative approach, assign the second column to the row index of the data frame and then perform the same query again using the row index. Explain the difference of the two methods.  Calculations on Data Frames  Step 7: Count the number of duplicates in the loci column with the table function and append the result to the data frame with the cbind function.  mycounts \u003c- table(my_mw_target3[,1])[my_mw_target3[,1]] my_mw_target4 \u003c- cbind(my_mw_target3, Freq=mycounts[as.character(my_mw_target3[,1])])   Step 8: Perform a vectorized devision of columns 3 and 4 (average AA weight per protein)  data.frame(my_mw_target4, avg_AA_WT=(my_mw_target4[,3] / my_mw_target4[,4]))[1:2,5:11]  ## Loc cTP mTP SP other Freq.Var1 Freq.Freq ## 1 _ 0.10 0.090 0.075 0.925 AT1G01010 1 ## 2 * 0.01 0.636 0.158 0.448 AT1G01020 2   Step 9: Calculate for each row the mean and standard deviation across several columns  mymean \u003c- apply(my_mw_target4[,6:9], 1, mean) mystdev \u003c- apply(my_mw_target4[,6:9], 1, sd, na.rm=TRUE) data.frame(my_mw_target4, mean=mymean, stdev=mystdev)[1:2,5:12]  ## Loc cTP mTP SP other Freq.Var1 Freq.Freq mean ## 1 _ 0.10 0.090 0.075 0.925 AT1G01010 1 0.2975 ## 2 * 0.01 0.636 0.158 0.448 AT1G01020 2 0.3130  Plotting Example  Step 10: Generate scatter plot columns: ‘MW’ and ‘Residues’  plot(my_mw_target4[1:500,3:4], col=\"red\")  Export Results and Run Entire Exercise as Script  Step 11: Write the data frame my_mw_target4 into a tab-delimited text file and inspect it in Excel.  write.table(my_mw_target4, file=\"my_file.xls\", quote=F, sep=\"\\t\", col.names = NA)   Homework 3H: Write all commands from this exercise into an R script named exerciseRbasics.R, or download it from here. Then execute the script with the source function like this: source(\"exerciseRbasics.R\"). This will run all commands of this exercise and generate the corresponding output files in the current working directory.  source(\"exerciseRbasics.R\")  R Markdown Overview R Markdown combines markdown (an easy to write plain text format) with embedded R code chunks. When compiling R Markdown documents, the code components can be evaluated so that both the code and its output can be included in the final document. This makes analysis reports highly reproducible by allowing to automatically regenerate them when the underlying R code or data changes. R Markdown documents (.Rmd files) can be rendered to various formats including HTML and PDF. The R code in an .Rmd document is processed by knitr, while the resulting .md file is rendered by pandoc to the final output formats (e.g. HTML or PDF). Historically, R Markdown is an extension of the older Sweave/Latex environment. Rendering of mathematical expressions and reference management is also supported by R Markdown using embedded Latex syntax and Bibtex, respectively.\nQuick Start Install R Markdown install.packages(\"rmarkdown\")  Initialize a new R Markdown (Rmd) script To minimize typing, it can be helful to start with an R Markdown template and then modify it as needed. Note the file name of an R Markdown scirpt needs to have the extension .Rmd. Template files for the following examples are available here:\n R Markdown sample script: sample.Rmd Bibtex file for handling citations and reference section: bibtex.bib  Users want to download these files, open the sample.Rmd file with their preferred R IDE (e.g. RStudio, vim or emacs), initilize an R session and then direct their R session to the location of these two files.\nMetadata section The metadata section (YAML header) in an R Markdown script defines how it will be processed and rendered. The metadata section also includes both title, author, and date information as well as options for customizing the output format. For instance, PDF and HTML output can be defined with pdf_document and html_document, respectively. The BiocStyle:: prefix will use the formatting style of the BiocStyle package from Bioconductor.\n --- title: \"My First R Markdown Document\" author: \"Author: First Last\" date: \"Last update: 22 April, 2021\" output: BiocStyle::html_document: toc: true toc_depth: 3 fig_caption: yes fontsize: 14pt bibliography: bibtex.bib ---  Render Rmd script An R Markdown script can be evaluated and rendered with the following render command or by pressing the knit button in RStudio. The output_format argument defines the format of the output (e.g. html_document). The setting output_format=\"all\" will generate all supported output formats. Alternatively, one can specify several output formats in the metadata section as shown in the above example.\nrmarkdown::render(\"sample.Rmd\", clean=TRUE, output_format=\"html_document\")  The following shows two options how to run the rendering from the command-line.\n$ Rscript -e \"rmarkdown::render('sample.Rmd', clean=TRUE)\"  Alternatively, one can use a Makefile to evaluate and render an R Markdown script. A sample Makefile for rendering the above sample.Rmd can be downloaded here. To apply it to a custom Rmd file, one needs open the Makefile in a text editor and change the value assigned to MAIN (line 13) to the base name of the corresponding .Rmd file (e.g. assign systemPipeRNAseq if the file name is systemPipeRNAseq.Rmd). To execute the Makefile, run the following command from the command-line.\n$ make -B  R code chunks R Code Chunks can be embedded in an R Markdown script by using three backticks at the beginning of a new line along with arguments enclosed in curly braces controlling the behavior of the code. The following lines contain the plain R code. A code chunk is terminated by a new line starting with three backticks. The following shows an example of such a code chunk. Note the backslashes are not part of it. They have been added to print the code chunk syntax in this document.\n ```\\{r code_chunk_name, eval=FALSE\\} x \u003c- 1:10 ```  The following lists the most important arguments to control the behavior of R code chunks:\n r: specifies language for code chunk, here R chode_chunk_name: name of code chunk; this name needs to be unique eval: if assigned TRUE the code will be evaluated warning: if assigned FALSE warnings will not be shown message: if assigned FALSE messages will not be shown cache: if assigned TRUE results will be cached to reuse in future rendering instances fig.height: allows to specify height of figures in inches fig.width: allows to specify width of figures in inches  For more details on code chunk options see here.\nLearning Markdown The basic syntax of Markdown and derivatives like kramdown is extremely easy to learn. Rather than providing another introduction on this topic, here are some useful sites for learning Markdown:\n Markdown Intro on GitHub Markdown Cheet Sheet Markdown Basics from RStudio R Markdown Cheat Sheet kramdown Syntax  Tables There are several ways to render tables. First, they can be printed within the R code chunks. Second, much nicer formatted tables can be generated with the functions kable, pander or xtable. The following example uses kable from the knitr package.\nlibrary(knitr) kable(iris[1:12,])     Sepal.Length Sepal.Width Petal.Length Petal.Width Species     5.1 3.5 1.4 0.2 setosa   4.9 3.0 1.4 0.2 setosa   4.7 3.2 1.3 0.2 setosa   4.6 3.1 1.5 0.2 setosa   5.0 3.6 1.4 0.2 setosa   5.4 3.9 1.7 0.4 setosa   4.6 3.4 1.4 0.3 setosa   5.0 3.4 1.5 0.2 setosa   4.4 2.9 1.4 0.2 setosa   4.9 3.1 1.5 0.1 setosa   5.4 3.7 1.5 0.2 setosa   4.8 3.4 1.6 0.2 setosa    A much more elegant and powerful solution is to create fully interactive tables with the DT package. This JavaScirpt based environment provides a wrapper to the DataTables library using jQuery. The resulting tables can be sorted, queried and resized by the user. For an example see here.\nlibrary(DT) datatable(iris, filter = 'top', options = list( pageLength = 100, scrollX = TRUE, scrollY = \"600px\", autoWidth = TRUE ))   {\"x\":{\"filter\":\"top\",\"filterHTML\":\"\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n\",\"data\":[[\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\",\"11\",\"12\",\"13\",\"14\",\"15\",\"16\",\"17\",\"18\",\"19\",\"20\",\"21\",\"22\",\"23\",\"24\",\"25\",\"26\",\"27\",\"28\",\"29\",\"30\",\"31\",\"32\",\"33\",\"34\",\"35\",\"36\",\"37\",\"38\",\"39\",\"40\",\"41\",\"42\",\"43\",\"44\",\"45\",\"46\",\"47\",\"48\",\"49\",\"50\",\"51\",\"52\",\"53\",\"54\",\"55\",\"56\",\"57\",\"58\",\"59\",\"60\",\"61\",\"62\",\"63\",\"64\",\"65\",\"66\",\"67\",\"68\",\"69\",\"70\",\"71\",\"72\",\"73\",\"74\",\"75\",\"76\",\"77\",\"78\",\"79\",\"80\",\"81\",\"82\",\"83\",\"84\",\"85\",\"86\",\"87\",\"88\",\"89\",\"90\",\"91\",\"92\",\"93\",\"94\",\"95\",\"96\",\"97\",\"98\",\"99\",\"100\",\"101\",\"102\",\"103\",\"104\",\"105\",\"106\",\"107\",\"108\",\"109\",\"110\",\"111\",\"112\",\"113\",\"114\",\"115\",\"116\",\"117\",\"118\",\"119\",\"120\",\"121\",\"122\",\"123\",\"124\",\"125\",\"126\",\"127\",\"128\",\"129\",\"130\",\"131\",\"132\",\"133\",\"134\",\"135\",\"136\",\"137\",\"138\",\"139\",\"140\",\"141\",\"142\",\"143\",\"144\",\"145\",\"146\",\"147\",\"148\",\"149\",\"150\"],[5.1,4.9,4.7,4.6,5,5.4,4.6,5,4.4,4.9,5.4,4.8,4.8,4.3,5.8,5.7,5.4,5.1,5.7,5.1,5.4,5.1,4.6,5.1,4.8,5,5,5.2,5.2,4.7,4.8,5.4,5.2,5.5,4.9,5,5.5,4.9,4.4,5.1,5,4.5,4.4,5,5.1,4.8,5.1,4.6,5.3,5,7,6.4,6.9,5.5,6.5,5.7,6.3,4.9,6.6,5.2,5,5.9,6,6.1,5.6,6.7,5.6,5.8,6.2,5.6,5.9,6.1,6.3,6.1,6.4,6.6,6.8,6.7,6,5.7,5.5,5.5,5.8,6,5.4,6,6.7,6.3,5.6,5.5,5.5,6.1,5.8,5,5.6,5.7,5.7,6.2,5.1,5.7,6.3,5.8,7.1,6.3,6.5,7.6,4.9,7.3,6.7,7.2,6.5,6.4,6.8,5.7,5.8,6.4,6.5,7.7,7.7,6,6.9,5.6,7.7,6.3,6.7,7.2,6.2,6.1,6.4,7.2,7.4,7.9,6.4,6.3,6.1,7.7,6.3,6.4,6,6.9,6.7,6.9,5.8,6.8,6.7,6.7,6.3,6.5,6.2,5.9],[3.5,3,3.2,3.1,3.6,3.9,3.4,3.4,2.9,3.1,3.7,3.4,3,3,4,4.4,3.9,3.5,3.8,3.8,3.4,3.7,3.6,3.3,3.4,3,3.4,3.5,3.4,3.2,3.1,3.4,4.1,4.2,3.1,3.2,3.5,3.6,3,3.4,3.5,2.3,3.2,3.5,3.8,3,3.8,3.2,3.7,3.3,3.2,3.2,3.1,2.3,2.8,2.8,3.3,2.4,2.9,2.7,2,3,2.2,2.9,2.9,3.1,3,2.7,2.2,2.5,3.2,2.8,2.5,2.8,2.9,3,2.8,3,2.9,2.6,2.4,2.4,2.7,2.7,3,3.4,3.1,2.3,3,2.5,2.6,3,2.6,2.3,2.7,3,2.9,2.9,2.5,2.8,3.3,2.7,3,2.9,3,3,2.5,2.9,2.5,3.6,3.2,2.7,3,2.5,2.8,3.2,3,3.8,2.6,2.2,3.2,2.8,2.8,2.7,3.3,3.2,2.8,3,2.8,3,2.8,3.8,2.8,2.8,2.6,3,3.4,3.1,3,3.1,3.1,3.1,2.7,3.2,3.3,3,2.5,3,3.4,3],[1.4,1.4,1.3,1.5,1.4,1.7,1.4,1.5,1.4,1.5,1.5,1.6,1.4,1.1,1.2,1.5,1.3,1.4,1.7,1.5,1.7,1.5,1,1.7,1.9,1.6,1.6,1.5,1.4,1.6,1.6,1.5,1.5,1.4,1.5,1.2,1.3,1.4,1.3,1.5,1.3,1.3,1.3,1.6,1.9,1.4,1.6,1.4,1.5,1.4,4.7,4.5,4.9,4,4.6,4.5,4.7,3.3,4.6,3.9,3.5,4.2,4,4.7,3.6,4.4,4.5,4.1,4.5,3.9,4.8,4,4.9,4.7,4.3,4.4,4.8,5,4.5,3.5,3.8,3.7,3.9,5.1,4.5,4.5,4.7,4.4,4.1,4,4.4,4.6,4,3.3,4.2,4.2,4.2,4.3,3,4.1,6,5.1,5.9,5.6,5.8,6.6,4.5,6.3,5.8,6.1,5.1,5.3,5.5,5,5.1,5.3,5.5,6.7,6.9,5,5.7,4.9,6.7,4.9,5.7,6,4.8,4.9,5.6,5.8,6.1,6.4,5.6,5.1,5.6,6.1,5.6,5.5,4.8,5.4,5.6,5.1,5.1,5.9,5.7,5.2,5,5.2,5.4,5.1],[0.2,0.2,0.2,0.2,0.2,0.4,0.3,0.2,0.2,0.1,0.2,0.2,0.1,0.1,0.2,0.4,0.4,0.3,0.3,0.3,0.2,0.4,0.2,0.5,0.2,0.2,0.4,0.2,0.2,0.2,0.2,0.4,0.1,0.2,0.2,0.2,0.2,0.1,0.2,0.2,0.3,0.3,0.2,0.6,0.4,0.3,0.2,0.2,0.2,0.2,1.4,1.5,1.5,1.3,1.5,1.3,1.6,1,1.3,1.4,1,1.5,1,1.4,1.3,1.4,1.5,1,1.5,1.1,1.8,1.3,1.5,1.2,1.3,1.4,1.4,1.7,1.5,1,1.1,1,1.2,1.6,1.5,1.6,1.5,1.3,1.3,1.3,1.2,1.4,1.2,1,1.3,1.2,1.3,1.3,1.1,1.3,2.5,1.9,2.1,1.8,2.2,2.1,1.7,1.8,1.8,2.5,2,1.9,2.1,2,2.4,2.3,1.8,2.2,2.3,1.5,2.3,2,2,1.8,2.1,1.8,1.8,1.8,2.1,1.6,1.9,2,2.2,1.5,1.4,2.3,2.4,1.8,1.8,2.1,2.4,2.3,1.9,2.3,2.5,2.3,1.9,2,2.3,1.8],[\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\"]],\"container\":\"\\n \\n \\n  \\n Sepal.Length\\n Sepal.Width\\n Petal.Length\\n Petal.Width\\n Species\\n \\n \\n\",\"options\":{\"pageLength\":100,\"scrollX\":true,\"scrollY\":\"600px\",\"autoWidth\":true,\"columnDefs\":[{\"className\":\"dt-right\",\"targets\":[1,2,3,4]},{\"orderable\":false,\"targets\":0}],\"order\":[],\"orderClasses\":false,\"orderCellsTop\":true}},\"evals\":[],\"jsHooks\":[]} Figures Plots generated by the R code chunks in an R Markdown document can be automatically inserted in the output file. The size of the figure can be controlled with the fig.height and fig.width arguments.\nlibrary(ggplot2) dsmall \u003c- diamonds[sample(nrow(diamonds), 1000), ] ggplot(dsmall, aes(color, price/carat)) + geom_jitter(alpha = I(1 / 2), aes(color=color))  Sometimes it can be useful to explicitly write an image to a file and then insert that image into the final document by referencing its file name in the R Markdown source. For instance, this can be useful for time consuming analyses. The following code will generate a file named myplot.png. To insert the file in the final document, one can use standard Markdown or HTML syntax, e.g.: \u003cimg src=\"myplot.png\"/\u003e.\npng(\"images/myplot.png\") ggplot(dsmall, aes(color, price/carat)) + geom_jitter(alpha = I(1 / 2), aes(color=color)) dev.off()  ## png ## 2    Inline R code To evaluate R code inline, one can enclose an R expression with a single back-tick followed by r and then the actual expression. For instance, the back-ticked version of ‘r 1 + 1’ evaluates to 2 and ‘r pi’ evaluates to 3.1415927.\nMathematical equations To render mathematical equations, one can use standard Latex syntax. When expressions are enclosed with single $ signs then they will be shown inline, while enclosing them with double $$ signs will show them in display mode. For instance, the following Latex syntax d(X,Y) = \\sqrt[]{ \\sum_{i=1}^{n}{(x_{i}-y_{i})^2} } renders in display mode as follows:\n$$d(X,Y) = \\sqrt[]{ \\sum_{i=1}^{n}{(x_{i}-y_{i})^2} }$$\nCitations and bibliographies Citations and bibliographies can be autogenerated in R Markdown in a similar way as in Latex/Bibtex. Reference collections should be stored in a separate file in Bibtex or other supported formats. To cite a publication in an R Markdown script, one uses the syntax [@\u003cid1\u003e] where \u003cid1\u003e needs to be replaced with a reference identifier present in the Bibtex database listed in the metadata section of the R Markdown script (e.g. bibtex.bib). For instance, to cite Lawrence et al. (2013), one uses its reference identifier (e.g. Lawrence2013-kt) as \u003cid1\u003e (Lawrence et al. 2013). This will place the citation inline in the text and add the corresponding reference to a reference list at the end of the output document. For the latter a special section called References needs to be specified at the end of the R Markdown script. To fine control the formatting of citations and reference lists, users want to consult this the corresponding R Markdown page. Also, for general reference management and outputting references in Bibtex format Paperpile can be very helpful.\nViewing R Markdown report on HPCC cluster R Markdown reports located on UCR’s HPCC Cluster can be viewed locally in a web browser (without moving the source HTML) by creating a symbolic link from a user’s .html directory. This way any updates to the report can be viewed immediately without creating another copy of the HTML file. For instance, if user ttest has generated an R Markdown report under ~/bigdata/today/rmarkdown/sample.html, then the proper symbolic link to this file can be created as follows:\ncd ~/.html ln -s ~/bigdata/today/rmarkdown/sample.html sample.html  After this one can view the report in a web browser using this URL http://biocluster.ucr.edu/~ttest/rmarkdown/sample.html. If necessary access to the URL can be restricted with a password following the instructions here.\nA sample R Markdown report for an RNA-Seq project is given here:\n RNASeq.html{:target=\"_blank\"} RNASeq.Rmd{:target=\"_blank\"}  Shiny Web Apps What is Shiny? Shiny is an R-based environment for building interactive web applications for data analysis and exploration. Since most JavaScript code is autogenerated by the environment, basic R knowledge is sufficient for developing Shiny apps. They can be deployed on local computers or web servers including custom and cloud-based servers (e.g. AWS, GCP, shinyapp.io service). The basic structure of a Shiny app is an app.R script containing the following components:\n  User interface\nui \u003c- fluidPage()    Server function\nserver \u003c- function(input, output) {}    Statement to run shiny app\nshinyApp(ui = ui, server = server)    Alternatively, the ui and server functions can be organized in two script files, a ui.R and a server.R script, respectively.\nDevelop and test Shiny app locally Open R and set session to parent directory (here myappdir) containing shiny script app.R, and the run it with the runApp() function. A sample app.R script for testing can be downloaded from here.\nlibrary(shiny) runApp(\"myappdir\") # To show code in app, add argument: display.mode=\"showcase\"  This will open the app in a web browser.\nDeploy on web server This can be done on local or cloud systems. An easy solution is to get an account on shinyapps.io and then deploy Shiny apps there. For details, see here.\nsetwd(\"myappdir\") library(rsconnect) deployApp()  Example Shiny app The following Shiny app is hosted on shinyapps.io and embedded into the markdown (or html) source of this page using the following iframe syntax:\n\u003ciframe src=\"https://tgirke.shinyapps.io/diamonds/\" style=\"border: none; width: 880px; height: 900px\"\u003e\u003c/iframe\u003e   Learning Shiny The Shiny section on the Rstudio site contains excellent tutorials. In addition, users may want to explore the example apps included in the shiny package. This can be done by loading the individual examples (see here) or saving the code to a user writable directory like this:\nmydir \u003c- system.file(\"examples\", package=\"shiny\") dir.create('my_shiny_test_dir') file.copy(mydir, \"my_shiny_test_dir\", recursive=TRUE) setwd(\"my_shiny_test_dir/examples\") runApp(\"01_hello\") # Runs first example app in directory dir() # Lists available Shiny examples (directories).  Session Info sessionInfo()  ## R version 4.0.4 (2021-02-15) ## Platform: x86_64-pc-linux-gnu (64-bit) ## Running under: Debian GNU/Linux 10 (buster) ## ## Matrix products: default ## BLAS: /usr/lib/x86_64-linux-gnu/blas/libblas.so.3.8.0 ## LAPACK: /usr/lib/x86_64-linux-gnu/lapack/liblapack.so.3.8.0 ## ## locale: ## [1] LC_CTYPE=en_US.UTF-8 LC_NUMERIC=C LC_TIME=en_US.UTF-8 ## [4] LC_COLLATE=en_US.UTF-8 LC_MONETARY=en_US.UTF-8 LC_MESSAGES=en_US.UTF-8 ## [7] LC_PAPER=en_US.UTF-8 LC_NAME=C LC_ADDRESS=C ## [10] LC_TELEPHONE=C LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C ## ## attached base packages: ## [1] stats graphics grDevices utils datasets methods base ## ## other attached packages: ## [1] DT_0.16 knitr_1.30 gplots_3.1.1 RSQLite_2.2.1 data.table_1.13.2 ## [6] forcats_0.5.0 stringr_1.4.0 dplyr_1.0.2 purrr_0.3.4 readr_1.4.0 ## [11] tidyr_1.1.2 tibble_3.0.4 tidyverse_1.3.0 ggplot2_3.3.2 limma_3.46.0 ## [16] BiocStyle_2.18.0 ## ## loaded via a namespace (and not attached): ## [1] httr_1.4.2 viridisLite_0.3.0 bit64_4.0.5 jsonlite_1.7.1 ## [5] modelr_0.1.8 gtools_3.8.2 assertthat_0.2.1 BiocManager_1.30.10 ## [9] highr_0.8 blob_1.2.1 cellranger_1.1.0 yaml_2.2.1 ## [13] pillar_1.4.7 backports_1.2.0 glue_1.4.2 digest_0.6.27 ## [17] rvest_0.3.6 colorspace_2.0-0 htmltools_0.5.1.1 plyr_1.8.6 ## [21] pkgconfig_2.0.3 broom_0.7.2 haven_2.3.1 bookdown_0.21 ## [25] scales_1.1.1 generics_0.1.0 farver_2.0.3 ellipsis_0.3.1 ## [29] withr_2.3.0 cli_2.2.0 magrittr_2.0.1 crayon_1.3.4 ## [33] readxl_1.3.1 memoise_1.1.0 evaluate_0.14 ps_1.4.0 ## [37] fs_1.5.0 fansi_0.4.1 xml2_1.3.2 blogdown_1.1.7 ## [41] tools_4.0.4 hms_0.5.3 lifecycle_0.2.0 munsell_0.5.0 ## [45] reprex_0.3.0 compiler_4.0.4 caTools_1.18.1 rlang_0.4.8 ## [49] grid_4.0.4 rstudioapi_0.13 htmlwidgets_1.5.2 crosstalk_1.1.0.1 ## [53] bitops_1.0-6 labeling_0.4.2 rmarkdown_2.5 gtable_0.3.0 ## [57] codetools_0.2-18 DBI_1.1.0 reshape2_1.4.4 R6_2.5.0 ## [61] lubridate_1.7.9.2 bit_4.0.4 utf8_1.1.4 KernSmooth_2.23-18 ## [65] stringi_1.5.3 Rcpp_1.0.5 vctrs_0.3.5 dbplyr_2.0.0 ## [69] tidyselect_1.1.0 xfun_0.20  References Lawrence, Michael, Wolfgang Huber, Hervé Pagès, Patrick Aboyoun, Marc Carlson, Robert Gentleman, Martin T Morgan, and Vincent J Carey. 2013. “Software for Computing and Annotating Genomic Ranges.” PLoS Comput. Biol. 9 (8): e1003118. https://doi.org/10.1371/journal.pcbi.1003118.\n  ","categories":"","description":"","excerpt":"       document.addEventListener(\"DOMContentLoaded\", function() { …","ref":"/manuals/rbasics/rbasics/","tags":"","title":"Introduction to R"},{"body":"document.addEventListener(\"DOMContentLoaded\", function() { document.querySelector(\"h1\").className = \"title\"; });  document.addEventListener(\"DOMContentLoaded\", function() { var links = document.links; for (var i = 0, linksLength = links.length; i Source code downloads: [ .Rmd ] [ .R ]\n Overview What is R? R is a powerful statistical environment and programming language for the analysis and visualization of data. The associated Bioconductor and CRAN package repositories provide many additional R packages for statistical data analysis for a wide array of research areas. The R software is free and runs on all common operating systems.\nWhy Using R?  Complete statistical environment and programming language Efficient functions and data structures for data analysis Powerful graphics Access to fast growing number of analysis packages Most widely used language in bioinformatics Is standard for data mining and biostatistical analysis Technical advantages: free, open-source, available for all OSs  Books and Documentation  simpleR - Using R for Introductory Statistics (John Verzani, 2004) - URL Bioinformatics and Computational Biology Solutions Using R and Bioconductor (Gentleman et al., 2005) - URL More on this see “Finding Help” section in UCR Manual - URL  R Working Environments    R Projects and Interfaces  Some R working environments with support for syntax highlighting and utilities to send code to the R console:\n RStudio: excellent choice for beginners (Cheat Sheet) Basic R code editors provided by Rguis gedit, Rgedit, RKWard, Eclipse, Tinn-R, Notepad++, NppToR Vim-R-Tmux: R working environment based on vim and tmux Emacs (ESS add-on package)  Example: RStudio New integrated development environment (IDE) for R. Highly functional for both beginners and advanced.\n   RStudio IDE  Some userful shortcuts: Ctrl+Enter (send code), Ctrl+Shift+C (comment/uncomment), Ctrl+1/2 (switch window focus)\nExample: Nvim-R-Tmux Terminal-based Working Environment for R: Nvim-R-Tmux.\n   Nvim-R-Tmux IDE for R  R Package Repositories  CRAN (\u003e14,000 packages) general data analysis - URL Bioconductor (\u003e2,000 packages) bioscience data analysis - URL Omegahat (\u003e90 packages) programming interfaces - URL RStudio packages - URL  Installation of R, RStudio and R Packages   Install R for your operating system from CRAN.\n  Install RStudio from RStudio.\n  Install CRAN Packages from R console like this:\ninstall.packages(c(\"pkg1\", \"pkg2\")) install.packages(\"pkg.zip\", repos=NULL)    Install Bioconductor packages as follows:\nif (!requireNamespace(\"BiocManager\", quietly = TRUE)) install.packages(\"BiocManager\") # Installs BiocManager if not available yet BiocManager::version() # Reports Bioconductor version BiocManager::install(c(\"pkg1\", \"pkg2\")) # Installs packages specified under \"pkg1\"    For more details consult the Bioc Install page and BiocInstaller package.\n  Getting Around Startup and Closing Behavior   Starting R: The R GUI versions, including RStudio, under Windows and Mac OS X can be opened by double-clicking their icons. Alternatively, one can start it by typing R in a terminal (default under Linux).\n  Startup/Closing Behavior: The R environment is controlled by hidden files in the startup directory: .RData, .Rhistory and .Rprofile (optional).\n  Closing R:\n  q()  Save workspace image? [y/n/c]:   Note: When responding with y, then the entire R workspace will be written to the .RData file which can become very large. Often it is better to select n here, because a much better working pratice is to save an analysis protocol to an R or Rmd source file. This way one can quickly regenerate all data sets and objects needed in a future session.  Navigating directories List objects in current R session\nls()  Return content of current working directory\ndir()  Return path of current working directory\ngetwd()  Change current working directory\nsetwd(\"/home/user\")  Basic Syntax Create an object with the assignment operator \u003c- or =\nobject \u003c- ...  General R command syntax\nobject \u003c- function_name(arguments) object \u003c- object[arguments]  Instead of the assignment operator one can use the assign function\nassign(\"x\", function(arguments))  Finding help\n?function_name  Load a library/package\nlibrary(\"my_library\")  List functions defined by a library\nlibrary(help=\"my_library\")  Load library manual (PDF or HTML file)\nvignette(\"my_library\")  Execute an R script from within R\nsource(\"my_script.R\")  Execute an R script from command-line (the first of the three options is preferred)\n$ Rscript my_script.R $ R CMD BATCH my_script.R $ R --slave \u003c my_script.R  Data Types Numeric data Example: 1, 2, 3, ...\nx \u003c- c(1, 2, 3) x  ## [1] 1 2 3  is.numeric(x)  ## [1] TRUE  as.character(x)  ## [1] \"1\" \"2\" \"3\"  Character data Example: \"a\", \"b\", \"c\", ...\nx \u003c- c(\"1\", \"2\", \"3\") x  ## [1] \"1\" \"2\" \"3\"  is.character(x)  ## [1] TRUE  as.numeric(x)  ## [1] 1 2 3  Complex data Example: mix of both\nc(1, \"b\", 3)  ## [1] \"1\" \"b\" \"3\"  Logical data Example: TRUE of FALSE\nx \u003c- 1:10 \u003c 5 x  ## [1] TRUE TRUE TRUE TRUE FALSE FALSE FALSE FALSE FALSE FALSE  !x  ## [1] FALSE FALSE FALSE FALSE TRUE TRUE TRUE TRUE TRUE TRUE  which(x) # Returns index for the 'TRUE' values in logical vector  ## [1] 1 2 3 4  Data Objects Object types Vectors (1D) Definition: numeric or character\nmyVec \u003c- 1:10; names(myVec) \u003c- letters[1:10] myVec \u003c- setNames(1:10, letters[1:10]) # Same as above in single step myVec[1:5]  ## a b c d e ## 1 2 3 4 5  myVec[c(2,4,6,8)]  ## b d f h ## 2 4 6 8  myVec[c(\"b\", \"d\", \"f\")]  ## b d f ## 2 4 6  Factors (1D) Definition: vectors with grouping information\nfactor(c(\"dog\", \"cat\", \"mouse\", \"dog\", \"dog\", \"cat\"))  ## [1] dog cat mouse dog dog cat ## Levels: cat dog mouse  Matrices (2D) Definition: two dimensional structures with data of same type\nmyMA \u003c- matrix(1:30, 3, 10, byrow = TRUE) class(myMA)  ## [1] \"matrix\" \"array\"  myMA[1:2,]  ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] ## [1,] 1 2 3 4 5 6 7 8 9 10 ## [2,] 11 12 13 14 15 16 17 18 19 20  myMA[1, , drop=FALSE]  ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] ## [1,] 1 2 3 4 5 6 7 8 9 10  Data Frames (2D) Definition: data.frames are two dimensional objects with data of variable types\nmyDF \u003c- data.frame(Col1=1:10, Col2=10:1) myDF[1:2, ]  ## Col1 Col2 ## 1 1 10 ## 2 2 9  Tibbles Tibbles are a more modern version of data.frames. Among many other advantages, one can see here that tibbles have a nicer printing bahavior. Much more detailed information on this object class is provided in the dplyr/tidyverse manual section.\nlibrary(tidyverse) as_tibble(iris)  ## # A tibble: 150 x 5 ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cfct\u003e ## 1 5.1 3.5 1.4 0.2 setosa ## 2 4.9 3 1.4 0.2 setosa ## 3 4.7 3.2 1.3 0.2 setosa ## 4 4.6 3.1 1.5 0.2 setosa ## 5 5 3.6 1.4 0.2 setosa ## 6 5.4 3.9 1.7 0.4 setosa ## 7 4.6 3.4 1.4 0.3 setosa ## 8 5 3.4 1.5 0.2 setosa ## 9 4.4 2.9 1.4 0.2 setosa ## 10 4.9 3.1 1.5 0.1 setosa ## # … with 140 more rows  Arrays Definition: data structure with one, two or more dimensions\nLists Definition: containers for any object type\nmyL \u003c- list(name=\"Fred\", wife=\"Mary\", no.children=3, child.ages=c(4,7,9)) myL  ## $name ## [1] \"Fred\" ## ## $wife ## [1] \"Mary\" ## ## $no.children ## [1] 3 ## ## $child.ages ## [1] 4 7 9  myL[[4]][1:2]  ## [1] 4 7  Functions Definition: piece of code\nmyfct \u003c- function(arg1, arg2, ...) { function_body }  Subsetting of data objects (1.) Subsetting by positive or negative index/position numbers\nmyVec \u003c- 1:26; names(myVec) \u003c- LETTERS myVec[1:4]  ## A B C D ## 1 2 3 4  (2.) Subsetting by same length logical vectors\nmyLog \u003c- myVec \u003e 10 myVec[myLog]  ## K L M N O P Q R S T U V W X Y Z ## 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26  (3.) Subsetting by field names\nmyVec[c(\"B\", \"K\", \"M\")]  ## B K M ## 2 11 13  (4.) Subset with $ sign: references a single column or list component by its name\niris$Species[1:8]  ## [1] setosa setosa setosa setosa setosa setosa setosa setosa ## Levels: setosa versicolor virginica  Important Utilities Combining Objects The c function combines vectors and lists\nc(1, 2, 3)  ## [1] 1 2 3  x \u003c- 1:3; y \u003c- 101:103 c(x, y)  ## [1] 1 2 3 101 102 103  The cbind and rbind functions can be used to append columns and rows, respecively.\nma \u003c- cbind(x, y) ma  ## x y ## [1,] 1 101 ## [2,] 2 102 ## [3,] 3 103  rbind(ma, ma)  ## x y ## [1,] 1 101 ## [2,] 2 102 ## [3,] 3 103 ## [4,] 1 101 ## [5,] 2 102 ## [6,] 3 103  Accessing Dimensions of Objects Length and dimension information of objects\nlength(iris$Species)  ## [1] 150  dim(iris)  ## [1] 150 5  Accessing Name Slots of Objects Accessing row and column names of 2D objects\nrownames(iris)[1:8]  ## [1] \"1\" \"2\" \"3\" \"4\" \"5\" \"6\" \"7\" \"8\"  colnames(iris)  ## [1] \"Sepal.Length\" \"Sepal.Width\" \"Petal.Length\" \"Petal.Width\" \"Species\"  Return name field of vectors and lists\nnames(myVec)  ## [1] \"A\" \"B\" \"C\" \"D\" \"E\" \"F\" \"G\" \"H\" \"I\" \"J\" \"K\" \"L\" \"M\" \"N\" \"O\" \"P\" \"Q\" \"R\" \"S\" \"T\" \"U\" \"V\" \"W\" \"X\" ## [25] \"Y\" \"Z\"  names(myL)  ## [1] \"name\" \"wife\" \"no.children\" \"child.ages\"  Sorting Objects The function sort returns a vector in ascending or descending order\nsort(10:1)  ## [1] 1 2 3 4 5 6 7 8 9 10  The function order returns a sorting index for sorting an object\nsortindex \u003c- order(iris[,1], decreasing = FALSE) sortindex[1:12]  ## [1] 14 9 39 43 42 4 7 23 48 3 30 12  iris[sortindex,][1:2,]  ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 14 4.3 3.0 1.1 0.1 setosa ## 9 4.4 2.9 1.4 0.2 setosa  sortindex \u003c- order(-iris[,1]) # Same as decreasing=TRUE  Sorting multiple columns\niris[order(iris$Sepal.Length, iris$Sepal.Width),][1:2,]  ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 14 4.3 3.0 1.1 0.1 setosa ## 9 4.4 2.9 1.4 0.2 setosa  Operators and Calculations Comparison Operators Comparison operators: ==, !=, \u003c, \u003e, \u003c=, \u003e=\n1==1  ## [1] TRUE  Logical operators: AND: \u0026, OR: |, NOT: !\nx \u003c- 1:10; y \u003c- 10:1 x \u003e y \u0026 x \u003e 5  ## [1] FALSE FALSE FALSE FALSE FALSE TRUE TRUE TRUE TRUE TRUE  Basic Calculations To look up math functions, see Function Index here\nx + y  ## [1] 11 11 11 11 11 11 11 11 11 11  sum(x)  ## [1] 55  mean(x)  ## [1] 5.5  apply(iris[1:6,1:3], 1, mean)  ## 1 2 3 4 5 6 ## 3.333333 3.100000 3.066667 3.066667 3.333333 3.666667  Reading and Writing External Data Import of tabular data Import of a tab-delimited tabular file\nmyDF \u003c- read.delim(\"myData.xls\", sep=\"\\t\")  Import of Google Sheets. The following example imports a sample Google Sheet from here. Detailed instructions for interacting from R with Google Sheets with the required googlesheets4 package are here.\nlibrary(googlesheets4) mysheet \u003c- read_sheet(\"1U-32UcwZP1k3saKeaH1mbvEAOfZRdNHNkWK2GI1rpPM\", skip=4) myDF \u003c- as.data.frame(mysheet) myDF  Import from Excel sheets works well with readxl. For details see the readxl package manual here. Note: working with tab- or comma-delimited files is more flexible and highly preferred for automated analysis workflows.\nlibrary(\"readxl\") mysheet \u003c- read_excel(targets_path, sheet=\"Sheet1\")  Additional import functions are described in the readr package section here.\nExport of tabular data write.table(myDF, file=\"myfile.xls\", sep=\"\\t\", quote=FALSE, col.names=NA)  Line-wise import myDF \u003c- readLines(\"myData.txt\")  Line-wise export writeLines(month.name, \"myData.txt\")  Export R object mylist \u003c- list(C1=iris[,1], C2=iris[,2]) # Example to export saveRDS(mylist, \"mylist.rds\")  Import R object mylist \u003c- readRDS(\"mylist.rds\")  Copy and paste into R On Windows/Linux systems\nread.delim(\"clipboard\")  On Mac OS X systems\nread.delim(pipe(\"pbpaste\"))  Copy and paste from R On Windows/Linux systems\nwrite.table(iris, \"clipboard\", sep=\"\\t\", col.names=NA, quote=FALSE)  On Mac OS X systems\nzz \u003c- pipe('pbcopy', 'w') write.table(iris, zz, sep=\"\\t\", col.names=NA, quote=FALSE) close(zz)  Homework 3A Homework 3A: Object Subsetting Routines and Import/Export\nUseful R Functions Unique entries Make vector entries unique with unique\nlength(iris$Sepal.Length)  ## [1] 150  length(unique(iris$Sepal.Length))  ## [1] 35  Count occurrences Count occurrences of entries with table\ntable(iris$Species)  ## ## setosa versicolor virginica ## 50 50 50  Aggregate data Compute aggregate statistics with aggregate\naggregate(iris[,1:4], by=list(iris$Species), FUN=mean, na.rm=TRUE)  ## Group.1 Sepal.Length Sepal.Width Petal.Length Petal.Width ## 1 setosa 5.006 3.428 1.462 0.246 ## 2 versicolor 5.936 2.770 4.260 1.326 ## 3 virginica 6.588 2.974 5.552 2.026  Intersect data Compute intersect between two vectors with %in%\nmonth.name %in% c(\"May\", \"July\")  ## [1] FALSE FALSE FALSE FALSE TRUE FALSE TRUE FALSE FALSE FALSE FALSE FALSE  Merge data frames Join two data frames by common field entries with merge (here row names by.x=0). To obtain only the common rows, change all=TRUE to all=FALSE. To merge on specific columns, refer to them by their position numbers or their column names.\nframe1 \u003c- iris[sample(1:length(iris[,1]), 30), ] frame1[1:2,]  ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 55 6.5 2.8 4.6 1.5 versicolor ## 49 5.3 3.7 1.5 0.2 setosa  dim(frame1)  ## [1] 30 5  my_result \u003c- merge(frame1, iris, by.x = 0, by.y = 0, all = TRUE) dim(my_result)  ## [1] 150 11  Graphics in R Advantages  Powerful environment for visualizing scientific data Integrated graphics and statistics infrastructure Publication quality graphics Fully programmable Highly reproducible Full LaTeX and Markdown support via knitr and R markdown Vast number of R packages with graphics utilities  Documentation for R Graphics General\n Graphics Task Page - URL R Graph Gallery - URL R Graphical Manual - URL Paul Murrell’s book R (Grid) Graphics - URL  Interactive graphics\n rggobi` (GGobi) - URL iplots - URL Open GL (rgl) - URL  Graphics Environments Viewing and saving graphics in R\n On-screen graphics postscript, pdf, svg jpeg, png, wmf, tiff, …  Four major graphic environments\n Low-level infrastructure   R Base Graphics (low- and high-level) grid: Manual  High-level infrastructure \\begin{itemize}   lattice: Manual, Intro, Book ggplot2: Manual, Intro, Book  Base Graphics: Overview Important high-level plotting functions\n plot: generic x-y plotting barplot: bar plots boxplot: box-and-whisker plot hist: histograms pie: pie charts dotchart: cleveland dot plots image, heatmap, contour, persp: functions to generate image-like plots qqnorm, qqline, qqplot: distribution comparison plots pairs, coplot: display of multivariant data  Help on graphics functions\n ?myfct ?plot ?par  Preferred Object Types  Matrices and data frames Vectors Named vectors  Scatter Plots Basic Scatter Plot Sample data set for subsequent plots\nset.seed(1410) y \u003c- matrix(runif(30), ncol=3, dimnames=list(letters[1:10], LETTERS[1:3]))  Plot data\nplot(y[,1], y[,2])  All pairs pairs(y)  With labels plot(y[,1], y[,2], pch=20, col=\"red\", main=\"Symbols and Labels\") text(y[,1]+0.03, y[,2], rownames(y))  More examples Print instead of symbols the row names\nplot(y[,1], y[,2], type=\"n\", main=\"Plot of Labels\") text(y[,1], y[,2], rownames(y))  Usage of important plotting parameters\ngrid(5, 5, lwd = 2) op \u003c- par(mar=c(8,8,8,8), bg=\"lightblue\") plot(y[,1], y[,2], type=\"p\", col=\"red\", cex.lab=1.2, cex.axis=1.2, cex.main=1.2, cex.sub=1, lwd=4, pch=20, xlab=\"x label\", ylab=\"y label\", main=\"My Main\", sub=\"My Sub\") par(op)  Important arguments\n mar: specifies the margin sizes around the plotting area in order: c(bottom, left, top, right) col: color of symbols pch: type of symbols, samples: example(points) lwd: size of symbols cex.*: control font sizes For details see ?par  Add regression line plot(y[,1], y[,2]) myline \u003c- lm(y[,2]~y[,1]); abline(myline, lwd=2)  summary(myline)  ## ## Call: ## lm(formula = y[, 2] ~ y[, 1]) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.40357 -0.17912 -0.04299 0.22147 0.46623 ## ## Coefficients: ## Estimate Std. Error t value Pr(\u003e|t|) ## (Intercept) 0.5764 0.2110 2.732 0.0258 * ## y[, 1] -0.3647 0.3959 -0.921 0.3839 ## --- ## Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ## ## Residual standard error: 0.3095 on 8 degrees of freedom ## Multiple R-squared: 0.09589, Adjusted R-squared: -0.01712 ## F-statistic: 0.8485 on 1 and 8 DF, p-value: 0.3839  Log scale Same plot as above, but on log scale\nplot(y[,1], y[,2], log=\"xy\")  Add a mathematical expression plot(y[,1], y[,2]); text(y[1,1], y[1,2], expression(sum(frac(1,sqrt(x^2*pi)))), cex=1.3)  Homework 3B Homework 3B: Scatter Plots\nLine Plots Single data set plot(y[,1], type=\"l\", lwd=2, col=\"blue\")  Many Data Sets Plots line graph for all columns in data frame y. The split.screen function is used in this example in a for loop to overlay several line graphs in the same plot.\nsplit.screen(c(1,1))  ## [1] 1  plot(y[,1], ylim=c(0,1), xlab=\"Measurement\", ylab=\"Intensity\", type=\"l\", lwd=2, col=1) for(i in 2:length(y[1,])) { screen(1, new=FALSE) plot(y[,i], ylim=c(0,1), type=\"l\", lwd=2, col=i, xaxt=\"n\", yaxt=\"n\", ylab=\"\", xlab=\"\", main=\"\", bty=\"n\") }  close.screen(all=TRUE)  Bar Plots Basics barplot(y[1:4,], ylim=c(0, max(y[1:4,])+0.3), beside=TRUE, legend=letters[1:4]) text(labels=round(as.vector(as.matrix(y[1:4,])),2), x=seq(1.5, 13, by=1) + sort(rep(c(0,1,2), 4)), y=as.vector(as.matrix(y[1:4,]))+0.04)  Error Bars bar \u003c- barplot(m \u003c- rowMeans(y) * 10, ylim=c(0, 10)) stdev \u003c- sd(t(y)) arrows(bar, m, bar, m + stdev, length=0.15, angle = 90)  Histograms hist(y, freq=TRUE, breaks=10)  Density Plots plot(density(y), col=\"red\")  Pie Charts pie(y[,1], col=rainbow(length(y[,1]), start=0.1, end=0.8), clockwise=TRUE) legend(\"topright\", legend=row.names(y), cex=1.3, bty=\"n\", pch=15, pt.cex=1.8, col=rainbow(length(y[,1]), start=0.1, end=0.8), ncol=1)  Color Selection Utilities Default color palette and how to change it\npalette()  ## [1] \"black\" \"#DF536B\" \"#61D04F\" \"#2297E6\" \"#28E2E5\" \"#CD0BBC\" \"#F5C710\" \"gray62\"  palette(rainbow(5, start=0.1, end=0.2)) palette()  ## [1] \"#FF9900\" \"#FFBF00\" \"#FFE600\" \"#F2FF00\" \"#CCFF00\"  palette(\"default\")  The gray function allows to select any type of gray shades by providing values from 0 to 1\ngray(seq(0.1, 1, by= 0.2))  ## [1] \"#1A1A1A\" \"#4D4D4D\" \"#808080\" \"#B3B3B3\" \"#E6E6E6\"  Color gradients with colorpanel function from gplots library`\nlibrary(gplots) colorpanel(5, \"darkblue\", \"yellow\", \"white\")  ## [1] \"#00008B\" \"#808046\" \"#FFFF00\" \"#FFFF80\" \"#FFFFFF\"  Much more on colors in R see Earl Glynn’s color chart here\nSaving Graphics to File After the pdf() command all graphs are redirected to file test.pdf. Works for all common formats similarly: jpeg, png, ps, tiff, …\npdf(\"test.pdf\") plot(1:10, 1:10) dev.off()  Generates Scalable Vector Graphics (SVG) files that can be edited in vector graphics programs, such as InkScape.\nlibrary(\"RSvgDevice\") devSVG(\"test.svg\") plot(1:10, 1:10) dev.off()  Homework 3C Homework 3C: Bar Plots\nAnalysis Routine Overview The following exercise introduces a variety of useful data analysis utilities in R.\nAnalysis Routine: Data Import   Step 1: To get started with this exercise, direct your R session to a dedicated workshop directory and download into this directory the following sample tables. Then import the files into Excel and save them as tab delimited text files.\n MolecularWeight_tair7.xls TargetP_analysis_tair7.xls    Import the tables into R\nImport molecular weight table\nmy_mw \u003c- read.delim(file=\"MolecularWeight_tair7.xls\", header=TRUE, sep=\"\\t\") my_mw[1:2,]  Import subcelluar targeting table\nmy_target \u003c- read.delim(file=\"TargetP_analysis_tair7.xls\", header=TRUE, sep=\"\\t\") my_target[1:2,]  Online import of molecular weight table\nmy_mw \u003c- read.delim(file=\"http://faculty.ucr.edu/~tgirke/Documents/R_BioCond/Samples/MolecularWeight_tair7.xls\", header=TRUE, sep=\"\\t\") my_mw[1:2,]  ## Sequence.id Molecular.Weight.Da. Residues ## 1 AT1G08520.1 83285 760 ## 2 AT1G08530.1 27015 257  Online import of subcelluar targeting table\nmy_target \u003c- read.delim(file=\"http://faculty.ucr.edu/~tgirke/Documents/R_BioCond/Samples/TargetP_analysis_tair7.xls\", header=TRUE, sep=\"\\t\") my_target[1:2,]  ## GeneName Loc cTP mTP SP other ## 1 AT1G08520.1 C 0.822 0.137 0.029 0.039 ## 2 AT1G08530.1 C 0.817 0.058 0.010 0.100  Merging Data Frames  Step 2: Assign uniform gene ID column titles  colnames(my_target)[1] \u003c- \"ID\" colnames(my_mw)[1] \u003c- \"ID\"   Step 3: Merge the two tables based on common ID field  my_mw_target \u003c- merge(my_mw, my_target, by.x=\"ID\", by.y=\"ID\", all.x=T)   Step 4: Shorten one table before the merge and then remove the non-matching rows (NAs) in the merged file  my_mw_target2a \u003c- merge(my_mw, my_target[1:40,], by.x=\"ID\", by.y=\"ID\", all.x=T) # To remove non-matching rows, use the argument setting 'all=F'. my_mw_target2 \u003c- na.omit(my_mw_target2a) # Removes rows containing \"NAs\" (non-matching rows).   Homework 3D: How can the merge function in the previous step be executed so that only the common rows among the two data frames are returned? Prove that both methods - the two step version with na.omit and your method - return identical results. Homework 3E: Replace all NAs in the data frame my_mw_target2a with zeros.  Filtering Data  Step 5: Retrieve all records with a value of greater than 100,000 in ‘MW’ column and ‘C’ value in ‘Loc’ column (targeted to chloroplast).  query \u003c- my_mw_target[my_mw_target[, 2] \u003e 100000 \u0026 my_mw_target[, 4] == \"C\", ] query[1:4, ]  ## ID Molecular.Weight.Da. Residues Loc cTP mTP SP other ## 219 AT1G02730.1 132588 1181 C 0.972 0.038 0.008 0.045 ## 243 AT1G02890.1 136825 1252 C 0.748 0.529 0.011 0.013 ## 281 AT1G03160.1 100732 912 C 0.871 0.235 0.011 0.007 ## 547 AT1G05380.1 126360 1138 C 0.740 0.099 0.016 0.358  dim(query)  ## [1] 170 8   Homework 3F: How many protein entries in the my_mw_target data frame have a MW of greater then 4,000 and less then 5,000. Subset the data frame accordingly and sort it by MW to check that your result is correct.  String Substitutions  Step 6: Use a regular expression in a substitute function to generate a separate ID column that lacks the gene model extensions.  my_mw_target3 \u003c- data.frame(loci=gsub(\"\\\\..*\", \"\", as.character(my_mw_target[,1]), perl = TRUE), my_mw_target) my_mw_target3[1:3,1:8]  ## loci ID Molecular.Weight.Da. Residues Loc cTP mTP SP ## 1 AT1G01010 AT1G01010.1 49426 429 _ 0.10 0.090 0.075 ## 2 AT1G01020 AT1G01020.1 28092 245 * 0.01 0.636 0.158 ## 3 AT1G01020 AT1G01020.2 21711 191 * 0.01 0.636 0.158   Homework 3G: Retrieve those rows in my_mw_target3 where the second column contains the following identifiers: c(\"AT5G52930.1\", \"AT4G18950.1\", \"AT1G15385.1\", \"AT4G36500.1\", \"AT1G67530.1\"). Use the %in% function for this query. As an alternative approach, assign the second column to the row index of the data frame and then perform the same query again using the row index. Explain the difference of the two methods.  Calculations on Data Frames  Step 7: Count the number of duplicates in the loci column with the table function and append the result to the data frame with the cbind function.  mycounts \u003c- table(my_mw_target3[,1])[my_mw_target3[,1]] my_mw_target4 \u003c- cbind(my_mw_target3, Freq=mycounts[as.character(my_mw_target3[,1])])   Step 8: Perform a vectorized devision of columns 3 and 4 (average AA weight per protein)  data.frame(my_mw_target4, avg_AA_WT=(my_mw_target4[,3] / my_mw_target4[,4]))[1:2,]  ## loci ID Molecular.Weight.Da. Residues Loc cTP mTP SP other Freq.Var1 ## 1 AT1G01010 AT1G01010.1 49426 429 _ 0.10 0.090 0.075 0.925 AT1G01010 ## 2 AT1G01020 AT1G01020.1 28092 245 * 0.01 0.636 0.158 0.448 AT1G01020 ## Freq.Freq avg_AA_WT ## 1 1 115.2121 ## 2 2 114.6612   Step 9: Calculate for each row the mean and standard deviation across several columns  mymean \u003c- apply(my_mw_target4[,6:9], 1, mean) mystdev \u003c- apply(my_mw_target4[,6:9], 1, sd, na.rm=TRUE) data.frame(my_mw_target4, mean=mymean, stdev=mystdev)[1:2,5:12]  ## Loc cTP mTP SP other Freq.Var1 Freq.Freq mean ## 1 _ 0.10 0.090 0.075 0.925 AT1G01010 1 0.2975 ## 2 * 0.01 0.636 0.158 0.448 AT1G01020 2 0.3130  Plotting Example  Step 10: Generate scatter plot columns: ‘MW’ and ‘Residues’  plot(my_mw_target4[1:500,3:4], col=\"red\")  Export Results and Run Entire Exercise as Script  Step 11: Write the data frame my_mw_target4 into a tab-delimited text file and inspect it in Excel.  write.table(my_mw_target4, file=\"my_file.xls\", quote=FALSE, sep=\"\\t\", col.names = NA)   Homework 3H: Write all commands from this exercise into an R script named exerciseRbasics.R, or download it from here. Then execute the script with the source function like this: source(\"exerciseRbasics.R\"). This will run all commands of this exercise and generate the corresponding output files in the current working directory.  source(\"exerciseRbasics.R\")  Session Info sessionInfo()  ## R version 4.0.3 (2020-10-10) ## Platform: x86_64-pc-linux-gnu (64-bit) ## Running under: Debian GNU/Linux 10 (buster) ## ## Matrix products: default ## BLAS: /usr/lib/x86_64-linux-gnu/blas/libblas.so.3.8.0 ## LAPACK: /usr/lib/x86_64-linux-gnu/lapack/liblapack.so.3.8.0 ## ## locale: ## [1] LC_CTYPE=en_US.UTF-8 LC_NUMERIC=C LC_TIME=en_US.UTF-8 ## [4] LC_COLLATE=en_US.UTF-8 LC_MONETARY=en_US.UTF-8 LC_MESSAGES=en_US.UTF-8 ## [7] LC_PAPER=en_US.UTF-8 LC_NAME=C LC_ADDRESS=C ## [10] LC_TELEPHONE=C LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C ## ## attached base packages: ## [1] stats graphics grDevices utils datasets methods base ## ## other attached packages: ## [1] knitr_1.30 gplots_3.1.1 RSQLite_2.2.1 data.table_1.13.2 forcats_0.5.0 ## [6] stringr_1.4.0 dplyr_1.0.2 purrr_0.3.4 readr_1.4.0 tidyr_1.1.2 ## [11] tibble_3.0.4 tidyverse_1.3.0 ggplot2_3.3.2 limma_3.46.0 BiocStyle_2.18.0 ## ## loaded via a namespace (and not attached): ## [1] httr_1.4.2 viridisLite_0.3.0 bit64_4.0.5 jsonlite_1.7.1 ## [5] modelr_0.1.8 gtools_3.8.2 assertthat_0.2.1 BiocManager_1.30.10 ## [9] highr_0.8 blob_1.2.1 cellranger_1.1.0 yaml_2.2.1 ## [13] pillar_1.4.7 backports_1.2.0 glue_1.4.2 digest_0.6.27 ## [17] rvest_0.3.6 colorspace_2.0-0 htmltools_0.5.1.1 plyr_1.8.6 ## [21] pkgconfig_2.0.3 broom_0.7.2 haven_2.3.1 bookdown_0.21 ## [25] scales_1.1.1 generics_0.1.0 farver_2.0.3 ellipsis_0.3.1 ## [29] withr_2.3.0 cli_2.2.0 magrittr_2.0.1 crayon_1.3.4 ## [33] readxl_1.3.1 memoise_1.1.0 evaluate_0.14 ps_1.4.0 ## [37] fs_1.5.0 fansi_0.4.1 xml2_1.3.2 blogdown_1.1.7 ## [41] tools_4.0.3 hms_0.5.3 lifecycle_0.2.0 munsell_0.5.0 ## [45] reprex_0.3.0 compiler_4.0.3 caTools_1.18.1 rlang_0.4.8 ## [49] grid_4.0.3 rstudioapi_0.13 bitops_1.0-6 labeling_0.4.2 ## [53] rmarkdown_2.5 gtable_0.3.0 codetools_0.2-16 DBI_1.1.0 ## [57] reshape2_1.4.4 R6_2.5.0 lubridate_1.7.9.2 bit_4.0.4 ## [61] utf8_1.1.4 KernSmooth_2.23-17 stringi_1.5.3 Rcpp_1.0.5 ## [65] vctrs_0.3.5 dbplyr_2.0.0 tidyselect_1.1.0 xfun_0.20  References ","categories":"","description":"","excerpt":"document.addEventListener(\"DOMContentLoaded\", function() { …","ref":"/tutorials/rbasics/rbasics/","tags":"","title":"Introduction to R"},{"body":"document.addEventListener(\"DOMContentLoaded\", function() { document.querySelector(\"h1\").className = \"title\"; });  document.addEventListener(\"DOMContentLoaded\", function() { var links = document.links; for (var i = 0, linksLength = links.length; i Source code downloads: [ .Rmd ] [ .R ]\n Overview One of the main attractions of using the R (http://cran.at.r-project.org) environment is the ease with which users can write their own programs and custom functions. The R programming syntax is extremely easy to learn, even for users with no previous programming experience. Once the basic R programming control structures are understood, users can use the R language as a powerful environment to perform complex custom analyses of almost any type of data (Gentleman 2008).\nWhy Programming in R?  Powerful statistical environment and programming language Facilitates reproducible research Efficient data structures make programming very easy Ease of implementing custom functions Powerful graphics Access to fast growing number of analysis packages One of the most widely used languages in bioinformatics Is standard for data mining and biostatistical analysis Technical advantages: free, open-source, available for all OSs  R Basics The previous Rbasics tutorial provides a general introduction to the usage of the R environment and its basic command syntax. More details can be found in the R \u0026 BioConductor manual here.\nCode Editors for R Several excellent code editors are available that provide functionalities like R syntax highlighting, auto code indenting and utilities to send code/functions to the R console.\n RStudio: GUI-based IDE for R Vim-R-Tmux: R working environment based on vim and tmux Emacs (ESS add-on package) gedit and Rgedit RKWard Eclipse Tinn-R Notepad++ (NppToR)   Programming in R using RStudio     Programming in R using Vim or Emacs    Finding Help Reference list on R programming (selection)\n Advanced R, by Hadley Wickham R Programming for Bioinformatics, by Robert Gentleman S Programming, by W. N. Venables and B. D. Ripley Programming with Data, by John M. Chambers R Help \u0026 R Coding Conventions, Henrik Bengtsson, Lund University Programming in R (Vincent Zoonekynd) Peter’s R Programming Pages, University of Warwick Rtips, Paul Johnsson, University of Kansas R for Programmers, Norm Matloff, UC Davis High-Performance R, Dirk Eddelbuettel tutorial presented at useR-2008 C/C++ level programming for R, Gopi Goswami  Control Structures Important Operators Comparison operators  == (equal) != (not equal) \u003e (greater than) \u003e= (greater than or equal) \u003c (less than) \u003c= (less than or equal)  Logical operators  \u0026 (and) \u0026\u0026 (and) | (or) || (or) ! (not)  Note: \u0026 and \u0026\u0026 indicate logical AND, while | and || indicate logical OR. The shorter form performs element-wise comparisons of same-length vectors. The longer form evaluates left to right examining only the first element of each vector (can be of different lengths). Evaluation proceeds only until the result is determined. The longer form is preferred for programming control-flow, e.g. via if clauses.\nConditional Executions: if Statements An if statement operates on length-one logical vectors.\nSyntax\nif (TRUE) { statements_1 } else { statements_2 }  In the else component, avoid inserting newlines between } else. For details on how to best and consistently format R code, this style guide is a good start. In addition, the formatR package can be helpful.\nExample\nif (1==0) { print(1) } else { print(2) }  ## [1] 2  Conditional Executions: ifelse Statements The ifelse statement operates on vectors.\nSyntax\nifelse(test, true_value, false_value)  Example\nx \u003c- 1:10 ifelse(x\u003c5, sqrt(x), 0)  ## [1] 1.000000 1.414214 1.732051 2.000000 0.000000 0.000000 0.000000 0.000000 0.000000 0.000000  Loops for loop for loops iterate over elements of a looping vector.\nSyntax\nfor(variable in sequence) { statements }  Example\nmydf \u003c- iris myve \u003c- NULL for(i in seq(along=mydf[,1])) { myve \u003c- c(myve, mean(as.numeric(mydf[i,1:3]))) } myve[1:8]  ## [1] 3.333333 3.100000 3.066667 3.066667 3.333333 3.666667 3.133333 3.300000  Note: Inject into objecs is much faster than append approach with c, cbind, etc.\nExample\nmyve \u003c- numeric(length(mydf[,1])) for(i in seq(along=myve)) { myve[i] \u003c- mean(as.numeric(mydf[i,1:3])) } myve[1:8]  ## [1] 3.333333 3.100000 3.066667 3.066667 3.333333 3.666667 3.133333 3.300000  Conditional Stop of Loops The stop function can be used to break out of a loop (or a function) when a condition becomes TRUE. In addition, an error message will be printed.\nExample\nx \u003c- 1:10 z \u003c- NULL for(i in seq(along=x)) { if (x[i] \u003c 5) { z \u003c- c(z, x[i]-1) } else { stop(\"values need to be \u003c 5\") } }  while loop Iterates as long as a condition is true.\nSyntax\nwhile(condition) { statements }  Example\nz \u003c- 0 while(z\u003c5) { z \u003c- z + 2 print(z) }  ## [1] 2 ## [1] 4 ## [1] 6  The apply Function Family apply Syntax\napply(X, MARGIN, FUN, ARGs)  Arguments\n X: array, matrix or data.frame MARGIN: 1 for rows, 2 for columns FUN: one or more functions ARGs: possible arguments for functions  Example\napply(iris[1:8,1:3], 1, mean)  ## 1 2 3 4 5 6 7 8 ## 3.333333 3.100000 3.066667 3.066667 3.333333 3.666667 3.133333 3.300000  tapply Applies a function to vector components that are defined by a factor.\nSyntax\ntapply(vector, factor, FUN)  Example\niris[1:2,]  ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 1 5.1 3.5 1.4 0.2 setosa ## 2 4.9 3.0 1.4 0.2 setosa  tapply(iris$Sepal.Length, iris$Species, mean)  ## setosa versicolor virginica ## 5.006 5.936 6.588  sapply, lapply and vapply The iterator functions sapply, lapply and vapply apply a function to vectors or lists. The lapply function always returns a list, while sapply returns vector or matrix objects when possible. If not then a list is returned. The vapply function returns a vector or array of type matching the FUN.VALUE. Compared to sapply, vapply is a safer choice with respect to controlling specific output types to avoid exception handling problems.\nExamples\nl \u003c- list(a = 1:10, beta = exp(-3:3), logic = c(TRUE,FALSE,FALSE,TRUE)) lapply(l, mean)  ## $a ## [1] 5.5 ## ## $beta ## [1] 4.535125 ## ## $logic ## [1] 0.5  sapply(l, mean)  ## a beta logic ## 5.500000 4.535125 0.500000  vapply(l, mean, FUN.VALUE=numeric(1))  ## a beta logic ## 5.500000 4.535125 0.500000  Often used in combination with a function definition:\nlapply(names(l), function(x) mean(l[[x]])) sapply(names(l), function(x) mean(l[[x]])) vapply(names(l), function(x) mean(l[[x]]), FUN.VALUE=numeric(1))  Functions Function Overview A very useful feature of the R environment is the possibility to expand existing functions and to easily write custom functions. In fact, most of the R software can be viewed as a series of R functions.\nSyntax to define function\nmyfct \u003c- function(arg1, arg2, ...) { function_body }  Syntax to call functions\nmyfct(arg1=..., arg2=...)  The value returned by a function is the value of the function body, which is usually an unassigned final expression, e.g.: return()\nFunction Syntax Rules General\n Functions are defined by  The assignment with the keyword function The declaration of arguments/variables (arg1, arg2, ...) The definition of operations (function_body) that perform computations on the provided arguments. A function name needs to be assigned to call the function.    Naming\n Function names can be almost anything. However, the usage of names of existing functions should be avoided.  Arguments\n It is often useful to provide default values for arguments (e.g.: arg1=1:10). This way they don’t need to be provided in a function call. The argument list can also be left empty (myfct \u003c- function() { fct_body }) if a function is expected to return always the same value(s). The argument ... can be used to allow one function to pass on argument settings to another.  Body\n The actual expressions (commands/operations) are defined in the function body which should be enclosed by braces. The individual commands are separated by semicolons or new lines (preferred).  Usage\n Functions are called by their name followed by parentheses containing possible argument names. Empty parenthesis after the function name will result in an error message when a function requires certain arguments to be provided by the user. The function name alone will print the definition of a function.  Scope\n Variables created inside a function exist only for the life time of a function. Thus, they are not accessible outside of the function. To force variables in functions to exist globally, one can use the double assignment operator: \u003c\u003c-  Examples Define sample function\nmyfct \u003c- function(x1, x2=5) { z1 \u003c- x1 / x1 z2 \u003c- x2 * x2 myvec \u003c- c(z1, z2) return(myvec) }  Function usage\nApply function to values 2 and 5\nmyfct(x1=2, x2=5)  ## [1] 1 25  Run without argument names\nmyfct(2, 5)  ## [1] 1 25  Makes use of default value 5\nmyfct(x1=2)  ## [1] 1 25  Print function definition (often unintended)\nmyfct  ## function(x1, x2=5) { ## z1 \u003c- x1 / x1 ## z2 \u003c- x2 * x2 ## myvec \u003c- c(z1, z2) ## return(myvec) ## } ## \u003cbytecode: 0x5865ccde4df0\u003e  Useful Utilities Debugging Utilities Several debugging utilities are available for R. They include:\n traceback browser options(error=recover) options(error=NULL) debug  The Debugging in R page provides an overview of the available resources.\nRegular Expressions R’s regular expression utilities work similar as in other languages. To learn how to use them in R, one can consult the main help page on this topic with ?regexp.\nString matching with grep The grep function can be used for finding patterns in strings, here letter A in vector month.name.\nmonth.name[grep(\"A\", month.name)]  ## [1] \"April\" \"August\"  String substitution with gsub Example for using regular expressions to substitute a pattern by another one using a back reference. Remember: single escapes \\ need to be double escaped \\\\ in R.\ngsub('(i.*a)', 'xxx_\\\\1', \"virginica\", perl = TRUE)  ## [1] \"vxxx_irginica\"  Interpreting a Character String as Expression Some useful examples\nGenerates vector of object names in session\nmyfct \u003c- function(x) x^2 mylist \u003c- ls() n \u003c- which(mylist %in% \"myfct\") mylist[n]  ## [1] \"myfct\"  Executes entry in position n as expression\nget(mylist[n])  ## function(x) x^2  get(mylist[n])(2)  ## [1] 4  Alternative approach\neval(parse(text=mylist[n]))  ## function(x) x^2  Replacement, Split and Paste Functions for Strings Selected examples\nSubstitution with back reference which inserts in this example _ character\nx \u003c- gsub(\"(a)\",\"\\\\1_\", month.name[1], perl=T) x  ## [1] \"Ja_nua_ry\"  Split string on inserted character from above\nstrsplit(x,\"_\")  ## [[1]] ## [1] \"Ja\" \"nua\" \"ry\"  Reverse a character string by splitting first all characters into vector fields\npaste(rev(unlist(strsplit(x, NULL))), collapse=\"\")  ## [1] \"yr_aun_aJ\"  Time, Date and Sleep Selected examples\nReturn CPU (and other) times that an expression used (here ls)\nsystem.time(ls())  ## user system elapsed ## 0 0 0  Return the current system date and time\ndate()  ## [1] \"Sat Feb 13 18:30:39 2021\"  Pause execution of R expressions for a given number of seconds (e.g. in loop)\nSys.sleep(1)  Example Import of Specific File Lines with Regular Expression The following example demonstrates the retrieval of specific lines from an external file with a regular expression. First, an external file is created with the cat function, all lines of this file are imported into a vector with readLines, the specific elements (lines) are then retieved with the grep function, and the resulting lines are split into vector fields with strsplit.\ncat(month.name, file=\"zzz.txt\", sep=\"\\n\") x \u003c- readLines(\"zzz.txt\") x[1:6]  ## [1] \"January\" \"February\" \"March\" \"April\" \"May\" \"June\"  x \u003c- x[c(grep(\"^J\", as.character(x), perl = TRUE))] t(as.data.frame(strsplit(x, \"u\")))  ## [,1] [,2] ## c..Jan....ary.. \"Jan\" \"ary\" ## c..J....ne.. \"J\" \"ne\" ## c..J....ly.. \"J\" \"ly\"  Calling External Software External command-line software can be called with system. The following example calls blastall from R\nsystem(\"blastall -p blastp -i seq.fasta -d uniprot -o seq.blastp\")  Running R Scripts Possibilities for Executing R Scripts R console source(\"my_script.R\")  Command-line Rscript my_script.R # or just ./myscript.R after making it executable R CMD BATCH my_script.R # Alternative way 1 R --slave \u003c my_script.R # Alternative way 2  Passing arguments from command-line to R Create an R script named test.R with the following content:\nmyarg \u003c- commandArgs() print(iris[1:myarg[6], ])  Then run it from the command-line like this:\nRscript test.R 10  In the given example the number 10 is passed on from the command-line as an argument to the R script which is used to return to STDOUT the first 10 rows of the iris sample data. If several arguments are provided, they will be interpreted as one string and need to be split in R with the strsplit function. A more detailed example can be found here.\nBuilding R Packages Short Overview of Package Building Process R packages can be built with the package.skeleton function. The given example will create a directory named mypackage containing the skeleton of the package for all functions, methods and classes defined in the R script(s) passed on to the code_files argument. The basic structure of the package directory is described here. The package directory will also contain a file named Read-and-delete-me with instructions for completing the package:\npackage.skeleton(name=\"mypackage\", code_files=c(\"script1.R\", \"script2.R\"))  Once a package skeleton is available one can build the package from the command-line (Linux/OS X). This will create a tarball of the package with its version number encoded in the file name. Subequently, the package tarball needs to be checked for errors with:\nR CMD build mypackage R CMD check mypackage_1.0.tar.gz  Install package from source\ninstall.packages(\"mypackage_1.0.tar.gz\", repos=NULL)  For more details see here. Additional utilities for building R packages are provided by devtools::create and usethis::create_package functions. For details see the R Packages online book by Hadley Wickham and Jenny Bryan here.\nProgramming Exercises Exercise 1 for loop Task 1.1: Compute the mean of each row in myMA by applying the mean function in a for loop.\nmyMA \u003c- matrix(rnorm(500), 100, 5, dimnames=list(1:100, paste(\"C\", 1:5, sep=\"\"))) myve_for \u003c- NULL for(i in seq(along=myMA[,1])) { myve_for \u003c- c(myve_for, mean(as.numeric(myMA[i, ]))) } myResult \u003c- cbind(myMA, mean_for=myve_for) myResult[1:4, ]  ## C1 C2 C3 C4 C5 mean_for ## 1 1.7988703 0.785864023 1.2763288 0.2950553 0.9858471 1.02839310 ## 2 -0.9683694 2.724133446 -0.8274809 -0.3208423 -0.4600894 0.02947028 ## 3 -1.1476365 -0.002864923 1.2573494 0.9574395 1.0390970 0.42067691 ## 4 -0.3476123 0.639676778 -1.4706145 -1.3904486 -0.1612300 -0.54604574  while loop Task 1.2: Compute the mean of each row in myMA by applying the mean function in a while loop.\nz \u003c- 1 myve_while \u003c- NULL while(z \u003c= length(myMA[,1])) { myve_while \u003c- c(myve_while, mean(as.numeric(myMA[z, ]))) z \u003c- z + 1 } myResult \u003c- cbind(myMA, mean_for=myve_for, mean_while=myve_while) myResult[1:4, -c(1,2)]  ## C3 C4 C5 mean_for mean_while ## 1 1.2763288 0.2950553 0.9858471 1.02839310 1.02839310 ## 2 -0.8274809 -0.3208423 -0.4600894 0.02947028 0.02947028 ## 3 1.2573494 0.9574395 1.0390970 0.42067691 0.42067691 ## 4 -1.4706145 -1.3904486 -0.1612300 -0.54604574 -0.54604574  Task 1.3: Confirm that the results from both mean calculations are identical\nall(myResult[,6] == myResult[,7])  ## [1] TRUE  apply loop Task 1.4: Compute the mean of each row in myMA by applying the mean function in an apply loop\nmyve_apply \u003c- apply(myMA, 1, mean) myResult \u003c- cbind(myMA, mean_for=myve_for, mean_while=myve_while, mean_apply=myve_apply) myResult[1:4, -c(1,2)]  ## C3 C4 C5 mean_for mean_while mean_apply ## 1 1.2763288 0.2950553 0.9858471 1.02839310 1.02839310 1.02839310 ## 2 -0.8274809 -0.3208423 -0.4600894 0.02947028 0.02947028 0.02947028 ## 3 1.2573494 0.9574395 1.0390970 0.42067691 0.42067691 0.42067691 ## 4 -1.4706145 -1.3904486 -0.1612300 -0.54604574 -0.54604574 -0.54604574  Avoiding loops Task 1.5: When operating on large data sets it is much faster to use the rowMeans function\nmymean \u003c- rowMeans(myMA) myResult \u003c- cbind(myMA, mean_for=myve_for, mean_while=myve_while, mean_apply=myve_apply, mean_int=mymean) myResult[1:4, -c(1,2,3)]  ## C4 C5 mean_for mean_while mean_apply mean_int ## 1 0.2950553 0.9858471 1.02839310 1.02839310 1.02839310 1.02839310 ## 2 -0.3208423 -0.4600894 0.02947028 0.02947028 0.02947028 0.02947028 ## 3 0.9574395 1.0390970 0.42067691 0.42067691 0.42067691 0.42067691 ## 4 -1.3904486 -0.1612300 -0.54604574 -0.54604574 -0.54604574 -0.54604574  To find out which other built-in functions for basic calculations exist, type ?rowMeans.\nExercise 2 Custom functions Task 2.1: Use the following code as basis to implement a function that allows the user to compute the mean for any combination of columns in a matrix or data frame. The first argument of this function should specify the input data set, the second the mathematical function to be passed on (e.g. mean, sd, max) and the third one should allow the selection of the columns by providing a grouping vector.\nmyMA \u003c- matrix(rnorm(100000), 10000, 10, dimnames=list(1:10000, paste(\"C\", 1:10, sep=\"\"))) myMA[1:2,]  ## C1 C2 C3 C4 C5 C6 C7 C8 C9 ## 1 0.2457294 1.0377898 -0.1467638 -0.3248598 0.6157826 -1.4879414 2.0392123 -0.08362708 0.5044756 ## 2 -0.8500019 -0.7396865 -0.2914722 1.0449035 0.4690041 -0.2100562 0.7917301 0.17614233 0.3136505 ## C10 ## 1 -0.6699119 ## 2 -0.6938574  myList \u003c- tapply(colnames(myMA), c(1,1,1,2,2,2,3,3,4,4), list) names(myList) \u003c- sapply(myList, paste, collapse=\"_\") myMAmean \u003c- sapply(myList, function(x) apply(myMA[,x], 1, mean)) myMAmean[1:4,]  ## C1_C2_C3 C4_C5_C6 C7_C8 C9_C10 ## 1 0.37891844 -0.39900621 0.9777926 -0.08271812 ## 2 -0.62705354 0.43461709 0.4839362 -0.19010345 ## 3 0.44567197 -0.03322511 -0.1556891 -0.56857498 ## 4 -0.07690464 0.66825754 -0.3142668 -0.43291652  Exercise 3 Nested loops to generate similarity matrices Task 3.1: Create a sample list populated with character vectors of different lengths\nsetlist \u003c- lapply(11:30, function(x) sample(letters, x, replace=TRUE)) names(setlist) \u003c- paste(\"S\", seq(along=setlist), sep=\"\") setlist[1:6]  ## $S1 ## [1] \"t\" \"y\" \"l\" \"w\" \"x\" \"c\" \"w\" \"i\" \"n\" \"v\" \"v\" ## ## $S2 ## [1] \"t\" \"f\" \"q\" \"z\" \"e\" \"g\" \"u\" \"m\" \"q\" \"t\" \"l\" \"f\" ## ## $S3 ## [1] \"j\" \"g\" \"t\" \"z\" \"l\" \"q\" \"p\" \"k\" \"a\" \"k\" \"s\" \"q\" \"y\" ## ## $S4 ## [1] \"y\" \"g\" \"j\" \"n\" \"a\" \"x\" \"h\" \"a\" \"t\" \"q\" \"f\" \"u\" \"p\" \"n\" ## ## $S5 ## [1] \"i\" \"c\" \"y\" \"e\" \"k\" \"u\" \"j\" \"v\" \"t\" \"u\" \"q\" \"w\" \"b\" \"q\" \"s\" ## ## $S6 ## [1] \"w\" \"i\" \"d\" \"u\" \"w\" \"m\" \"o\" \"u\" \"v\" \"k\" \"m\" \"t\" \"b\" \"h\" \"h\" \"v\"  Task 3.2: Compute the length for all pairwise intersects of the vectors stored in setlist. The intersects can be determined with the %in% function like this: sum(setlist[[1]] %in% setlist[[2]])\nsetlist \u003c- sapply(setlist, unique) olMA \u003c- sapply(names(setlist), function(x) sapply(names(setlist), function(y) sum(setlist[[x]] %in% setlist[[y]]))) olMA[1:12,]  ## S1 S2 S3 S4 S5 S6 S7 S8 S9 S10 S11 S12 S13 S14 S15 S16 S17 S18 S19 S20 ## S1 9 2 3 4 6 4 4 4 5 5 6 5 5 3 5 5 4 6 7 7 ## S2 2 9 5 5 4 3 4 5 4 6 4 6 5 7 5 4 5 7 5 7 ## S3 3 5 11 7 6 2 4 6 5 3 7 7 5 8 6 5 7 5 6 10 ## S4 4 5 7 12 5 3 6 6 3 6 5 6 6 8 7 6 8 6 7 9 ## S5 6 4 6 5 13 7 4 3 5 6 9 7 7 7 9 4 8 8 8 11 ## S6 4 3 2 3 7 11 3 3 4 7 6 8 4 6 6 6 8 9 7 8 ## S7 4 4 4 6 4 3 12 6 5 7 6 6 8 7 7 7 9 8 9 9 ## S8 4 5 6 6 3 3 6 10 7 5 5 5 6 7 4 7 6 5 7 9 ## S9 5 4 5 3 5 4 5 7 11 5 6 7 6 6 7 7 5 6 7 9 ## S10 5 6 3 6 6 7 7 5 5 14 6 8 6 8 7 9 8 8 11 9 ## S11 6 4 7 5 9 6 6 5 6 6 13 7 4 8 10 6 10 9 10 10 ## S12 5 6 7 6 7 8 6 5 7 8 7 15 6 10 8 9 10 10 7 11  Task 3.3 Plot the resulting intersect matrix as heat map. The image or the pheatmap functions can be used for this.\nlibrary(pheatmap); library(\"RColorBrewer\") pheatmap(olMA, color=brewer.pal(9,\"Blues\"), cluster_rows=FALSE, cluster_cols=FALSE, display_numbers=TRUE, number_format=\"%.0f\", fontsize_number=10)  # image(olMA)  Exercise 4 Build your own R package Task 4.1: Save one or more of your functions to a file called script.R and build the package with the package.skeleton function.\npackage.skeleton(name=\"mypackage\", code_files=c(\"script1.R\"))  Task 4.2: Build tarball of the package\nsystem(\"R CMD build mypackage\")  Task 4.3: Install and use package\ninstall.packages(\"mypackage_1.0.tar.gz\", repos=NULL, type=\"source\") library(mypackage) ?myMAcomp # Opens help for function defined by mypackage  Homework 5 See homework section here.\nSession Info sessionInfo()  ## R version 4.0.3 (2020-10-10) ## Platform: x86_64-pc-linux-gnu (64-bit) ## Running under: Debian GNU/Linux 10 (buster) ## ## Matrix products: default ## BLAS: /usr/lib/x86_64-linux-gnu/blas/libblas.so.3.8.0 ## LAPACK: /usr/lib/x86_64-linux-gnu/lapack/liblapack.so.3.8.0 ## ## locale: ## [1] LC_CTYPE=en_US.UTF-8 LC_NUMERIC=C LC_TIME=en_US.UTF-8 ## [4] LC_COLLATE=en_US.UTF-8 LC_MONETARY=en_US.UTF-8 LC_MESSAGES=en_US.UTF-8 ## [7] LC_PAPER=en_US.UTF-8 LC_NAME=C LC_ADDRESS=C ## [10] LC_TELEPHONE=C LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C ## ## attached base packages: ## [1] stats graphics grDevices utils datasets methods base ## ## other attached packages: ## [1] ggplot2_3.3.2 limma_3.46.0 BiocStyle_2.18.0 ## ## loaded via a namespace (and not attached): ## [1] knitr_1.30 magrittr_2.0.1 tidyselect_1.1.0 munsell_0.5.0 ## [5] colorspace_2.0-0 R6_2.5.0 rlang_0.4.8 dplyr_1.0.2 ## [9] stringr_1.4.0 tools_4.0.3 grid_4.0.3 gtable_0.3.0 ## [13] xfun_0.20 withr_2.3.0 ellipsis_0.3.1 htmltools_0.5.1.1 ## [17] yaml_2.2.1 digest_0.6.27 tibble_3.0.4 lifecycle_0.2.0 ## [21] crayon_1.3.4 bookdown_0.21 purrr_0.3.4 BiocManager_1.30.10 ## [25] codetools_0.2-16 vctrs_0.3.5 glue_1.4.2 evaluate_0.14 ## [29] rmarkdown_2.5 blogdown_1.1.7 stringi_1.5.3 pillar_1.4.7 ## [33] compiler_4.0.3 generics_0.1.0 scales_1.1.1 pkgconfig_2.0.3  References Gentleman, Robert. 2008. R Programming for Bioinformatics (Chapman \u0026 Hall/CRC Computer Science \u0026 Data Analysis). 1 edition. Chapman; Hall/CRC. http://www.amazon.com/Programming-Bioinformatics-Chapman-Computer-Analysis/dp/1420063677.\n  ","categories":"","description":"","excerpt":"document.addEventListener(\"DOMContentLoaded\", function() { …","ref":"/tutorials/rprogramming/rprogramming/","tags":"","title":"Programming in R"},{"body":"  Source code downloads: [ .Rmd ] [ pairwiseAlign_Fct.R ]\n Rendering Instructions To render this R Markdown document, one needs to download the following files to the same directory.\n HW4_key.Rmd: Rmd source file for this document pairwiseAlign_Fct.R: R script defining pairwise alignment functions bibtex.bib: references cited in the text in BibTeX format  Next, one can render the report to HTML, PDF and other formats following the instructions below. Both the HTML and PDF versions are linked here:\n HTML: this report in HTML format PDF: corresponding PDF version  The HTML report can be rendered with rmarkdown::render() as follows.\nrmarkdown::render('HW4_key.Rmd') # From R Rscript -e \"rmarkdown::render('HW4_key.Rmd')\" # From command-line  To render a PDF file instead of HTML, one can instruct the rendering function to do so like this: rmarkdown::render('HW4_key.Rmd', c('pdf_document'). To render to several formats with a single command, one can concatenate the formatting values with c('html_document', 'pdf_document').\nA. Choice of Sequence Type Task 1: Which sequence type - amino acid or nucleotide - is more appropriate to search databases for remotely related sequences? Provide at least three reasons for your decision.\nAnswer: When coding sequences are expected to have weak similarities then one should use protein sequences rather than DNA sequences for database searching, because of (1) their higher information content (20 versus 4 letter alphabet), as well as (2) the better scoring and (3) functional classification systems available for amino acids.\nB. Dynamic Programming for Pairwise Alignments Task 2: Create manually (or write an R script for it) one global and one local alignment for the following two protein sequences using the Needleman-Wusch and Smith-Waterman algorithms, respectively (Smith and Waterman 1981; Needleman and Wunsch 1970).\nO15528: PFGFGKRSCMGRRLA P98187: FIPFSAGPRNCIGQK  Source functions All alignment functions used in the following sections are defined in the downloaded R script file that is named pairwiseAlign_Fct.R. These functions are loaded with the source() command below.\nsource(\"pairwiseAlign_Fct.R\")  Input sequences Define within R or import them (here former).\nS1 \u003c- \"PFGFGKRSCMGRRLA\" S2 \u003c- \"FIPFSAGPRNCIGQK\"  Additional test sequences\n# S1 \u003c- \"HEAGAWGHEE\" # S2 \u003c- \"PAWHEAE\"  Global alignment The alignment type choice is passed on to all following functions.\nalign_type \u003c- \"global\" # align_type \u003c- \"local\"  Dynamic programming matrices dynMA \u003c- dynProgMatrix(S1, S2, align_method=align_type, gap_penalty=8, substitutionMA=\"BLOSUM50\")  The matrices are stored in a list and returned below. The path is indicated by three numbers in the glob_ma_path matrix. Their meaning is:\n 1: diagonal 2: vertical (up) 3: horizontal (left)  dynMA  ## $glob_ma ## gp P F G F G K R S C M G R R L A ## gp 0 -8 -16 -24 -32 -40 -48 -56 -64 -72 -80 -88 -96 -104 -112 -120 ## F -8 -4 0 -8 -16 -24 -32 -40 -48 -56 -64 -72 -80 -88 -96 -104 ## I -16 -11 -4 -4 -8 -16 -24 -32 -40 -48 -54 -62 -70 -78 -86 -94 ## P -24 -6 -12 -6 -8 -10 -17 -25 -33 -41 -49 -56 -64 -72 -80 -87 ## F -32 -14 2 -6 2 -6 -14 -20 -28 -35 -41 -49 -57 -65 -71 -79 ## S -40 -22 -6 2 -6 2 -6 -14 -15 -23 -31 -39 -47 -55 -63 -70 ## A -48 -30 -14 -6 -1 -6 1 -7 -13 -16 -24 -31 -39 -47 -55 -58 ## G -56 -38 -22 -6 -9 7 -1 -2 -7 -15 -19 -16 -24 -32 -40 -48 ## P -64 -46 -30 -14 -10 -1 6 -2 -3 -11 -18 -21 -19 -27 -35 -41 ## R -72 -54 -38 -22 -17 -9 2 13 5 -3 -11 -19 -14 -12 -20 -28 ## N -80 -62 -46 -30 -25 -17 -6 5 14 6 -2 -10 -18 -15 -16 -21 ## C -88 -70 -54 -38 -32 -25 -14 -3 6 27 19 11 3 -5 -13 -17 ## I -96 -78 -62 -46 -38 -33 -22 -11 -2 19 29 21 13 5 -3 -11 ## G -104 -86 -70 -54 -46 -30 -30 -19 -10 11 21 37 29 21 13 5 ## Q -112 -94 -78 -62 -54 -38 -28 -27 -18 3 13 29 38 30 22 14 ## K -120 -102 -86 -70 -62 -46 -32 -25 -26 -5 5 21 32 41 33 25 ## ## $glob_ma_path ## gp P F G F G K R S C M G R R L A ## gp 0 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 ## F 2 1 1 3 1 3 3 3 3 3 3 3 3 3 3 3 ## I 2 1 1 1 1 3 3 3 3 3 1 3 3 3 1 3 ## P 2 1 2 1 1 1 1 3 1 3 3 1 3 3 3 1 ## F 2 2 1 3 1 3 1 1 1 1 1 3 3 3 1 3 ## S 2 2 2 1 2 1 1 3 1 3 3 3 3 3 3 1 ## A 2 2 2 1 1 1 1 3 1 1 1 1 3 3 3 1 ## G 2 2 2 1 2 1 3 1 1 3 1 1 3 3 3 3 ## P 2 1 2 2 1 2 1 3 1 1 1 1 1 1 3 1 ## R 2 2 2 2 1 2 1 1 3 3 3 3 1 1 3 3 ## N 2 2 2 2 2 1 2 2 1 3 3 3 3 1 1 1 ## C 2 2 2 2 1 2 2 2 2 1 3 3 3 3 3 1 ## I 2 2 2 2 1 2 2 2 2 2 1 3 3 3 1 3 ## G 2 2 2 1 2 1 2 2 2 2 2 1 3 3 3 3 ## Q 2 2 2 2 2 2 1 2 2 2 2 2 1 1 3 3 ## K 2 2 2 2 2 2 1 1 2 2 2 2 1 1 3 3  Compute alignment The following alignList stores all relevant results in a list, including dynamic programming matrices, as well as the coordinates (named path_coor) to highlight path in dynamic progamming matrix (see below).\nalignList \u003c- alignmentTraceback(ma=dynMA[[1]], ma_path=dynMA[[2]], align_method=align_type) names(alignList)  ## [1] \"ma\" \"ma_path\" \"path_coor\" \"as1\" \"consensus\" \"as2\" ## [7] \"score\"  # alignList$ma # dyn ma with scores # alignList$ma_path # dyn ma with path # alignList$path_coor # coordinates for path to auto highlight path in HTML/PDF table  Return results Traceback in matrix The following prints the fully populated dynamic programming matrix where the traceback path is highlighted in color.\nprintColMa(alignList)     gp  P  F  G  F  G  K  R  S  C  M  G  R  R  L  A      gp  0  -8  -16  -24  -32  -40  -48  -56  -64  -72  -80  -88  -96  -104  -112  -120    F  -8  -4  0  -8  -16  -24  -32  -40  -48  -56  -64  -72  -80  -88  -96  -104    I  -16  -11  -4  -4  -8  -16  -24  -32  -40  -48  -54  -62  -70  -78  -86  -94    P  -24  -6  -12  -6  -8  -10  -17  -25  -33  -41  -49  -56  -64  -72  -80  -87    F  -32  -14  2  -6  2  -6  -14  -20  -28  -35  -41  -49  -57  -65  -71  -79    S  -40  -22  -6  2  -6  2  -6  -14  -15  -23  -31  -39  -47  -55  -63  -70    A  -48  -30  -14  -6  -1  -6  1  -7  -13  -16  -24  -31  -39  -47  -55  -58    G  -56  -38  -22  -6  -9  7  -1  -2  -7  -15  -19  -16  -24  -32  -40  -48    P  -64  -46  -30  -14  -10  -1  6  -2  -3  -11  -18  -21  -19  -27  -35  -41    R  -72  -54  -38  -22  -17  -9  2  13  5  -3  -11  -19  -14  -12  -20  -28    N  -80  -62  -46  -30  -25  -17  -6  5  14  6  -2  -10  -18  -15  -16  -21    C  -88  -70  -54  -38  -32  -25  -14  -3  6  27  19  11  3  -5  -13  -17    I  -96  -78  -62  -46  -38  -33  -22  -11  -2  19  29  21  13  5  -3  -11    G  -104  -86  -70  -54  -46  -30  -30  -19  -10  11  21  37  29  21  13  5    Q  -112  -94  -78  -62  -54  -38  -28  -27  -18  3  13  29  38  30  22  14    K  -120  -102  -86  -70  -62  -46  -32  -25  -26  -5  5  21  32  41  33  25     Alignment and score printAlign(x=alignList)  ## ## S1: --PFGFGKRSCMGRRLA ## || | | | | ## S2: FIPFSAGPRNCIGQK-- ## ## Score of alignment: 25  Local alignment The alignment type choice is passed on to all following functions.\n# align_type \u003c- \"global\" align_type \u003c- \"local\"  Dynamic programming matrices dynMA \u003c- dynProgMatrix(S1, S2, align_method=align_type, gap_penalty=8, substitutionMA=\"BLOSUM50\")  The matrices are stored in a list and returned below.\ndynMA  ## $loc_ma ## gp P F G F G K R S C M G R R L A ## gp 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ## F 0 0 8 0 8 0 0 0 0 0 0 0 0 0 1 0 ## I 0 0 0 4 0 4 0 0 0 0 2 0 0 0 2 0 ## P 0 10 2 0 0 0 3 0 0 0 0 0 0 0 0 1 ## F 0 2 18 10 8 0 0 0 0 0 0 0 0 0 1 0 ## S 0 0 10 18 10 8 0 0 5 0 0 0 0 0 0 2 ## A 0 0 2 10 15 10 7 0 1 4 0 0 0 0 0 5 ## G 0 0 0 10 7 23 15 7 0 0 1 8 0 0 0 0 ## P 0 10 2 2 6 15 22 14 6 0 0 0 5 0 0 0 ## R 0 2 7 0 0 7 18 29 21 13 5 0 7 12 4 0 ## N 0 0 0 7 0 0 10 21 30 22 14 6 0 6 8 3 ## C 0 0 0 0 5 0 2 13 22 43 35 27 19 11 4 7 ## I 0 0 0 0 0 1 0 5 14 35 45 37 29 21 13 5 ## G 0 0 0 8 0 8 0 0 6 27 37 53 45 37 29 21 ## Q 0 0 0 0 4 0 10 2 0 19 29 45 54 46 38 30 ## K 0 0 0 0 0 2 6 13 5 11 21 37 48 57 49 41 ## ## $loc_ma_path ## gp P F G F G K R S C M G R R L A ## gp 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ## F 0 1 1 3 1 3 1 1 1 1 1 1 1 1 1 1 ## I 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 ## P 0 1 3 1 1 1 1 1 1 1 1 1 1 1 1 1 ## F 0 2 1 3 1 3 1 1 1 1 1 1 1 1 1 1 ## S 0 1 2 1 3 1 1 1 1 1 1 1 1 1 1 1 ## A 0 1 2 1 1 1 1 3 1 1 1 1 1 1 1 1 ## G 0 1 1 1 2 1 3 3 1 1 1 1 3 1 1 1 ## P 0 1 3 2 1 2 1 3 1 3 1 2 1 1 1 1 ## R 0 2 1 1 1 2 1 1 3 3 3 1 1 1 3 1 ## N 0 1 2 1 3 1 2 2 1 3 3 3 1 1 1 1 ## C 0 1 1 2 1 1 2 2 2 1 3 3 3 3 1 1 ## I 0 1 1 1 1 1 1 2 2 2 1 3 3 3 1 3 ## G 0 1 1 1 3 1 3 1 2 2 2 1 3 3 3 3 ## Q 0 1 1 2 1 2 1 3 1 2 2 2 1 1 3 3 ## K 0 1 1 1 1 1 1 1 3 2 2 2 1 1 3 3  Compute alignment Note: alignList stores all relevant results in a list, including dynamic programming matrices, as well as the coordinates (named path_coor) to highlight the path in the dynamic progamming matrix. This way one can easily generate a single dynamic programming matrix with the traceback path highlighted by colors or arrows in an HTML or PDF document (see below).\nalignList \u003c- alignmentTraceback(ma=dynMA[[1]], ma_path=dynMA[[2]], align_method=align_type) names(alignList)  ## [1] \"ma\" \"ma_path\" \"path_coor\" \"as1\" \"consensus\" \"as2\" ## [7] \"score\"  # alignList$ma # dyn ma with scores # alignList$ma_path # dyn ma with path # alignList$path_coor # coordinates for path to auto highlight path in HTML/PDF table  Return results Traceback in matrix The following prints the fully populated dynamic programming matrix where the traceback path is highlighted in color.\nprintColMa(alignList)     gp  P  F  G  F  G  K  R  S  C  M  G  R  R  L  A      gp  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0    F  0  0  8  0  8  0  0  0  0  0  0  0  0  0  1  0    I  0  0  0  4  0  4  0  0  0  0  2  0  0  0  2  0    P  0  10  2  0  0  0  3  0  0  0  0  0  0  0  0  1    F  0  2  18  10  8  0  0  0  0  0  0  0  0  0  1  0    S  0  0  10  18  10  8  0  0  5  0  0  0  0  0  0  2    A  0  0  2  10  15  10  7  0  1  4  0  0  0  0  0  5    G  0  0  0  10  7  23  15  7  0  0  1  8  0  0  0  0    P  0  10  2  2  6  15  22  14  6  0  0  0  5  0  0  0    R  0  2  7  0  0  7  18  29  21  13  5  0  7  12  4  0    N  0  0  0  7  0  0  10  21  30  22  14  6  0  6  8  3    C  0  0  0  0  5  0  2  13  22  43  35  27  19  11  4  7    I  0  0  0  0  0  1  0  5  14  35  45  37  29  21  13  5    G  0  0  0  8  0  8  0  0  6  27  37  53  45  37  29  21    Q  0  0  0  0  4  0  10  2  0  19  29  45  54  46  38  30    K  0  0  0  0  0  2  6  13  5  11  21  37  48  57  49  41     Alignment and score printAlign(x=alignList)  ## ## S1: PFGFGKRSCMGRR ## || | | | | ## S2: PFSAGPRNCIGQK ## ## Score of alignment: 57  C. Different Substitution Matrices Task 1: Load the Biostrings package in R, import the following two cytochrome P450 sequences O15528 and P98187 from NCBI (save as myseq.fasta), and create a global alignment with the pairwiseAlignment function from Biostrings as follows.\nlibrary(Biostrings) myseq \u003c- readAAStringSet(\"myseq.fasta\", \"fasta\") (p \u003c- pairwiseAlignment(myseq[[1]], myseq[[2]], type=\"global\", substitutionMatrix=\"BLOSUM50\")) writePairwiseAlignments(p)  Your answers should address the following items:\nRecord the scores for the scoring matrices BLOSUM50, BLOSUM62 and BLOSUM80. How and why do the scores differ for the three scoring matrices?\nAnswer 1: The scores for the three BLOSUM substitutions matrices are:\n BLOSUM50: 227 BLOSUM62: 54 BLOSUM80: -52  Answer 2: Since the two sequences are relatively dissimilar (as determined by alignment view from writePairwiseAlignments(p)) it is expected that the BLOSUM matrices trained on more dissimilar sequences (e.g. BLOSUM50) result in higher scores than those trained on less similar sequences (e.g. BLOSUM80).\nSession Info sessionInfo()  ## R version 4.0.5 (2021-03-31) ## Platform: x86_64-pc-linux-gnu (64-bit) ## Running under: Debian GNU/Linux 10 (buster) ## ## Matrix products: default ## BLAS: /usr/lib/x86_64-linux-gnu/blas/libblas.so.3.8.0 ## LAPACK: /usr/lib/x86_64-linux-gnu/lapack/liblapack.so.3.8.0 ## ## locale: ## [1] LC_CTYPE=en_US.UTF-8 LC_NUMERIC=C ## [3] LC_TIME=en_US.UTF-8 LC_COLLATE=en_US.UTF-8 ## [5] LC_MONETARY=en_US.UTF-8 LC_MESSAGES=en_US.UTF-8 ## [7] LC_PAPER=en_US.UTF-8 LC_NAME=C ## [9] LC_ADDRESS=C LC_TELEPHONE=C ## [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C ## ## attached base packages: ## [1] stats4 parallel stats graphics grDevices utils datasets ## [8] methods base ## ## other attached packages: ## [1] kableExtra_1.3.4 Biostrings_2.58.0 XVector_0.30.0 ## [4] IRanges_2.24.0 S4Vectors_0.28.0 BiocGenerics_0.36.0 ## ## loaded via a namespace (and not attached): ## [1] bslib_0.2.4 compiler_4.0.5 jquerylib_0.1.3 tools_4.0.5 ## [5] zlibbioc_1.36.0 digest_0.6.27 viridisLite_0.3.0 jsonlite_1.7.1 ## [9] evaluate_0.14 lifecycle_0.2.0 rlang_0.4.8 rstudioapi_0.13 ## [13] yaml_2.2.1 blogdown_1.2 xfun_0.22 stringr_1.4.0 ## [17] httr_1.4.2 knitr_1.30 xml2_1.3.2 sass_0.3.1 ## [21] systemfonts_1.0.1 webshot_0.5.2 svglite_2.0.0 glue_1.4.2 ## [25] R6_2.5.0 rmarkdown_2.7 bookdown_0.21 magrittr_2.0.1 ## [29] scales_1.1.1 htmltools_0.5.1.1 rvest_0.3.6 colorspace_2.0-0 ## [33] stringi_1.5.3 munsell_0.5.0 crayon_1.3.4  References Needleman, S B, and C D Wunsch. 1970. “A general method applicable to the search for similarities in the amino acid sequence of two proteins.” J. Mol. Biol. 48 (3): 443–53. https://doi.org/10.1016/0022-2836(70)90057-4.\n Smith, T F, and M S Waterman. 1981. “Identification of common molecular subsequences.” J. Mol. Biol. 147 (1): 195–97. http://www.ncbi.nlm.nih.gov/pubmed/7265238.\n  ","categories":"","description":"","excerpt":"  Source code downloads: [ .Rmd ] [ pairwiseAlign_Fct.R ]\n Rendering …","ref":"/assignments/homework/hw04/hw4_solution/hw4_key/","tags":"","title":"HW4: Pairwise Alignments"},{"body":"Overview  R provides a large number of packages for parallel evaluations on multi-core, multi-socket and multi-node systems. The latter are usually referred to as computer clusters. MPI is also supported For an overview of parallelization packages available for R see here One of the most comprehensive parallel computing environments for R is batchtools. Older versions of this package were released under the name BatchJobs (Bischl et al. 2015). batchtools supports both multi-core and multi-node computations with and without schedulers. By making use of cluster template files, most schedulers and queueing systems are supported (e.g. Torque, Sun Grid Engine, Slurm).  Reminder: Traditional Job Submission for R This topic is covered in more detail in other tutorials. The following only provides a very brief overview of this submission method.\n1. Create Slurm submission script, here called script_name.sh with:\n#!/bin/bash -l #SBATCH --nodes=1 #SBATCH --ntasks=1 #SBATCH --cpus-per-task=1 #SBATCH --mem-per-cpu=1G #SBATCH --time=1-00:15:00 # 1 day and 15 minutes #SBATCH --mail-user=useremail@address.com #SBATCH --mail-type=ALL #SBATCH --job-name=\"some_test\" #SBATCH -p short # Choose queue/partition from: intel, batch, highmem, gpu, short Rscript my_script.R  2. Submit R script called my_script.R by above Slurm script with:\nsbatch script_name.sh  Parallel Evaluations on Clusters with batchtools  The following introduces the usage of batchtools for a computer cluster using SLURM as scheduler (workload manager). SLURM is the scheduler used by the HPCC. Similar instructions are provided in HPCC’s manual section covering batchtools here To simplify the evaluation of the R code on the following slides, the corresponding text version is available for download from here.  Hands-on Demo of batchtools Set up working directory for SLURM First login to your cluster account, open R and execute the following lines. This will create a test directory (here mytestdir), redirect R into this directory and then download the required files:\n slurm.tmpl .batchtools.conf.R  dir.create(\"mytestdir\") setwd(\"mytestdir\") download.file(\"https://bit.ly/3gZJBsy\", \"slurm.tmpl\") download.file(\"https://bit.ly/3nvSNHA\", \".batchtools.conf.R\")  Load package and define some custom function The following code defines a test function (here myFct) that will be run on the cluster for demonstration purposes.\nThe test function (myFct) subsets the iris data frame by rows, and appends the host name and R version of each node where the function was executed. The R version to be used on each node can be specified in the slurm.tmpl file (under module load).\nlibrary('RenvModule') module('load','slurm') # Loads slurm among other modules library(batchtools) myFct \u003c- function(x) { Sys.sleep(10) # to see job in queue, pause for 10 sec result \u003c- cbind(iris[x, 1:4,], Node=system(\"hostname\", intern=TRUE), Rversion=paste(R.Version()[6:7], collapse=\".\")) }  Submit jobs from R to cluster The following creates a batchtools registry, defines the number of jobs and resource requests, and then submits the jobs to the cluster via SLURM.\nreg \u003c- makeRegistry(file.dir=\"myregdir\", conf.file=\".batchtools.conf.R\") Njobs \u003c- 1:4 # Define number of jobs (here 4) ids \u003c- batchMap(fun=myFct, x=Njobs) done \u003c- submitJobs(ids, reg=reg, resources=list(partition=\"short\", walltime=120, ntasks=1, ncpus=1, memory=1024)) waitForJobs() # Wait until jobs are completed  Summarize job status After the jobs are completed one can inspect their status as follows.\ngetStatus() # Summarize job status showLog(Njobs[1]) # killJobs(Njobs) # # Possible from within R or outside with scancel  Access/assemble results The results are stored as .rds files in the registry directory (here myregdir). One can access them manually via readRDS or use various convenience utilities provided by the batchtools package.\nreadRDS(\"myregdir/results/1.rds\") # reads from rds file first result chunk loadResult(1) lapply(Njobs, loadResult) reduceResults(rbind) # Assemble result chunks in single data.frame do.call(\"rbind\", lapply(Njobs, loadResult))  Remove registry directory from file system By default existing registries will not be overwritten. If required one can explicitly clean and delete them with the following functions.\nclearRegistry() # Clear registry in R session removeRegistry(wait=0, reg=reg) # Delete registry directory # unlink(\"myregdir\", recursive=TRUE) # Same as previous line  Load registry into R Loading a registry can be useful when accessing the results at a later state or after moving them to a local system.\nfrom_file \u003c- loadRegistry(\"myregdir\", conf.file=\".batchtools.conf.R\") reduceResults(rbind)  Conclusions Advantages of batchtools  many parallelization methods multiple cores, and across both multiple CPU sockets and nodes most schedulers supported takes full advantage of a cluster robust job management by organizing results in registry file-based database simplifies submission, monitoring and restart of jobs well supported and maintained package  Session Info sessionInfo()  ## R version 4.0.5 (2021-03-31) ## Platform: x86_64-pc-linux-gnu (64-bit) ## Running under: Debian GNU/Linux 10 (buster) ## ## Matrix products: default ## BLAS: /usr/lib/x86_64-linux-gnu/blas/libblas.so.3.8.0 ## LAPACK: /usr/lib/x86_64-linux-gnu/lapack/liblapack.so.3.8.0 ## ## locale: ## [1] LC_CTYPE=en_US.UTF-8 LC_NUMERIC=C ## [3] LC_TIME=en_US.UTF-8 LC_COLLATE=en_US.UTF-8 ## [5] LC_MONETARY=en_US.UTF-8 LC_MESSAGES=en_US.UTF-8 ## [7] LC_PAPER=en_US.UTF-8 LC_NAME=C ## [9] LC_ADDRESS=C LC_TELEPHONE=C ## [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C ## ## attached base packages: ## [1] stats graphics grDevices utils datasets methods base ## ## loaded via a namespace (and not attached): ## [1] bookdown_0.21 digest_0.6.27 R6_2.5.0 jsonlite_1.7.1 ## [5] magrittr_2.0.1 evaluate_0.14 blogdown_1.2 stringi_1.5.3 ## [9] rlang_0.4.8 jquerylib_0.1.3 bslib_0.2.4 rmarkdown_2.7 ## [13] tools_4.0.5 stringr_1.4.0 xfun_0.22 yaml_2.2.1 ## [17] compiler_4.0.5 htmltools_0.5.1.1 knitr_1.30 sass_0.3.1  References Bischl, Bernd, Michel Lang, Olaf Mersmann, Jörg Rahnenführer, and Claus Weihs. 2015. “BatchJobs and BatchExperiments: Abstraction Mechanisms for Using R in Batch Environments.” Journal of Statistical Software. http://www.jstatsoft.org/v64/i11/.\n  ","categories":"","description":"","excerpt":"Overview  R provides a large number of packages for parallel …","ref":"/tutorials/rparallel/rparallel/","tags":"","title":"Parallel Evaluations in R"},{"body":"document.addEventListener(\"DOMContentLoaded\", function() { document.querySelector(\"h1\").className = \"title\"; });  document.addEventListener(\"DOMContentLoaded\", function() { var links = document.links; for (var i = 0, linksLength = links.length; i Overview One of the main attractions of using the R (http://cran.at.r-project.org) environment is the ease with which users can write their own programs and custom functions. The R programming syntax is extremely easy to learn, even for users with no previous programming experience. Once the basic R programming control structures are understood, users can use the R language as a powerful environment to perform complex custom analyses of almost any type of data (Gentleman 2008).\nWhy Programming in R?  Powerful statistical environment and programming language Facilitates reproducible research Efficient data structures make programming very easy Ease of implementing custom functions Powerful graphics Access to fast growing number of analysis packages Most widely used language in bioinformatics Is standard for data mining and biostatistical analysis Technical advantages: free, open-source, available for all OSs  R Basics The previous Rbasics tutorial provides a general introduction to the usage of the R environment and its basic command syntax. More details can be found in the R \u0026 BioConductor manual here.\nCode Editors for R Several excellent code editors are available that provide functionalities like R syntax highlighting, auto code indenting and utilities to send code/functions to the R console.\n RStudio: GUI-based IDE for R Vim-R-Tmux: R working environment based on vim and tmux Emacs (ESS add-on package) gedit and Rgedit RKWard Eclipse Tinn-R Notepad++ (NppToR)   Programming in R using RStudio     Programming in R using Vim or Emacs    Finding Help Reference list on R programming (selection)\n Advanced R, by Hadley Wickham R Programming for Bioinformatics, by Robert Gentleman S Programming, by W. N. Venables and B. D. Ripley Programming with Data, by John M. Chambers R Help \u0026 R Coding Conventions, Henrik Bengtsson, Lund University Programming in R (Vincent Zoonekynd) Peter’s R Programming Pages, University of Warwick Rtips, Paul Johnsson, University of Kansas R for Programmers, Norm Matloff, UC Davis High-Performance R, Dirk Eddelbuettel tutorial presented at useR-2008 C/C++ level programming for R, Gopi Goswami  Control Structures Important Operators Comparison operators  == (equal) != (not equal) \u003e (greater than) \u003e= (greater than or equal) \u003c (less than) \u003c= (less than or equal)  Logical operators  \u0026 (and) | (or) ! (not)  Conditional Executions: if Statements An if statement operates on length-one logical vectors.\nSyntax\nif (TRUE) { statements_1 } else { statements_2 }  In the else component, avoid inserting newlines between } else. For details on how to best and consistently format R code, this style guide is a good start. In addition, the formatR package can be helpful.\nExample\nif (1==0) { print(1) } else { print(2) }  ## [1] 2  Conditional Executions: ifelse Statements The ifelse statement operates on vectors.\nSyntax\nifelse(test, true_value, false_value)  Example\nx \u003c- 1:10 ifelse(x\u003c5, x, 0)  ## [1] 1 2 3 4 0 0 0 0 0 0  Loops for loop for loops iterate over elements of a looping vector.\nSyntax\nfor(variable in sequence) { statements }  Example\nmydf \u003c- iris myve \u003c- NULL for(i in seq(along=mydf[,1])) { myve \u003c- c(myve, mean(as.numeric(mydf[i,1:3]))) } myve[1:8]  ## [1] 3.333333 3.100000 3.066667 3.066667 3.333333 3.666667 3.133333 3.300000  Note: Inject into objecs is much faster than append approach with c, cbind, etc.\nExample\nmyve \u003c- numeric(length(mydf[,1])) for(i in seq(along=myve)) { myve[i] \u003c- mean(as.numeric(mydf[i,1:3])) } myve[1:8]  ## [1] 3.333333 3.100000 3.066667 3.066667 3.333333 3.666667 3.133333 3.300000  Conditional Stop of Loops The stop function can be used to break out of a loop (or a function) when a condition becomes TRUE. In addition, an error message will be printed.\nExample\nx \u003c- 1:10 z \u003c- NULL for(i in seq(along=x)) { if(x[i] \u003c 5) { z \u003c- c(z, x[i]-1) } else { stop(\"values need to be \u003c 5\") } }  while loop Iterates as long as a condition is true.\nSyntax\nwhile(condition) { statements }  Example\nz \u003c- 0 while(z\u003c5) { z \u003c- z + 2 print(z) }  ## [1] 2 ## [1] 4 ## [1] 6  The apply Function Family apply Syntax\napply(X, MARGIN, FUN, ARGs)  Arguments\n X: array, matrix or data.frame MARGIN: 1 for rows, 2 for columns FUN: one or more functions ARGs: possible arguments for functions  Example\napply(iris[1:8,1:3], 1, mean)  ## 1 2 3 4 5 6 7 8 ## 3.333333 3.100000 3.066667 3.066667 3.333333 3.666667 3.133333 3.300000  tapply Applies a function to vector components that are defined by a factor.\nSyntax\ntapply(vector, factor, FUN)  Example\niris[1:2,]  ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 1 5.1 3.5 1.4 0.2 setosa ## 2 4.9 3.0 1.4 0.2 setosa  tapply(iris$Sepal.Length, iris$Species, mean)  ## setosa versicolor virginica ## 5.006 5.936 6.588  sapply, lapply and vapply All three apply a function to vector or list. The lapply function always returns a list, while sapply returns vector or matrix objects when possible. If not then a list is returned. The vapply function returns a vector or array of type matching the FUN.VALUE. Compared to sappy, vapply is a safer choice with respect to controlling specific output types to avoid exception handling problems.\nExamples\nl \u003c- list(a = 1:10, beta = exp(-3:3), logic = c(TRUE,FALSE,FALSE,TRUE)) lapply(l, mean)  ## $a ## [1] 5.5 ## ## $beta ## [1] 4.535125 ## ## $logic ## [1] 0.5  sapply(l, mean)  ## a beta logic ## 5.500000 4.535125 0.500000  vapply(l, mean, FUN.VALUE=numeric(1))  ## a beta logic ## 5.500000 4.535125 0.500000  Often used in combination with a function definition:\nlapply(names(l), function(x) mean(l[[x]])) sapply(names(l), function(x) mean(l[[x]])) vapply(names(l), function(x) mean(l[[x]]), FUN.VALUE=numeric(1))  Functions Function Overview A very useful feature of the R environment is the possibility to expand existing functions and to easily write custom functions. In fact, most of the R software can be viewed as a series of R functions.\nSyntax to define function\nmyfct \u003c- function(arg1, arg2, ...) { function_body }  Syntax to call functions\nmyfct(arg1=..., arg2=...)  The value returned by a function is the value of the function body, which is usually an unassigned final expression, e.g.: return()\nFunction Syntax Rules General\n Functions are defined by  The assignment with the keyword function The declaration of arguments/variables (arg1, arg2, ...) The definition of operations (function_body) that perform computations on the provided arguments. A function name needs to be assigned to call the function.    Naming\n Function names can be almost anything. However, the usage of names of existing functions should be avoided.  Arguments\n It is often useful to provide default values for arguments (e.g.: arg1=1:10). This way they don’t need to be provided in a function call. The argument list can also be left empty (myfct \u003c- function() { fct_body }) if a function is expected to return always the same value(s). The argument ... can be used to allow one function to pass on argument settings to another.  Body\n The actual expressions (commands/operations) are defined in the function body which should be enclosed by braces. The individual commands are separated by semicolons or new lines (preferred).  Usage\n Functions are called by their name followed by parentheses containing possible argument names. Empty parenthesis after the function name will result in an error message when a function requires certain arguments to be provided by the user. The function name alone will print the definition of a function.  Scope\n Variables created inside a function exist only for the life time of a function. Thus, they are not accessible outside of the function. To force variables in functions to exist globally, one can use the double assignment operator: \u003c\u003c-  Examples Define sample function\nmyfct \u003c- function(x1, x2=5) { z1 \u003c- x1 / x1 z2 \u003c- x2 * x2 myvec \u003c- c(z1, z2) return(myvec) }  Function usage\nApply function to values 2 and 5\nmyfct(x1=2, x2=5)  ## [1] 1 25  Run without argument names\nmyfct(2, 5)  ## [1] 1 25  Makes use of default value 5\nmyfct(x1=2)  ## [1] 1 25  Print function definition (often unintended)\nmyfct  ## function(x1, x2=5) { ## z1 \u003c- x1 / x1 ## z2 \u003c- x2 * x2 ## myvec \u003c- c(z1, z2) ## return(myvec) ## } ## \u003cbytecode: 0x575bef4fbd40\u003e  Useful Utilities Debugging Utilities Several debugging utilities are available for R. They include:\n traceback browser options(error=recover) options(error=NULL) debug  The Debugging in R page provides an overview of the available resources.\nRegular Expressions R’s regular expression utilities work similar as in other languages. To learn how to use them in R, one can consult the main help page on this topic with ?regexp.\nString matching with grep The grep function can be used for finding patterns in strings, here letter A in vector month.name.\nmonth.name[grep(\"A\", month.name)]  ## [1] \"April\" \"August\"  String substitution with gsub Example for using regular expressions to substitute a pattern by another one using a back reference. Remember: single escapes \\ need to be double escaped \\\\ in R.\ngsub('(i.*a)', 'xxx_\\\\1', \"virginica\", perl = TRUE)  ## [1] \"vxxx_irginica\"  Interpreting a Character String as Expression Some useful examples\nGenerates vector of object names in session\nmylist \u003c- ls() mylist[1]  ## [1] \"i\"  Executes 1st entry as expression\nget(mylist[1])  ## [1] 150  Alternative approach\neval(parse(text=mylist[1]))  ## [1] 150  Replacement, Split and Paste Functions for Strings Selected examples\nSubstitution with back reference which inserts in this example _ character\nx \u003c- gsub(\"(a)\",\"\\\\1_\", month.name[1], perl=T) x  ## [1] \"Ja_nua_ry\"  Split string on inserted character from above\nstrsplit(x,\"_\")  ## [[1]] ## [1] \"Ja\" \"nua\" \"ry\"  Reverse a character string by splitting first all characters into vector fields\npaste(rev(unlist(strsplit(x, NULL))), collapse=\"\")  ## [1] \"yr_aun_aJ\"  Time, Date and Sleep Selected examples\nReturn CPU (and other) times that an expression used (here ls)\nsystem.time(ls())  ## user system elapsed ## 0 0 0  Return the current system date and time\ndate()  ## [1] \"Thu Feb 18 14:46:40 2021\"  Pause execution of R expressions for a given number of seconds (e.g. in loop)\nSys.sleep(1)  Example Import of Specific File Lines with Regular Expression The following example demonstrates the retrieval of specific lines from an external file with a regular expression. First, an external file is created with the cat function, all lines of this file are imported into a vector with readLines, the specific elements (lines) are then retieved with the grep function, and the resulting lines are split into vector fields with strsplit.\ncat(month.name, file=\"zzz.txt\", sep=\"\\n\") x \u003c- readLines(\"zzz.txt\") x[1:6]  ## [1] \"January\" \"February\" \"March\" \"April\" \"May\" \"June\"  x \u003c- x[c(grep(\"^J\", as.character(x), perl = TRUE))] t(as.data.frame(strsplit(x, \"u\")))  ## [,1] [,2] ## c..Jan....ary.. \"Jan\" \"ary\" ## c..J....ne.. \"J\" \"ne\" ## c..J....ly.. \"J\" \"ly\"  Calling External Software External command-line software can be called with system. The following example calls blastall from R\nsystem(\"blastall -p blastp -i seq.fasta -d uniprot -o seq.blastp\")  ## Warning in system(\"blastall -p blastp -i seq.fasta -d uniprot -o seq.blastp\"): error in running ## command  Running R Scripts Possibilities for Executing R Scripts R console source(\"my_script.R\")  Command-line Rscript my_script.R # or just ./myscript.R after making it executable R CMD BATCH my_script.R # Alternative way 1 R --slave \u003c my_script.R # Alternative way 2  Passing arguments from command-line to R Create an R script named test.R with the following content:\nmyarg \u003c- commandArgs() print(iris[1:myarg[6], ])  Then run it from the command-line like this:\nRscript test.R 10  In the given example the number 10 is passed on from the command-line as an argument to the R script which is used to return to STDOUT the first 10 rows of the iris sample data. If several arguments are provided, they will be interpreted as one string and need to be split in R with the strsplit function. A more detailed example can be found here.\nBuilding R Packages Short Overview of Package Building Process R packages can be built with the package.skeleton function. The given example will create a directory named mypackage containing the skeleton of the package for all functions, methods and classes defined in the R script(s) passed on to the code_files argument. The basic structure of the package directory is described here. The package directory will also contain a file named Read-and-delete-me with instructions for completing the package:\npackage.skeleton(name=\"mypackage\", code_files=c(\"script1.R\", \"script2.R\"))  Once a package skeleton is available one can build the package from the command-line (Linux/OS X). This will create a tarball of the package with its version number encoded in the file name. Subequently, the package tarball needs to be checked for errors with:\nR CMD build mypackage R CMD check mypackage_1.0.tar.gz  Install package from source\ninstall.packages(\"mypackage_1.0.tar.gz\", repos=NULL)  For more details see here\nProgramming Exercises Exercise 1 for loop Task 1.1: Compute the mean of each row in myMA by applying the mean function in a for loop.\nmyMA \u003c- matrix(rnorm(500), 100, 5, dimnames=list(1:100, paste(\"C\", 1:5, sep=\"\"))) myve_for \u003c- NULL for(i in seq(along=myMA[,1])) { myve_for \u003c- c(myve_for, mean(as.numeric(myMA[i, ]))) } myResult \u003c- cbind(myMA, mean_for=myve_for) myResult[1:4, ]  ## C1 C2 C3 C4 C5 mean_for ## 1 -1.5890569 -0.00759616 -0.7651252 -0.1334947 1.75902044 -0.1472505 ## 2 -0.5760445 -0.07502956 1.8156748 -0.6022573 0.04071099 0.1206109 ## 3 0.1452555 -0.85005686 0.8514295 -0.4692688 -0.95188121 -0.2549044 ## 4 0.9678927 -0.48747853 0.5058947 0.5961237 -0.84373458 0.1477396  while loop Task 1.2: Compute the mean of each row in myMA by applying the mean function in a while loop.\nz \u003c- 1 myve_while \u003c- NULL while(z \u003c= length(myMA[,1])) { myve_while \u003c- c(myve_while, mean(as.numeric(myMA[z, ]))) z \u003c- z + 1 } myResult \u003c- cbind(myMA, mean_for=myve_for, mean_while=myve_while) myResult[1:4, -c(1,2)]  ## C3 C4 C5 mean_for mean_while ## 1 -0.7651252 -0.1334947 1.75902044 -0.1472505 -0.1472505 ## 2 1.8156748 -0.6022573 0.04071099 0.1206109 0.1206109 ## 3 0.8514295 -0.4692688 -0.95188121 -0.2549044 -0.2549044 ## 4 0.5058947 0.5961237 -0.84373458 0.1477396 0.1477396  Task 1.3: Confirm that the results from both mean calculations are identical\nall(myResult[,6] == myResult[,7])  ## [1] TRUE  apply loop Task 1.4: Compute the mean of each row in myMA by applying the mean function in an apply loop\nmyve_apply \u003c- apply(myMA, 1, mean) myResult \u003c- cbind(myMA, mean_for=myve_for, mean_while=myve_while, mean_apply=myve_apply) myResult[1:4, -c(1,2)]  ## C3 C4 C5 mean_for mean_while mean_apply ## 1 -0.7651252 -0.1334947 1.75902044 -0.1472505 -0.1472505 -0.1472505 ## 2 1.8156748 -0.6022573 0.04071099 0.1206109 0.1206109 0.1206109 ## 3 0.8514295 -0.4692688 -0.95188121 -0.2549044 -0.2549044 -0.2549044 ## 4 0.5058947 0.5961237 -0.84373458 0.1477396 0.1477396 0.1477396  Avoiding loops Task 1.5: When operating on large data sets it is much faster to use the rowMeans function\nmymean \u003c- rowMeans(myMA) myResult \u003c- cbind(myMA, mean_for=myve_for, mean_while=myve_while, mean_apply=myve_apply, mean_int=mymean) myResult[1:4, -c(1,2,3)]  ## C4 C5 mean_for mean_while mean_apply mean_int ## 1 -0.1334947 1.75902044 -0.1472505 -0.1472505 -0.1472505 -0.1472505 ## 2 -0.6022573 0.04071099 0.1206109 0.1206109 0.1206109 0.1206109 ## 3 -0.4692688 -0.95188121 -0.2549044 -0.2549044 -0.2549044 -0.2549044 ## 4 0.5961237 -0.84373458 0.1477396 0.1477396 0.1477396 0.1477396  Exercise 2 Custom functions Task 2.1: Use the following code as basis to implement a function that allows the user to compute the mean for any combination of columns in a matrix or data frame. The first argument of this function should specify the input data set, the second the mathematical function to be passed on (e.g. mean, sd, max) and the third one should allow the selection of the columns by providing a grouping vector.\nmyMA \u003c- matrix(rnorm(100000), 10000, 10, dimnames=list(1:10000, paste(\"C\", 1:10, sep=\"\"))) myMA[1:2,]  ## C1 C2 C3 C4 C5 C6 C7 C8 C9 ## 1 -0.1430870 1.6518732 -0.4030777 1.3449119 -1.275383 0.8054689 0.7659832 0.2528063 0.2783535 ## 2 -0.6469048 0.5299854 -0.4038505 0.4141411 -1.097646 1.9669993 -2.5523817 1.6555577 -1.4068711 ## C10 ## 1 -0.03573911 ## 2 -0.58036942  myList \u003c- tapply(colnames(myMA), c(1,1,1,2,2,2,3,3,4,4), list) names(myList) \u003c- sapply(myList, paste, collapse=\"_\") myMAmean \u003c- sapply(myList, function(x) apply(myMA[,x], 1, mean)) myMAmean[1:4,]  ## C1_C2_C3 C4_C5_C6 C7_C8 C9_C10 ## 1 0.3685695 0.29166595 0.5093947 0.121307169 ## 2 -0.1735900 0.42783144 -0.4484120 -0.993620282 ## 3 -0.5667075 -0.04833491 0.6504228 0.006118701 ## 4 0.7495088 -0.44156279 0.5179593 0.082354279  Exercise 3 Nested loops to generate similarity matrices Task 3.1: Create a sample list populated with character vectors of different lengths\nsetlist \u003c- lapply(11:30, function(x) sample(letters, x, replace=TRUE)) names(setlist) \u003c- paste(\"S\", seq(along=setlist), sep=\"\") setlist[1:6]  ## $S1 ## [1] \"s\" \"a\" \"m\" \"n\" \"w\" \"s\" \"m\" \"t\" \"n\" \"y\" \"c\" ## ## $S2 ## [1] \"x\" \"r\" \"p\" \"v\" \"a\" \"n\" \"d\" \"b\" \"o\" \"d\" \"g\" \"d\" ## ## $S3 ## [1] \"e\" \"p\" \"k\" \"q\" \"x\" \"p\" \"u\" \"s\" \"z\" \"t\" \"j\" \"r\" \"a\" ## ## $S4 ## [1] \"c\" \"f\" \"e\" \"j\" \"k\" \"j\" \"c\" \"q\" \"b\" \"j\" \"o\" \"x\" \"n\" \"x\" ## ## $S5 ## [1] \"q\" \"d\" \"a\" \"f\" \"j\" \"m\" \"m\" \"o\" \"c\" \"k\" \"c\" \"q\" \"s\" \"u\" \"s\" ## ## $S6 ## [1] \"v\" \"i\" \"f\" \"z\" \"d\" \"m\" \"w\" \"f\" \"u\" \"b\" \"l\" \"c\" \"g\" \"f\" \"c\" \"u\"  Task 3.2: Compute the length for all pairwise intersects of the vectors stored in setlist. The intersects can be determined with the %in% function like this: sum(setlist[[1]] %in% setlist[[2]])\nsetlist \u003c- sapply(setlist, unique) olMA \u003c- sapply(names(setlist), function(x) sapply(names(setlist), function(y) sum(setlist[[x]] %in% setlist[[y]]))) olMA[1:12,]  ## S1 S2 S3 S4 S5 S6 S7 S8 S9 S10 S11 S12 S13 S14 S15 S16 S17 S18 S19 S20 ## S1 8 2 3 2 4 3 3 4 6 3 3 5 5 8 4 8 6 5 8 5 ## S2 2 10 4 4 3 4 3 4 4 8 4 7 6 6 6 8 6 6 6 7 ## S3 3 4 12 5 6 2 5 6 6 7 7 7 7 6 6 9 12 8 9 8 ## S4 2 4 5 10 6 3 2 4 4 8 2 7 6 8 6 7 8 6 6 6 ## S5 4 3 6 6 11 5 3 6 7 8 5 6 5 8 6 10 9 7 9 7 ## S6 3 4 2 3 5 12 6 8 5 7 4 6 6 8 10 8 7 10 9 8 ## S7 3 3 5 2 3 6 11 5 7 5 4 5 6 5 8 8 6 7 7 8 ## S8 4 4 6 4 6 8 5 13 5 8 5 7 9 10 9 10 8 11 12 7 ## S9 6 4 6 4 7 5 7 5 13 8 5 8 8 7 8 11 9 6 8 11 ## S10 3 8 7 8 8 7 5 8 8 16 8 10 11 10 10 12 11 9 9 10 ## S11 3 4 7 2 5 4 4 5 5 8 11 6 6 6 7 7 10 7 9 9 ## S12 5 7 7 7 6 6 5 7 8 10 6 15 10 11 12 11 11 9 11 11  Task 3.3 Plot the resulting intersect matrix as heat map. The image or the heatmap.2 function from the gplots library can be used for this.\nimage(olMA)  Exercise 4 Build your own R package Task 4.1: Save one or more of your functions to a file called script.R and build the package with the package.skeleton function.\npackage.skeleton(name=\"mypackage\", code_files=c(\"script1.R\"))  Task 4.2: Build tarball of the package\nsystem(\"R CMD build mypackage\")  Task 4.3: Install and use package\ninstall.packages(\"mypackage_1.0.tar.gz\", repos=NULL, type=\"source\") library(mypackage) ?myMAcomp # Opens help for function defined by mypackage  Homework 5 Reverse and complement of DNA Task 1: Write a RevComp function that returns the reverse and complement of a DNA sequence string. Include an argument that will allow to return only the reversed sequence, the complemented sequence or the reversed and complemented sequence. The following R functions will be useful for the implementation:\nx \u003c- c(\"ATGCATTGGACGTTAG\") x  ## [1] \"ATGCATTGGACGTTAG\"  x \u003c- substring(x, 1:nchar(x), 1:nchar(x)) x  ## [1] \"A\" \"T\" \"G\" \"C\" \"A\" \"T\" \"T\" \"G\" \"G\" \"A\" \"C\" \"G\" \"T\" \"T\" \"A\" \"G\"  x \u003c- rev(x) x  ## [1] \"G\" \"A\" \"T\" \"T\" \"G\" \"C\" \"A\" \"G\" \"G\" \"T\" \"T\" \"A\" \"C\" \"G\" \"T\" \"A\"  x \u003c- paste(x, collapse=\"\") x  ## [1] \"GATTGCAGGTTACGTA\"  chartr(\"ATGC\", \"TACG\", x)  ## [1] \"CTAACGTCCAATGCAT\"  Task 2: Write a function that applies the RevComp function to many sequences stored in a vector.\nTranslate DNA into Protein Task 3: Write a function that will translate one or many DNA sequences in all three reading frames into proteins. The following commands will simplify this task:\nAAdf \u003c- read.table(file=\"http://faculty.ucr.edu/~tgirke/Documents/R_BioCond/My_R_Scripts/AA.txt\", header=TRUE, sep=\"\\t\") AAdf[1:4,]  ## Codon AA_1 AA_3 AA_Full AntiCodon ## 1 TCA S Ser Serine TGA ## 2 TCG S Ser Serine CGA ## 3 TCC S Ser Serine GGA ## 4 TCT S Ser Serine AGA  AAv \u003c- as.character(AAdf[,2]) names(AAv) \u003c- AAdf[,1] AAv  ## TCA TCG TCC TCT TTT TTC TTA TTG TAT TAC TAA TAG TGT TGC TGA TGG CTA CTG CTC CTT CCA CCG CCC CCT CAT ## \"S\" \"S\" \"S\" \"S\" \"F\" \"F\" \"L\" \"L\" \"Y\" \"Y\" \"*\" \"*\" \"C\" \"C\" \"*\" \"W\" \"L\" \"L\" \"L\" \"L\" \"P\" \"P\" \"P\" \"P\" \"H\" ## CAC CAA CAG CGA CGG CGC CGT ATT ATC ATA ATG ACA ACG ACC ACT AAT AAC AAA AAG AGT AGC AGA AGG GTA GTG ## \"H\" \"Q\" \"Q\" \"R\" \"R\" \"R\" \"R\" \"I\" \"I\" \"I\" \"M\" \"T\" \"T\" \"T\" \"T\" \"N\" \"N\" \"K\" \"K\" \"S\" \"S\" \"R\" \"R\" \"V\" \"V\" ## GTC GTT GCA GCG GCC GCT GAT GAC GAA GAG GGA GGG GGC GGT ## \"V\" \"V\" \"A\" \"A\" \"A\" \"A\" \"D\" \"D\" \"E\" \"E\" \"G\" \"G\" \"G\" \"G\"  y \u003c- gsub(\"(...)\", \"\\\\1_\", x) y \u003c- unlist(strsplit(y, \"_\")) y \u003c- y[grep(\"^...$\", y)] AAv[y]  ## GAT TGC AGG TTA CGT ## \"D\" \"C\" \"R\" \"L\" \"R\"  Homework submission Submit the 3 functions in one well structured and annotated R script to the instructor. The script should include instructions on how to use the functions.\nDue date This homework is due on Thu, April 26th at 6:00 PM.\nHomework Solutions See homework section here\nSession Info sessionInfo()  ## R version 4.0.4 (2021-02-15) ## Platform: x86_64-pc-linux-gnu (64-bit) ## Running under: Debian GNU/Linux 10 (buster) ## ## Matrix products: default ## BLAS: /usr/lib/x86_64-linux-gnu/blas/libblas.so.3.8.0 ## LAPACK: /usr/lib/x86_64-linux-gnu/lapack/liblapack.so.3.8.0 ## ## locale: ## [1] LC_CTYPE=en_US.UTF-8 LC_NUMERIC=C LC_TIME=en_US.UTF-8 ## [4] LC_COLLATE=en_US.UTF-8 LC_MONETARY=en_US.UTF-8 LC_MESSAGES=en_US.UTF-8 ## [7] LC_PAPER=en_US.UTF-8 LC_NAME=C LC_ADDRESS=C ## [10] LC_TELEPHONE=C LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C ## ## attached base packages: ## [1] stats graphics grDevices utils datasets methods base ## ## other attached packages: ## [1] ggplot2_3.3.2 limma_3.46.0 BiocStyle_2.18.0 ## ## loaded via a namespace (and not attached): ## [1] knitr_1.30 magrittr_2.0.1 tidyselect_1.1.0 munsell_0.5.0 ## [5] colorspace_2.0-0 R6_2.5.0 rlang_0.4.8 dplyr_1.0.2 ## [9] stringr_1.4.0 tools_4.0.4 grid_4.0.4 gtable_0.3.0 ## [13] xfun_0.20 withr_2.3.0 ellipsis_0.3.1 htmltools_0.5.1.1 ## [17] yaml_2.2.1 digest_0.6.27 tibble_3.0.4 lifecycle_0.2.0 ## [21] crayon_1.3.4 bookdown_0.21 purrr_0.3.4 BiocManager_1.30.10 ## [25] codetools_0.2-18 vctrs_0.3.5 glue_1.4.2 evaluate_0.14 ## [29] rmarkdown_2.5 blogdown_1.1.7 stringi_1.5.3 pillar_1.4.7 ## [33] compiler_4.0.4 generics_0.1.0 scales_1.1.1 pkgconfig_2.0.3  References Gentleman, Robert. 2008. R Programming for Bioinformatics (Chapman \u0026 Hall/CRC Computer Science \u0026 Data Analysis). 1 edition. Chapman; Hall/CRC. http://www.amazon.com/Programming-Bioinformatics-Chapman-Computer-Analysis/dp/1420063677.\n  ","categories":"","description":"","excerpt":"document.addEventListener(\"DOMContentLoaded\", function() { …","ref":"/manuals/rprogramming/rprogramming/","tags":"","title":"Programming in R"},{"body":"Internal  This page provides links to password protected resources that are only accessible to the instructor and/or students enrolled in this class.\n  Zoom URLs and course planning sheets: shared via an internal Google Doc named URLs_to_Private_Info. GitHub: private repositories for course assignments (course projects). GitHub Classroom: homework assignments are distributed and autograded via GitHub Classroom. Course communication: depending on student preferences this class uses for group communications Piazza and/or Slack. This year the preference was to use only Piazza.  Piazza: for communication among students and instructor (please avoid email!) Slack: not used this year.   Information on how to set up and maintain this site is here.  ","categories":"","description":"","excerpt":"Internal  This page provides links to password protected resources …","ref":"/about/internal/internal_resources/","tags":"","title":"Internal Resources"},{"body":"       R Markdown Overview R Markdown combines markdown (an easy to write plain text format) with embedded R code chunks. When compiling R Markdown documents, the code components can be evaluated so that both the code and its output can be included in the final document. This makes analysis reports highly reproducible by allowing to automatically regenerate them when the underlying R code or data changes. R Markdown documents (.Rmd files) can be rendered to various formats including HTML and PDF. The R code in an .Rmd document is processed by knitr, while the resulting .md file is rendered by pandoc to the final output formats (e.g. HTML or PDF). Historically, R Markdown is an extension of the older Sweave/Latex environment. Rendering of mathematical expressions and reference management is also supported by R Markdown using embedded Latex syntax and Bibtex, respectively.\nQuick Start Install R Markdown install.packages(\"rmarkdown\")  Initialize a new R Markdown (Rmd) script To minimize typing, it can be helful to start with an R Markdown template and then modify it as needed. Note the file name of an R Markdown scirpt needs to have the extension .Rmd. Template files for the following examples are available here:\n R Markdown sample script: sample.Rmd Bibtex file for handling citations and reference section: bibtex.bib  Users want to download these files, open the sample.Rmd file with their preferred R IDE (e.g. RStudio, vim or emacs), initilize an R session and then direct their R session to the location of these two files.\nMetadata section The metadata section (YAML header) in an R Markdown script defines how it will be processed and rendered. The metadata section also includes both title, author, and date information as well as options for customizing the output format. For instance, PDF and HTML output can be defined with pdf_document and html_document, respectively. The BiocStyle:: prefix will use the formatting style of the BiocStyle package from Bioconductor.\n --- title: \"My First R Markdown Document\" author: \"Author: First Last\" date: \"Last update: 03 May, 2021\" output: BiocStyle::html_document: toc: true toc_depth: 3 fig_caption: yes fontsize: 14pt bibliography: bibtex.bib ---  Render Rmd script An R Markdown script can be evaluated and rendered with the following render command or by pressing the knit button in RStudio. The output_format argument defines the format of the output (e.g. html_document or pdf_document). The setting output_format=\"all\" will generate all supported output formats. Alternatively, one can specify several output formats in the metadata section.\nrmarkdown::render(\"sample.Rmd\", clean=TRUE, output_format=\"html_document\")  The following shows two options how to run the rendering from the command-line.\n$ Rscript -e \"rmarkdown::render('sample.Rmd', output_format='html_document', clean=TRUE)\"  Alternatively, one can use a Makefile to evaluate and render an R Markdown script. A sample Makefile for rendering the above sample.Rmd can be downloaded here. To apply it to a custom Rmd file, one needs open the Makefile in a text editor and change the value assigned to MAIN (line 13) to the base name of the corresponding .Rmd file (e.g. assign systemPipeRNAseq if the file name is systemPipeRNAseq.Rmd). To execute the Makefile, run the following command from the command-line.\n$ make -B  R code chunks R Code Chunks can be embedded in an R Markdown script by using three backticks at the beginning of a new line along with arguments enclosed in curly braces controlling the behavior of the code. The following lines contain the plain R code. A code chunk is terminated by a new line starting with three backticks. The following shows an example of such a code chunk. Note the backslashes are not part of it. They have been added to print the code chunk syntax in this document.\n ```\\{r code_chunk_name, eval=FALSE\\} x \u003c- 1:10 ```  The following lists the most important arguments to control the behavior of R code chunks:\n r: specifies language for code chunk, here R chode_chunk_name: name of code chunk; this name needs to be unique eval: if assigned TRUE the code will be evaluated warning: if assigned FALSE warnings will not be shown message: if assigned FALSE messages will not be shown cache: if assigned TRUE results will be cached to reuse in future rendering instances fig.height: allows to specify height of figures in inches fig.width: allows to specify width of figures in inches  For more details on code chunk options see here.\nLearning Markdown The basic syntax of Markdown and derivatives like kramdown is extremely easy to learn. Rather than providing another introduction on this topic, here are some useful sites for learning Markdown:\n R Markdown Online Book Markdown Intro on GitHub Markdown Cheet Sheet Markdown Basics from RStudio R Markdown Cheat Sheet kramdown Syntax  Tables There are several ways to render tables. First, they can be printed within the R code chunks. Second, much nicer formatted tables can be generated with the functions kable, pander or xtable. The following example uses kable from the knitr package.\nlibrary(knitr) kable(iris[1:12,])     Sepal.Length Sepal.Width Petal.Length Petal.Width Species     5.1 3.5 1.4 0.2 setosa   4.9 3.0 1.4 0.2 setosa   4.7 3.2 1.3 0.2 setosa   4.6 3.1 1.5 0.2 setosa   5.0 3.6 1.4 0.2 setosa   5.4 3.9 1.7 0.4 setosa   4.6 3.4 1.4 0.3 setosa   5.0 3.4 1.5 0.2 setosa   4.4 2.9 1.4 0.2 setosa   4.9 3.1 1.5 0.1 setosa   5.4 3.7 1.5 0.2 setosa   4.8 3.4 1.6 0.2 setosa    A much more elegant and powerful solution is to create fully interactive tables with the DT package. This JavaScirpt based environment provides a wrapper to the DataTables library using jQuery. The resulting tables can be sorted, queried and resized by the user.\nlibrary(DT) datatable(iris, filter = 'top', options = list( pageLength = 100, scrollX = TRUE, scrollY = \"600px\", autoWidth = TRUE ))   {\"x\":{\"filter\":\"top\",\"filterHTML\":\"\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n\",\"data\":[[\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\",\"11\",\"12\",\"13\",\"14\",\"15\",\"16\",\"17\",\"18\",\"19\",\"20\",\"21\",\"22\",\"23\",\"24\",\"25\",\"26\",\"27\",\"28\",\"29\",\"30\",\"31\",\"32\",\"33\",\"34\",\"35\",\"36\",\"37\",\"38\",\"39\",\"40\",\"41\",\"42\",\"43\",\"44\",\"45\",\"46\",\"47\",\"48\",\"49\",\"50\",\"51\",\"52\",\"53\",\"54\",\"55\",\"56\",\"57\",\"58\",\"59\",\"60\",\"61\",\"62\",\"63\",\"64\",\"65\",\"66\",\"67\",\"68\",\"69\",\"70\",\"71\",\"72\",\"73\",\"74\",\"75\",\"76\",\"77\",\"78\",\"79\",\"80\",\"81\",\"82\",\"83\",\"84\",\"85\",\"86\",\"87\",\"88\",\"89\",\"90\",\"91\",\"92\",\"93\",\"94\",\"95\",\"96\",\"97\",\"98\",\"99\",\"100\",\"101\",\"102\",\"103\",\"104\",\"105\",\"106\",\"107\",\"108\",\"109\",\"110\",\"111\",\"112\",\"113\",\"114\",\"115\",\"116\",\"117\",\"118\",\"119\",\"120\",\"121\",\"122\",\"123\",\"124\",\"125\",\"126\",\"127\",\"128\",\"129\",\"130\",\"131\",\"132\",\"133\",\"134\",\"135\",\"136\",\"137\",\"138\",\"139\",\"140\",\"141\",\"142\",\"143\",\"144\",\"145\",\"146\",\"147\",\"148\",\"149\",\"150\"],[5.1,4.9,4.7,4.6,5,5.4,4.6,5,4.4,4.9,5.4,4.8,4.8,4.3,5.8,5.7,5.4,5.1,5.7,5.1,5.4,5.1,4.6,5.1,4.8,5,5,5.2,5.2,4.7,4.8,5.4,5.2,5.5,4.9,5,5.5,4.9,4.4,5.1,5,4.5,4.4,5,5.1,4.8,5.1,4.6,5.3,5,7,6.4,6.9,5.5,6.5,5.7,6.3,4.9,6.6,5.2,5,5.9,6,6.1,5.6,6.7,5.6,5.8,6.2,5.6,5.9,6.1,6.3,6.1,6.4,6.6,6.8,6.7,6,5.7,5.5,5.5,5.8,6,5.4,6,6.7,6.3,5.6,5.5,5.5,6.1,5.8,5,5.6,5.7,5.7,6.2,5.1,5.7,6.3,5.8,7.1,6.3,6.5,7.6,4.9,7.3,6.7,7.2,6.5,6.4,6.8,5.7,5.8,6.4,6.5,7.7,7.7,6,6.9,5.6,7.7,6.3,6.7,7.2,6.2,6.1,6.4,7.2,7.4,7.9,6.4,6.3,6.1,7.7,6.3,6.4,6,6.9,6.7,6.9,5.8,6.8,6.7,6.7,6.3,6.5,6.2,5.9],[3.5,3,3.2,3.1,3.6,3.9,3.4,3.4,2.9,3.1,3.7,3.4,3,3,4,4.4,3.9,3.5,3.8,3.8,3.4,3.7,3.6,3.3,3.4,3,3.4,3.5,3.4,3.2,3.1,3.4,4.1,4.2,3.1,3.2,3.5,3.6,3,3.4,3.5,2.3,3.2,3.5,3.8,3,3.8,3.2,3.7,3.3,3.2,3.2,3.1,2.3,2.8,2.8,3.3,2.4,2.9,2.7,2,3,2.2,2.9,2.9,3.1,3,2.7,2.2,2.5,3.2,2.8,2.5,2.8,2.9,3,2.8,3,2.9,2.6,2.4,2.4,2.7,2.7,3,3.4,3.1,2.3,3,2.5,2.6,3,2.6,2.3,2.7,3,2.9,2.9,2.5,2.8,3.3,2.7,3,2.9,3,3,2.5,2.9,2.5,3.6,3.2,2.7,3,2.5,2.8,3.2,3,3.8,2.6,2.2,3.2,2.8,2.8,2.7,3.3,3.2,2.8,3,2.8,3,2.8,3.8,2.8,2.8,2.6,3,3.4,3.1,3,3.1,3.1,3.1,2.7,3.2,3.3,3,2.5,3,3.4,3],[1.4,1.4,1.3,1.5,1.4,1.7,1.4,1.5,1.4,1.5,1.5,1.6,1.4,1.1,1.2,1.5,1.3,1.4,1.7,1.5,1.7,1.5,1,1.7,1.9,1.6,1.6,1.5,1.4,1.6,1.6,1.5,1.5,1.4,1.5,1.2,1.3,1.4,1.3,1.5,1.3,1.3,1.3,1.6,1.9,1.4,1.6,1.4,1.5,1.4,4.7,4.5,4.9,4,4.6,4.5,4.7,3.3,4.6,3.9,3.5,4.2,4,4.7,3.6,4.4,4.5,4.1,4.5,3.9,4.8,4,4.9,4.7,4.3,4.4,4.8,5,4.5,3.5,3.8,3.7,3.9,5.1,4.5,4.5,4.7,4.4,4.1,4,4.4,4.6,4,3.3,4.2,4.2,4.2,4.3,3,4.1,6,5.1,5.9,5.6,5.8,6.6,4.5,6.3,5.8,6.1,5.1,5.3,5.5,5,5.1,5.3,5.5,6.7,6.9,5,5.7,4.9,6.7,4.9,5.7,6,4.8,4.9,5.6,5.8,6.1,6.4,5.6,5.1,5.6,6.1,5.6,5.5,4.8,5.4,5.6,5.1,5.1,5.9,5.7,5.2,5,5.2,5.4,5.1],[0.2,0.2,0.2,0.2,0.2,0.4,0.3,0.2,0.2,0.1,0.2,0.2,0.1,0.1,0.2,0.4,0.4,0.3,0.3,0.3,0.2,0.4,0.2,0.5,0.2,0.2,0.4,0.2,0.2,0.2,0.2,0.4,0.1,0.2,0.2,0.2,0.2,0.1,0.2,0.2,0.3,0.3,0.2,0.6,0.4,0.3,0.2,0.2,0.2,0.2,1.4,1.5,1.5,1.3,1.5,1.3,1.6,1,1.3,1.4,1,1.5,1,1.4,1.3,1.4,1.5,1,1.5,1.1,1.8,1.3,1.5,1.2,1.3,1.4,1.4,1.7,1.5,1,1.1,1,1.2,1.6,1.5,1.6,1.5,1.3,1.3,1.3,1.2,1.4,1.2,1,1.3,1.2,1.3,1.3,1.1,1.3,2.5,1.9,2.1,1.8,2.2,2.1,1.7,1.8,1.8,2.5,2,1.9,2.1,2,2.4,2.3,1.8,2.2,2.3,1.5,2.3,2,2,1.8,2.1,1.8,1.8,1.8,2.1,1.6,1.9,2,2.2,1.5,1.4,2.3,2.4,1.8,1.8,2.1,2.4,2.3,1.9,2.3,2.5,2.3,1.9,2,2.3,1.8],[\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\"]],\"container\":\"\\n \\n \\n  \\n Sepal.Length\\n Sepal.Width\\n Petal.Length\\n Petal.Width\\n Species\\n \\n \\n\",\"options\":{\"pageLength\":100,\"scrollX\":true,\"scrollY\":\"600px\",\"autoWidth\":true,\"columnDefs\":[{\"className\":\"dt-right\",\"targets\":[1,2,3,4]},{\"orderable\":false,\"targets\":0}],\"order\":[],\"orderClasses\":false,\"orderCellsTop\":true}},\"evals\":[],\"jsHooks\":[]} Figures Plots generated by the R code chunks in an R Markdown document can be automatically inserted in the output file. The size of the figure can be controlled with the fig.height and fig.width arguments.\nlibrary(ggplot2) dsmall \u003c- diamonds[sample(nrow(diamonds), 1000), ] ggplot(dsmall, aes(color, price/carat)) + geom_jitter(alpha = I(1 / 2), aes(color=color))  Sometimes it can be useful to explicitly write an image to a file and then insert that image into the final document by referencing its file name in the R Markdown source. For instance, this can be useful for time consuming analyses. The following code will generate a file named myplot.png. To insert the file in the final document, one can use standard Markdown or HTML syntax, e.g.: \u003cimg src=\"myplot.png\"/\u003e.\npng(\"myplot.png\") ggplot(dsmall, aes(color, price/carat)) + geom_jitter(alpha = I(1 / 2), aes(color=color)) dev.off()  ## png ## 2    Inline R code To evaluate R code inline, one can enclose an R expression with a single back-tick followed by r and then the actual expression. For instance, the back-ticked version of ‘r 1 + 1’ evaluates to 2 and ‘r pi’ evaluates to 3.1415927.\nMathematical equations To render mathematical equations, one can use standard Latex syntax. When expressions are enclosed with single $ signs then they will be shown inline, while enclosing them with double $$ signs will show them in display mode. For instance, the following Latex syntax d(X,Y) = \\sqrt[]{ \\sum_{i=1}^{n}{(x_{i}-y_{i})^2} } renders in display mode as follows:\n$$d(X,Y) = \\sqrt[]{ \\sum_{i=1}^{n}{(x_{i}-y_{i})^2} }$$\nCitations and bibliographies Citations and bibliographies can be autogenerated in R Markdown in a similar way as in Latex/Bibtex. Reference collections should be stored in a separate file in Bibtex or other supported formats. To cite a publication in an R Markdown script, one uses the syntax [@\u003cid1\u003e] where \u003cid1\u003e needs to be replaced with a reference identifier present in the Bibtex database listed in the metadata section of the R Markdown script (e.g. bibtex.bib). For instance, to cite Lawrence et al. (2013), one uses its reference identifier (e.g. Lawrence2013-kt) as \u003cid1\u003e (Lawrence et al. 2013). This will place the citation inline in the text and add the corresponding reference to a reference list at the end of the output document. For the latter a special section called References needs to be specified at the end of the R Markdown script. To fine control the formatting of citations and reference lists, users want to consult this the corresponding R Markdown page. Also, for general reference management and outputting references in Bibtex format Paperpile can be very helpful.\nViewing R Markdown report on HPCC cluster R Markdown reports located on UCR’s HPCC Cluster can be viewed locally in a web browser (without moving the source HTML) by creating a symbolic link from a user’s .html directory. This way any updates to the report will show up immediately without creating another copy of the HTML file. For instance, if user ttest has generated an R Markdown report under ~/bigdata/today/rmarkdown/sample.html, then the symbolic link can be created as follows:\ncd ~/.html ln -s ~/bigdata/today/rmarkdown/sample.html sample.html  After this one can view the report in a web browser using this URL http://biocluster.ucr.edu/~ttest/rmarkdown/sample.html. If necessary access to the URL can be restricted with a password following the instructions here.\nSession Info sessionInfo()  ## R version 4.0.5 (2021-03-31) ## Platform: x86_64-pc-linux-gnu (64-bit) ## Running under: Debian GNU/Linux 10 (buster) ## ## Matrix products: default ## BLAS: /usr/lib/x86_64-linux-gnu/blas/libblas.so.3.8.0 ## LAPACK: /usr/lib/x86_64-linux-gnu/lapack/liblapack.so.3.8.0 ## ## locale: ## [1] LC_CTYPE=en_US.UTF-8 LC_NUMERIC=C ## [3] LC_TIME=en_US.UTF-8 LC_COLLATE=en_US.UTF-8 ## [5] LC_MONETARY=en_US.UTF-8 LC_MESSAGES=en_US.UTF-8 ## [7] LC_PAPER=en_US.UTF-8 LC_NAME=C ## [9] LC_ADDRESS=C LC_TELEPHONE=C ## [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C ## ## attached base packages: ## [1] stats graphics grDevices utils datasets methods base ## ## other attached packages: ## [1] ggplot2_3.3.2 DT_0.16 knitr_1.30 ## ## loaded via a namespace (and not attached): ## [1] bslib_0.2.4 compiler_4.0.5 pillar_1.4.7 jquerylib_0.1.3 ## [5] highr_0.8 tools_4.0.5 digest_0.6.27 viridisLite_0.3.0 ## [9] jsonlite_1.7.1 evaluate_0.14 lifecycle_0.2.0 tibble_3.0.4 ## [13] gtable_0.3.0 pkgconfig_2.0.3 rlang_0.4.8 crosstalk_1.1.0.1 ## [17] yaml_2.2.1 blogdown_1.2 xfun_0.22 withr_2.3.0 ## [21] stringr_1.4.0 dplyr_1.0.2 generics_0.1.0 htmlwidgets_1.5.2 ## [25] sass_0.3.1 vctrs_0.3.5 tidyselect_1.1.0 grid_4.0.5 ## [29] glue_1.4.2 R6_2.5.0 rmarkdown_2.7 bookdown_0.21 ## [33] farver_2.0.3 purrr_0.3.4 magrittr_2.0.1 scales_1.1.1 ## [37] htmltools_0.5.1.1 ellipsis_0.3.1 colorspace_2.0-0 labeling_0.4.2 ## [41] stringi_1.5.3 munsell_0.5.0 crayon_1.3.4  References Lawrence, Michael, Wolfgang Huber, Hervé Pagès, Patrick Aboyoun, Marc Carlson, Robert Gentleman, Martin T Morgan, and Vincent J Carey. 2013. “Software for Computing and Annotating Genomic Ranges.” PLoS Comput. Biol. 9 (8): e1003118. https://doi.org/10.1371/journal.pcbi.1003118.\n  ","categories":"","description":"","excerpt":"       R Markdown Overview R Markdown combines markdown (an easy to …","ref":"/manuals/rbasics/sample/","tags":"","title":"Sample R Markdown"},{"body":"   This page provides instructions how to create new deployment instances of this teaching site, and how to configure and customize it. It uses the Docsy theme of the Hugo framework for building content driven websites.\n Quick start  Click on the Use this Template button. Choose a Repository Name Click on the Create repository from template button.  Usage locally  Go to your new repository that created from our template https://github.com/\u003cusername\u003e/\u003crepository_name\u003e Click on the Code button. Copy the URL https://github.com/\u003cusername\u003e/\u003crepository_name\u003e.git Open terminal  git clone --recurse-submodules --depth 1 https://github.com/\u003cusername\u003e/\u003crepository_name\u003e.git cd \u003crepository_name\u003e   Run the website locally  hugo server   Run the website locally with blogdown  blogdown::serve_site()  Prerequisites and Installation Install blogdown and Hugo blogdown installed.packages(\"rstudio/blogdown\") # If anything wrong try develop version remotes::install_github(\"rstudio/blogdown\")  Hugo You need a recent extended version (we recommend version 0.79.0 or later) of Hugo to do local builds and previews of sites that use Docsy.\nIt is recommended to install Hugo from R for working with blogdown\nblogdown::install_hugo(extended = TRUE)  or from commandline\nwget https://github.com/gohugoio/hugo/releases/download/v0.79.0/hugo_extended_0.79.0_Linux-64bit.deb sudo dpkg -i hugo_extended_0.79.0_Linux-64bit.deb hugo version  For Windows and macOS please see instructions here.\nInstall PostCSS To build or update your site’s CSS resources, you also need PostCSS to create the final assets. If you need to install it, you must have a recent version of NodeJS installed on your machine so you can use npm, the Node package manager. By default npm installs tools under the directory where you run npm install:\nsudo npm install -D autoprefixer sudo npm install -D postcss-cli # Starting in version 8 of postcss-cli, you must also separately install postcss: sudo npm install -D postcss # go to your website directory cd \u003crepository_name\u003e npm audit fix  Run the website locally with blogdown  Open R in console or Rstudio  This repo contains a .Rprofile file that will automatically serve the site for you R starting directory is this newly cloned repository. Otherwise, change working directory to the repository and run:\nblogdown::serve_site()  You should see a website is opened in your local browser or Rstudio viewer.\nRun the website locally on the terminal cd YOUR_NEW_REPO_PATH hugo server  ","categories":"","description":"","excerpt":"   This page provides instructions how to create new deployment …","ref":"/about/internal/install/","tags":"","title":"Deployment and Maintenance of this Site"},{"body":"document.addEventListener(\"DOMContentLoaded\", function() { document.querySelector(\"h1\").className = \"title\"; });  document.addEventListener(\"DOMContentLoaded\", function() { var links = document.links; for (var i = 0, linksLength = links.length; i Source code downloads: [ .Rmd ] [ .R ]\n Overview Sequence Analysis in R and Bioconductor R Base\n Some basic string handling utilities. Wide spectrum of numeric data analysis tools.  Bioconductor\nBioconductor packages provide much more sophisticated string handling utilities for sequence analysis (Lawrence et al. 2013; Huber et al. 2015).\n Biostrings: general sequence analysis environment ShortRead: pipeline for short read data IRanges: low-level infrastructure for range data GenomicRanges: high-level infrastructure for range data GenomicFeatures: managing transcript centric annotations GenomicAlignments: handling short genomic alignments Rsamtools: interface to samtools, bcftools and tabix BSgenome: genome annotation data biomaRt: interface to BioMart annotations rtracklayer: Annotation imports, interface to online genome browsers HelloRanges: Bedtools semantics in Bioc’s Ranges infrastructure  Package Requirements Several Bioconductor packages are required for this tutorial. To install them, execute the following lines in the R console. Please also make sure that you have a recent R version installed on your system. R versions 3.3.x or higher are recommended.\nsource(\"https://bioconductor.org/biocLite.R\") if (!requireNamespace(\"BiocManager\", quietly = TRUE)) install.packages(\"BiocManager\") BiocManager::install(c(\"Biostrings\", \"GenomicRanges\", \"rtracklayer\", \"systemPipeR\", \"seqLogo\", \"ShortRead\"))  Strings in R Base Basic String Matching and Parsing String matching Generate sample sequence data set\nmyseq \u003c- c(\"ATGCAGACATAGTG\", \"ATGAACATAGATCC\", \"GTACAGATCAC\")  String searching with regular expression support\nmyseq[grep(\"ATG\", myseq)]  ## [1] \"ATGCAGACATAGTG\" \"ATGAACATAGATCC\"  Searches myseq for first match of pattern “AT”\npos1 \u003c- regexpr(\"AT\", myseq) as.numeric(pos1); attributes(pos1)$match.length # Returns position information of matches  ## [1] 1 1 7 ## [1] 2 2 2  Searches myseq for all matches of pattern “AT”\npos2 \u003c- gregexpr(\"AT\", myseq) as.numeric(pos2[[1]]); attributes(pos2[[1]])$match.length # Returns positions of matches in first sequence  ## [1] 1 9 ## [1] 2 2  String substitution with regular expression support\ngsub(\"^ATG\", \"atg\", myseq)  ## [1] \"atgCAGACATAGTG\" \"atgAACATAGATCC\" \"GTACAGATCAC\"  Positional parsing nchar(myseq) # Computes length of strings  ## [1] 14 14 11  substring(myseq[1], c(1,3), c(2,5)) # Positional parsing of several fragments from one string  ## [1] \"AT\" \"GCA\"  substring(myseq, c(1,4,7), c(2,6,10)) # Positional parsing of many strings  ## [1] \"AT\" \"AAC\" \"ATCA\"  Random Sequence Generation Random DNA sequences of any length rand \u003c- sapply(1:100, function(x) paste(sample(c(\"A\",\"T\",\"G\",\"C\"), sample(10:20), replace=TRUE), collapse=\"\")) rand[1:3]  ## [1] \"TAGACCGGCTGCTAAATG\" \"ACTGCGTGCAATGCACAA\" \"ATGGGGCTCACACAG\"  Count identical sequences table(c(rand[1:4], rand[1]))  ## ## AGTATTCTAGGCGATGG CACGATCACGTCCGCTA GAGAACTTCTCGAG GGTCCAATAGTGTGACGACC ## 1 2 1 1  Extract reads from reference Note: this requires Biostrings package.\nlibrary(Biostrings) ref \u003c- DNAString(paste(sample(c(\"A\",\"T\",\"G\",\"C\"), 100000, replace=T), collapse=\"\")) randstart \u003c- sample(1:(length(ref)-15), 1000) randreads \u003c- Views(ref, randstart, width=15) rand_set \u003c- DNAStringSet(randreads) unlist(rand_set)  ## 15000-letter DNAString object ## seq: TTCGTACGGCAGACGCCAGGGAACGGATCCCCCCGTAGGAAGGCGG...ACCTGCCGTAGCTGGCCTGAGACCTCCTCGAACGACTATGGCATTA  Sequences in Bioconductor Important Data Objects of Biostrings XString for single sequence  DNAString: for DNA RNAString: for RNA AAString: for amino acid BString: for any string  XStringSet for many sequences  `DNAStringSet``: for DNA RNAStringSet: for RNA AAStringSet: for amino acid BStringSet: for any string  QualityScaleXStringSet for sequences with quality data  QualityScaledDNAStringSet: for DNA QualityScaledRNAStringSet: for RNA QualityScaledAAStringSet: for amino acid QualityScaledBStringSet: for any string  Sequence Import and Export Download the following sequences to your current working directory and then import them into R: https://ftp.ncbi.nlm.nih.gov/genomes/archive/old_genbank/Bacteria/Halobacterium_sp_uid217/AE004437.ffn\ndir.create(\"data\", showWarnings = FALSE) # system(\"wget https://ftp.ncbi.nlm.nih.gov/genomes/archive/old_genbank/Bacteria/Halobacterium_sp_uid217/AE004437.ffn\") download.file(\"https://ftp.ncbi.nlm.nih.gov/genomes/archive/old_genbank/Bacteria/Halobacterium_sp_uid217/AE004437.ffn\", \"data/AE004437.ffn\")  Import FASTA file with readDNAStringSet\nmyseq \u003c- readDNAStringSet(\"data/AE004437.ffn\") myseq[1:3]  ## DNAStringSet object of length 3: ## width seq names ## [1] 1206 ATGACTCGGCGGTCTCGTGTCGGTGCCGGCCTC...GTCGTCGTTGTTCGACGCTGGCGGAACCCATGA gi|12057215|gb|AE... ## [2] 666 ATGAGCATCATCGAACTCGAAGGCGTGGTCAAA...GTCAACCTCGTCGATGGGGTGTTACACACGTGA gi|12057215|gb|AE... ## [3] 1110 ATGGCGTGGCGGAACCTCGGGCGGAACCGCGTG...AACGATCCGCCCGTCGAGGCGCTCGGCGAATGA gi|12057215|gb|AE...  Subset sequences with regular expression on sequence name field\nsub \u003c- myseq[grep(\"99.*\", names(myseq))] length(sub)  ## [1] 170  Export subsetted sequences to FASTA file\nwriteXStringSet(sub, file=\"./data/AE004437sub.ffn\", width=80)  Now inspect exported sequence file AE004437sub.ffn in a text editor\nWorking with XString Containers The XString stores the different types of biosequences in dedicated containers\nlibrary(Biostrings) d \u003c- DNAString(\"GCATAT-TAC\") d  ## 10-letter DNAString object ## seq: GCATAT-TAC  d[1:4]  ## 4-letter DNAString object ## seq: GCAT  RNA sequences\nr \u003c- RNAString(\"GCAUAU-UAC\") r \u003c- RNAString(d) # Converts d to RNAString object r  ## 10-letter RNAString object ## seq: GCAUAU-UAC  Protein sequences\np \u003c- AAString(\"HCWYHH\") p  ## 6-letter AAString object ## seq: HCWYHH  Any type of character strings\nb \u003c- BString(\"I store any set of characters. Other XString objects store only the IUPAC characters.\") b  ## 85-letter BString object ## seq: I store any set of characters. Other XString objects store only the IUPAC characters.  Working with XStringSet Containers XStringSet containers allow to store many biosequences in one object\ndset \u003c- DNAStringSet(c(\"GCATATTAC\", \"AATCGATCC\", \"GCATATTAC\")) names(dset) \u003c- c(\"seq1\", \"seq2\", \"seq3\") # Assigns names dset[1:2]  ## DNAStringSet object of length 2: ## width seq names ## [1] 9 GCATATTAC seq1 ## [2] 9 AATCGATCC seq2  Important utilities for XStringSet containers\nwidth(dset) # Returns the length of each sequences  ## [1] 9 9 9  d \u003c- dset[[1]] # The [[ subsetting operator returns a single entry as XString object dset2 \u003c- c(dset, dset) # Appends/concatenates two XStringSet objects dsetchar \u003c- as.character(dset) # Converts XStringSet to named vector dsetone \u003c- unlist(dset) # Collapses many sequences to a single one stored in a DNAString container  Sequence subsetting by positions:\nDNAStringSet(dset, start=c(1,2,3), end=c(4,8,5))  ## DNAStringSet object of length 3: ## width seq names ## [1] 4 GCAT seq1 ## [2] 7 ATCGATC seq2 ## [3] 3 ATA seq3  Multiple Alignment Class The XMultipleAlignment class stores the different types of multiple sequence alignments:\norigMAlign \u003c- readDNAMultipleAlignment(filepath = system.file(\"extdata\", \"msx2_mRNA.aln\", package = \"Biostrings\"), format = \"clustal\") origMAlign  ## DNAMultipleAlignment with 8 rows and 2343 columns ## aln names ## [1] -----TCCCGTCTCCGCAGCAAAAAAGTTTGAGTCG...TTGTCCAAACTCACAATTAAAAAAAAAAAAAAAAA gi|84452153|ref|N... ## [2] ------------------------------------...----------------------------------- gi|208431713|ref|... ## [3] ------------------------------------...----------------------------------- gi|118601823|ref|... ## [4] ----------------------AAAAGTTGGAGTCT...----------------------------------- gi|114326503|ref|... ## [5] ------------------------------------...----------------------------------- gi|119220589|ref|... ## [6] ------------------------------------...----------------------------------- gi|148540149|ref|... ## [7] --------------CGGCTCCGCAGCGCCTCACTCG...----------------------------------- gi|45383056|ref|N... ## [8] GGGGGAGACTTCAGAAGTTGTTGTCCTCTCCGCTGA...----------------------------------- gi|213515133|ref|...  Basic Sequence Manipulations Reverse and Complement randset \u003c- DNAStringSet(rand) complement(randset[1:2])  ## DNAStringSet object of length 2: ## width seq ## [1] 17 GTGCTAGTGCAGGCGAT ## [2] 17 TCATAAGATCCGCTACC  reverse(randset[1:2])  ## DNAStringSet object of length 2: ## width seq ## [1] 17 ATCGCCTGCACTAGCAC ## [2] 17 GGTAGCGGATCTTATGA  reverseComplement(randset[1:2])  ## DNAStringSet object of length 2: ## width seq ## [1] 17 TAGCGGACGTGATCGTG ## [2] 17 CCATCGCCTAGAATACT  Translate DNA into Protein translate(randset[1:2])  ## Warning in .Call2(\"DNAStringSet_translate\", x, skip_code, dna_codes[codon_alphabet], : in 'x[[1]]': ## last 2 bases were ignored ## Warning in .Call2(\"DNAStringSet_translate\", x, skip_code, dna_codes[codon_alphabet], : in 'x[[2]]': ## last 2 bases were ignored ## AAStringSet object of length 2: ## width seq ## [1] 5 HDHVR ## [2] 5 SILGD  Pattern Matching Pattern matching with mismatches Find pattern matches in reference\nmyseq1 \u003c- readDNAStringSet(\"./data/AE004437.ffn\") mypos \u003c- matchPattern(\"ATGGTG\", myseq1[[1]], max.mismatch=1)  Count only the corresponding matches\ncountPattern(\"ATGGCT\", myseq1[[1]], max.mismatch=1)  ## [1] 3  Count matches in many sequences\nvcountPattern(\"ATGGCT\", myseq1, max.mismatch=1)[1:20]  ## [1] 3 0 5 4 1 2 2 1 4 3 0 0 1 2 0 1 4 0 0 1  Results shown in DNAStringSet object\ntmp \u003c- c(DNAStringSet(\"ATGGTG\"), DNAStringSet(mypos))  Return a consensus matrix for query and hits\nconsensusMatrix(tmp)[1:4,]  ## [,1] [,2] [,3] [,4] [,5] [,6] ## A 3 0 0 0 0 0 ## C 1 1 0 0 0 0 ## G 0 0 4 4 1 4 ## T 0 3 0 0 3 0  Find all pattern matches in reference\nmyvpos \u003c- vmatchPattern(\"ATGGCT\", myseq1, max.mismatch=1) myvpos # The results are stored as MIndex object.  ## MIndex object of length 2058 ## $`gi|12057215|gb|AE004437.1|:248-1453 Halobacterium sp. NRC-1, complete genome` ## IRanges object with 3 ranges and 0 metadata columns: ## start end width ## \u003cinteger\u003e \u003cinteger\u003e \u003cinteger\u003e ## [1] 1 6 6 ## [2] 383 388 6 ## [3] 928 933 6 ## ## $`gi|12057215|gb|AE004437.1|:1450-2115 Halobacterium sp. NRC-1, complete genome` ## IRanges object with 0 ranges and 0 metadata columns: ## start end width ## \u003cinteger\u003e \u003cinteger\u003e \u003cinteger\u003e ## ## $`gi|12057215|gb|AE004437.1|:2145-3254 Halobacterium sp. NRC-1, complete genome` ## IRanges object with 5 ranges and 0 metadata columns: ## start end width ## \u003cinteger\u003e \u003cinteger\u003e \u003cinteger\u003e ## [1] 1 6 6 ## [2] 94 99 6 ## [3] 221 226 6 ## [4] 535 540 6 ## [5] 601 606 6 ## ## ... ## \u003c2055 more elements\u003e  Views(myseq1[[1]], start(myvpos[[1]]), end(myvpos[[1]])) # Retrieves the result for single entry  ## Views on a 1206-letter DNAString subject ## subject: ATGACTCGGCGGTCTCGTGTCGGTGCCGGCCTCGCAGCCATTGT...TTGCGATCGTCGTCGTCGTTGTTCGACGCTGGCGGAACCCATGA ## views: ## start end width ## [1] 1 6 6 [ATGACT] ## [2] 383 388 6 [ATGGCA] ## [3] 928 933 6 [ATGACT]  Return all matches\nsapply(names(myseq1), function(x) as.character(Views(myseq1[[x]], start(myvpos[[x]]), end(myvpos[[x]]))))[1:4]  Pattern matching with regular expression support myseq \u003c- DNAStringSet(c(\"ATGCAGACATAGTG\", \"ATGAACATAGATCC\", \"GTACAGATCAC\")) myseq[grep(\"^ATG\", myseq, perl=TRUE)] # String searching with regular expression support  ## DNAStringSet object of length 2: ## width seq ## [1] 14 ATGCAGACATAGTG ## [2] 14 ATGAACATAGATCC  pos1 \u003c- regexpr(\"AT\", myseq) # Searches 'myseq' for first match of pattern \"AT\" as.numeric(pos1); attributes(pos1)$match.length # Returns position information of matches  ## [1] 1 1 7 ## [1] 2 2 2  pos2 \u003c- gregexpr(\"AT\", myseq) # Searches 'myseq' for all matches of pattern \"AT\" as.numeric(pos2[[1]]); attributes(pos2[[1]])$match.length # Match positions in first sequence  ## [1] 1 9 ## [1] 2 2  DNAStringSet(gsub(\"^ATG\", \"NNN\", myseq)) # String substitution with regular expression support  ## DNAStringSet object of length 3: ## width seq ## [1] 14 NNNCAGACATAGTG ## [2] 14 NNNAACATAGATCC ## [3] 11 GTACAGATCAC  PWM Viewing and Searching Plot with seqLogo library(seqLogo)  ## Loading required package: grid  pwm \u003c- PWM(DNAStringSet(c(\"GCT\", \"GGT\", \"GCA\"))) pwm  ## [,1] [,2] [,3] ## A 0.0000000 0.0000000 0.2312611 ## C 0.0000000 0.3157205 0.0000000 ## G 0.3685591 0.2312611 0.0000000 ## T 0.0000000 0.0000000 0.3157205  seqLogo(t(t(pwm) * 1/colSums(pwm)))  Plot with ggseqlogo The ggseqlogo package (manual) provides many customization options for plotting sequence logos. It also supports various alphabets including sequence logos for amino acid sequences.\nlibrary(ggplot2); library(ggseqlogo) pwm \u003c- PWM(DNAStringSet(c(\"GCT\", \"GGT\", \"GCA\"))) ggseqlogo(pwm)  Search sequence for PWM matches with score better than min.score\nchr \u003c- DNAString(\"AAAGCTAAAGGTAAAGCAAAA\") matchPWM(pwm, chr, min.score=0.9)  ## Views on a 21-letter DNAString subject ## subject: AAAGCTAAAGGTAAAGCAAAA ## views: ## start end width ## [1] 4 6 3 [GCT] ## [2] 10 12 3 [GGT] ## [3] 16 18 3 [GCA]  NGS Sequences Sequence and Quality Data: FASTQ Format Four lines per sequence:\n ID Sequence ID Base call qualities (Phred scores) as ASCII characters  The following gives an example of 3 Illumina reads in a FASTQ file. The numbers at the beginning of each line are not part of the FASTQ format. They have been added solely for illustration purposes.\n1. @SRR038845.3 HWI-EAS038:6:1:0:1938 length=36 2. CAACGAGTTCACACCTTGGCCGACAGGCCCGGGTAA 3. +SRR038845.3 HWI-EAS038:6:1:0:1938 length=36 4. BA@7\u003eB=\u003e:\u003e\u003e7@7@\u003e\u003e9=BAA?;\u003e52;\u003e:9=8.=A 1. @SRR038845.41 HWI-EAS038:6:1:0:1474 length=36 2. CCAATGATTTTTTTCCGTGTTTCAGAATACGGTTAA 3. +SRR038845.41 HWI-EAS038:6:1:0:1474 length=36 4. BCCBA@BB@BBBBAB@B9B@=BABA@A:@693:@B= 1. @SRR038845.53 HWI-EAS038:6:1:1:360 length=36 2. GTTCAAAAAGAACTAAATTGTGTCAATAGAAAACTC 3. +SRR038845.53 HWI-EAS038:6:1:1:360 length=36 4. BBCBBBBBB@@BAB?BBBBCBC\u003eBBBAA8\u003eBBBAA@  Sequence and Quality Data: QualityScaleXStringSet Phred quality scores are integers from 0-50 that are stored as ASCII characters after adding 33. The basic R functions rawToChar and charToRaw can be used to interconvert among their representations.\nPhred score interconversion\nphred \u003c- 1:9 phreda \u003c- paste(sapply(as.raw((phred)+33), rawToChar), collapse=\"\") phreda  ## [1] \"\\\"#$%\u0026'()*\"  as.integer(charToRaw(phreda))-33  ## [1] 1 2 3 4 5 6 7 8 9  Construct QualityScaledDNAStringSet from scratch\ndset \u003c- DNAStringSet(sapply(1:100, function(x) paste(sample(c(\"A\",\"T\",\"G\",\"C\"), 20, replace=T), collapse=\"\"))) # Creates random sample sequence. myqlist \u003c- lapply(1:100, function(x) sample(1:40, 20, replace=T)) # Creates random Phred score list. myqual \u003c- sapply(myqlist, function(x) toString(PhredQuality(x))) # Converts integer scores into ASCII characters. myqual \u003c- PhredQuality(myqual) # Converts to a PhredQuality object. dsetq1 \u003c- QualityScaledDNAStringSet(dset, myqual) # Combines DNAStringSet and quality data in QualityScaledDNAStringSet object. dsetq1[1:2]  ## A QualityScaledDNAStringSet instance containing: ## ## DNAStringSet object of length 2: ## width seq ## [1] 20 ACCAGCAGGGGTGTCGGTCA ## [2] 20 GGACCTGCACAGAGCAGCGT ## ## PhredQuality object of length 2: ## width seq ## [1] 20 G;7H5GA7-(B6@0/GB'67 ## [2] 20 6D:31,,\u003cA\u0026%3%:9H2I'E  Processing FASTQ Files with ShortRead The following explains the basic usage of ShortReadQ objects. To make the sample code work, download and unzip this file to your current working directory. The following code performs the download for you.\nlibrary(ShortRead) download.file(\"http://cluster.hpcc.ucr.edu/~tgirke/HTML_Presentations/Manuals/testdata/samplefastq/data.zip\", \"data.zip\") unzip(\"data.zip\")  Important utilities for accessing FASTQ files\nfastq \u003c- list.files(\"data\", \"*.fastq$\"); fastq \u003c- paste(\"data/\", fastq, sep=\"\") names(fastq) \u003c- paste(\"flowcell6_lane\", 1:length(fastq), sep=\"_\") (fq \u003c- readFastq(fastq[1])) # Imports first FASTQ file  ## class: ShortReadQ ## length: 1000 reads; width: 36 cycles  countLines(dirPath=\"./data\", pattern=\".fastq$\")/4 # Counts numbers of reads in FASTQ files  ## SRR038845.fastq SRR038846.fastq SRR038848.fastq SRR038850.fastq ## 1000 1000 1000 1000  id(fq)[1] # Returns ID field  ## BStringSet object of length 1: ## width seq ## [1] 43 SRR038845.3 HWI-EAS038:6:1:0:1938 length=36  sread(fq)[1] # Returns sequence  ## DNAStringSet object of length 1: ## width seq ## [1] 36 CAACGAGTTCACACCTTGGCCGACAGGCCCGGGTAA  quality(fq)[1] # Returns Phred scores  ## class: FastqQuality ## quality: ## BStringSet object of length 1: ## width seq ## [1] 36 BA@7\u003eB=\u003e:\u003e\u003e7@7@\u003e\u003e9=BAA?;\u003e52;\u003e:9=8.=A  as(quality(fq), \"matrix\")[1:4,1:12] # Coerces Phred scores to numeric matrix  ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] ## [1,] 33 32 31 22 29 33 28 29 25 29 29 22 ## [2,] 33 34 34 33 32 31 33 33 31 33 33 33 ## [3,] 33 33 34 33 33 33 33 33 33 31 31 33 ## [4,] 33 33 33 33 31 33 28 31 28 32 33 33  ShortReadQ(sread=sread(fq), quality=quality(fq), id=id(fq)) # Constructs a ShortReadQ from components  ## class: ShortReadQ ## length: 1000 reads; width: 36 cycles  FASTQ Quality Reports Using systemPipeR The following seeFastq and seeFastqPlot functions generate and plot a series of useful quality statistics for a set of FASTQ files.\nlibrary(systemPipeR) fqlist \u003c- seeFastq(fastq=fastq, batchsize=800, klength=8) # For real data set batchsize to at least 10^5 seeFastqPlot(fqlist)  Handles many samples in one PDF file. For more details see here\nUsing ShortRead The ShortRead package contains several FASTQ quality reporting functions.\nsp \u003c- SolexaPath(system.file('extdata', package='ShortRead')) fl \u003c- file.path(analysisPath(sp), \"s_1_sequence.txt\") fls \u003c- c(fl, fl) coll \u003c- QACollate(QAFastqSource(fls), QAReadQuality(), QAAdapterContamination(), QANucleotideUse(), QAQualityUse(), QASequenceUse(), QAFrequentSequence(n=10), QANucleotideByCycle(), QAQualityByCycle()) x \u003c- qa2(coll, verbose=TRUE) res \u003c- report(x) if(interactive()) browseURL(res)  Filtering and Trimming FASTQ Files with ShortRead Adaptor trimming fqtrim \u003c- trimLRPatterns(Rpattern=\"GCCCGGGTAA\", subject=fq) sread(fq)[1:2] # Before trimming  ## DNAStringSet object of length 2: ## width seq ## [1] 36 CAACGAGTTCACACCTTGGCCGACAGGCCCGGGTAA ## [2] 36 CCAATGATTTTTTTCCGTGTTTCAGAATACGGTTAA  sread(fqtrim)[1:2] # After trimming  ## DNAStringSet object of length 2: ## width seq ## [1] 26 CAACGAGTTCACACCTTGGCCGACAG ## [2] 36 CCAATGATTTTTTTCCGTGTTTCAGAATACGGTTAA  Read counting and duplicate removal tables(fq)$distribution # Counts read occurences  ## nOccurrences nReads ## 1 1 948 ## 2 2 26  sum(srduplicated(fq)) # Identifies duplicated reads  ## [1] 26  fq[!srduplicated(fq)]  ## class: ShortReadQ ## length: 974 reads; width: 36 cycles  Trimming low quality tails cutoff \u003c- 30 cutoff \u003c- rawToChar(as.raw(cutoff+33)) sread(trimTails(fq, k=2, a=cutoff, successive=FALSE))[1:2]  ## DNAStringSet object of length 2: ## width seq ## [1] 4 CAAC ## [2] 20 CCAATGATTTTTTTCCGTGT  Removal of reads with Phred scores below a threshold value cutoff \u003c- 30 qcount \u003c- rowSums(as(quality(fq), \"matrix\") \u003c= 20) fq[qcount == 0] # Number of reads where all Phred scores \u003e= 20  ## class: ShortReadQ ## length: 349 reads; width: 36 cycles  Removal of reads with x Ns and/or low complexity segments filter1 \u003c- nFilter(threshold=1) # Keeps only reads without Ns filter2 \u003c- polynFilter(threshold=20, nuc=c(\"A\",\"T\",\"G\",\"C\")) # Removes reads with nucleotide bias, \u003e=20 of any base filter \u003c- compose(filter1, filter2) fq[filter(fq)]  ## class: ShortReadQ ## length: 989 reads; width: 36 cycles  Memory Efficient FASTQ Processing Streaming through FASTQ files with FastqStreamer and random sampling reads with FastqSampler\nfq \u003c- yield(FastqStreamer(fastq[1], 50)) # Imports first 50 reads fq \u003c- yield(FastqSampler(fastq[1], 50)) # Random samples 50 reads  Streaming through a FASTQ file while applying filtering/trimming functions and writing the results to a new file here SRR038845.fastq_sub in data directory.\nf \u003c- FastqStreamer(fastq[1], 50) while(length(fq \u003c- yield(f))) { fqsub \u003c- fq[grepl(\"^TT\", sread(fq))] writeFastq(fqsub, paste(fastq[1], \"sub\", sep=\"_\"), mode=\"a\", compress=FALSE) } close(f)  Range Operations Important Data Objects for Range Operations  IRanges: stores range data only (IRanges library) GRanges: stores ranges and annotations (GenomicRanges library) GRangesList: list version of GRanges container (GenomicRanges library)  Range Data Are Stored in IRanges and GRanges Containers Construct GRanges Object library(GenomicRanges); library(rtracklayer) gr \u003c- GRanges(seqnames = Rle(c(\"chr1\", \"chr2\", \"chr1\", \"chr3\"), c(1, 3, 2, 4)), ranges = IRanges(1:10, end = 7:16, names = head(letters, 10)), strand = Rle(strand(c(\"-\", \"+\", \"*\", \"+\", \"-\")), c(1, 2, 2, 3, 2)), score = 1:10, GC = seq(1, 0, length = 10)) # Example of creating a GRanges object with its constructor function.  Import GFF into GRanges Object gff \u003c- import.gff(\"http://cluster.hpcc.ucr.edu/~tgirke/Documents/R_BioCond/Samples/gff3.gff\") # Imports a simplified GFF3 genome annotation file. seqlengths(gff) \u003c- end(ranges(gff[which(values(gff)[,\"type\"]==\"chromosome\"),])) names(gff) \u003c- 1:length(gff) # Assigns names to corresponding slot gff[1:4,]  ## GRanges object with 4 ranges and 10 metadata columns: ## seqnames ranges strand | source type score phase ID ## \u003cRle\u003e \u003cIRanges\u003e \u003cRle\u003e | \u003cfactor\u003e \u003cfactor\u003e \u003cnumeric\u003e \u003cinteger\u003e \u003ccharacter\u003e ## 1 Chr1 1-30427671 + | TAIR10 chromosome NA \u003cNA\u003e Chr1 ## 2 Chr1 3631-5899 + | TAIR10 gene NA \u003cNA\u003e AT1G01010 ## 3 Chr1 3631-5899 + | TAIR10 mRNA NA \u003cNA\u003e AT1G01010.1 ## 4 Chr1 3760-5630 + | TAIR10 protein NA \u003cNA\u003e AT1G01010.1-Protein ## Name Note Parent Index Derives_from ## \u003ccharacter\u003e \u003cCharacterList\u003e \u003cCharacterList\u003e \u003ccharacter\u003e \u003ccharacter\u003e ## 1 Chr1 \u003cNA\u003e \u003cNA\u003e ## 2 AT1G01010 protein_coding_gene \u003cNA\u003e \u003cNA\u003e ## 3 AT1G01010.1 AT1G01010 1 \u003cNA\u003e ## 4 AT1G01010.1 \u003cNA\u003e AT1G01010.1 ## ------- ## seqinfo: 7 sequences from an unspecified genome  Coerce GRanges object to data.frame as.data.frame(gff)[1:4, 1:7]  ## seqnames start end width strand source type ## 1 Chr1 1 30427671 30427671 + TAIR10 chromosome ## 2 Chr1 3631 5899 2269 + TAIR10 gene ## 3 Chr1 3631 5899 2269 + TAIR10 mRNA ## 4 Chr1 3760 5630 1871 + TAIR10 protein  Utilities for Range Containers Accessor and subsetting methods for GRanges objects Subsetting and replacement\ngff[1:4]  ## GRanges object with 4 ranges and 10 metadata columns: ## seqnames ranges strand | source type score phase ID ## \u003cRle\u003e \u003cIRanges\u003e \u003cRle\u003e | \u003cfactor\u003e \u003cfactor\u003e \u003cnumeric\u003e \u003cinteger\u003e \u003ccharacter\u003e ## 1 Chr1 1-30427671 + | TAIR10 chromosome NA \u003cNA\u003e Chr1 ## 2 Chr1 3631-5899 + | TAIR10 gene NA \u003cNA\u003e AT1G01010 ## 3 Chr1 3631-5899 + | TAIR10 mRNA NA \u003cNA\u003e AT1G01010.1 ## 4 Chr1 3760-5630 + | TAIR10 protein NA \u003cNA\u003e AT1G01010.1-Protein ## Name Note Parent Index Derives_from ## \u003ccharacter\u003e \u003cCharacterList\u003e \u003cCharacterList\u003e \u003ccharacter\u003e \u003ccharacter\u003e ## 1 Chr1 \u003cNA\u003e \u003cNA\u003e ## 2 AT1G01010 protein_coding_gene \u003cNA\u003e \u003cNA\u003e ## 3 AT1G01010.1 AT1G01010 1 \u003cNA\u003e ## 4 AT1G01010.1 \u003cNA\u003e AT1G01010.1 ## ------- ## seqinfo: 7 sequences from an unspecified genome  gff[1:4, c(\"type\", \"ID\")]  ## GRanges object with 4 ranges and 2 metadata columns: ## seqnames ranges strand | type ID ## \u003cRle\u003e \u003cIRanges\u003e \u003cRle\u003e | \u003cfactor\u003e \u003ccharacter\u003e ## 1 Chr1 1-30427671 + | chromosome Chr1 ## 2 Chr1 3631-5899 + | gene AT1G01010 ## 3 Chr1 3631-5899 + | mRNA AT1G01010.1 ## 4 Chr1 3760-5630 + | protein AT1G01010.1-Protein ## ------- ## seqinfo: 7 sequences from an unspecified genome  gff[2] \u003c- gff[3]  GRanges objects can be concatenated with the c function\nc(gff[1:2], gff[401:402])  ## GRanges object with 4 ranges and 10 metadata columns: ## seqnames ranges strand | source type score phase ID ## \u003cRle\u003e \u003cIRanges\u003e \u003cRle\u003e | \u003cfactor\u003e \u003cfactor\u003e \u003cnumeric\u003e \u003cinteger\u003e \u003ccharacter\u003e ## 1 Chr1 1-30427671 + | TAIR10 chromosome NA \u003cNA\u003e Chr1 ## 2 Chr1 3631-5899 + | TAIR10 mRNA NA \u003cNA\u003e AT1G01010.1 ## 401 Chr5 5516-5769 - | TAIR10 protein NA \u003cNA\u003e AT5G01015.2-Protein ## 402 Chr5 5770-5801 - | TAIR10 five_prime_UTR NA \u003cNA\u003e \u003cNA\u003e ## Name Note Parent Index Derives_from ## \u003ccharacter\u003e \u003cCharacterList\u003e \u003cCharacterList\u003e \u003ccharacter\u003e \u003ccharacter\u003e ## 1 Chr1 \u003cNA\u003e \u003cNA\u003e ## 2 AT1G01010.1 AT1G01010 1 \u003cNA\u003e ## 401 AT5G01015.2 \u003cNA\u003e AT5G01015.2 ## 402 \u003cNA\u003e AT5G01015.2 \u003cNA\u003e \u003cNA\u003e ## ------- ## seqinfo: 7 sequences from an unspecified genome  Acessor functions\nseqnames(gff)  ## factor-Rle of length 449 with 7 runs ## Lengths: 72 22 38 118 172 13 14 ## Values : Chr1 Chr2 Chr3 Chr4 Chr5 ChrC ChrM ## Levels(7): Chr1 Chr2 Chr3 Chr4 Chr5 ChrC ChrM  ranges(gff)  ## IRanges object with 449 ranges and 0 metadata columns: ## start end width ## \u003cinteger\u003e \u003cinteger\u003e \u003cinteger\u003e ## 1 1 30427671 30427671 ## 2 3631 5899 2269 ## 3 3631 5899 2269 ## 4 3760 5630 1871 ## 5 3631 3913 283 ## ... ... ... ... ## 445 11918 12241 324 ## 446 11918 12241 324 ## 447 11918 12241 324 ## 448 11918 12241 324 ## 449 11918 12241 324  strand(gff)  ## factor-Rle of length 449 with 13 runs ## Lengths: 18 54 28 21 12 117 1 171 1 12 1 8 5 ## Values : + - + - + - + - + - + - + ## Levels(3): + - *  seqlengths(gff)  ## Chr1 Chr2 Chr3 Chr4 Chr5 ChrC ChrM ## 30427671 19698289 23459830 18585056 26975502 154478 366924  start(gff[1:4])  ## [1] 1 3631 3631 3760  end(gff[1:4])  ## [1] 30427671 5899 5899 5630  width(gff[1:4])  ## [1] 30427671 2269 2269 1871  Accessing metadata component\nvalues(gff) # or elementMetadata(gff)  ## DataFrame with 449 rows and 10 columns ## source type score phase ID Name Note ## \u003cfactor\u003e \u003cfactor\u003e \u003cnumeric\u003e \u003cinteger\u003e \u003ccharacter\u003e \u003ccharacter\u003e \u003cCharacterList\u003e ## 1 TAIR10 chromosome NA NA Chr1 Chr1 ## 2 TAIR10 mRNA NA NA AT1G01010.1 AT1G01010.1 ## 3 TAIR10 mRNA NA NA AT1G01010.1 AT1G01010.1 ## 4 TAIR10 protein NA NA AT1G01010.1-Protein AT1G01010.1 ## 5 TAIR10 exon NA NA NA NA ## ... ... ... ... ... ... ... ... ## 445 TAIR10 gene NA NA ATMG00030 ATMG00030 protein_coding_gene ## 446 TAIR10 mRNA NA NA ATMG00030.1 ATMG00030.1 ## 447 TAIR10 protein NA NA ATMG00030.1-Protein ATMG00030.1 ## 448 TAIR10 exon NA NA NA NA ## 449 TAIR10 CDS NA 0 NA NA ## Parent Index Derives_from ## \u003cCharacterList\u003e \u003ccharacter\u003e \u003ccharacter\u003e ## 1 NA NA ## 2 AT1G01010 1 NA ## 3 AT1G01010 1 NA ## 4 NA AT1G01010.1 ## 5 AT1G01010.1 NA NA ## ... ... ... ... ## 445 NA NA ## 446 ATMG00030 1 NA ## 447 NA ATMG00030.1 ## 448 ATMG00030.1 NA NA ## 449 ATMG00030.1,ATMG00030.1-Protein NA NA  values(gff)[, \"type\"][1:20]  ## [1] chromosome mRNA mRNA protein exon five_prime_UTR ## [7] CDS exon CDS exon CDS exon ## [13] CDS exon CDS exon CDS three_prime_UTR ## [19] gene mRNA ## Levels: chromosome gene mRNA protein exon five_prime_UTR CDS three_prime_UTR rRNA tRNA  gff[values(gff)[ ,\"type\"] == \"gene\"]  ## GRanges object with 21 ranges and 10 metadata columns: ## seqnames ranges strand | source type score phase ID Name ## \u003cRle\u003e \u003cIRanges\u003e \u003cRle\u003e | \u003cfactor\u003e \u003cfactor\u003e \u003cnumeric\u003e \u003cinteger\u003e \u003ccharacter\u003e \u003ccharacter\u003e ## 19 Chr1 5928-8737 - | TAIR10 gene NA \u003cNA\u003e AT1G01020 AT1G01020 ## 64 Chr1 11649-13714 - | TAIR10 gene NA \u003cNA\u003e AT1G01030 AT1G01030 ## 74 Chr2 1025-2810 + | TAIR10 gene NA \u003cNA\u003e AT2G01008 AT2G01008 ## 84 Chr2 3706-5513 + | TAIR10 gene NA \u003cNA\u003e AT2G01010 AT2G01010 ## 87 Chr2 5782-5945 + | TAIR10 gene NA \u003cNA\u003e AT2G01020 AT2G01020 ## ... ... ... ... . ... ... ... ... ... ... ## 427 ChrC 383-1444 - | TAIR10 gene NA \u003cNA\u003e ATCG00020 ATCG00020 ## 432 ChrC 1717-4347 - | TAIR10 gene NA \u003cNA\u003e ATCG00030 ATCG00030 ## 437 ChrM 273-734 - | TAIR10 gene NA \u003cNA\u003e ATMG00010 ATMG00010 ## 442 ChrM 8848-11415 - | TAIR10 gene NA \u003cNA\u003e ATMG00020 ATMG00020 ## 445 ChrM 11918-12241 + | TAIR10 gene NA \u003cNA\u003e ATMG00030 ATMG00030 ## Note Parent Index Derives_from ## \u003cCharacterList\u003e \u003cCharacterList\u003e \u003ccharacter\u003e \u003ccharacter\u003e ## 19 protein_coding_gene \u003cNA\u003e \u003cNA\u003e ## 64 protein_coding_gene \u003cNA\u003e \u003cNA\u003e ## 74 protein_coding_gene \u003cNA\u003e \u003cNA\u003e ## 84 rRNA \u003cNA\u003e \u003cNA\u003e ## 87 rRNA \u003cNA\u003e \u003cNA\u003e ## ... ... ... ... ... ## 427 protein_coding_gene \u003cNA\u003e \u003cNA\u003e ## 432 tRNA \u003cNA\u003e \u003cNA\u003e ## 437 protein_coding_gene \u003cNA\u003e \u003cNA\u003e ## 442 rRNA \u003cNA\u003e \u003cNA\u003e ## 445 protein_coding_gene \u003cNA\u003e \u003cNA\u003e ## ------- ## seqinfo: 7 sequences from an unspecified genome  Useful utilities for GRanges objects Remove chromosome ranges\ngff \u003c- gff[values(gff)$type != \"chromosome\"]  Erase the strand information\nstrand(gff) \u003c- \"*\"  Collapses overlapping ranges to continuous ranges.\nreduce(gff)  ## GRanges object with 22 ranges and 0 metadata columns: ## seqnames ranges strand ## \u003cRle\u003e \u003cIRanges\u003e \u003cRle\u003e ## [1] Chr1 3631-5899 * ## [2] Chr1 5928-8737 * ## [3] Chr1 11649-13714 * ## [4] Chr2 1025-2810 * ## [5] Chr2 3706-5513 * ## ... ... ... ... ## [18] ChrC 383-1444 * ## [19] ChrC 1717-4347 * ## [20] ChrM 273-734 * ## [21] ChrM 8848-11415 * ## [22] ChrM 11918-12241 * ## ------- ## seqinfo: 7 sequences from an unspecified genome  Return uncovered regions\ngaps(gff)  ## GRanges object with 43 ranges and 0 metadata columns: ## seqnames ranges strand ## \u003cRle\u003e \u003cIRanges\u003e \u003cRle\u003e ## [1] Chr1 1-30427671 + ## [2] Chr1 1-30427671 - ## [3] Chr1 1-3630 * ## [4] Chr1 5900-5927 * ## [5] Chr1 8738-11648 * ## ... ... ... ... ## [39] ChrM 1-366924 - ## [40] ChrM 1-272 * ## [41] ChrM 735-8847 * ## [42] ChrM 11416-11917 * ## [43] ChrM 12242-366924 * ## ------- ## seqinfo: 7 sequences from an unspecified genome  More intuitive way to get uncovered regions\nsetdiff(as(seqinfo(gff), \"GRanges\"), gff)  ## GRanges object with 29 ranges and 0 metadata columns: ## seqnames ranges strand ## \u003cRle\u003e \u003cIRanges\u003e \u003cRle\u003e ## [1] Chr1 1-3630 * ## [2] Chr1 5900-5927 * ## [3] Chr1 8738-11648 * ## [4] Chr1 13715-30427671 * ## [5] Chr2 1-1024 * ## ... ... ... ... ## [25] ChrC 4348-154478 * ## [26] ChrM 1-272 * ## [27] ChrM 735-8847 * ## [28] ChrM 11416-11917 * ## [29] ChrM 12242-366924 * ## ------- ## seqinfo: 7 sequences from an unspecified genome  Return disjoint ranges\ndisjoin(gff)  ## GRanges object with 211 ranges and 0 metadata columns: ## seqnames ranges strand ## \u003cRle\u003e \u003cIRanges\u003e \u003cRle\u003e ## [1] Chr1 3631-3759 * ## [2] Chr1 3760-3913 * ## [3] Chr1 3914-3995 * ## [4] Chr1 3996-4276 * ## [5] Chr1 4277-4485 * ## ... ... ... ... ## [207] ChrC 1752-4310 * ## [208] ChrC 4311-4347 * ## [209] ChrM 273-734 * ## [210] ChrM 8848-11415 * ## [211] ChrM 11918-12241 * ## ------- ## seqinfo: 7 sequences from an unspecified genome  Returns coverage of ranges\ncoverage(gff)  ## RleList of length 7 ## $Chr1 ## integer-Rle of length 30427671 with 45 runs ## Lengths: 3630 129 154 82 281 ... 233 161 380 30413957 ## Values : 0 4 5 3 5 ... 4 2 4 0 ## ## $Chr2 ## integer-Rle of length 19698289 with 14 runs ## Lengths: 1024 248 185 53 362 ... 164 625 102 19691617 ## Values : 0 5 3 5 3 ... 3 0 5 0 ## ## $Chr3 ## integer-Rle of length 23459830 with 29 runs ## Lengths: 1652 145 139 111 95 ... 155 148 156 23453781 ## Values : 0 4 5 3 5 ... 3 5 4 0 ## ## $Chr4 ## integer-Rle of length 18585056 with 72 runs ## Lengths: 1179 357 1358 128 872 ... 212 114 74 18571697 ## Values : 0 5 0 5 3 ... 3 5 4 0 ## ## $Chr5 ## integer-Rle of length 26975502 with 64 runs ## Lengths: 1222 28 28 109 72 ... 76 55 174 26967058 ## Values : 0 4 7 13 16 ... 3 5 4 0 ## ## ... ## \u003c2 more elements\u003e  Return the index pairings for overlapping ranges\nfindOverlaps(gff, gff[1:4])  ## Hits object with 55 hits and 0 metadata columns: ## queryHits subjectHits ## \u003cinteger\u003e \u003cinteger\u003e ## [1] 1 1 ## [2] 1 2 ## [3] 1 4 ## [4] 1 3 ## [5] 2 1 ## ... ... ... ## [51] 16 1 ## [52] 16 2 ## [53] 16 3 ## [54] 17 1 ## [55] 17 2 ## ------- ## queryLength: 442 / subjectLength: 4  Counts overlapping ranges\ncountOverlaps(gff, gff[1:4])[1:40]  ## 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 ## 4 4 4 4 3 4 3 3 3 3 3 3 3 3 3 3 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ## 35 36 37 38 39 40 41 ## 0 0 0 0 0 0 0  Return only overlapping ranges\nsubsetByOverlaps(gff, gff[1:4])  ## GRanges object with 17 ranges and 10 metadata columns: ## seqnames ranges strand | source type score phase ID ## \u003cRle\u003e \u003cIRanges\u003e \u003cRle\u003e | \u003cfactor\u003e \u003cfactor\u003e \u003cnumeric\u003e \u003cinteger\u003e \u003ccharacter\u003e ## 2 Chr1 3631-5899 * | TAIR10 mRNA NA \u003cNA\u003e AT1G01010.1 ## 3 Chr1 3631-5899 * | TAIR10 mRNA NA \u003cNA\u003e AT1G01010.1 ## 4 Chr1 3760-5630 * | TAIR10 protein NA \u003cNA\u003e AT1G01010.1-Protein ## 5 Chr1 3631-3913 * | TAIR10 exon NA \u003cNA\u003e \u003cNA\u003e ## 6 Chr1 3631-3759 * | TAIR10 five_prime_UTR NA \u003cNA\u003e \u003cNA\u003e ## .. ... ... ... . ... ... ... ... ... ## 14 Chr1 5174-5326 * | TAIR10 exon NA \u003cNA\u003e \u003cNA\u003e ## 15 Chr1 5174-5326 * | TAIR10 CDS NA 0 \u003cNA\u003e ## 16 Chr1 5439-5899 * | TAIR10 exon NA \u003cNA\u003e \u003cNA\u003e ## 17 Chr1 5439-5630 * | TAIR10 CDS NA 0 \u003cNA\u003e ## 18 Chr1 5631-5899 * | TAIR10 three_prime_UTR NA \u003cNA\u003e \u003cNA\u003e ## Name Note Parent Index Derives_from ## \u003ccharacter\u003e \u003cCharacterList\u003e \u003cCharacterList\u003e \u003ccharacter\u003e \u003ccharacter\u003e ## 2 AT1G01010.1 AT1G01010 1 \u003cNA\u003e ## 3 AT1G01010.1 AT1G01010 1 \u003cNA\u003e ## 4 AT1G01010.1 \u003cNA\u003e AT1G01010.1 ## 5 \u003cNA\u003e AT1G01010.1 \u003cNA\u003e \u003cNA\u003e ## 6 \u003cNA\u003e AT1G01010.1 \u003cNA\u003e \u003cNA\u003e ## .. ... ... ... ... ... ## 14 \u003cNA\u003e AT1G01010.1 \u003cNA\u003e \u003cNA\u003e ## 15 \u003cNA\u003e AT1G01010.1,AT1G01010.1-Protein \u003cNA\u003e \u003cNA\u003e ## 16 \u003cNA\u003e AT1G01010.1 \u003cNA\u003e \u003cNA\u003e ## 17 \u003cNA\u003e AT1G01010.1,AT1G01010.1-Protein \u003cNA\u003e \u003cNA\u003e ## 18 \u003cNA\u003e AT1G01010.1 \u003cNA\u003e \u003cNA\u003e ## ------- ## seqinfo: 7 sequences from an unspecified genome  GRangesList Objects sp \u003c- split(gff, seq(along=gff)) # Stores every range in separate component of a GRangesList object split(gff, seqnames(gff)) # Stores ranges of each chromosome in separate component.  ## GRangesList object of length 7: ## $Chr1 ## GRanges object with 71 ranges and 10 metadata columns: ## seqnames ranges strand | source type score phase ID ## \u003cRle\u003e \u003cIRanges\u003e \u003cRle\u003e | \u003cfactor\u003e \u003cfactor\u003e \u003cnumeric\u003e \u003cinteger\u003e \u003ccharacter\u003e ## 2 Chr1 3631-5899 * | TAIR10 mRNA NA \u003cNA\u003e AT1G01010.1 ## 3 Chr1 3631-5899 * | TAIR10 mRNA NA \u003cNA\u003e AT1G01010.1 ## 4 Chr1 3760-5630 * | TAIR10 protein NA \u003cNA\u003e AT1G01010.1-Protein ## 5 Chr1 3631-3913 * | TAIR10 exon NA \u003cNA\u003e \u003cNA\u003e ## 6 Chr1 3631-3759 * | TAIR10 five_prime_UTR NA \u003cNA\u003e \u003cNA\u003e ## .. ... ... ... . ... ... ... ... ... ## 68 Chr1 13335-13714 * | TAIR10 exon NA \u003cNA\u003e \u003cNA\u003e ## 69 Chr1 12941-13173 * | TAIR10 five_prime_UTR NA \u003cNA\u003e \u003cNA\u003e ## 70 Chr1 11864-12940 * | TAIR10 CDS NA 0 \u003cNA\u003e ## 71 Chr1 11649-11863 * | TAIR10 three_prime_UTR NA \u003cNA\u003e \u003cNA\u003e ## 72 Chr1 11649-13173 * | TAIR10 exon NA \u003cNA\u003e \u003cNA\u003e ## Name Note Parent Index Derives_from ## \u003ccharacter\u003e \u003cCharacterList\u003e \u003cCharacterList\u003e \u003ccharacter\u003e \u003ccharacter\u003e ## 2 AT1G01010.1 AT1G01010 1 \u003cNA\u003e ## 3 AT1G01010.1 AT1G01010 1 \u003cNA\u003e ## 4 AT1G01010.1 \u003cNA\u003e AT1G01010.1 ## 5 \u003cNA\u003e AT1G01010.1 \u003cNA\u003e \u003cNA\u003e ## 6 \u003cNA\u003e AT1G01010.1 \u003cNA\u003e \u003cNA\u003e ## .. ... ... ... ... ... ## 68 \u003cNA\u003e AT1G01030.1 \u003cNA\u003e \u003cNA\u003e ## 69 \u003cNA\u003e AT1G01030.1 \u003cNA\u003e \u003cNA\u003e ## 70 \u003cNA\u003e AT1G01030.1,AT1G01030.1-Protein \u003cNA\u003e \u003cNA\u003e ## 71 \u003cNA\u003e AT1G01030.1 \u003cNA\u003e \u003cNA\u003e ## 72 \u003cNA\u003e AT1G01030.1 \u003cNA\u003e \u003cNA\u003e ## ------- ## seqinfo: 7 sequences from an unspecified genome ## ## ... ## \u003c6 more elements\u003e  unlist(sp) # Returns data as GRanges object  ## GRanges object with 442 ranges and 10 metadata columns: ## seqnames ranges strand | source type score phase ## \u003cRle\u003e \u003cIRanges\u003e \u003cRle\u003e | \u003cfactor\u003e \u003cfactor\u003e \u003cnumeric\u003e \u003cinteger\u003e ## 1.2 Chr1 3631-5899 * | TAIR10 mRNA NA \u003cNA\u003e ## 2.3 Chr1 3631-5899 * | TAIR10 mRNA NA \u003cNA\u003e ## 3.4 Chr1 3760-5630 * | TAIR10 protein NA \u003cNA\u003e ## 4.5 Chr1 3631-3913 * | TAIR10 exon NA \u003cNA\u003e ## 5.6 Chr1 3631-3759 * | TAIR10 five_prime_UTR NA \u003cNA\u003e ## ... ... ... ... . ... ... ... ... ## 438.445 ChrM 11918-12241 * | TAIR10 gene NA \u003cNA\u003e ## 439.446 ChrM 11918-12241 * | TAIR10 mRNA NA \u003cNA\u003e ## 440.447 ChrM 11918-12241 * | TAIR10 protein NA \u003cNA\u003e ## 441.448 ChrM 11918-12241 * | TAIR10 exon NA \u003cNA\u003e ## 442.449 ChrM 11918-12241 * | TAIR10 CDS NA 0 ## ID Name Note Parent ## \u003ccharacter\u003e \u003ccharacter\u003e \u003cCharacterList\u003e \u003cCharacterList\u003e ## 1.2 AT1G01010.1 AT1G01010.1 AT1G01010 ## 2.3 AT1G01010.1 AT1G01010.1 AT1G01010 ## 3.4 AT1G01010.1-Protein AT1G01010.1 ## 4.5 \u003cNA\u003e \u003cNA\u003e AT1G01010.1 ## 5.6 \u003cNA\u003e \u003cNA\u003e AT1G01010.1 ## ... ... ... ... ... ## 438.445 ATMG00030 ATMG00030 protein_coding_gene ## 439.446 ATMG00030.1 ATMG00030.1 ATMG00030 ## 440.447 ATMG00030.1-Protein ATMG00030.1 ## 441.448 \u003cNA\u003e \u003cNA\u003e ATMG00030.1 ## 442.449 \u003cNA\u003e \u003cNA\u003e ATMG00030.1,ATMG00030.1-Protein ## Index Derives_from ## \u003ccharacter\u003e \u003ccharacter\u003e ## 1.2 1 \u003cNA\u003e ## 2.3 1 \u003cNA\u003e ## 3.4 \u003cNA\u003e AT1G01010.1 ## 4.5 \u003cNA\u003e \u003cNA\u003e ## 5.6 \u003cNA\u003e \u003cNA\u003e ## ... ... ... ## 438.445 \u003cNA\u003e \u003cNA\u003e ## 439.446 1 \u003cNA\u003e ## 440.447 \u003cNA\u003e ATMG00030.1 ## 441.448 \u003cNA\u003e \u003cNA\u003e ## 442.449 \u003cNA\u003e \u003cNA\u003e ## ------- ## seqinfo: 7 sequences from an unspecified genome  sp[1:4, \"type\"] # Subsetting of GRangesList objects is similar to GRanges objects.  ## GRangesList object of length 4: ## $`1` ## GRanges object with 1 range and 1 metadata column: ## seqnames ranges strand | type ## \u003cRle\u003e \u003cIRanges\u003e \u003cRle\u003e | \u003cfactor\u003e ## 2 Chr1 3631-5899 * | mRNA ## ------- ## seqinfo: 7 sequences from an unspecified genome ## ## $`2` ## GRanges object with 1 range and 1 metadata column: ## seqnames ranges strand | type ## \u003cRle\u003e \u003cIRanges\u003e \u003cRle\u003e | \u003cfactor\u003e ## 3 Chr1 3631-5899 * | mRNA ## ------- ## seqinfo: 7 sequences from an unspecified genome ## ## $`3` ## GRanges object with 1 range and 1 metadata column: ## seqnames ranges strand | type ## \u003cRle\u003e \u003cIRanges\u003e \u003cRle\u003e | \u003cfactor\u003e ## 4 Chr1 3760-5630 * | protein ## ------- ## seqinfo: 7 sequences from an unspecified genome ## ## $`4` ## GRanges object with 1 range and 1 metadata column: ## seqnames ranges strand | type ## \u003cRle\u003e \u003cIRanges\u003e \u003cRle\u003e | \u003cfactor\u003e ## 5 Chr1 3631-3913 * | exon ## ------- ## seqinfo: 7 sequences from an unspecified genome  lapply(sp[1:4], length) # Looping over GRangesList objects similar to lists  ## $`1` ## [1] 1 ## ## $`2` ## [1] 1 ## ## $`3` ## [1] 1 ## ## $`4` ## [1] 1  Transcript Ranges Storing annotation ranges in TranscriptDb databases makes many operations more robust and convenient.\nlibrary(GenomicFeatures) download.file(\"http://cluster.hpcc.ucr.edu/~tgirke/Documents/R_BioCond/Samples/gff3.gff\", \"data/gff3.gff\") txdb \u003c- makeTxDbFromGFF(file=\"data/gff3.gff\", format=\"gff\", dataSource=\"TAIR\", organism=\"Arabidopsis thaliana\")  ## Warning in .extract_exons_from_GRanges(cds_IDX, gr, mcols0, tx_IDX, feature = \"cds\", : 163 CDS couldn't be linked to a transcript so were dropped (showing only the first 6): ## seqid start end strand ID Name Parent Parent_type ## 1 Chr1 3760 3913 + \u003cNA\u003e \u003cNA\u003e AT1G01010.1-Protein \u003cNA\u003e ## 2 Chr1 3996 4276 + \u003cNA\u003e \u003cNA\u003e AT1G01010.1-Protein \u003cNA\u003e ## 3 Chr1 4486 4605 + \u003cNA\u003e \u003cNA\u003e AT1G01010.1-Protein \u003cNA\u003e ## 4 Chr1 4706 5095 + \u003cNA\u003e \u003cNA\u003e AT1G01010.1-Protein \u003cNA\u003e ## 5 Chr1 5174 5326 + \u003cNA\u003e \u003cNA\u003e AT1G01010.1-Protein \u003cNA\u003e ## 6 Chr1 5439 5630 + \u003cNA\u003e \u003cNA\u003e AT1G01010.1-Protein \u003cNA\u003e  saveDb(txdb, file=\"./data/TAIR10.sqlite\")  ## TxDb object: ## # Db type: TxDb ## # Supporting package: GenomicFeatures ## # Data source: TAIR ## # Organism: Arabidopsis thaliana ## # Taxonomy ID: 3702 ## # miRBase build ID: NA ## # Genome: NA ## # Nb of transcripts: 28 ## # Db created by: GenomicFeatures package from Bioconductor ## # Creation time: 2021-02-15 15:24:24 -0800 (Mon, 15 Feb 2021) ## # GenomicFeatures version at creation time: 1.42.1 ## # RSQLite version at creation time: 2.2.1 ## # DBSCHEMAVERSION: 1.2  txdb \u003c- loadDb(\"./data/TAIR10.sqlite\") transcripts(txdb)  ## GRanges object with 28 ranges and 2 metadata columns: ## seqnames ranges strand | tx_id tx_name ## \u003cRle\u003e \u003cIRanges\u003e \u003cRle\u003e | \u003cinteger\u003e \u003ccharacter\u003e ## [1] Chr1 3631-5899 + | 1 AT1G01010.1 ## [2] Chr1 5928-8737 - | 2 AT1G01020.1 ## [3] Chr1 6790-8737 - | 3 AT1G01020.2 ## [4] Chr1 11649-13714 - | 4 AT1G01030.1 ## [5] Chr2 1025-2810 + | 5 AT2G01008.1 ## ... ... ... ... . ... ... ## [24] ChrC 383-1444 - | 24 ATCG00020.1 ## [25] ChrC 1717-4347 - | 25 ATCG00030.1 ## [26] ChrM 11918-12241 + | 26 ATMG00030.1 ## [27] ChrM 273-734 - | 27 ATMG00010.1 ## [28] ChrM 8848-11415 - | 28 ATMG00020.1 ## ------- ## seqinfo: 7 sequences (2 circular) from an unspecified genome; no seqlengths  transcriptsBy(txdb, by = \"gene\")  ## GRangesList object of length 22: ## $AT1G01010 ## GRanges object with 1 range and 2 metadata columns: ## seqnames ranges strand | tx_id tx_name ## \u003cRle\u003e \u003cIRanges\u003e \u003cRle\u003e | \u003cinteger\u003e \u003ccharacter\u003e ## [1] Chr1 3631-5899 + | 1 AT1G01010.1 ## ------- ## seqinfo: 7 sequences (2 circular) from an unspecified genome; no seqlengths ## ## $AT1G01020 ## GRanges object with 2 ranges and 2 metadata columns: ## seqnames ranges strand | tx_id tx_name ## \u003cRle\u003e \u003cIRanges\u003e \u003cRle\u003e | \u003cinteger\u003e \u003ccharacter\u003e ## [1] Chr1 5928-8737 - | 2 AT1G01020.1 ## [2] Chr1 6790-8737 - | 3 AT1G01020.2 ## ------- ## seqinfo: 7 sequences (2 circular) from an unspecified genome; no seqlengths ## ## $AT1G01030 ## GRanges object with 1 range and 2 metadata columns: ## seqnames ranges strand | tx_id tx_name ## \u003cRle\u003e \u003cIRanges\u003e \u003cRle\u003e | \u003cinteger\u003e \u003ccharacter\u003e ## [1] Chr1 11649-13714 - | 4 AT1G01030.1 ## ------- ## seqinfo: 7 sequences (2 circular) from an unspecified genome; no seqlengths ## ## ... ## \u003c19 more elements\u003e  exonsBy(txdb, by = \"gene\")  ## GRangesList object of length 22: ## $AT1G01010 ## GRanges object with 6 ranges and 2 metadata columns: ## seqnames ranges strand | exon_id exon_name ## \u003cRle\u003e \u003cIRanges\u003e \u003cRle\u003e | \u003cinteger\u003e \u003ccharacter\u003e ## [1] Chr1 3631-3913 + | 1 \u003cNA\u003e ## [2] Chr1 3996-4276 + | 2 \u003cNA\u003e ## [3] Chr1 4486-4605 + | 3 \u003cNA\u003e ## [4] Chr1 4706-5095 + | 4 \u003cNA\u003e ## [5] Chr1 5174-5326 + | 5 \u003cNA\u003e ## [6] Chr1 5439-5899 + | 6 \u003cNA\u003e ## ------- ## seqinfo: 7 sequences (2 circular) from an unspecified genome; no seqlengths ## ## $AT1G01020 ## GRanges object with 12 ranges and 2 metadata columns: ## seqnames ranges strand | exon_id exon_name ## \u003cRle\u003e \u003cIRanges\u003e \u003cRle\u003e | \u003cinteger\u003e \u003ccharacter\u003e ## [1] Chr1 5928-6263 - | 7 \u003cNA\u003e ## [2] Chr1 6437-7069 - | 8 \u003cNA\u003e ## [3] Chr1 6790-7069 - | 9 \u003cNA\u003e ## [4] Chr1 7157-7232 - | 10 \u003cNA\u003e ## [5] Chr1 7157-7450 - | 11 \u003cNA\u003e ## ... ... ... ... . ... ... ## [8] Chr1 7762-7835 - | 14 \u003cNA\u003e ## [9] Chr1 7942-7987 - | 15 \u003cNA\u003e ## [10] Chr1 8236-8325 - | 16 \u003cNA\u003e ## [11] Chr1 8417-8464 - | 17 \u003cNA\u003e ## [12] Chr1 8571-8737 - | 18 \u003cNA\u003e ## ------- ## seqinfo: 7 sequences (2 circular) from an unspecified genome; no seqlengths ## ## $AT1G01030 ## GRanges object with 2 ranges and 2 metadata columns: ## seqnames ranges strand | exon_id exon_name ## \u003cRle\u003e \u003cIRanges\u003e \u003cRle\u003e | \u003cinteger\u003e \u003ccharacter\u003e ## [1] Chr1 11649-13173 - | 19 \u003cNA\u003e ## [2] Chr1 13335-13714 - | 20 \u003cNA\u003e ## ------- ## seqinfo: 7 sequences (2 circular) from an unspecified genome; no seqlengths ## ## ... ## \u003c19 more elements\u003e  txdb from BioMart Alternative sources for creating txdb databases are BioMart, Bioc annotation packages, UCSC, etc. The following shows how to create a txdb from BioMart.\nlibrary(GenomicFeatures); library(\"biomaRt\") txdb \u003c- makeTxDbFromBiomart(biomart = \"plants_mart\", dataset = \"athaliana_eg_gene\", host=\"plants.ensembl.org\")  The following steps are useful to find out what is availble in BioMart.\nlistMarts() # Lists BioMart databases listMarts(host=\"plants.ensembl.org\") mymart \u003c- useMart(\"plants_mart\", host=\"plants.ensembl.org\") # Select one, here plants_mart listDatasets(mymart) # List datasets available in the selected BioMart database mymart \u003c- useMart(\"plants_mart\", dataset=\"athaliana_eg_gene\", host=\"plants.ensembl.org\") listAttributes(mymart) # List available features getBM(attributes=c(\"ensembl_gene_id\", \"description\"), mart=mymart)[1:4,]  Efficient Sequence Parsing getSeq The following parses all annotation ranges provided by a GRanges object (e.g. gff) from a genome sequence stored in a local file.\ngff \u003c- gff[values(gff)$type != \"chromosome\"] # Remove chromosome ranges rand \u003c- DNAStringSet(sapply(unique(as.character(seqnames(gff))), function(x) paste(sample(c(\"A\",\"T\",\"G\",\"C\"), 200000, replace=T), collapse=\"\"))) writeXStringSet(DNAStringSet(rand), \"./data/test\") getSeq(FaFile(\"./data/test\"), gff)  ## DNAStringSet object of length 442: ## width seq names ## [1] 2269 \u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m...\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m Chr1 ## [2] 2269 \u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m...\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m Chr1 ## [3] 1871 \u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m...\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m Chr1 ## [4] 283 \u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m...\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m Chr1 ## [5] 129 \u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m...\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m Chr1 ## ... ... ... ## [438] 324 \u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m...\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m ChrM ## [439] 324 \u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m...\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m ChrM ## [440] 324 \u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m...\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m ChrM ## [441] 324 \u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m...\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m ChrM ## [442] 324 \u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m...\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m ChrM  extractTranscriptSeqs Sequences composed of several ranges, such as transcripts (or CDSs) with several exons, can be parsed with extractTranscriptSeqs. Note: the following expects the genome sequence in a file with path data/test and a valid txdb defining the ranges for that genome.\nlibrary(GenomicFeatures); library(Biostrings); library(Rsamtools) txdb \u003c- loadDb(\"./data/TAIR10.sqlite\") indexFa(\"data/test\") # Creates index for genome fasta  ## [1] \"data/test.fai\"  txseq \u003c- extractTranscriptSeqs(FaFile(\"data/test\"), txdb, use.names=TRUE) txseq  ## DNAStringSet object of length 28: ## width seq names ## [1] 1688 \u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m...\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m AT1G01010.1 ## [2] 1623 \u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m...\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m AT1G01020.1 ## [3] 1085 \u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m...\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m AT1G01020.2 ## [4] 1905 \u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m...\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m AT1G01030.1 ## [5] 1239 \u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m...\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m AT2G01008.1 ## ... ... ... ## [24] 1062 \u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m...\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m ATCG00020.1 ## [25] 72 \u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m...\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m ATCG00030.1 ## [26] 324 \u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m...\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m ATMG00030.1 ## [27] 462 \u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m...\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m ATMG00010.1 ## [28] 2568 \u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m...\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;217m\u001b[30mA\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;223m\u001b[30mT\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m\u001b[48;5;157m\u001b[30mC\u001b[39m\u001b[49m\u001b[48;5;159m\u001b[30mG\u001b[39m\u001b[49m ATMG00020.1  Homework 6 See here.\nSession Info sessionInfo()  ## R version 4.0.3 (2020-10-10) ## Platform: x86_64-pc-linux-gnu (64-bit) ## Running under: Debian GNU/Linux 10 (buster) ## ## Matrix products: default ## BLAS: /usr/lib/x86_64-linux-gnu/blas/libblas.so.3.8.0 ## LAPACK: /usr/lib/x86_64-linux-gnu/lapack/liblapack.so.3.8.0 ## ## locale: ## [1] LC_CTYPE=en_US.UTF-8 LC_NUMERIC=C LC_TIME=en_US.UTF-8 ## [4] LC_COLLATE=en_US.UTF-8 LC_MONETARY=en_US.UTF-8 LC_MESSAGES=en_US.UTF-8 ## [7] LC_PAPER=en_US.UTF-8 LC_NAME=C LC_ADDRESS=C ## [10] LC_TELEPHONE=C LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C ## ## attached base packages: ## [1] grid stats4 parallel stats graphics grDevices utils datasets methods ## [10] base ## ## other attached packages: ## [1] GenomicFeatures_1.42.1 AnnotationDbi_1.52.0 rtracklayer_1.50.0 ## [4] systemPipeR_1.24.2 ShortRead_1.48.0 GenomicAlignments_1.26.0 ## [7] SummarizedExperiment_1.20.0 Biobase_2.50.0 MatrixGenerics_1.2.0 ## [10] matrixStats_0.57.0 Rsamtools_2.6.0 GenomicRanges_1.42.0 ## [13] GenomeInfoDb_1.26.1 BiocParallel_1.24.1 ggseqlogo_0.1 ## [16] seqLogo_1.56.0 Biostrings_2.58.0 XVector_0.30.0 ## [19] IRanges_2.24.0 S4Vectors_0.28.0 BiocGenerics_0.36.0 ## [22] ggplot2_3.3.2 limma_3.46.0 BiocStyle_2.18.0 ## ## loaded via a namespace (and not attached): ## [1] colorspace_2.0-0 rjson_0.2.20 hwriter_1.3.2 ## [4] ellipsis_0.3.1 bit64_4.0.5 xml2_1.3.2 ## [7] codetools_0.2-16 splines_4.0.3 knitr_1.30 ## [10] jsonlite_1.7.1 annotate_1.68.0 GO.db_3.12.1 ## [13] dbplyr_2.0.0 png_0.1-7 pheatmap_1.0.12 ## [16] graph_1.68.0 BiocManager_1.30.10 compiler_4.0.3 ## [19] httr_1.4.2 GOstats_2.56.0 backports_1.2.0 ## [22] assertthat_0.2.1 Matrix_1.2-18 htmltools_0.5.1.1 ## [25] prettyunits_1.1.1 tools_4.0.3 gtable_0.3.0 ## [28] glue_1.4.2 GenomeInfoDbData_1.2.4 Category_2.56.0 ## [31] dplyr_1.0.2 rsvg_2.1 batchtools_0.9.14 ## [34] rappdirs_0.3.1 V8_3.4.0 Rcpp_1.0.5 ## [37] vctrs_0.3.5 blogdown_1.1.7 xfun_0.20 ## [40] stringr_1.4.0 lifecycle_0.2.0 XML_3.99-0.5 ## [43] edgeR_3.32.0 zlibbioc_1.36.0 scales_1.1.1 ## [46] BSgenome_1.58.0 VariantAnnotation_1.36.0 hms_0.5.3 ## [49] RBGL_1.66.0 RColorBrewer_1.1-2 yaml_2.2.1 ## [52] curl_4.3 memoise_1.1.0 biomaRt_2.46.0 ## [55] latticeExtra_0.6-29 stringi_1.5.3 RSQLite_2.2.1 ## [58] genefilter_1.72.0 checkmate_2.0.0 DOT_0.1 ## [61] rlang_0.4.8 pkgconfig_2.0.3 bitops_1.0-6 ## [64] evaluate_0.14 lattice_0.20-41 purrr_0.3.4 ## [67] bit_4.0.4 tidyselect_1.1.0 GSEABase_1.52.0 ## [70] AnnotationForge_1.32.0 magrittr_2.0.1 bookdown_0.21 ## [73] R6_2.5.0 generics_0.1.0 base64url_1.4 ## [76] DelayedArray_0.16.0 DBI_1.1.0 pillar_1.4.7 ## [79] withr_2.3.0 survival_3.2-7 RCurl_1.98-1.2 ## [82] tibble_3.0.4 crayon_1.3.4 BiocFileCache_1.14.0 ## [85] rmarkdown_2.5 jpeg_0.1-8.1 progress_1.2.2 ## [88] locfit_1.5-9.4 data.table_1.13.2 blob_1.2.1 ## [91] Rgraphviz_2.34.0 digest_0.6.27 xtable_1.8-4 ## [94] brew_1.0-6 openssl_1.4.3 munsell_0.5.0 ## [97] askpass_1.1  References Huber, Wolfgang, Vincent J Carey, Robert Gentleman, Simon Anders, Marc Carlson, Benilton S Carvalho, Hector Corrada Bravo, et al. 2015. “Orchestrating High-Throughput Genomic Analysis with Bioconductor.” Nat. Methods 12 (2): 115–21. https://doi.org/10.1038/nmeth.3252.\n Lawrence, Michael, Wolfgang Huber, Hervé Pagès, Patrick Aboyoun, Marc Carlson, Robert Gentleman, Martin T Morgan, and Vincent J Carey. 2013. “Software for Computing and Annotating Genomic Ranges.” PLoS Comput. Biol. 9 (8): e1003118. https://doi.org/10.1371/journal.pcbi.1003118.\n  ","categories":"","description":"","excerpt":"document.addEventListener(\"DOMContentLoaded\", function() { …","ref":"/tutorials/rsequences/rsequences/","tags":"","title":"NGS Analysis Basics"},{"body":"Overview  R provides a large number of packages for parallel evaluations on multi-core, multi-socket and multi-node systems. The latter are usually referred to as computer clusters. MPI is also supported For an overview of parallelization packages available for R see here One of the most comprehensive parallel computing environments for R is batchtools. Older versions of this package were released under the name BatchJobs (Bischl et al. 2015). batchtools supports both multi-core and multi-node computations with and without schedulers. By making use of cluster template files, most schedulers and queueing systems are supported (e.g. Torque, Sun Grid Engine, Slurm).  Reminder: Traditional Job Submission for R This topic is covered in more detail in other tutorials. The following only provides a very brief overview of this submission method.\n1. Create Slurm submission script, here called script_name.sh with:\n#!/bin/bash -l #SBATCH --nodes=1 #SBATCH --ntasks=1 #SBATCH --cpus-per-task=1 #SBATCH --mem-per-cpu=1G #SBATCH --time=1-00:15:00 # 1 day and 15 minutes #SBATCH --mail-user=useremail@address.com #SBATCH --mail-type=ALL #SBATCH --job-name=\"some_test\" #SBATCH -p short # Choose queue/partition from: intel, batch, highmem, gpu, short Rscript my_script.R  2. Submit R script (my_script.R) called by above Slurm script with:\nsbatch script_name.sh  Parallel Evaluations on Clusters with batchtools  The following introduces the usage of batchtools for a computer cluster using SLURM as scheduler (workload manager). SLURM is the scheduler used by the HPCC. Similar instructions are provided in HPCC’s manual section covering batchtools here To simplify the evaluation of the R code on the following slides, the corresponding text version is available for download from here.  Hands-on Demo of batchtools Set up working directory for SLURM First login to your cluster account, open R and execute the following lines. This will create a test directory (here mytestdir), redirect R into this directory and then download the required files:\n slurm.tmpl .batchtools.conf.R  dir.create(\"mytestdir\") setwd(\"mytestdir\") download.file(\"https://bit.ly/3gZJBsy\", \"slurm.tmpl\") download.file(\"https://bit.ly/3nvSNHA\", \".batchtools.conf.R\")  Load package and define some custom function The following code defines a test function (here myFct) that will be run on the cluster for demonstration purposes.\nThe test function (myFct) subsets the iris data frame by rows, and appends the host name and R version of each node where the function was executed. The R version to be used on each node can be specified in the slurm.tmpl file (under module load).\nlibrary('RenvModule') module('load','slurm') # Loads slurm among other modules library(batchtools) myFct \u003c- function(x) { Sys.sleep(10) # to see job in queue, pause for 10 sec result \u003c- cbind(iris[x, 1:4,], Node=system(\"hostname\", intern=TRUE), Rversion=paste(R.Version()[6:7], collapse=\".\")) }  Submit jobs from R to cluster The following creates a batchtools registry, defines the number of jobs and resource requests, and then submits the jobs to the cluster via SLURM.\nreg \u003c- makeRegistry(file.dir=\"myregdir\", conf.file=\".batchtools.conf.R\") Njobs \u003c- 1:4 # Define number of jobs (here 4) ids \u003c- batchMap(fun=myFct, x=Njobs) done \u003c- submitJobs(ids, reg=reg, resources=list(partition=\"short\", walltime=120, ntasks=1, ncpus=1, memory=1024)) waitForJobs() # Wait until jobs are completed  Summarize job status After the jobs are completed one can inspect their status as follows.\ngetStatus() # Summarize job status showLog(Njobs[1]) # killJobs(Njobs) # # Possible from within R or outside with scancel  Access/assemble results The results are stored as .rds files in the registry directory (here myregdir). One can access them manually via readRDS or use various convenience utilities provided by the batchtools package.\nreadRDS(\"myregdir/results/1.rds\") # reads from rds file first result chunk loadResult(1) lapply(Njobs, loadResult) reduceResults(rbind) # Assemble result chunks in single data.frame do.call(\"rbind\", lapply(Njobs, loadResult))  Remove registry directory from file system By default existing registries will not be overwritten. If required one can explicitly clean and delete them with the following functions.\nclearRegistry() # Clear registry in R session removeRegistry(wait=0, reg=reg) # Delete registry directory # unlink(\"myregdir\", recursive=TRUE) # Same as previous line  Load registry into R Loading a registry can be useful when accessing the results at a later state or after moving them to a local system.\nfrom_file \u003c- loadRegistry(\"myregdir\", conf.file=\".batchtools.conf.R\") reduceResults(rbind)  Conclusions Advantages of batchtools  many parallelization methods multiple cores, and across both multiple CPU sockets and nodes most schedulers supported takes full advantage of a cluster robust job management by organizing results in registry file-based database simplifies submission, monitoring and restart of jobs well supported and maintained package  Session Info sessionInfo()  ## R version 4.0.5 (2021-03-31) ## Platform: x86_64-pc-linux-gnu (64-bit) ## Running under: Debian GNU/Linux 10 (buster) ## ## Matrix products: default ## BLAS: /usr/lib/x86_64-linux-gnu/blas/libblas.so.3.8.0 ## LAPACK: /usr/lib/x86_64-linux-gnu/lapack/liblapack.so.3.8.0 ## ## locale: ## [1] LC_CTYPE=en_US.UTF-8 LC_NUMERIC=C ## [3] LC_TIME=en_US.UTF-8 LC_COLLATE=en_US.UTF-8 ## [5] LC_MONETARY=en_US.UTF-8 LC_MESSAGES=en_US.UTF-8 ## [7] LC_PAPER=en_US.UTF-8 LC_NAME=C ## [9] LC_ADDRESS=C LC_TELEPHONE=C ## [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C ## ## attached base packages: ## [1] stats graphics grDevices utils datasets methods base ## ## loaded via a namespace (and not attached): ## [1] bookdown_0.21 digest_0.6.27 R6_2.5.0 jsonlite_1.7.1 ## [5] magrittr_2.0.1 evaluate_0.14 blogdown_1.2 stringi_1.5.3 ## [9] rlang_0.4.8 jquerylib_0.1.3 bslib_0.2.4 rmarkdown_2.7 ## [13] tools_4.0.5 stringr_1.4.0 xfun_0.22 yaml_2.2.1 ## [17] compiler_4.0.5 htmltools_0.5.1.1 knitr_1.30 sass_0.3.1  References Bischl, Bernd, Michel Lang, Olaf Mersmann, Jörg Rahnenführer, and Claus Weihs. 2015. “BatchJobs and BatchExperiments: Abstraction Mechanisms for Using R in Batch Environments.” Journal of Statistical Software. http://www.jstatsoft.org/v64/i11/.\n  ","categories":"","description":"","excerpt":"Overview  R provides a large number of packages for parallel …","ref":"/manuals/rparallel/rparallel/","tags":"","title":"Parallel Evaluations in R"},{"body":"document.addEventListener(\"DOMContentLoaded\", function() { document.querySelector(\"h1\").className = \"title\"; });  document.addEventListener(\"DOMContentLoaded\", function() { var links = document.links; for (var i = 0, linksLength = links.length; i Overview Sequence Analysis in R and Bioconductor R Base\n Some basic string handling utilities. Wide spectrum of numeric data analysis tools.  Bioconductor\nBioconductor packages provide much more sophisticated string handling utilities for sequence analysis (Lawrence et al. 2013; Huber et al. 2015).\n Biostrings: general sequence analysis environment ShortRead: pipeline for short read data IRanges: low-level infrastructure for range data GenomicRanges: high-level infrastructure for range data GenomicFeatures: managing transcript centric annotations GenomicAlignments: handling short genomic alignments Rsamtools: interface to samtools, bcftools and tabix BSgenome: genome annotation data biomaRt: interface to BioMart annotations rtracklayer: Annotation imports, interface to online genome browsers HelloRanges: Bedtools semantics in Bioc’s Ranges infrastructure  Package Requirements Several Bioconductor packages are required for this tutorial. To install them, execute the following lines in the R console. Please also make sure that you have a recent R version installed on your system. R versions 3.3.x or higher are recommended.\nsource(\"https://bioconductor.org/biocLite.R\") if (!requireNamespace(\"BiocManager\", quietly = TRUE)) install.packages(\"BiocManager\") BiocManager::install(c(\"Biostrings\", \"GenomicRanges\", \"rtracklayer\", \"systemPipeR\", \"seqLogo\", \"ShortRead\"))  Strings in R Base Basic String Matching and Parsing String matching Generate sample sequence data set\nmyseq \u003c- c(\"ATGCAGACATAGTG\", \"ATGAACATAGATCC\", \"GTACAGATCAC\")  String searching with regular expression support\nmyseq[grep(\"ATG\", myseq)]  ## [1] \"ATGCAGACATAGTG\" \"ATGAACATAGATCC\"  Searches myseq for first match of pattern “AT”\npos1 \u003c- regexpr(\"AT\", myseq) as.numeric(pos1); attributes(pos1)$match.length # Returns position information of matches  ## [1] 1 1 7 ## [1] 2 2 2  Searches myseq for all matches of pattern “AT”\npos2 \u003c- gregexpr(\"AT\", myseq) as.numeric(pos2[[1]]); attributes(pos2[[1]])$match.length # Returns positions of matches in first sequence  ## [1] 1 9 ## [1] 2 2  String substitution with regular expression support\ngsub(\"^ATG\", \"atg\", myseq)  ## [1] \"atgCAGACATAGTG\" \"atgAACATAGATCC\" \"GTACAGATCAC\"  Positional parsing nchar(myseq) # Computes length of strings  ## [1] 14 14 11  substring(myseq[1], c(1,3), c(2,5)) # Positional parsing of several fragments from one string  ## [1] \"AT\" \"GCA\"  substring(myseq, c(1,4,7), c(2,6,10)) # Positional parsing of many strings  ## [1] \"AT\" \"AAC\" \"ATCA\"  Random Sequence Generation Random DNA sequences of any length rand \u003c- sapply(1:100, function(x) paste(sample(c(\"A\",\"T\",\"G\",\"C\"), sample(10:20), replace=T), collapse=\"\")) rand[1:3]  ## [1] \"GGTCTATTTGCTGG\" \"CCTTCGCGGTAA\" \"AGAACTGATGCCAGAG\"  Count identical sequences table(c(rand[1:4], rand[1]))  ## ## AGAACTGATGCCAGAG CCTTCGCGGTAA GGTCTATTTGCTGG GTTTCTCCCTCAAATACTG ## 1 1 2 1  Extract reads from reference Note: this requires Biostrings package.\nlibrary(Biostrings) ref \u003c- DNAString(paste(sample(c(\"A\",\"T\",\"G\",\"C\"), 100000, replace=T), collapse=\"\")) randstart \u003c- sample(1:(length(ref)-15), 1000) randreads \u003c- Views(ref, randstart, width=15) rand_set \u003c- DNAStringSet(randreads) unlist(rand_set)  ## 15000-letter DNAString object ## seq: TACGTACTTCAGAAGTATATCATGATAGGGATGCCCTGTACGTCCA...CCTAGCGGAGCCTACTAACGCCGGAATTCGAAGACTGAATACGTAC  Sequences in Bioconductor Important Data Objects of Biostrings XString for single sequence  DNAString: for DNA RNAString: for RNA AAString: for amino acid BString: for any string  XStringSet for many sequences  `DNAStringSet``: for DNA RNAStringSet: for RNA AAStringSet: for amino acid BStringSet: for any string  QualityScaleXStringSet for sequences with quality data  QualityScaledDNAStringSet: for DNA QualityScaledRNAStringSet: for RNA QualityScaledAAStringSet: for amino acid QualityScaledBStringSet: for any string  Sequence Import and Export Download the following sequences to your current working directory and then import them into R: ftp://ftp.ncbi.nlm.nih.gov/genomes/archive/old_genbank/Bacteria/Halobacterium_sp_uid217/AE004437.ffn\ndir.create(\"data\", showWarnings = FALSE) # system(\"wget ftp://ftp.ncbi.nlm.nih.gov/genomes/archive/old_genbank/Bacteria/Halobacterium_sp_uid217/AE004437.ffn\") download.file(\"ftp://ftp.ncbi.nlm.nih.gov/genomes/archive/old_genbank/Bacteria/Halobacterium_sp_uid217/AE004437.ffn\", \"data/AE004437.ffn\")  Import FASTA file with readDNAStringSet\nmyseq \u003c- readDNAStringSet(\"data/AE004437.ffn\") myseq[1:3]  ## DNAStringSet object of length 3: ## width seq names ## [1] 1206 ATGACTCGGCGGTCTCGTGTCGGTGCCGGCCTC...GTCGTCGTTGTTCGACGCTGGCGGAACCCATGA gi|12057215|gb|AE... ## [2] 666 ATGAGCATCATCGAACTCGAAGGCGTGGTCAAA...GTCAACCTCGTCGATGGGGTGTTACACACGTGA gi|12057215|gb|AE... ## [3] 1110 ATGGCGTGGCGGAACCTCGGGCGGAACCGCGTG...AACGATCCGCCCGTCGAGGCGCTCGGCGAATGA gi|12057215|gb|AE...  Subset sequences with regular expression on sequence name field\nsub \u003c- myseq[grep(\"99.*\", names(myseq))] length(sub)  ## [1] 170  Export subsetted sequences to FASTA file\nwriteXStringSet(sub, file=\"./data/AE004437sub.ffn\", width=80)  Now inspect exported sequence file AE004437sub.ffn in a text editor\nWorking with XString Containers The XString stores the different types of biosequences in dedicated containers\nlibrary(Biostrings) d \u003c- DNAString(\"GCATAT-TAC\") d  ## 10-letter DNAString object ## seq: GCATAT-TAC  d[1:4]  ## 4-letter DNAString object ## seq: GCAT  RNA sequences\nr \u003c- RNAString(\"GCAUAU-UAC\") r \u003c- RNAString(d) # Converts d to RNAString object r  ## 10-letter RNAString object ## seq: GCAUAU-UAC  Protein sequences\np \u003c- AAString(\"HCWYHH\") p  ## 6-letter AAString object ## seq: HCWYHH  Any type of character strings\nb \u003c- BString(\"I store any set of characters. Other XString objects store only the IUPAC characters.\") b  ## 85-letter BString object ## seq: I store any set of characters. Other XString objects store only the IUPAC characters.  Working with XStringSet Containers XStringSet containers allow to store many biosequences in one object\ndset \u003c- DNAStringSet(c(\"GCATATTAC\", \"AATCGATCC\", \"GCATATTAC\")) names(dset) \u003c- c(\"seq1\", \"seq2\", \"seq3\") # Assigns names dset[1:2]  ## DNAStringSet object of length 2: ## width seq names ## [1] 9 GCATATTAC seq1 ## [2] 9 AATCGATCC seq2  Important utilities for XStringSet containers\nwidth(dset) # Returns the length of each sequences  ## [1] 9 9 9  d \u003c- dset[[1]] # The [[ subsetting operator returns a single entry as XString object dset2 \u003c- c(dset, dset) # Appends/concatenates two XStringSet objects dsetchar \u003c- as.character(dset) # Converts XStringSet to named vector dsetone \u003c- unlist(dset) # Collapses many sequences to a single one stored in a DNAString container  Sequence subsetting by positions:\nDNAStringSet(dset, start=c(1,2,3), end=c(4,8,5))  ## DNAStringSet object of length 3: ## width seq names ## [1] 4 GCAT seq1 ## [2] 7 ATCGATC seq2 ## [3] 3 ATA seq3  Multiple Alignment Class The XMultipleAlignment class stores the different types of multiple sequence alignments:\norigMAlign \u003c- readDNAMultipleAlignment(filepath = system.file(\"extdata\", \"msx2_mRNA.aln\", package = \"Biostrings\"), format = \"clustal\") origMAlign  ## DNAMultipleAlignment with 8 rows and 2343 columns ## aln names ## [1] -----TCCCGTCTCCGCAGCAAAAAAGTTTGAGTCG...TTGTCCAAACTCACAATTAAAAAAAAAAAAAAAAA gi|84452153|ref|N... ## [2] ------------------------------------...----------------------------------- gi|208431713|ref|... ## [3] ------------------------------------...----------------------------------- gi|118601823|ref|... ## [4] ----------------------AAAAGTTGGAGTCT...----------------------------------- gi|114326503|ref|... ## [5] ------------------------------------...----------------------------------- gi|119220589|ref|... ## [6] ------------------------------------...----------------------------------- gi|148540149|ref|... ## [7] --------------CGGCTCCGCAGCGCCTCACTCG...----------------------------------- gi|45383056|ref|N... ## [8] GGGGGAGACTTCAGAAGTTGTTGTCCTCTCCGCTGA...----------------------------------- gi|213515133|ref|...  Basic Sequence Manipulations Reverse and Complement randset \u003c- DNAStringSet(rand) complement(randset[1:2])  ## DNAStringSet object of length 2: ## width seq ## [1] 14 CCAGATAAACGACC ## [2] 12 GGAAGCGCCATT  reverse(randset[1:2])  ## DNAStringSet object of length 2: ## width seq ## [1] 14 GGTCGTTTATCTGG ## [2] 12 AATGGCGCTTCC  reverseComplement(randset[1:2])  ## DNAStringSet object of length 2: ## width seq ## [1] 14 CCAGCAAATAGACC ## [2] 12 TTACCGCGAAGG  Translate DNA into Protein translate(randset[1:2])  ## Warning in .Call2(\"DNAStringSet_translate\", x, skip_code, dna_codes[codon_alphabet], : in 'x[[1]]': ## last 2 bases were ignored ## AAStringSet object of length 2: ## width seq ## [1] 4 GLFA ## [2] 4 PSR*  Pattern Matching Pattern matching with mismatches Find pattern matches in reference\nmyseq1 \u003c- readDNAStringSet(\"./data/AE004437.ffn\") mypos \u003c- matchPattern(\"ATGGTG\", myseq1[[1]], max.mismatch=1)  Count only the corresponding matches\ncountPattern(\"ATGGCT\", myseq1[[1]], max.mismatch=1)  ## [1] 3  Count matches in many sequences\nvcountPattern(\"ATGGCT\", myseq1, max.mismatch=1)[1:20]  ## [1] 3 0 5 4 1 2 2 1 4 3 0 0 1 2 0 1 4 0 0 1  Results shown in DNAStringSet object\ntmp \u003c- c(DNAStringSet(\"ATGGTG\"), DNAStringSet(mypos))  Return a consensus matrix for query and hits\nconsensusMatrix(tmp)[1:4,]  ## [,1] [,2] [,3] [,4] [,5] [,6] ## A 3 0 0 0 0 0 ## C 1 1 0 0 0 0 ## G 0 0 4 4 1 4 ## T 0 3 0 0 3 0  Find all pattern matches in reference\nmyvpos \u003c- vmatchPattern(\"ATGGCT\", myseq1, max.mismatch=1) myvpos # The results are stored as MIndex object.  ## MIndex object of length 2058 ## $`gi|12057215|gb|AE004437.1|:248-1453 Halobacterium sp. NRC-1, complete genome` ## IRanges object with 3 ranges and 0 metadata columns: ## start end width ## \u003cinteger\u003e \u003cinteger\u003e \u003cinteger\u003e ## [1] 1 6 6 ## [2] 383 388 6 ## [3] 928 933 6 ## ## $`gi|12057215|gb|AE004437.1|:1450-2115 Halobacterium sp. NRC-1, complete genome` ## IRanges object with 0 ranges and 0 metadata columns: ## start end width ## \u003cinteger\u003e \u003cinteger\u003e \u003cinteger\u003e ## ## $`gi|12057215|gb|AE004437.1|:2145-3254 Halobacterium sp. NRC-1, complete genome` ## IRanges object with 5 ranges and 0 metadata columns: ## start end width ## \u003cinteger\u003e \u003cinteger\u003e \u003cinteger\u003e ## [1] 1 6 6 ## [2] 94 99 6 ## [3] 221 226 6 ## [4] 535 540 6 ## [5] 601 606 6 ## ## ... ## \u003c2055 more elements\u003e  Views(myseq1[[1]], start(myvpos[[1]]), end(myvpos[[1]])) # Retrieves the result for single entry  ## Views on a 1206-letter DNAString subject ## subject: ATGACTCGGCGGTCTCGTGTCGGTGCCGGCCTCGCAGCCATTGT...TTGCGATCGTCGTCGTCGTTGTTCGACGCTGGCGGAACCCATGA ## views: ## start end width ## [1] 1 6 6 [ATGACT] ## [2] 383 388 6 [ATGGCA] ## [3] 928 933 6 [ATGACT]  Return all matches\nsapply(seq(along=myseq1), function(x) as.character(Views(myseq1[[x]], start(myvpos[[x]]), end(myvpos[[x]]))))[1:4]  Pattern matching with regular expression support myseq \u003c- DNAStringSet(c(\"ATGCAGACATAGTG\", \"ATGAACATAGATCC\", \"GTACAGATCAC\")) myseq[grep(\"^ATG\", myseq, perl=TRUE)] # String searching with regular expression support  ## DNAStringSet object of length 2: ## width seq ## [1] 14 ATGCAGACATAGTG ## [2] 14 ATGAACATAGATCC  pos1 \u003c- regexpr(\"AT\", myseq) # Searches 'myseq' for first match of pattern \"AT\" as.numeric(pos1); attributes(pos1)$match.length # Returns position information of matches  ## [1] 1 1 7 ## [1] 2 2 2  pos2 \u003c- gregexpr(\"AT\", myseq) # Searches 'myseq' for all matches of pattern \"AT\" as.numeric(pos2[[1]]); attributes(pos2[[1]])$match.length # Match positions in first sequence  ## [1] 1 9 ## [1] 2 2  DNAStringSet(gsub(\"^ATG\", \"NNN\", myseq)) # String substitution with regular expression support  ## DNAStringSet object of length 3: ## width seq ## [1] 14 NNNCAGACATAGTG ## [2] 14 NNNAACATAGATCC ## [3] 11 GTACAGATCAC  PWM Viewing and Searching Plot with seqLogo library(seqLogo)  ## Loading required package: grid  pwm \u003c- PWM(DNAStringSet(c(\"GCT\", \"GGT\", \"GCA\"))) pwm  ## [,1] [,2] [,3] ## A 0.0000000 0.0000000 0.2312611 ## C 0.0000000 0.3157205 0.0000000 ## G 0.3685591 0.2312611 0.0000000 ## T 0.0000000 0.0000000 0.3157205  seqLogo(t(t(pwm) * 1/colSums(pwm)))  Plot with ggseqlogo The ggseqlogo package (manual) provides many customization options for plotting sequence logos. It also supports various alphabets including sequence logos for amino acid sequences.\nlibrary(ggplot2); library(ggseqlogo) pwm \u003c- PWM(DNAStringSet(c(\"GCT\", \"GGT\", \"GCA\"))) ggseqlogo(pwm)  Search sequence for PWM matches with score better than min.score\nchr \u003c- DNAString(\"AAAGCTAAAGGTAAAGCAAAA\") matchPWM(pwm, chr, min.score=0.9)  ## Views on a 21-letter DNAString subject ## subject: AAAGCTAAAGGTAAAGCAAAA ## views: ## start end width ## [1] 4 6 3 [GCT] ## [2] 10 12 3 [GGT] ## [3] 16 18 3 [GCA]  NGS Sequences Sequence and Quality Data: FASTQ Format Four lines per sequence:\n ID Sequence ID Base call qualities (Phred scores) as ASCII characters  The following gives an example of 3 Illumina reads in a FASTQ file. The numbers at the beginning of each line are not part of the FASTQ format. They have been added solely for illustration purposes.\n1. @SRR038845.3 HWI-EAS038:6:1:0:1938 length=36 2. CAACGAGTTCACACCTTGGCCGACAGGCCCGGGTAA 3. +SRR038845.3 HWI-EAS038:6:1:0:1938 length=36 4. BA@7\u003eB=\u003e:\u003e\u003e7@7@\u003e\u003e9=BAA?;\u003e52;\u003e:9=8.=A 1. @SRR038845.41 HWI-EAS038:6:1:0:1474 length=36 2. CCAATGATTTTTTTCCGTGTTTCAGAATACGGTTAA 3. +SRR038845.41 HWI-EAS038:6:1:0:1474 length=36 4. BCCBA@BB@BBBBAB@B9B@=BABA@A:@693:@B= 1. @SRR038845.53 HWI-EAS038:6:1:1:360 length=36 2. GTTCAAAAAGAACTAAATTGTGTCAATAGAAAACTC 3. +SRR038845.53 HWI-EAS038:6:1:1:360 length=36 4. BBCBBBBBB@@BAB?BBBBCBC\u003eBBBAA8\u003eBBBAA@  Sequence and Quality Data: QualityScaleXStringSet Phred quality scores are integers from 0-50 that are stored as ASCII characters after adding 33. The basic R functions rawToChar and charToRaw can be used to interconvert among their representations.\nPhred score interconversion\nphred \u003c- 1:9 phreda \u003c- paste(sapply(as.raw((phred)+33), rawToChar), collapse=\"\") phreda  ## [1] \"\\\"#$%\u0026'()*\"  as.integer(charToRaw(phreda))-33  ## [1] 1 2 3 4 5 6 7 8 9  Construct QualityScaledDNAStringSet from scratch\ndset \u003c- DNAStringSet(sapply(1:100, function(x) paste(sample(c(\"A\",\"T\",\"G\",\"C\"), 20, replace=T), collapse=\"\"))) # Creates random sample sequence. myqlist \u003c- lapply(1:100, function(x) sample(1:40, 20, replace=T)) # Creates random Phred score list. myqual \u003c- sapply(myqlist, function(x) toString(PhredQuality(x))) # Converts integer scores into ASCII characters. myqual \u003c- PhredQuality(myqual) # Converts to a PhredQuality object. dsetq1 \u003c- QualityScaledDNAStringSet(dset, myqual) # Combines DNAStringSet and quality data in QualityScaledDNAStringSet object. dsetq1[1:2]  ## A QualityScaledDNAStringSet instance containing: ## ## DNAStringSet object of length 2: ## width seq ## [1] 20 GGACTGCAATCACTAATCCC ## [2] 20 TCTGATGAACAAACTGGTTT ## ## PhredQuality object of length 2: ## width seq ## [1] 20 (@5.;ECA0$.3\u003c$'7?H3D ## [2] 20 5\u003c(;1C@*BI:92\u0026;#2F\u003eI  Processing FASTQ Files with ShortRead The following expains the basic usage of ShortReadQ objects. To make the sample code work, download and unzip this file to your current working directory. The following code performs the download for you.\nlibrary(ShortRead) download.file(\"http://cluster.hpcc.ucr.edu/~tgirke/HTML_Presentations/Manuals/Workshop_Dec_6_10_2012/Rsequences/data.zip\", \"data.zip\") unzip(\"data.zip\")  Important utilities for accessing FASTQ files\nfastq \u003c- list.files(\"data\", \"*.fastq$\"); fastq \u003c- paste(\"data/\", fastq, sep=\"\") names(fastq) \u003c- paste(\"flowcell6_lane\", 1:length(fastq), sep=\"_\") (fq \u003c- readFastq(fastq[1])) # Imports first FASTQ file  ## class: ShortReadQ ## length: 1000 reads; width: 36 cycles  countLines(dirPath=\"./data\", pattern=\".fastq$\")/4 # Counts numbers of reads in FASTQ files  ## SRR038845.fastq SRR038846.fastq SRR038848.fastq SRR038850.fastq ## 1000 1000 1000 1000  id(fq)[1] # Returns ID field  ## BStringSet object of length 1: ## width seq ## [1] 43 SRR038845.3 HWI-EAS038:6:1:0:1938 length=36  sread(fq)[1] # Returns sequence  ## DNAStringSet object of length 1: ## width seq ## [1] 36 CAACGAGTTCACACCTTGGCCGACAGGCCCGGGTAA  quality(fq)[1] # Returns Phred scores  ## class: FastqQuality ## quality: ## BStringSet object of length 1: ## width seq ## [1] 36 BA@7\u003eB=\u003e:\u003e\u003e7@7@\u003e\u003e9=BAA?;\u003e52;\u003e:9=8.=A  as(quality(fq), \"matrix\")[1:4,1:12] # Coerces Phred scores to numeric matrix  ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] ## [1,] 33 32 31 22 29 33 28 29 25 29 29 22 ## [2,] 33 34 34 33 32 31 33 33 31 33 33 33 ## [3,] 33 33 34 33 33 33 33 33 33 31 31 33 ## [4,] 33 33 33 33 31 33 28 31 28 32 33 33  ShortReadQ(sread=sread(fq), quality=quality(fq), id=id(fq)) # Constructs a ShortReadQ from components  ## class: ShortReadQ ## length: 1000 reads; width: 36 cycles  FASTQ Quality Reports Using systemPipeR The following seeFastq and seeFastqPlot functions generate and plot a series of useful quality statistics for a set of FASTQ files.\nlibrary(systemPipeR) fqlist \u003c- seeFastq(fastq=fastq, batchsize=800, klength=8) # For real data set batchsize to at least 10^5 seeFastqPlot(fqlist)  Handles many samples in one PDF file. For more details see here\nUsing ShortRead The ShortRead package contains several FASTQ quality reporting functions.\nsp \u003c- SolexaPath(system.file('extdata', package='ShortRead')) fl \u003c- file.path(analysisPath(sp), \"s_1_sequence.txt\") fls \u003c- c(fl, fl) coll \u003c- QACollate(QAFastqSource(fls), QAReadQuality(), QAAdapterContamination(), QANucleotideUse(), QAQualityUse(), QASequenceUse(), QAFrequentSequence(n=10), QANucleotideByCycle(), QAQualityByCycle()) x \u003c- qa2(coll, verbose=TRUE) res \u003c- report(x) if(interactive()) browseURL(res)  Filtering and Trimming FASTQ Files with ShortRead Adaptor trimming fqtrim \u003c- trimLRPatterns(Rpattern=\"GCCCGGGTAA\", subject=fq) sread(fq)[1:2] # Before trimming  ## DNAStringSet object of length 2: ## width seq ## [1] 36 CAACGAGTTCACACCTTGGCCGACAGGCCCGGGTAA ## [2] 36 CCAATGATTTTTTTCCGTGTTTCAGAATACGGTTAA  sread(fqtrim)[1:2] # After trimming  ## DNAStringSet object of length 2: ## width seq ## [1] 26 CAACGAGTTCACACCTTGGCCGACAG ## [2] 36 CCAATGATTTTTTTCCGTGTTTCAGAATACGGTTAA  Read counting and duplicate removal tables(fq)$distribution # Counts read occurences  ## nOccurrences nReads ## 1 1 948 ## 2 2 26  sum(srduplicated(fq)) # Identifies duplicated reads  ## [1] 26  fq[!srduplicated(fq)]  ## class: ShortReadQ ## length: 974 reads; width: 36 cycles  Trimming low quality tails cutoff \u003c- 30 cutoff \u003c- rawToChar(as.raw(cutoff+33)) sread(trimTails(fq, k=2, a=cutoff, successive=FALSE))[1:2]  ## DNAStringSet object of length 2: ## width seq ## [1] 4 CAAC ## [2] 20 CCAATGATTTTTTTCCGTGT  Removal of reads with Phred scores below a threshold value cutoff \u003c- 30 qcount \u003c- rowSums(as(quality(fq), \"matrix\") \u003c= 20) fq[qcount == 0] # Number of reads where all Phred scores \u003e= 20  ## class: ShortReadQ ## length: 349 reads; width: 36 cycles  Removal of reads with x Ns and/or low complexity segments filter1 \u003c- nFilter(threshold=1) # Keeps only reads without Ns filter2 \u003c- polynFilter(threshold=20, nuc=c(\"A\",\"T\",\"G\",\"C\")) # Removes reads with \u003e=20 of one nucleotide filter \u003c- compose(filter1, filter2) fq[filter(fq)]  ## class: ShortReadQ ## length: 989 reads; width: 36 cycles  Memory Efficient FASTQ Processing Streaming through FASTQ files with FastqStreamer and random sampling reads with FastqSampler\nfq \u003c- yield(FastqStreamer(fastq[1], 50)) # Imports first 50 reads fq \u003c- yield(FastqSampler(fastq[1], 50)) # Random samples 50 reads  Streaming through a FASTQ file while applying filtering/trimming functions and writing the results to a new file here SRR038845.fastq_sub in data directory.\nf \u003c- FastqStreamer(fastq[1], 50) while(length(fq \u003c- yield(f))) { fqsub \u003c- fq[grepl(\"^TT\", sread(fq))] writeFastq(fqsub, paste(fastq[1], \"sub\", sep=\"_\"), mode=\"a\", compress=FALSE) } close(f)  Range Operations Important Data Objects for Range Operations  IRanges: stores range data only (IRanges library) GRanges: stores ranges and annotations (GenomicRanges library) GRangesList: list version of GRanges container (GenomicRanges library)  Range Data Are Stored in IRanges and GRanges Containers Construct GRanges Object library(GenomicRanges); library(rtracklayer) gr \u003c- GRanges(seqnames = Rle(c(\"chr1\", \"chr2\", \"chr1\", \"chr3\"), c(1, 3, 2, 4)), ranges = IRanges(1:10, end = 7:16, names = head(letters, 10)), strand = Rle(strand(c(\"-\", \"+\", \"*\", \"+\", \"-\")), c(1, 2, 2, 3, 2)), score = 1:10, GC = seq(1, 0, length = 10)) # Example of creating a GRanges object with its constructor function.  Import GFF into GRanges Object gff \u003c- import.gff(\"http://cluster.hpcc.ucr.edu/~tgirke/Documents/R_BioCond/Samples/gff3.gff\") # Imports a simplified GFF3 genome annotation file. seqlengths(gff) \u003c- end(ranges(gff[which(values(gff)[,\"type\"]==\"chromosome\"),])) names(gff) \u003c- 1:length(gff) # Assigns names to corresponding slot gff[1:4,]  ## GRanges object with 4 ranges and 10 metadata columns: ## seqnames ranges strand | source type score phase ID ## \u003cRle\u003e \u003cIRanges\u003e \u003cRle\u003e | \u003cfactor\u003e \u003cfactor\u003e \u003cnumeric\u003e \u003cinteger\u003e \u003ccharacter\u003e ## 1 Chr1 1-30427671 + | TAIR10 chromosome NA \u003cNA\u003e Chr1 ## 2 Chr1 3631-5899 + | TAIR10 gene NA \u003cNA\u003e AT1G01010 ## 3 Chr1 3631-5899 + | TAIR10 mRNA NA \u003cNA\u003e AT1G01010.1 ## 4 Chr1 3760-5630 + | TAIR10 protein NA \u003cNA\u003e AT1G01010.1-Protein ## Name Note Parent Index Derives_from ## \u003ccharacter\u003e \u003cCharacterList\u003e \u003cCharacterList\u003e \u003ccharacter\u003e \u003ccharacter\u003e ## 1 Chr1 \u003cNA\u003e \u003cNA\u003e ## 2 AT1G01010 protein_coding_gene \u003cNA\u003e \u003cNA\u003e ## 3 AT1G01010.1 AT1G01010 1 \u003cNA\u003e ## 4 AT1G01010.1 \u003cNA\u003e AT1G01010.1 ## ------- ## seqinfo: 7 sequences from an unspecified genome  Coerce GRanges object to data.frame as.data.frame(gff)[1:4, 1:7]  ## seqnames start end width strand source type ## 1 Chr1 1 30427671 30427671 + TAIR10 chromosome ## 2 Chr1 3631 5899 2269 + TAIR10 gene ## 3 Chr1 3631 5899 2269 + TAIR10 mRNA ## 4 Chr1 3760 5630 1871 + TAIR10 protein  Utilities for Range Containers Accessor and subsetting methods for GRanges objects Subsetting and replacement\ngff[1:4]  ## GRanges object with 4 ranges and 10 metadata columns: ## seqnames ranges strand | source type score phase ID ## \u003cRle\u003e \u003cIRanges\u003e \u003cRle\u003e | \u003cfactor\u003e \u003cfactor\u003e \u003cnumeric\u003e \u003cinteger\u003e \u003ccharacter\u003e ## 1 Chr1 1-30427671 + | TAIR10 chromosome NA \u003cNA\u003e Chr1 ## 2 Chr1 3631-5899 + | TAIR10 gene NA \u003cNA\u003e AT1G01010 ## 3 Chr1 3631-5899 + | TAIR10 mRNA NA \u003cNA\u003e AT1G01010.1 ## 4 Chr1 3760-5630 + | TAIR10 protein NA \u003cNA\u003e AT1G01010.1-Protein ## Name Note Parent Index Derives_from ## \u003ccharacter\u003e \u003cCharacterList\u003e \u003cCharacterList\u003e \u003ccharacter\u003e \u003ccharacter\u003e ## 1 Chr1 \u003cNA\u003e \u003cNA\u003e ## 2 AT1G01010 protein_coding_gene \u003cNA\u003e \u003cNA\u003e ## 3 AT1G01010.1 AT1G01010 1 \u003cNA\u003e ## 4 AT1G01010.1 \u003cNA\u003e AT1G01010.1 ## ------- ## seqinfo: 7 sequences from an unspecified genome  gff[1:4, c(\"type\", \"ID\")]  ## GRanges object with 4 ranges and 2 metadata columns: ## seqnames ranges strand | type ID ## \u003cRle\u003e \u003cIRanges\u003e \u003cRle\u003e | \u003cfactor\u003e \u003ccharacter\u003e ## 1 Chr1 1-30427671 + | chromosome Chr1 ## 2 Chr1 3631-5899 + | gene AT1G01010 ## 3 Chr1 3631-5899 + | mRNA AT1G01010.1 ## 4 Chr1 3760-5630 + | protein AT1G01010.1-Protein ## ------- ## seqinfo: 7 sequences from an unspecified genome  gff[2] \u003c- gff[3]  GRanges objects can be concatenated with the c function\nc(gff[1:2], gff[401:402])  ## GRanges object with 4 ranges and 10 metadata columns: ## seqnames ranges strand | source type score phase ID ## \u003cRle\u003e \u003cIRanges\u003e \u003cRle\u003e | \u003cfactor\u003e \u003cfactor\u003e \u003cnumeric\u003e \u003cinteger\u003e \u003ccharacter\u003e ## 1 Chr1 1-30427671 + | TAIR10 chromosome NA \u003cNA\u003e Chr1 ## 2 Chr1 3631-5899 + | TAIR10 mRNA NA \u003cNA\u003e AT1G01010.1 ## 401 Chr5 5516-5769 - | TAIR10 protein NA \u003cNA\u003e AT5G01015.2-Protein ## 402 Chr5 5770-5801 - | TAIR10 five_prime_UTR NA \u003cNA\u003e \u003cNA\u003e ## Name Note Parent Index Derives_from ## \u003ccharacter\u003e \u003cCharacterList\u003e \u003cCharacterList\u003e \u003ccharacter\u003e \u003ccharacter\u003e ## 1 Chr1 \u003cNA\u003e \u003cNA\u003e ## 2 AT1G01010.1 AT1G01010 1 \u003cNA\u003e ## 401 AT5G01015.2 \u003cNA\u003e AT5G01015.2 ## 402 \u003cNA\u003e AT5G01015.2 \u003cNA\u003e \u003cNA\u003e ## ------- ## seqinfo: 7 sequences from an unspecified genome  Acessor functions\nseqnames(gff)  ## factor-Rle of length 449 with 7 runs ## Lengths: 72 22 38 118 172 13 14 ## Values : Chr1 Chr2 Chr3 Chr4 Chr5 ChrC ChrM ## Levels(7): Chr1 Chr2 Chr3 Chr4 Chr5 ChrC ChrM  ranges(gff)  ## IRanges object with 449 ranges and 0 metadata columns: ## start end width ## \u003cinteger\u003e \u003cinteger\u003e \u003cinteger\u003e ## 1 1 30427671 30427671 ## 2 3631 5899 2269 ## 3 3631 5899 2269 ## 4 3760 5630 1871 ## 5 3631 3913 283 ## ... ... ... ... ## 445 11918 12241 324 ## 446 11918 12241 324 ## 447 11918 12241 324 ## 448 11918 12241 324 ## 449 11918 12241 324  strand(gff)  ## factor-Rle of length 449 with 13 runs ## Lengths: 18 54 28 21 12 117 1 171 1 12 1 8 5 ## Values : + - + - + - + - + - + - + ## Levels(3): + - *  seqlengths(gff)  ## Chr1 Chr2 Chr3 Chr4 Chr5 ChrC ChrM ## 30427671 19698289 23459830 18585056 26975502 154478 366924  start(gff[1:4])  ## [1] 1 3631 3631 3760  end(gff[1:4])  ## [1] 30427671 5899 5899 5630  width(gff[1:4])  ## [1] 30427671 2269 2269 1871  Accessing metadata component\nvalues(gff) # or elementMetadata(gff)  ## DataFrame with 449 rows and 10 columns ## source type score phase ID Name Note ## \u003cfactor\u003e \u003cfactor\u003e \u003cnumeric\u003e \u003cinteger\u003e \u003ccharacter\u003e \u003ccharacter\u003e \u003cCharacterList\u003e ## 1 TAIR10 chromosome NA NA Chr1 Chr1 ## 2 TAIR10 mRNA NA NA AT1G01010.1 AT1G01010.1 ## 3 TAIR10 mRNA NA NA AT1G01010.1 AT1G01010.1 ## 4 TAIR10 protein NA NA AT1G01010.1-Protein AT1G01010.1 ## 5 TAIR10 exon NA NA NA NA ## ... ... ... ... ... ... ... ... ## 445 TAIR10 gene NA NA ATMG00030 ATMG00030 protein_coding_gene ## 446 TAIR10 mRNA NA NA ATMG00030.1 ATMG00030.1 ## 447 TAIR10 protein NA NA ATMG00030.1-Protein ATMG00030.1 ## 448 TAIR10 exon NA NA NA NA ## 449 TAIR10 CDS NA 0 NA NA ## Parent Index Derives_from ## \u003cCharacterList\u003e \u003ccharacter\u003e \u003ccharacter\u003e ## 1 NA NA ## 2 AT1G01010 1 NA ## 3 AT1G01010 1 NA ## 4 NA AT1G01010.1 ## 5 AT1G01010.1 NA NA ## ... ... ... ... ## 445 NA NA ## 446 ATMG00030 1 NA ## 447 NA ATMG00030.1 ## 448 ATMG00030.1 NA NA ## 449 ATMG00030.1,ATMG00030.1-Protein NA NA  values(gff)[, \"type\"][1:20]  ## [1] chromosome mRNA mRNA protein exon five_prime_UTR ## [7] CDS exon CDS exon CDS exon ## [13] CDS exon CDS exon CDS three_prime_UTR ## [19] gene mRNA ## Levels: chromosome gene mRNA protein exon five_prime_UTR CDS three_prime_UTR rRNA tRNA  gff[values(gff)[ ,\"type\"] == \"gene\"]  ## GRanges object with 21 ranges and 10 metadata columns: ## seqnames ranges strand | source type score phase ID Name ## \u003cRle\u003e \u003cIRanges\u003e \u003cRle\u003e | \u003cfactor\u003e \u003cfactor\u003e \u003cnumeric\u003e \u003cinteger\u003e \u003ccharacter\u003e \u003ccharacter\u003e ## 19 Chr1 5928-8737 - | TAIR10 gene NA \u003cNA\u003e AT1G01020 AT1G01020 ## 64 Chr1 11649-13714 - | TAIR10 gene NA \u003cNA\u003e AT1G01030 AT1G01030 ## 74 Chr2 1025-2810 + | TAIR10 gene NA \u003cNA\u003e AT2G01008 AT2G01008 ## 84 Chr2 3706-5513 + | TAIR10 gene NA \u003cNA\u003e AT2G01010 AT2G01010 ## 87 Chr2 5782-5945 + | TAIR10 gene NA \u003cNA\u003e AT2G01020 AT2G01020 ## ... ... ... ... . ... ... ... ... ... ... ## 427 ChrC 383-1444 - | TAIR10 gene NA \u003cNA\u003e ATCG00020 ATCG00020 ## 432 ChrC 1717-4347 - | TAIR10 gene NA \u003cNA\u003e ATCG00030 ATCG00030 ## 437 ChrM 273-734 - | TAIR10 gene NA \u003cNA\u003e ATMG00010 ATMG00010 ## 442 ChrM 8848-11415 - | TAIR10 gene NA \u003cNA\u003e ATMG00020 ATMG00020 ## 445 ChrM 11918-12241 + | TAIR10 gene NA \u003cNA\u003e ATMG00030 ATMG00030 ## Note Parent Index Derives_from ## \u003cCharacterList\u003e \u003cCharacterList\u003e \u003ccharacter\u003e \u003ccharacter\u003e ## 19 protein_coding_gene \u003cNA\u003e \u003cNA\u003e ## 64 protein_coding_gene \u003cNA\u003e \u003cNA\u003e ## 74 protein_coding_gene \u003cNA\u003e \u003cNA\u003e ## 84 rRNA \u003cNA\u003e \u003cNA\u003e ## 87 rRNA \u003cNA\u003e \u003cNA\u003e ## ... ... ... ... ... ## 427 protein_coding_gene \u003cNA\u003e \u003cNA\u003e ## 432 tRNA \u003cNA\u003e \u003cNA\u003e ## 437 protein_coding_gene \u003cNA\u003e \u003cNA\u003e ## 442 rRNA \u003cNA\u003e \u003cNA\u003e ## 445 protein_coding_gene \u003cNA\u003e \u003cNA\u003e ## ------- ## seqinfo: 7 sequences from an unspecified genome  Useful utilities for GRanges objects Remove chromosome ranges\ngff \u003c- gff[values(gff)$type != \"chromosome\"]  Erase the strand information\nstrand(gff) \u003c- \"*\"  Collapses overlapping ranges to continuous ranges.\nreduce(gff)  ## GRanges object with 22 ranges and 0 metadata columns: ## seqnames ranges strand ## \u003cRle\u003e \u003cIRanges\u003e \u003cRle\u003e ## [1] Chr1 3631-5899 * ## [2] Chr1 5928-8737 * ## [3] Chr1 11649-13714 * ## [4] Chr2 1025-2810 * ## [5] Chr2 3706-5513 * ## ... ... ... ... ## [18] ChrC 383-1444 * ## [19] ChrC 1717-4347 * ## [20] ChrM 273-734 * ## [21] ChrM 8848-11415 * ## [22] ChrM 11918-12241 * ## ------- ## seqinfo: 7 sequences from an unspecified genome  Return uncovered regions\ngaps(gff)  ## GRanges object with 43 ranges and 0 metadata columns: ## seqnames ranges strand ## \u003cRle\u003e \u003cIRanges\u003e \u003cRle\u003e ## [1] Chr1 1-30427671 + ## [2] Chr1 1-30427671 - ## [3] Chr1 1-3630 * ## [4] Chr1 5900-5927 * ## [5] Chr1 8738-11648 * ## ... ... ... ... ## [39] ChrM 1-366924 - ## [40] ChrM 1-272 * ## [41] ChrM 735-8847 * ## [42] ChrM 11416-11917 * ## [43] ChrM 12242-366924 * ## ------- ## seqinfo: 7 sequences from an unspecified genome  More intuitive way to get uncovered regions\nsetdiff(as(seqinfo(gff), \"GRanges\"), gff)  ## GRanges object with 29 ranges and 0 metadata columns: ## seqnames ranges strand ## \u003cRle\u003e \u003cIRanges\u003e \u003cRle\u003e ## [1] Chr1 1-3630 * ## [2] Chr1 5900-5927 * ## [3] Chr1 8738-11648 * ## [4] Chr1 13715-30427671 * ## [5] Chr2 1-1024 * ## ... ... ... ... ## [25] ChrC 4348-154478 * ## [26] ChrM 1-272 * ## [27] ChrM 735-8847 * ## [28] ChrM 11416-11917 * ## [29] ChrM 12242-366924 * ## ------- ## seqinfo: 7 sequences from an unspecified genome  Return disjoint ranges\ndisjoin(gff)  ## GRanges object with 211 ranges and 0 metadata columns: ## seqnames ranges strand ## \u003cRle\u003e \u003cIRanges\u003e \u003cRle\u003e ## [1] Chr1 3631-3759 * ## [2] Chr1 3760-3913 * ## [3] Chr1 3914-3995 * ## [4] Chr1 3996-4276 * ## [5] Chr1 4277-4485 * ## ... ... ... ... ## [207] ChrC 1752-4310 * ## [208] ChrC 4311-4347 * ## [209] ChrM 273-734 * ## [210] ChrM 8848-11415 * ## [211] ChrM 11918-12241 * ## ------- ## seqinfo: 7 sequences from an unspecified genome  Returns coverage of ranges\ncoverage(gff)  ## RleList of length 7 ## $Chr1 ## integer-Rle of length 30427671 with 45 runs ## Lengths: 3630 129 154 82 281 ... 233 161 380 30413957 ## Values : 0 4 5 3 5 ... 4 2 4 0 ## ## $Chr2 ## integer-Rle of length 19698289 with 14 runs ## Lengths: 1024 248 185 53 362 ... 164 625 102 19691617 ## Values : 0 5 3 5 3 ... 3 0 5 0 ## ## $Chr3 ## integer-Rle of length 23459830 with 29 runs ## Lengths: 1652 145 139 111 95 ... 155 148 156 23453781 ## Values : 0 4 5 3 5 ... 3 5 4 0 ## ## $Chr4 ## integer-Rle of length 18585056 with 72 runs ## Lengths: 1179 357 1358 128 872 ... 212 114 74 18571697 ## Values : 0 5 0 5 3 ... 3 5 4 0 ## ## $Chr5 ## integer-Rle of length 26975502 with 64 runs ## Lengths: 1222 28 28 109 72 ... 76 55 174 26967058 ## Values : 0 4 7 13 16 ... 3 5 4 0 ## ## ... ## \u003c2 more elements\u003e  Return the index pairings for overlapping ranges\nfindOverlaps(gff, gff[1:4])  ## Hits object with 55 hits and 0 metadata columns: ## queryHits subjectHits ## \u003cinteger\u003e \u003cinteger\u003e ## [1] 1 1 ## [2] 1 2 ## [3] 1 4 ## [4] 1 3 ## [5] 2 1 ## ... ... ... ## [51] 16 1 ## [52] 16 2 ## [53] 16 3 ## [54] 17 1 ## [55] 17 2 ## ------- ## queryLength: 442 / subjectLength: 4  Counts overlapping ranges\ncountOverlaps(gff, gff[1:4])[1:40]  ## 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 ## 4 4 4 4 3 4 3 3 3 3 3 3 3 3 3 3 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ## 35 36 37 38 39 40 41 ## 0 0 0 0 0 0 0  Return only overlapping ranges\nsubsetByOverlaps(gff, gff[1:4])  ## GRanges object with 17 ranges and 10 metadata columns: ## seqnames ranges strand | source type score phase ID ## \u003cRle\u003e \u003cIRanges\u003e \u003cRle\u003e | \u003cfactor\u003e \u003cfactor\u003e \u003cnumeric\u003e \u003cinteger\u003e \u003ccharacter\u003e ## 2 Chr1 3631-5899 * | TAIR10 mRNA NA \u003cNA\u003e AT1G01010.1 ## 3 Chr1 3631-5899 * | TAIR10 mRNA NA \u003cNA\u003e AT1G01010.1 ## 4 Chr1 3760-5630 * | TAIR10 protein NA \u003cNA\u003e AT1G01010.1-Protein ## 5 Chr1 3631-3913 * | TAIR10 exon NA \u003cNA\u003e \u003cNA\u003e ## 6 Chr1 3631-3759 * | TAIR10 five_prime_UTR NA \u003cNA\u003e \u003cNA\u003e ## .. ... ... ... . ... ... ... ... ... ## 14 Chr1 5174-5326 * | TAIR10 exon NA \u003cNA\u003e \u003cNA\u003e ## 15 Chr1 5174-5326 * | TAIR10 CDS NA 0 \u003cNA\u003e ## 16 Chr1 5439-5899 * | TAIR10 exon NA \u003cNA\u003e \u003cNA\u003e ## 17 Chr1 5439-5630 * | TAIR10 CDS NA 0 \u003cNA\u003e ## 18 Chr1 5631-5899 * | TAIR10 three_prime_UTR NA \u003cNA\u003e \u003cNA\u003e ## Name Note Parent Index Derives_from ## \u003ccharacter\u003e \u003cCharacterList\u003e \u003cCharacterList\u003e \u003ccharacter\u003e \u003ccharacter\u003e ## 2 AT1G01010.1 AT1G01010 1 \u003cNA\u003e ## 3 AT1G01010.1 AT1G01010 1 \u003cNA\u003e ## 4 AT1G01010.1 \u003cNA\u003e AT1G01010.1 ## 5 \u003cNA\u003e AT1G01010.1 \u003cNA\u003e \u003cNA\u003e ## 6 \u003cNA\u003e AT1G01010.1 \u003cNA\u003e \u003cNA\u003e ## .. ... ... ... ... ... ## 14 \u003cNA\u003e AT1G01010.1 \u003cNA\u003e \u003cNA\u003e ## 15 \u003cNA\u003e AT1G01010.1,AT1G01010.1-Protein \u003cNA\u003e \u003cNA\u003e ## 16 \u003cNA\u003e AT1G01010.1 \u003cNA\u003e \u003cNA\u003e ## 17 \u003cNA\u003e AT1G01010.1,AT1G01010.1-Protein \u003cNA\u003e \u003cNA\u003e ## 18 \u003cNA\u003e AT1G01010.1 \u003cNA\u003e \u003cNA\u003e ## ------- ## seqinfo: 7 sequences from an unspecified genome  GRangesList Objects sp \u003c- split(gff, seq(along=gff)) # Stores every range in separate component of a GRangesList object split(gff, seqnames(gff)) # Stores ranges of each chromosome in separate component.  ## GRangesList object of length 7: ## $Chr1 ## GRanges object with 71 ranges and 10 metadata columns: ## seqnames ranges strand | source type score phase ID ## \u003cRle\u003e \u003cIRanges\u003e \u003cRle\u003e | \u003cfactor\u003e \u003cfactor\u003e \u003cnumeric\u003e \u003cinteger\u003e \u003ccharacter\u003e ## 2 Chr1 3631-5899 * | TAIR10 mRNA NA \u003cNA\u003e AT1G01010.1 ## 3 Chr1 3631-5899 * | TAIR10 mRNA NA \u003cNA\u003e AT1G01010.1 ## 4 Chr1 3760-5630 * | TAIR10 protein NA \u003cNA\u003e AT1G01010.1-Protein ## 5 Chr1 3631-3913 * | TAIR10 exon NA \u003cNA\u003e \u003cNA\u003e ## 6 Chr1 3631-3759 * | TAIR10 five_prime_UTR NA \u003cNA\u003e \u003cNA\u003e ## .. ... ... ... . ... ... ... ... ... ## 68 Chr1 13335-13714 * | TAIR10 exon NA \u003cNA\u003e \u003cNA\u003e ## 69 Chr1 12941-13173 * | TAIR10 five_prime_UTR NA \u003cNA\u003e \u003cNA\u003e ## 70 Chr1 11864-12940 * | TAIR10 CDS NA 0 \u003cNA\u003e ## 71 Chr1 11649-11863 * | TAIR10 three_prime_UTR NA \u003cNA\u003e \u003cNA\u003e ## 72 Chr1 11649-13173 * | TAIR10 exon NA \u003cNA\u003e \u003cNA\u003e ## Name Note Parent Index Derives_from ## \u003ccharacter\u003e \u003cCharacterList\u003e \u003cCharacterList\u003e \u003ccharacter\u003e \u003ccharacter\u003e ## 2 AT1G01010.1 AT1G01010 1 \u003cNA\u003e ## 3 AT1G01010.1 AT1G01010 1 \u003cNA\u003e ## 4 AT1G01010.1 \u003cNA\u003e AT1G01010.1 ## 5 \u003cNA\u003e AT1G01010.1 \u003cNA\u003e \u003cNA\u003e ## 6 \u003cNA\u003e AT1G01010.1 \u003cNA\u003e \u003cNA\u003e ## .. ... ... ... ... ... ## 68 \u003cNA\u003e AT1G01030.1 \u003cNA\u003e \u003cNA\u003e ## 69 \u003cNA\u003e AT1G01030.1 \u003cNA\u003e \u003cNA\u003e ## 70 \u003cNA\u003e AT1G01030.1,AT1G01030.1-Protein \u003cNA\u003e \u003cNA\u003e ## 71 \u003cNA\u003e AT1G01030.1 \u003cNA\u003e \u003cNA\u003e ## 72 \u003cNA\u003e AT1G01030.1 \u003cNA\u003e \u003cNA\u003e ## ------- ## seqinfo: 7 sequences from an unspecified genome ## ## ... ## \u003c6 more elements\u003e  unlist(sp) # Returns data as GRanges object  ## GRanges object with 442 ranges and 10 metadata columns: ## seqnames ranges strand | source type score phase ## \u003cRle\u003e \u003cIRanges\u003e \u003cRle\u003e | \u003cfactor\u003e \u003cfactor\u003e \u003cnumeric\u003e \u003cinteger\u003e ## 1.2 Chr1 3631-5899 * | TAIR10 mRNA NA \u003cNA\u003e ## 2.3 Chr1 3631-5899 * | TAIR10 mRNA NA \u003cNA\u003e ## 3.4 Chr1 3760-5630 * | TAIR10 protein NA \u003cNA\u003e ## 4.5 Chr1 3631-3913 * | TAIR10 exon NA \u003cNA\u003e ## 5.6 Chr1 3631-3759 * | TAIR10 five_prime_UTR NA \u003cNA\u003e ## ... ... ... ... . ... ... ... ... ## 438.445 ChrM 11918-12241 * | TAIR10 gene NA \u003cNA\u003e ## 439.446 ChrM 11918-12241 * | TAIR10 mRNA NA \u003cNA\u003e ## 440.447 ChrM 11918-12241 * | TAIR10 protein NA \u003cNA\u003e ## 441.448 ChrM 11918-12241 * | TAIR10 exon NA \u003cNA\u003e ## 442.449 ChrM 11918-12241 * | TAIR10 CDS NA 0 ## ID Name Note Parent ## \u003ccharacter\u003e \u003ccharacter\u003e \u003cCharacterList\u003e \u003cCharacterList\u003e ## 1.2 AT1G01010.1 AT1G01010.1 AT1G01010 ## 2.3 AT1G01010.1 AT1G01010.1 AT1G01010 ## 3.4 AT1G01010.1-Protein AT1G01010.1 ## 4.5 \u003cNA\u003e \u003cNA\u003e AT1G01010.1 ## 5.6 \u003cNA\u003e \u003cNA\u003e AT1G01010.1 ## ... ... ... ... ... ## 438.445 ATMG00030 ATMG00030 protein_coding_gene ## 439.446 ATMG00030.1 ATMG00030.1 ATMG00030 ## 440.447 ATMG00030.1-Protein ATMG00030.1 ## 441.448 \u003cNA\u003e \u003cNA\u003e ATMG00030.1 ## 442.449 \u003cNA\u003e \u003cNA\u003e ATMG00030.1,ATMG00030.1-Protein ## Index Derives_from ## \u003ccharacter\u003e \u003ccharacter\u003e ## 1.2 1 \u003cNA\u003e ## 2.3 1 \u003cNA\u003e ## 3.4 \u003cNA\u003e AT1G01010.1 ## 4.5 \u003cNA\u003e \u003cNA\u003e ## 5.6 \u003cNA\u003e \u003cNA\u003e ## ... ... ... ## 438.445 \u003cNA\u003e \u003cNA\u003e ## 439.446 1 \u003cNA\u003e ## 440.447 \u003cNA\u003e ATMG00030.1 ## 441.448 \u003cNA\u003e \u003cNA\u003e ## 442.449 \u003cNA\u003e \u003cNA\u003e ## ------- ## seqinfo: 7 sequences from an unspecified genome  sp[1:4, \"type\"] # Subsetting of GRangesList objects is similar to GRanges objects.  ## GRangesList object of length 4: ## $`1` ## GRanges object with 1 range and 1 metadata column: ## seqnames ranges strand | type ## \u003cRle\u003e \u003cIRanges\u003e \u003cRle\u003e | \u003cfactor\u003e ## 2 Chr1 3631-5899 * | mRNA ## ------- ## seqinfo: 7 sequences from an unspecified genome ## ## $`2` ## GRanges object with 1 range and 1 metadata column: ## seqnames ranges strand | type ## \u003cRle\u003e \u003cIRanges\u003e \u003cRle\u003e | \u003cfactor\u003e ## 3 Chr1 3631-5899 * | mRNA ## ------- ## seqinfo: 7 sequences from an unspecified genome ## ## $`3` ## GRanges object with 1 range and 1 metadata column: ## seqnames ranges strand | type ## \u003cRle\u003e \u003cIRanges\u003e \u003cRle\u003e | \u003cfactor\u003e ## 4 Chr1 3760-5630 * | protein ## ------- ## seqinfo: 7 sequences from an unspecified genome ## ## $`4` ## GRanges object with 1 range and 1 metadata column: ## seqnames ranges strand | type ## \u003cRle\u003e \u003cIRanges\u003e \u003cRle\u003e | \u003cfactor\u003e ## 5 Chr1 3631-3913 * | exon ## ------- ## seqinfo: 7 sequences from an unspecified genome  lapply(sp[1:4], length) # Looping over GRangesList objects similar to lists  ## $`1` ## [1] 1 ## ## $`2` ## [1] 1 ## ## $`3` ## [1] 1 ## ## $`4` ## [1] 1  Transcript Ranges Storing annotation ranges in TranscriptDb databases makes many operations more robust and convenient.\nlibrary(GenomicFeatures) download.file(\"http://cluster.hpcc.ucr.edu/~tgirke/Documents/R_BioCond/Samples/gff3.gff\", \"data/gff3.gff\") txdb \u003c- makeTxDbFromGFF(file=\"data/gff3.gff\", format=\"gff\", dataSource=\"TAIR\", organism=\"Arabidopsis thaliana\")  ## Warning in .extract_exons_from_GRanges(cds_IDX, gr, mcols0, tx_IDX, feature = \"cds\", : 163 CDS couldn't be linked to a transcript so were dropped (showing only the first 6): ## seqid start end strand ID Name Parent Parent_type ## 1 Chr1 3760 3913 + \u003cNA\u003e \u003cNA\u003e AT1G01010.1-Protein \u003cNA\u003e ## 2 Chr1 3996 4276 + \u003cNA\u003e \u003cNA\u003e AT1G01010.1-Protein \u003cNA\u003e ## 3 Chr1 4486 4605 + \u003cNA\u003e \u003cNA\u003e AT1G01010.1-Protein \u003cNA\u003e ## 4 Chr1 4706 5095 + \u003cNA\u003e \u003cNA\u003e AT1G01010.1-Protein \u003cNA\u003e ## 5 Chr1 5174 5326 + \u003cNA\u003e \u003cNA\u003e AT1G01010.1-Protein \u003cNA\u003e ## 6 Chr1 5439 5630 + \u003cNA\u003e \u003cNA\u003e AT1G01010.1-Protein \u003cNA\u003e  saveDb(txdb, file=\"./data/TAIR10.sqlite\")  ## TxDb object: ## # Db type: TxDb ## # Supporting package: GenomicFeatures ## # Data source: TAIR ## # Organism: Arabidopsis thaliana ## # Taxonomy ID: 3702 ## # miRBase build ID: NA ## # Genome: NA ## # Nb of transcripts: 28 ## # Db created by: GenomicFeatures package from Bioconductor ## # Creation time: 2021-02-18 14:48:05 -0800 (Thu, 18 Feb 2021) ## # GenomicFeatures version at creation time: 1.42.1 ## # RSQLite version at creation time: 2.2.1 ## # DBSCHEMAVERSION: 1.2  txdb \u003c- loadDb(\"./data/TAIR10.sqlite\") transcripts(txdb)  ## GRanges object with 28 ranges and 2 metadata columns: ## seqnames ranges strand | tx_id tx_name ## \u003cRle\u003e \u003cIRanges\u003e \u003cRle\u003e | \u003cinteger\u003e \u003ccharacter\u003e ## [1] Chr1 3631-5899 + | 1 AT1G01010.1 ## [2] Chr1 5928-8737 - | 2 AT1G01020.1 ## [3] Chr1 6790-8737 - | 3 AT1G01020.2 ## [4] Chr1 11649-13714 - | 4 AT1G01030.1 ## [5] Chr2 1025-2810 + | 5 AT2G01008.1 ## ... ... ... ... . ... ... ## [24] ChrC 383-1444 - | 24 ATCG00020.1 ## [25] ChrC 1717-4347 - | 25 ATCG00030.1 ## [26] ChrM 11918-12241 + | 26 ATMG00030.1 ## [27] ChrM 273-734 - | 27 ATMG00010.1 ## [28] ChrM 8848-11415 - | 28 ATMG00020.1 ## ------- ## seqinfo: 7 sequences (2 circular) from an unspecified genome; no seqlengths  transcriptsBy(txdb, by = \"gene\")  ## GRangesList object of length 22: ## $AT1G01010 ## GRanges object with 1 range and 2 metadata columns: ## seqnames ranges strand | tx_id tx_name ## \u003cRle\u003e \u003cIRanges\u003e \u003cRle\u003e | \u003cinteger\u003e \u003ccharacter\u003e ## [1] Chr1 3631-5899 + | 1 AT1G01010.1 ## ------- ## seqinfo: 7 sequences (2 circular) from an unspecified genome; no seqlengths ## ## $AT1G01020 ## GRanges object with 2 ranges and 2 metadata columns: ## seqnames ranges strand | tx_id tx_name ## \u003cRle\u003e \u003cIRanges\u003e \u003cRle\u003e | \u003cinteger\u003e \u003ccharacter\u003e ## [1] Chr1 5928-8737 - | 2 AT1G01020.1 ## [2] Chr1 6790-8737 - | 3 AT1G01020.2 ## ------- ## seqinfo: 7 sequences (2 circular) from an unspecified genome; no seqlengths ## ## $AT1G01030 ## GRanges object with 1 range and 2 metadata columns: ## seqnames ranges strand | tx_id tx_name ## \u003cRle\u003e \u003cIRanges\u003e \u003cRle\u003e | \u003cinteger\u003e \u003ccharacter\u003e ## [1] Chr1 11649-13714 - | 4 AT1G01030.1 ## ------- ## seqinfo: 7 sequences (2 circular) from an unspecified genome; no seqlengths ## ## ... ## \u003c19 more elements\u003e  exonsBy(txdb, by = \"gene\")  ## GRangesList object of length 22: ## $AT1G01010 ## GRanges object with 6 ranges and 2 metadata columns: ## seqnames ranges strand | exon_id exon_name ## \u003cRle\u003e \u003cIRanges\u003e \u003cRle\u003e | \u003cinteger\u003e \u003ccharacter\u003e ## [1] Chr1 3631-3913 + | 1 \u003cNA\u003e ## [2] Chr1 3996-4276 + | 2 \u003cNA\u003e ## [3] Chr1 4486-4605 + | 3 \u003cNA\u003e ## [4] Chr1 4706-5095 + | 4 \u003cNA\u003e ## [5] Chr1 5174-5326 + | 5 \u003cNA\u003e ## [6] Chr1 5439-5899 + | 6 \u003cNA\u003e ## ------- ## seqinfo: 7 sequences (2 circular) from an unspecified genome; no seqlengths ## ## $AT1G01020 ## GRanges object with 12 ranges and 2 metadata columns: ## seqnames ranges strand | exon_id exon_name ## \u003cRle\u003e \u003cIRanges\u003e \u003cRle\u003e | \u003cinteger\u003e \u003ccharacter\u003e ## [1] Chr1 5928-6263 - | 7 \u003cNA\u003e ## [2] Chr1 6437-7069 - | 8 \u003cNA\u003e ## [3] Chr1 6790-7069 - | 9 \u003cNA\u003e ## [4] Chr1 7157-7232 - | 10 \u003cNA\u003e ## [5] Chr1 7157-7450 - | 11 \u003cNA\u003e ## ... ... ... ... . ... ... ## [8] Chr1 7762-7835 - | 14 \u003cNA\u003e ## [9] Chr1 7942-7987 - | 15 \u003cNA\u003e ## [10] Chr1 8236-8325 - | 16 \u003cNA\u003e ## [11] Chr1 8417-8464 - | 17 \u003cNA\u003e ## [12] Chr1 8571-8737 - | 18 \u003cNA\u003e ## ------- ## seqinfo: 7 sequences (2 circular) from an unspecified genome; no seqlengths ## ## $AT1G01030 ## GRanges object with 2 ranges and 2 metadata columns: ## seqnames ranges strand | exon_id exon_name ## \u003cRle\u003e \u003cIRanges\u003e \u003cRle\u003e | \u003cinteger\u003e \u003ccharacter\u003e ## [1] Chr1 11649-13173 - | 19 \u003cNA\u003e ## [2] Chr1 13335-13714 - | 20 \u003cNA\u003e ## ------- ## seqinfo: 7 sequences (2 circular) from an unspecified genome; no seqlengths ## ## ... ## \u003c19 more elements\u003e  txdb from BioMart Alternative sources for creating txdb databases are BioMart, Bioc annotation packages, UCSC, etc. The following shows how to create a txdb from BioMart.\nlibrary(GenomicFeatures); library(\"biomaRt\") txdb \u003c- makeTxDbFromBiomart(biomart = \"plants_mart\", dataset = \"athaliana_eg_gene\", host=\"plants.ensembl.org\")  The following steps are useful to find out what is availble in BioMart.\nlistMarts() # Lists BioMart databases listMarts(host=\"plants.ensembl.org\") mymart \u003c- useMart(\"plants_mart\", host=\"plants.ensembl.org\") # Select one, here plants_mart_25 listDatasets(mymart) # List datasets available in the selected BioMart database mymart \u003c- useMart(\"plants_mart\", dataset=\"athaliana_eg_gene\", host=\"plants.ensembl.org\") listAttributes(mymart) # List available features getBM(attributes=c(\"ensembl_gene_id\", \"description\"), mart=mymart)[1:4,]  Efficient Sequence Parsing getSeq The following parses all annotation ranges provided by a GRanges object (e.g. gff) from a genome sequence stored in a local file.\ngff \u003c- gff[values(gff)$type != \"chromosome\"] # Remove chromosome ranges rand \u003c- DNAStringSet(sapply(unique(as.character(seqnames(gff))), function(x) paste(sample(c(\"A\",\"T\",\"G\",\"C\"), 200000, replace=T), collapse=\"\"))) writeXStringSet(DNAStringSet(rand), \"./data/test\") getSeq(FaFile(\"./data/test\"), gff)  ## DNAStringSet object of length 442: ## width seq names ## [1] 2269 CTTGGCTAGGCTGCCACATTCGTAACCCAGAT...GATACTGCCTCGACTTCCGGCATCTGATCATC Chr1 ## [2] 2269 CTTGGCTAGGCTGCCACATTCGTAACCCAGAT...GATACTGCCTCGACTTCCGGCATCTGATCATC Chr1 ## [3] 1871 TTGTGGGATAAAAATGCTATCAATGAGTGTGA...CATGAAGCAACAACCTAGCCGGTTAACCACCC Chr1 ## [4] 283 CTTGGCTAGGCTGCCACATTCGTAACCCAGAT...ATGCCCATACGGTTGGTTGTGGATTCCGCTAG Chr1 ## [5] 129 CTTGGCTAGGCTGCCACATTCGTAACCCAGAT...AGCCACGTATGGGCCGTCGTGGGCGGTCCATC Chr1 ## ... ... ... ## [438] 324 TCCGGTGACGCCCGCTAACACGGCGGGGGGTG...AATCACAAATGGTATGCGTCGTGTCAACTGCA ChrM ## [439] 324 TCCGGTGACGCCCGCTAACACGGCGGGGGGTG...AATCACAAATGGTATGCGTCGTGTCAACTGCA ChrM ## [440] 324 TCCGGTGACGCCCGCTAACACGGCGGGGGGTG...AATCACAAATGGTATGCGTCGTGTCAACTGCA ChrM ## [441] 324 TCCGGTGACGCCCGCTAACACGGCGGGGGGTG...AATCACAAATGGTATGCGTCGTGTCAACTGCA ChrM ## [442] 324 TCCGGTGACGCCCGCTAACACGGCGGGGGGTG...AATCACAAATGGTATGCGTCGTGTCAACTGCA ChrM  extractTranscriptSeqs Sequences composed of several ranges, such as transcripts (or CDSs) with several exons, can be parsed with extractTranscriptSeqs. Note: the following expects the genome sequence in a file called mygenome.fasta and a valid txdb defining the ranges for that genome.\nlibrary(GenomicFeatures); library(Biostrings); library(Rsamtools) indexFa(\"mygenome.fasta\") # Creates index for genome fasta txseq \u003c- extractTranscriptSeqs(FaFile(\"mygenome.fasta\"), txdb, use.names=TRUE)  Homework 6 HW6a - Demultiplexing Write a demultiplexing function that accepts any number of barcodes and splits a FASTQ file into as many subfiles as there are barcodes. At the same time the function should remove low quality tails from the reads. The following function accomplishes the first step. Expand this function so that it performs the second step as well.\ndemultiplex \u003c- function(x, barcode, nreads) { f \u003c- FastqStreamer(x, nreads) while(length(fq \u003c- yield(f))) { for(i in barcode) { pattern \u003c- paste(\"^\", i, sep=\"\") fqsub \u003c- fq[grepl(pattern, sread(fq))] if(length(fqsub) \u003e 0) { writeFastq(fqsub, paste(x, i, sep=\"_\"), mode=\"a\", compress=FALSE) } } } close(f) } demultiplex(x=fastq[1], barcode=c(\"TT\", \"AA\", \"GG\"), nreads=50)  HW6b - Sequence Parsing  Download GFF from Halobacterium sp here Download genome sequence from Halobacterium sp here Task 1 Extract gene ranges, parse their sequences from genome and translate them into proteins Task 2 Reduce overlapping genes and parse their sequences from genome Task 3 Generate intergenic ranges and parse their sequences from genome  Useful commands\ndownload.file(\"ftp://ftp.ncbi.nlm.nih.gov/genomes/archive/old_genbank/Bacteria/Halobacterium_sp_uid217/AE004437.gff\", \"data/AE004437.gff\") download.file(\"ftp://ftp.ncbi.nlm.nih.gov/genomes/archive/old_genbank/Bacteria/Halobacterium_sp_uid217/AE004437.fna\", \"data/AE004437.fna\") chr \u003c- readDNAStringSet(\"data/AE004437.fna\") gff \u003c- import(\"data/AE004437.gff\") gffgene \u003c- gff[values(gff)[,\"type\"]==\"gene\"] gene \u003c- DNAStringSet(Views(chr[[1]], IRanges(start(gffgene), end(gffgene)))) names(gene) \u003c- values(gffgene)[,\"locus_tag\"] pos \u003c- values(gffgene[strand(gffgene) == \"+\"])[,\"locus_tag\"] p1 \u003c- translate(gene[names(gene) %in% pos]) names(p1) \u003c- names(gene[names(gene) %in% pos]) neg \u003c- values(gffgene[strand(gffgene) == \"-\"])[,\"locus_tag\"] p2 \u003c- translate(reverseComplement(gene[names(gene) %in% neg])) names(p2) \u003c- names(gene[names(gene) %in% neg]) writeXStringSet(c(p1, p2), \"./data/mypep.fasta\")  Homework submission Submit the homework results in one well structured and annotated R script to the instructor. The script should include instructions on how to use the functions.\nDue date This homework is due on …\nHomework Solutions See here\nSession Info sessionInfo()  ## R version 4.0.4 (2021-02-15) ## Platform: x86_64-pc-linux-gnu (64-bit) ## Running under: Debian GNU/Linux 10 (buster) ## ## Matrix products: default ## BLAS: /usr/lib/x86_64-linux-gnu/blas/libblas.so.3.8.0 ## LAPACK: /usr/lib/x86_64-linux-gnu/lapack/liblapack.so.3.8.0 ## ## locale: ## [1] LC_CTYPE=en_US.UTF-8 LC_NUMERIC=C LC_TIME=en_US.UTF-8 ## [4] LC_COLLATE=en_US.UTF-8 LC_MONETARY=en_US.UTF-8 LC_MESSAGES=en_US.UTF-8 ## [7] LC_PAPER=en_US.UTF-8 LC_NAME=C LC_ADDRESS=C ## [10] LC_TELEPHONE=C LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C ## ## attached base packages: ## [1] grid stats4 parallel stats graphics grDevices utils datasets methods ## [10] base ## ## other attached packages: ## [1] GenomicFeatures_1.42.1 AnnotationDbi_1.52.0 rtracklayer_1.50.0 ## [4] systemPipeR_1.24.2 ShortRead_1.48.0 GenomicAlignments_1.26.0 ## [7] SummarizedExperiment_1.20.0 Biobase_2.50.0 MatrixGenerics_1.2.0 ## [10] matrixStats_0.57.0 Rsamtools_2.6.0 GenomicRanges_1.42.0 ## [13] GenomeInfoDb_1.26.1 BiocParallel_1.24.1 ggseqlogo_0.1 ## [16] seqLogo_1.56.0 Biostrings_2.58.0 XVector_0.30.0 ## [19] IRanges_2.24.0 S4Vectors_0.28.0 BiocGenerics_0.36.0 ## [22] ggplot2_3.3.2 limma_3.46.0 BiocStyle_2.18.0 ## ## loaded via a namespace (and not attached): ## [1] colorspace_2.0-0 rjson_0.2.20 hwriter_1.3.2 ## [4] ellipsis_0.3.1 farver_2.0.3 bit64_4.0.5 ## [7] xml2_1.3.2 codetools_0.2-18 splines_4.0.4 ## [10] knitr_1.30 jsonlite_1.7.1 annotate_1.68.0 ## [13] GO.db_3.12.1 dbplyr_2.0.0 png_0.1-7 ## [16] pheatmap_1.0.12 graph_1.68.0 BiocManager_1.30.10 ## [19] compiler_4.0.4 httr_1.4.2 GOstats_2.56.0 ## [22] backports_1.2.0 assertthat_0.2.1 Matrix_1.3-2 ## [25] htmltools_0.5.1.1 prettyunits_1.1.1 tools_4.0.4 ## [28] gtable_0.3.0 glue_1.4.2 GenomeInfoDbData_1.2.4 ## [31] Category_2.56.0 dplyr_1.0.2 rsvg_2.1 ## [34] batchtools_0.9.14 rappdirs_0.3.1 V8_3.4.0 ## [37] Rcpp_1.0.5 vctrs_0.3.5 blogdown_1.1.7 ## [40] xfun_0.20 stringr_1.4.0 lifecycle_0.2.0 ## [43] XML_3.99-0.5 edgeR_3.32.0 zlibbioc_1.36.0 ## [46] scales_1.1.1 BSgenome_1.58.0 VariantAnnotation_1.36.0 ## [49] hms_0.5.3 RBGL_1.66.0 RColorBrewer_1.1-2 ## [52] yaml_2.2.1 curl_4.3 memoise_1.1.0 ## [55] biomaRt_2.46.0 latticeExtra_0.6-29 stringi_1.5.3 ## [58] RSQLite_2.2.1 genefilter_1.72.0 checkmate_2.0.0 ## [61] DOT_0.1 rlang_0.4.8 pkgconfig_2.0.3 ## [64] bitops_1.0-6 evaluate_0.14 lattice_0.20-41 ## [67] purrr_0.3.4 labeling_0.4.2 bit_4.0.4 ## [70] tidyselect_1.1.0 GSEABase_1.52.0 AnnotationForge_1.32.0 ## [73] magrittr_2.0.1 bookdown_0.21 R6_2.5.0 ## [76] generics_0.1.0 base64url_1.4 DelayedArray_0.16.0 ## [79] DBI_1.1.0 pillar_1.4.7 withr_2.3.0 ## [82] survival_3.2-7 RCurl_1.98-1.2 tibble_3.0.4 ## [85] crayon_1.3.4 BiocFileCache_1.14.0 rmarkdown_2.5 ## [88] jpeg_0.1-8.1 progress_1.2.2 locfit_1.5-9.4 ## [91] data.table_1.13.2 blob_1.2.1 Rgraphviz_2.34.0 ## [94] digest_0.6.27 xtable_1.8-4 brew_1.0-6 ## [97] openssl_1.4.3 munsell_0.5.0 viridisLite_0.3.0 ## [100] askpass_1.1  References Huber, Wolfgang, Vincent J Carey, Robert Gentleman, Simon Anders, Marc Carlson, Benilton S Carvalho, Hector Corrada Bravo, et al. 2015. “Orchestrating High-Throughput Genomic Analysis with Bioconductor.” Nat. Methods 12 (2): 115–21. https://doi.org/10.1038/nmeth.3252.\n Lawrence, Michael, Wolfgang Huber, Hervé Pagès, Patrick Aboyoun, Marc Carlson, Robert Gentleman, Martin T Morgan, and Vincent J Carey. 2013. “Software for Computing and Annotating Genomic Ranges.” PLoS Comput. Biol. 9 (8): e1003118. https://doi.org/10.1371/journal.pcbi.1003118.\n  ","categories":"","description":"","excerpt":"document.addEventListener(\"DOMContentLoaded\", function() { …","ref":"/manuals/rsequences/rsequences/","tags":"","title":"NGS Analysis Basics"},{"body":" pre code { white-space: pre !important; overflow-x: scroll !important; word-break: keep-all !important; word-wrap: initial !important; }  document.addEventListener(\"DOMContentLoaded\", function() { document.querySelector(\"h1\").className = \"title\"; });  document.addEventListener(\"DOMContentLoaded\", function() { var links = document.links; for (var i = 0, linksLength = links.length; i Introduction systemPipeR is provides flexible utilities for building and running automated end-to-end analysis workflows for a wide range of research applications, including next-generation sequencing (NGS) experiments, such as RNA-Seq, ChIP-Seq, VAR-Seq and Ribo-Seq (H Backman and Girke 2016). Important features include a uniform workflow interface across different data analysis applications, automated report generation, and support for running both R and command-line software, such as NGS aligners or peak/variant callers, on local computers or compute clusters (Figure 1). The latter supports interactive job submissions and batch submissions to queuing systems of clusters. For instance, systemPipeR can be used with any command-line aligners such as BWA (Heng Li 2013; H. Li and Durbin 2009), HISAT2 (Kim, Langmead, and Salzberg 2015), TopHat2 (Kim et al. 2013) and Bowtie2 (Langmead and Salzberg 2012), as well as the R-based NGS aligners Rsubread (Liao, Smyth, and Shi 2013) and gsnap (gmapR) (Wu and Nacu 2010). Efficient handling of complex sample sets (e.g. FASTQ/BAM files) and experimental designs are facilitated by a well-defined sample annotation infrastructure which improves reproducibility and user-friendliness of many typical analysis workflows in the NGS area (Lawrence et al. 2013).\nThe main motivation and advantages of using systemPipeR for complex data analysis tasks are:\n Facilitates the design of complex NGS workflows involving multiple R/Bioconductor packages Common workflow interface for different NGS applications Makes NGS analysis with Bioconductor utilities more accessible to new users Simplifies usage of command-line software from within R Reduces the complexity of using compute clusters for R and command-line software Accelerates runtime of workflows via parallelization on computer systems with multiple CPU cores and/or multiple compute nodes Improves reproducibility by automating analyses and generation of analysis reports    Figure 1: Relevant features in systemPipeR. Workflow design concepts are illustrated under (A \u0026 B). Examples of systemPipeR’s visualization functionalities are given under (C). \nA central concept for designing workflows within the systemPipeR environment is the use of workflow management containers. In previous versions, systemPipeR used a custom command-line interface called SYSargs (see Figure 3) and for this purpose will continue to be supported for some time. With the latest Bioconductor Release 3.9, we are adopting for this functionality the widely used community standard Common Workflow Language (CWL) for describing analysis workflows in a generic and reproducible manner, introducing SYSargs2 workflow control class (see Figure 2). Using this community standard in systemPipeR has many advantages. For instance, the integration of CWL allows running systemPipeR workflows from a single specification instance either entirely from within R, from various command-line wrappers (e.g., cwl-runner) or from other languages (, e.g., Bash or Python). systemPipeR includes support for both command-line and R/Bioconductor software as well as resources for containerization, parallel evaluations on computer clusters along with the automated generation of interactive analysis reports.\nAn important feature of systemPipeR's CWL interface is that it provides two options to run command-line tools and workflows based on CWL. First, one can run CWL in its native way via an R-based wrapper utility for cwl-runner or cwl-tools (CWL-based approach). Second, one can run workflows using CWL’s command-line and workflow instructions from within R (R-based approach). In the latter case the same CWL workflow definition files (e.g. *.cwl and *.yml) are used but rendered and executed entirely with R functions defined by systemPipeR, and thus use CWL mainly as a command-line and workflow definition format rather than software to run workflows. In this regard systemPipeR also provides several convenience functions that are useful for designing and debugging workflows, such as a command-line rendering function to retrieve the exact command-line strings for each data set and processing step prior to running a command-line.\nThis overview introduces the design of a new CWL S4 class in systemPipeR, as well as the custom command-line interface, combined with the overview of all the common analysis steps of NGS experiments.\nWorkflow design structure using SYSargs2 The flexibility of systemPipeR's new interface workflow control class is the driving factor behind the use of as many steps necessary for the analysis, as well as the connection between command-line- or R-based software. The connectivity among all workflow steps is achieved by the SYSargs2 workflow control class (see Figure 3). This S4 class is a list-like container where each instance stores all the input/output paths and parameter components required for a particular data analysis step. SYSargs2 instances are generated by two constructor functions, loadWorkflow and renderWF, using as data input targets or yaml files as well as two cwl parameter files (for details see below). When running preconfigured workflows, the only input the user needs to provide is the initial targets file containing the paths to the input files (e.g. FASTQ) along with unique sample labels. Subsequent targets instances are created automatically. The parameters required for running command-line software is provided by the parameter (.cwl) files described below.\nWe also introduce the SYSargsList class that organizes one or many SYSargs2 containers in a single compound object capturing all information required to run, control and monitor complex workflows from start to finish. This design enhances the systemPipeR workflow framework with a generalized, flexible, and robust design.\n  Figure 2: Workflow steps with input/output file operations are controlled by SYSargs2 objects. Each SYSargs2 instance is constructed from one targets and two param files. The only input provided by the user is the initial targets file. Subsequent targets instances are created automatically, from the previous output files. Any number of predefined or custom workflow steps are supported. One or many SYSargs2 objects are organized in an SYSargsList container.\nWorkflow Management using SYSargsList systemPipeR allows creation (multi-step analyses) and workflow execution entirely for R, with control, flexibility, and scalability of all processes. The workflow execution can be sent to an HPC, can be parallelized, accelerating results acquisition. systemPipeR workflow management system provides an infrastructure for organizing all steps, execution, and monitoring all tasks.\n  Figure 3: Workflow Management using SYSargsList.\nWorkflow design structure using SYSargs: Previous version Instances of this S4 object class are constructed by the systemArgs function from two simple tabular files: a targets file and a param file. The latter is optional for workflow steps lacking command-line software. Typically, a SYSargs instance stores all sample-level inputs as well as the paths to the corresponding outputs generated by command-line- or R-based software generating sample-level output files, such as read preprocessors (trimmed/filtered FASTQ files), aligners (SAM/BAM files), variant callers (VCF/BCF files) or peak callers (BED/WIG files). Each sample level input/output operation uses its own SYSargs instance. The outpaths of SYSargs usually define the sample inputs for the next SYSargs instance. This connectivity is established by writing the outpaths with the writeTargetsout function to a new targets file that serves as input to the next systemArgs call. Typically, the user has to provide only the initial targets file. All downstream targets files are generated automatically. By chaining several SYSargs steps together one can construct complex workflows involving many sample-level input/output file operations with any combination of command-line or R-based software.\n  Figure 4: Workflow design structure of systemPipeR using SYSargs.\nGetting Started Installation The R software for running systemPipeR can be downloaded from CRAN. The systemPipeR* environment can be installed from the R console using the BiocManager::install* command. The associated data package systemPipeRdata can be installed the same way. The latter is a helper package for generating systemPipeR workflow environments with a single command containing all parameter files and sample data required to quickly test and run workflows.\nif (!requireNamespace(\"BiocManager\", quietly = TRUE)) install.packages(\"BiocManager\") BiocManager::install(\"systemPipeR\") BiocManager::install(\"systemPipeRdata\")  Please note that if you desire to use a third-party command line tool, the particular tool and dependencies need to be installed and exported in your PATH. See details.\nLoading package and documentation library(\"systemPipeR\") # Loads the package library(help = \"systemPipeR\") # Lists package info vignette(\"systemPipeR\") # Opens vignette  Load sample data and workflow templates The mini sample FASTQ files used by this overview vignette as well as the associated workflow reporting vignettes can be loaded via the systemPipeRdata package as shown below. The chosen data set SRP010938 obtains 18 paired-end (PE) read sets from Arabidposis thaliana (Howard et al. 2013). To minimize processing time during testing, each FASTQ file has been subsetted to 90,000-100,000 randomly sampled PE reads that map to the first 100,000 nucleotides of each chromosome of the A. thalina genome. The corresponding reference genome sequence (FASTA) and its GFF annotation files (provided in the same download) have been truncated accordingly. This way the entire test sample data set requires less than 200MB disk storage space. A PE read set has been chosen for this test data set for flexibility, because it can be used for testing both types of analysis routines requiring either SE (single-end) reads or PE reads.\nThe following generates a fully populated systemPipeR workflow environment (here for RNA-Seq) in the current working directory of an R session. At this time the package includes workflow templates for RNA-Seq, ChIP-Seq, VAR-Seq, and Ribo-Seq. Templates for additional NGS applications will be provided in the future.\nIf you desire run this tutorial with your data set, please follow the instruction here:\nlibrary(systemPipeRdata) genWorkenvir(workflow = \"rnaseq\") setwd(\"rnaseq\")  Workflow template from an individual’s package The package provides pre-configured workflows and reporting templates for a wide range of NGS applications that are listed here. Additional workflow templates will be provided in the future. If you desire to use an individual package and version, follow the instruction below:\nlibrary(systemPipeRdata) genWorkenvir(workflow = NULL, package_repo = \"systemPipeR/SPriboseq\", ref = \"master\", subdir = NULL)  library(systemPipeRdata) genWorkenvir(workflow = NULL, package_repo = \"systemPipeR/SPrnaseq\", ref = \"singleMachine\", subdir = NULL)  Directory Structure The working environment of the sample data loaded in the previous step contains the following pre-configured directory structure (Figure 4). Directory names are indicated in green. Users can change this structure as needed, but need to adjust the code in their workflows accordingly.\n workflow/ (e.g. rnaseq/)  This is the root directory of the R session running the workflow. Run script ( *.Rmd) and sample annotation (targets.txt) files are located here. Note, this directory can have any name (e.g. rnaseq, varseq). Changing its name does not require any modifications in the run script(s). Important subdirectories:  param/  Stores non-CWL parameter files such as: *.param, *.tmpl and *.run.sh. These files are only required for backwards compatibility to run old workflows using the previous custom command-line interface. param/cwl/: This subdirectory stores all the CWL parameter files. To organize workflows, each can have its own subdirectory, where all CWL param and input.yml files need to be in the same subdirectory.   data/   FASTQ files FASTA file of reference (e.g. reference genome) Annotation files etc.   results/  Analysis results are usually written to this directory, including: alignment, variant and peak files (BAM, VCF, BED); tabular result files; and image/plot files Note, the user has the option to organize results files for a given sample and analysis step in a separate subdirectory.          Figure 5: systemPipeR’s preconfigured directory structure.\nThe following parameter files are included in each workflow template:\n targets.txt: initial one provided by user; downstream targets_*.txt files are generated automatically *.param/cwl: defines parameter for input/output file operations, e.g.:  hisat2-se/hisat2-mapping-se.cwl hisat2-se/hisat2-mapping-se.yml   *_run.sh: optional bash scripts Configuration files for computer cluster environments (skip on single machines):  .batchtools.conf.R: defines the type of scheduler for batchtools pointing to template file of cluster, and located in user’s home directory *.tmpl: specifies parameters of scheduler used by a system, e.g. Torque, SGE, Slurm, etc.    Structure of targets file The targets file defines all input files (e.g. FASTQ, BAM, BCF) and sample comparisons of an analysis workflow. The following shows the format of a sample targets file included in the package. It also can be viewed and downloaded from systemPipeR’s GitHub repository here. In a target file with a single type of input files, here FASTQ files of single-end (SE) reads, the first three columns are mandatory including their column names, while it is four mandatory columns for FASTQ files of PE reads. All subsequent columns are optional and any number of additional columns can be added as needed.\nUsers should note here, the usage of targets files is optional when using systemPipeR’s new CWL interface. They can be replaced by a standard YAML input file used by CWL. Since for organizing experimental variables targets files are extremely useful and user-friendly. Thus, we encourage users to keep using them.\nStructure of targets file for single-end (SE) samples library(systemPipeR) targetspath \u003c- system.file(\"extdata\", \"targets.txt\", package = \"systemPipeR\") read.delim(targetspath, comment.char = \"#\")[1:4, ]  ## FileName SampleName Factor SampleLong Experiment ## 1 ./data/SRR446027_1.fastq.gz M1A M1 Mock.1h.A 1 ## 2 ./data/SRR446028_1.fastq.gz M1B M1 Mock.1h.B 1 ## 3 ./data/SRR446029_1.fastq.gz A1A A1 Avr.1h.A 1 ## 4 ./data/SRR446030_1.fastq.gz A1B A1 Avr.1h.B 1 ## Date ## 1 23-Mar-2012 ## 2 23-Mar-2012 ## 3 23-Mar-2012 ## 4 23-Mar-2012  To work with custom data, users need to generate a targets file containing the paths to their own FASTQ files and then provide under targetspath the path to the corresponding targets file.\nStructure of targets file for paired-end (PE) samples For paired-end (PE) samples, the structure of the targets file is similar, where users need to provide two FASTQ path columns: FileName1 and FileName2 with the paths to the PE FASTQ files.\ntargetspath \u003c- system.file(\"extdata\", \"targetsPE.txt\", package = \"systemPipeR\") read.delim(targetspath, comment.char = \"#\")[1:2, 1:6]  ## FileName1 FileName2 SampleName Factor ## 1 ./data/SRR446027_1.fastq.gz ./data/SRR446027_2.fastq.gz M1A M1 ## 2 ./data/SRR446028_1.fastq.gz ./data/SRR446028_2.fastq.gz M1B M1 ## SampleLong Experiment ## 1 Mock.1h.A 1 ## 2 Mock.1h.B 1  Sample comparisons Sample comparisons are defined in the header lines of the targets file starting with ‘# \u003cCMP\u003e.’\nreadLines(targetspath)[1:4]  ## [1] \"# Project ID: Arabidopsis - Pseudomonas alternative splicing study (SRA: SRP010938; PMID: 24098335)\" ## [2] \"# The following line(s) allow to specify the contrasts needed for comparative analyses, such as DEG identification. All possible comparisons can be specified with 'CMPset: ALL'.\" ## [3] \"# \u003cCMP\u003e CMPset1: M1-A1, M1-V1, A1-V1, M6-A6, M6-V6, A6-V6, M12-A12, M12-V12, A12-V12\" ## [4] \"# \u003cCMP\u003e CMPset2: ALL\"  The function readComp imports the comparison information and stores it in a list. Alternatively, readComp can obtain the comparison information from the corresponding SYSargs object (see below). Note, these header lines are optional. They are mainly useful for controlling comparative analyses according to certain biological expectations, such as identifying differentially expressed genes in RNA-Seq experiments based on simple pair-wise comparisons.\nreadComp(file = targetspath, format = \"vector\", delim = \"-\")  ## $CMPset1 ## [1] \"M1-A1\" \"M1-V1\" \"A1-V1\" \"M6-A6\" \"M6-V6\" \"A6-V6\" \"M12-A12\" ## [8] \"M12-V12\" \"A12-V12\" ## ## $CMPset2 ## [1] \"M1-A1\" \"M1-V1\" \"M1-M6\" \"M1-A6\" \"M1-V6\" \"M1-M12\" \"M1-A12\" ## [8] \"M1-V12\" \"A1-V1\" \"A1-M6\" \"A1-A6\" \"A1-V6\" \"A1-M12\" \"A1-A12\" ## [15] \"A1-V12\" \"V1-M6\" \"V1-A6\" \"V1-V6\" \"V1-M12\" \"V1-A12\" \"V1-V12\" ## [22] \"M6-A6\" \"M6-V6\" \"M6-M12\" \"M6-A12\" \"M6-V12\" \"A6-V6\" \"A6-M12\" ## [29] \"A6-A12\" \"A6-V12\" \"V6-M12\" \"V6-A12\" \"V6-V12\" \"M12-A12\" \"M12-V12\" ## [36] \"A12-V12\"  Structure of the new param files and construct SYSargs2 container SYSargs2 stores all the information and instructions needed for processing a set of input files with a single or many command-line steps within a workflow (i.e. several components of the software or several independent software tools). The SYSargs2 object is created and fully populated with the loadWF and renderWF functions, respectively.\nIn CWL, files with the extension .cwl define the parameters of a chosen command-line step or workflow, while files with the extension .yml define the input variables of command-line steps. Note, input variables provided by a targets file can be passed on to a SYSargs2 instance via the inputvars argument of the renderWF function.\nThe following imports a .cwl file (here hisat2-mapping-se.cwl) for running the short read aligner HISAT2 (Kim, Langmead, and Salzberg 2015). The loadWF and renderWF functions render the proper command-line strings for each sample and software tool.\nlibrary(systemPipeR) targets \u003c- system.file(\"extdata\", \"targets.txt\", package = \"systemPipeR\") dir_path \u003c- system.file(\"extdata/cwl/hisat2/hisat2-se\", package = \"systemPipeR\") WF \u003c- loadWF(targets = targets, wf_file = \"hisat2-mapping-se.cwl\", input_file = \"hisat2-mapping-se.yml\", dir_path = dir_path) WF \u003c- renderWF(WF, inputvars = c(FileName = \"_FASTQ_PATH1_\", SampleName = \"_SampleName_\"))  Several accessor methods are available that are named after the slot names of the SYSargs2 object.\nnames(WF)  ## [1] \"targets\" \"targetsheader\" \"modules\" \"wf\" ## [5] \"clt\" \"yamlinput\" \"cmdlist\" \"input\" ## [9] \"output\" \"cwlfiles\" \"inputvars\"  Of particular interest is the cmdlist() method. It constructs the system commands for running command-line software as specified by a given .cwl file combined with the paths to the input samples (e.g. FASTQ files) provided by a targets file. The example below shows the cmdlist() output for running HISAT2 on the first SE read sample. Evaluating the output of cmdlist() can be very helpful for designing and debugging .cwl files of new command-line software or changing the parameter settings of existing ones.\ncmdlist(WF)[1]  ## $M1A ## $M1A$`hisat2-mapping-se` ## [1] \"hisat2 -S ./results/M1A.sam -x ./data/tair10.fasta -k 1 --min-intronlen 30 --max-intronlen 3000 -U ./data/SRR446027_1.fastq.gz --threads 4\"  The output components of SYSargs2 define the expected output files for each step in the workflow; some of which are the input for the next workflow step, here next SYSargs2 instance (see Figure 2).\noutput(WF)[1]  ## $M1A ## $M1A$`hisat2-mapping-se` ## [1] \"./results/M1A.sam\"  modules(WF)  ## module1 ## \"hisat2/2.1.0\"  targets(WF)[1]  ## $M1A ## $M1A$FileName ## [1] \"./data/SRR446027_1.fastq.gz\" ## ## $M1A$SampleName ## [1] \"M1A\" ## ## $M1A$Factor ## [1] \"M1\" ## ## $M1A$SampleLong ## [1] \"Mock.1h.A\" ## ## $M1A$Experiment ## [1] 1 ## ## $M1A$Date ## [1] \"23-Mar-2012\"  targets.as.df(targets(WF))[1:4, 1:4]  ## FileName SampleName Factor SampleLong ## 1 ./data/SRR446027_1.fastq.gz M1A M1 Mock.1h.A ## 2 ./data/SRR446028_1.fastq.gz M1B M1 Mock.1h.B ## 3 ./data/SRR446029_1.fastq.gz A1A A1 Avr.1h.A ## 4 ./data/SRR446030_1.fastq.gz A1B A1 Avr.1h.B  output(WF)[1]  ## $M1A ## $M1A$`hisat2-mapping-se` ## [1] \"./results/M1A.sam\"  cwlfiles(WF)  ## $cwl ## [1] \"/home/tgirke/R/x86_64-pc-linux-gnu-library/4.0/systemPipeR/extdata/cwl/hisat2/hisat2-se/hisat2-mapping-se.cwl\" ## ## $yml ## [1] \"/home/tgirke/R/x86_64-pc-linux-gnu-library/4.0/systemPipeR/extdata/cwl/hisat2/hisat2-se/hisat2-mapping-se.yml\" ## ## $steps ## [1] \"hisat2-mapping-se\"  inputvars(WF)  ## $FileName ## [1] \"_FASTQ_PATH1_\" ## ## $SampleName ## [1] \"_SampleName_\"  In an ‘R-centric’ rather than a ‘CWL-centric’ workflow design the connectivity among workflow steps is established by writing all relevant output with the writeTargetsout function to a new targets file that serves as input to the next loadWorkflow and renderWF call. By chaining several SYSargs2 steps together one can construct complex workflows involving many sample-level input/output file operations with any combination of command-line or R-based software. Alternatively, a CWL-centric workflow design can be used that defines all/most workflow steps with CWL workflow and parameter files. Due to time and space restrictions, the CWL-centric approach is not covered by this tutorial.\nThird-party software tools Current, systemPipeR provides the param file templates for third-party software tools. Please check the listed software tools.\n  Tool Name  Description  Step      bwa  BWA is a software package for mapping low-divergent sequences against a large reference genome, such as the human genome.  Alignment    Bowtie2  Bowtie 2 is an ultrafast and memory-efficient tool for aligning sequencing reads to long reference sequences.  Alignment    FASTX-Toolkit  FASTX-Toolkit is a collection of command line tools for Short-Reads FASTA/FASTQ files preprocessing.  Read Preprocessing    TransRate  Transrate is software for de-novo transcriptome assembly quality analysis.  Quality    Gsnap  GSNAP is a genomic short-read nucleotide alignment program.  Alignment    Samtools  Samtools is a suite of programs for interacting with high-throughput sequencing data.  Post-processing    Trimmomatic  Trimmomatic is a flexible read trimming tool for Illumina NGS data.  Read Preprocessing    Rsubread  Rsubread is a Bioconductor software package that provides high-performance alignment and read counting functions for RNA-seq reads.  Alignment    Picard  Picard is a set of command line tools for manipulating high-throughput sequencing (HTS) data and formats such as SAM/BAM/CRAM and VCF.  Manipulating HTS data    Busco  BUSCO assesses genome assembly and annotation completeness with Benchmarking Universal Single-Copy Orthologs.  Quality    Hisat2  HISAT2 is a fast and sensitive alignment program for mapping NGS reads (both DNA and RNA) to reference genomes.  Alignment    Tophat2  TopHat is a fast splice junction mapper for RNA-Seq reads.  Alignment    GATK  Variant Discovery in High-Throughput Sequencing Data.  Variant Discovery    STAR  STAR is an ultrafast universal RNA-seq aligner.  Alignment    Trim\\_galore  Trim Galore is a wrapper around Cutadapt and FastQC to consistently apply adapter and quality trimming to FastQ files.  Read Preprocessing    TransDecoder  TransDecoder identifies candidate coding regions within transcript sequences.  Find Coding Regions    Trinity  Trinity assembles transcript sequences from Illumina RNA-Seq data.  denovo Transcriptome Assembly    Trinotate  Trinotate is a comprehensive annotation suite designed for automatic functional annotation of transcriptomes.  Transcriptome Functional Annotation    MACS2  MACS2 identifies transcription factor binding sites in ChIP-seq data.  Peak calling    Kallisto  kallisto is a program for quantifying abundances of transcripts from RNA-Seq data.  Read counting    BCFtools  BCFtools is a program for variant calling and manipulating files in the Variant Call Format (VCF) and its binary counterpart BCF.  Variant Discovery    Bismark  Bismark is a program to map bisulfite treated sequencing reads to a genome of interest and perform methylation calls in a single step.  Bisulfite mapping    Fastqc  FastQC is a quality control tool for high throughput sequence data.  Quality    Blast  BLAST finds regions of similarity between biological sequences.  Blast      Remember, if you desire to run any of these tools, make sure to have the respective software installed on your system and configure in the PATH. You can check as follows:\ntryCL(command = \"grep\")  Structure of param file and SYSargs container (Previous version) The param file defines the parameters of a chosen command-line software. The following shows the format of a sample param file provided by this package.\nparampath \u003c- system.file(\"extdata\", \"tophat.param\", package = \"systemPipeR\") read.delim(parampath, comment.char = \"#\")  ## PairSet Name Value ## 1 modules \u003cNA\u003e bowtie2/2.2.5 ## 2 modules \u003cNA\u003e tophat/2.0.14 ## 3 software \u003cNA\u003e tophat ## 4 cores -p 4 ## 5 other \u003cNA\u003e -g 1 --segment-length 25 -i 30 -I 3000 ## 6 outfile1 -o \u003cFileName1\u003e ## 7 outfile1 path ./results/ ## 8 outfile1 remove \u003cNA\u003e ## 9 outfile1 append .tophat ## 10 outfile1 outextension .tophat/accepted_hits.bam ## 11 reference \u003cNA\u003e ./data/tair10.fasta ## 12 infile1 \u003cNA\u003e \u003cFileName1\u003e ## 13 infile1 path \u003cNA\u003e ## 14 infile2 \u003cNA\u003e \u003cFileName2\u003e ## 15 infile2 path \u003cNA\u003e  The systemArgs function imports the definitions of both the param file and the targets file, and stores all relevant information in a SYSargs object (S4 class). To run the pipeline without command-line software, one can assign NULL to sysma instead of a param file. In addition, one can start systemPipeR workflows with pre-generated BAM files by providing a targets file where the FileName column provides the paths to the BAM files. Note, in the following example the usage of suppressWarnings() is only relevant for building this vignette. In typical workflows it should be removed.\ntargetspath \u003c- system.file(\"extdata\", \"targets.txt\", package = \"systemPipeR\") args \u003c- suppressWarnings(systemArgs(sysma = parampath, mytargets = targetspath)) args  ## An instance of 'SYSargs' for running 'tophat' on 18 samples  Several accessor methods are available that are named after the slot names of the SYSargs object.\nnames(args)  ## [1] \"targetsin\" \"targetsout\" \"targetsheader\" \"modules\" ## [5] \"software\" \"cores\" \"other\" \"reference\" ## [9] \"results\" \"infile1\" \"infile2\" \"outfile1\" ## [13] \"sysargs\" \"outpaths\"  Of particular interest is the sysargs() method. It constructs the system commands for running command-lined software as specified by a given param file combined with the paths to the input samples (e.g. FASTQ files) provided by a targets file. The example below shows the sysargs() output for running TopHat2 on the first PE read sample. Evaluating the output of sysargs() can be very helpful for designing and debugging param files of new command-line software or changing the parameter settings of existing ones.\nsysargs(args)[1]  ## M1A ## \"tophat -p 4 -g 1 --segment-length 25 -i 30 -I 3000 -o /home/tgirke/tmp/GEN242/content/en/manuals/systempiper/results/SRR446027_1.fastq.gz.tophat /home/tgirke/tmp/GEN242/content/en/manuals/systempiper/data/tair10.fasta ./data/SRR446027_1.fastq.gz \"  modules(args)  ## [1] \"bowtie2/2.2.5\" \"tophat/2.0.14\"  cores(args)  ## [1] 4  outpaths(args)[1]  ## M1A ## \"/home/tgirke/tmp/GEN242/content/en/manuals/systempiper/results/SRR446027_1.fastq.gz.tophat/accepted_hits.bam\"  The content of the param file can also be returned as JSON object as follows (requires rjson package).\nsystemArgs(sysma = parampath, mytargets = targetspath, type = \"json\")  ## [1] \"{\\\"modules\\\":{\\\"n1\\\":\\\"\\\",\\\"v2\\\":\\\"bowtie2/2.2.5\\\",\\\"n1\\\":\\\"\\\",\\\"v2\\\":\\\"tophat/2.0.14\\\"},\\\"software\\\":{\\\"n1\\\":\\\"\\\",\\\"v1\\\":\\\"tophat\\\"},\\\"cores\\\":{\\\"n1\\\":\\\"-p\\\",\\\"v1\\\":\\\"4\\\"},\\\"other\\\":{\\\"n1\\\":\\\"\\\",\\\"v1\\\":\\\"-g 1 --segment-length 25 -i 30 -I 3000\\\"},\\\"outfile1\\\":{\\\"n1\\\":\\\"-o\\\",\\\"v2\\\":\\\"\u003cFileName1\u003e\\\",\\\"n3\\\":\\\"path\\\",\\\"v4\\\":\\\"./results/\\\",\\\"n5\\\":\\\"remove\\\",\\\"v1\\\":\\\"\\\",\\\"n2\\\":\\\"append\\\",\\\"v3\\\":\\\".tophat\\\",\\\"n4\\\":\\\"outextension\\\",\\\"v5\\\":\\\".tophat/accepted_hits.bam\\\"},\\\"reference\\\":{\\\"n1\\\":\\\"\\\",\\\"v1\\\":\\\"./data/tair10.fasta\\\"},\\\"infile1\\\":{\\\"n1\\\":\\\"\\\",\\\"v2\\\":\\\"\u003cFileName1\u003e\\\",\\\"n1\\\":\\\"path\\\",\\\"v2\\\":\\\"\\\"},\\\"infile2\\\":{\\\"n1\\\":\\\"\\\",\\\"v2\\\":\\\"\u003cFileName2\u003e\\\",\\\"n1\\\":\\\"path\\\",\\\"v2\\\":\\\"\\\"}}\"  How to run a Workflow This tutorial introduces the basic ideas and tools needed to build a specific workflow from preconfigured templates.\nLoad sample data and workflow templates library(systemPipeRdata) genWorkenvir(workflow = \"rnaseq\") setwd(\"rnaseq\")  Setup and Requirements To go through this tutorial, you need the following software installed:\n R/\u003e=3.6.2 systemPipeR R package (version 1.22) Hisat2/2.1.0  If you desire to build your pipeline with any different software, make sure to have the respective software installed and configured in your PATH. To make sure if the configuration is right, you always can test as follow:\ntryCL(command = \"hisat2\") ## 'All set up, proceed!'  Project Initialization The Project management structure is essential, especially for reproducibility and efficiency in the analysis. Here we show how to construct an instance of this S4 object class by the initWF function. The object of class SYSarsgsList storing all the configuration information for the project and allows management and control at a high level.\ngetwd() ## rnaseq script \u003c- \"systemPipeRNAseq.Rmd\" targetspath \u003c- \"targets.txt\" sysargslist \u003c- initWF(script = script, targets = targetspath)  Project Initialization in a Temporary Directory library(systemPipeRdata) script \u003c- system.file(\"extdata/workflows/rnaseq\", \"systemPipeRNAseq.Rmd\", package = \"systemPipeRdata\") targets \u003c- system.file(\"extdata\", \"targets.txt\", package = \"systemPipeR\") dir_path \u003c- tempdir() SYSconfig \u003c- initProject(projPath = dir_path, targets = targets, script = script, overwrite = TRUE) sysargslist_temp \u003c- initWF(sysconfig = \"SYSconfig.yml\")  Configuration and run of the project sysargslist \u003c- configWF(x = sysargslist, input_steps = \"1:3\") sysargslist \u003c- runWF(sysargslist = sysargslist, steps = \"1:2\")  How to Use Pipes with systemPipeR At first encounter, you may wonder whether an operator such as %\u003e% can really be all that beneficial; but as you may notice, it semantically changes your code in a way that makes it more intuitive to both read and write.\nConsider the following example, in which the steps are the initialization, configuration and running the entire workflow.\nlibrary(systemPipeR) sysargslist \u003c- initWF(script = \"systemPipeRNAseq.Rmd\", overwrite = TRUE) %\u003e% configWF(input_steps = \"1:3\") %\u003e% runWF(steps = \"1:2\")  How to run the workflow on a cluster This section of the tutorial provides an introduction to the usage of the systemPipeR features on a cluster.\nNow open the R markdown script *.Rmdin your R IDE (_e.g._vim-r or RStudio) and run the workflow as outlined below. If you work under Vim-R-Tmux, the following command sequence will connect the user in an interactive session with a node on the cluster. The code of the Rmd script can then be sent from Vim on the login (head) node to an open R session running on the corresponding computer node. This is important since Tmux sessions should not be run on the computer nodes.\nq(\"no\") # closes R session on head node  srun --x11 --partition=short --mem=2gb --cpus-per-task 4 --ntasks 1 --time 2:00:00 --pty bash -l module load R/4.0.3 R  Now check whether your R session is running on a computer node of the cluster and not on a head node.\nsystem(\"hostname\") # should return name of a compute node starting with i or c getwd() # checks current working directory of R session dir() # returns content of current working directory  Parallelization on clusters Alternatively, the computation can be greatly accelerated by processing many files in parallel using several compute nodes of a cluster, where a scheduling/queuing system is used for load balancing. For this the clusterRun function submits the computing requests to the scheduler using the run specifications defined by runCommandline.\nTo avoid over-subscription of CPU cores on the compute nodes, the value from yamlinput(args)['thread'] is passed on to the submission command, here ncpus in the resources list object. The number of independent parallel cluster processes is defined under the Njobs argument. The following example will run 18 processes in parallel using for each 4 CPU cores. If the resources available on a cluster allow running all 18 processes at the same time then the shown sample submission will utilize in total 72 CPU cores. Note, clusterRun can be used with most queueing systems as it is based on utilities from the batchtools package which supports the use of template files (*.tmpl) for defining the run parameters of different schedulers. To run the following code, one needs to have both a conf file (see .batchtools.conf.R samples here) and a template file (see *.tmpl samples here) for the queueing available on a system. The following example uses the sample conf and template files for the Slurm scheduler provided by this package.\nlibrary(batchtools) resources \u003c- list(walltime = 120, ntasks = 1, ncpus = 4, memory = 1024) reg \u003c- clusterRun(args, FUN = runCommandline, more.args = list(args = args, make_bam = TRUE, dir = FALSE), conffile = \".batchtools.conf.R\", template = \"batchtools.slurm.tmpl\", Njobs = 18, runid = \"01\", resourceList = resources) getStatus(reg = reg) waitForJobs(reg = reg)  Workflow steps overview Define environment settings and samples A typical workflow starts with generating the expected working environment containing the proper directory structure, input files, and parameter settings. To simplify this task, one can load one of the existing NGS workflows templates provided by systemPipeRdata into the current working directory. The following does this for the rnaseq template. The name of the resulting workflow directory can be specified under the mydirname argument. The default NULL uses the name of the chosen workflow. An error is issued if a directory of the same name and path exists already. On Linux and OS X systems one can also create new workflow instances from the command-line of a terminal as shown here. To apply workflows to custom data, the user needs to modify the targets file and if necessary update the corresponding .cwl and .yml files. A collection of pre-generated .cwl and .yml files are provided in the param/cwl subdirectory of each workflow template. They are also viewable in the GitHub repository of systemPipeRdata (see here).\nlibrary(systemPipeR) library(systemPipeRdata) genWorkenvir(workflow = \"rnaseq\", mydirname = NULL) setwd(\"rnaseq\")  Read Preprocessing Preprocessing with preprocessReads function The function preprocessReads allows to apply predefined or custom read preprocessing functions to all FASTQ files referenced in a SYSargs2 container, such as quality filtering or adaptor trimming routines. The paths to the resulting output FASTQ files are stored in the output slot of the SYSargs2 object. Internally, preprocessReads uses the FastqStreamer function from the ShortRead package to stream through large FASTQ files in a memory-efficient manner. The following example performs adaptor trimming with the trimLRPatterns function from the Biostrings package. After the trimming step a new targets file is generated (here targets_trimPE.txt) containing the paths to the trimmed FASTQ files. The new targets file can be used for the next workflow step with an updated SYSargs2 instance, e.g. running the NGS alignments with the trimmed FASTQ files.\nConstruct SYSargs2 object from cwl and yml param and targets files.\ntargetsPE \u003c- system.file(\"extdata\", \"targetsPE.txt\", package = \"systemPipeR\") dir_path \u003c- system.file(\"extdata/cwl/preprocessReads/trim-pe\", package = \"systemPipeR\") trim \u003c- loadWorkflow(targets = targetsPE, wf_file = \"trim-pe.cwl\", input_file = \"trim-pe.yml\", dir_path = dir_path) trim \u003c- renderWF(trim, inputvars = c(FileName1 = \"_FASTQ_PATH1_\", FileName2 = \"_FASTQ_PATH2_\", SampleName = \"_SampleName_\")) trim output(trim)[1:2]  preprocessReads(args = trim, Fct = \"trimLRPatterns(Rpattern='GCCCGGGTAA', subject=fq)\", batchsize = 1e+05, overwrite = TRUE, compress = TRUE)  The following example shows how one can design a custom read preprocessing function using utilities provided by the ShortRead package, and then run it in batch mode with the ‘preprocessReads’ function (here on paired-end reads).\nfilterFct \u003c- function(fq, cutoff = 20, Nexceptions = 0) { qcount \u003c- rowSums(as(quality(fq), \"matrix\") \u003c= cutoff, na.rm = TRUE) # Retains reads where Phred scores are \u003e= cutoff with N exceptions fq[qcount \u003c= Nexceptions] } preprocessReads(args = trim, Fct = \"filterFct(fq, cutoff=20, Nexceptions=0)\", batchsize = 1e+05)  Preprocessing with TrimGalore! TrimGalore! is a wrapper tool to consistently apply quality and adapter trimming to fastq files, with some extra functionality for removing Reduced Representation Bisulfite-Seq (RRBS) libraries.\ntargets \u003c- system.file(\"extdata\", \"targets.txt\", package = \"systemPipeR\") dir_path \u003c- system.file(\"extdata/cwl/trim_galore/trim_galore-se\", package = \"systemPipeR\") trimG \u003c- loadWorkflow(targets = targets, wf_file = \"trim_galore-se.cwl\", input_file = \"trim_galore-se.yml\", dir_path = dir_path) trimG \u003c- renderWF(trimG, inputvars = c(FileName = \"_FASTQ_PATH1_\", SampleName = \"_SampleName_\")) trimG cmdlist(trimG)[1:2] output(trimG)[1:2] ### Run Single Machine Option trimG \u003c- runCommandline(trimG[1], make_bam = FALSE)  Preprocessing with Trimmomatic targetsPE \u003c- system.file(\"extdata\", \"targetsPE.txt\", package = \"systemPipeR\") dir_path \u003c- system.file(\"extdata/cwl/trimmomatic/trimmomatic-pe\", package = \"systemPipeR\") trimM \u003c- loadWorkflow(targets = targetsPE, wf_file = \"trimmomatic-pe.cwl\", input_file = \"trimmomatic-pe.yml\", dir_path = dir_path) trimM \u003c- renderWF(trimM, inputvars = c(FileName1 = \"_FASTQ_PATH1_\", FileName2 = \"_FASTQ_PATH2_\", SampleName = \"_SampleName_\")) trimM cmdlist(trimM)[1:2] output(trimM)[1:2] ### Run Single Machine Option trimM \u003c- runCommandline(trimM[1], make_bam = FALSE)  FASTQ quality report The following seeFastq and seeFastqPlot functions generate and plot a series of useful quality statistics for a set of FASTQ files including per cycle quality box plots, base proportions, base-level quality trends, relative k-mer diversity, length and occurrence distribution of reads, number of reads above quality cutoffs and mean quality distribution.\nThe function seeFastq computes the quality statistics and stores the results in a relatively small list object that can be saved to disk with save() and reloaded with load() for later plotting. The argument klength specifies the k-mer length and batchsize the number of reads to a random sample from each FASTQ file.\nfqlist \u003c- seeFastq(fastq = infile1(trim), batchsize = 10000, klength = 8) pdf(\"./results/fastqReport.pdf\", height = 18, width = 4 * length(fqlist)) seeFastqPlot(fqlist) dev.off()    Figure 5: FASTQ quality report\n  Parallelization of FASTQ quality report on a single machine with multiple cores.\nf \u003c- function(x) seeFastq(fastq = infile1(trim)[x], batchsize = 1e+05, klength = 8) fqlist \u003c- bplapply(seq(along = trim), f, BPPARAM = MulticoreParam(workers = 4)) seeFastqPlot(unlist(fqlist, recursive = FALSE))  Parallelization of FASTQ quality report via scheduler (e.g. Slurm) across several compute nodes.\nlibrary(BiocParallel) library(batchtools) f \u003c- function(x) { library(systemPipeR) targetsPE \u003c- system.file(\"extdata\", \"targetsPE.txt\", package = \"systemPipeR\") dir_path \u003c- system.file(\"extdata/cwl/preprocessReads/trim-pe\", package = \"systemPipeR\") trim \u003c- loadWorkflow(targets = targetsPE, wf_file = \"trim-pe.cwl\", input_file = \"trim-pe.yml\", dir_path = dir_path) trim \u003c- renderWF(trim, inputvars = c(FileName1 = \"_FASTQ_PATH1_\", FileName2 = \"_FASTQ_PATH2_\", SampleName = \"_SampleName_\")) seeFastq(fastq = infile1(trim)[x], batchsize = 1e+05, klength = 8) } resources \u003c- list(walltime = 120, ntasks = 1, ncpus = 4, memory = 1024) param \u003c- BatchtoolsParam(workers = 4, cluster = \"slurm\", template = \"batchtools.slurm.tmpl\", resources = resources) fqlist \u003c- bplapply(seq(along = trim), f, BPPARAM = param) seeFastqPlot(unlist(fqlist, recursive = FALSE))  NGS Alignment software After quality control, the sequence reads can be aligned to a reference genome or transcriptome database. The following sessions present some NGS sequence alignment software. Select the most accurate aligner and determining the optimal parameter for your custom data set project.\nFor all the following examples, it is necessary to install the respective software and export the PATH accordingly. If it is available Environment Module in the system, you can load all the request software with moduleload(args) function.\nAlignment with HISAT2 using SYSargs2 The following steps will demonstrate how to use the short read aligner Hisat2 (Kim, Langmead, and Salzberg 2015) in both interactive job submissions and batch submissions to queuing systems of clusters using the systemPipeR's new CWL command-line interface.\nThe parameter settings of the aligner are defined in the hisat2-mapping-se.cwl and hisat2-mapping-se.yml files. The following shows how to construct the corresponding SYSargs2 object, here args.\ntargets \u003c- system.file(\"extdata\", \"targets.txt\", package = \"systemPipeR\") dir_path \u003c- system.file(\"extdata/cwl/hisat2/hisat2-se\", package = \"systemPipeR\") args \u003c- loadWorkflow(targets = targets, wf_file = \"hisat2-mapping-se.cwl\", input_file = \"hisat2-mapping-se.yml\", dir_path = dir_path) args \u003c- renderWF(args, inputvars = c(FileName = \"_FASTQ_PATH1_\", SampleName = \"_SampleName_\")) args  ## Instance of 'SYSargs2': ## Slot names/accessors: ## targets: 18 (M1A...V12B), targetsheader: 4 (lines) ## modules: 1 ## wf: 0, clt: 1, yamlinput: 7 (components) ## input: 18, output: 18 ## cmdlist: 18 ## WF Steps: ## 1. hisat2-mapping-se (rendered: TRUE)  cmdlist(args)[1:2]  ## $M1A ## $M1A$`hisat2-mapping-se` ## [1] \"hisat2 -S ./results/M1A.sam -x ./data/tair10.fasta -k 1 --min-intronlen 30 --max-intronlen 3000 -U ./data/SRR446027_1.fastq.gz --threads 4\" ## ## ## $M1B ## $M1B$`hisat2-mapping-se` ## [1] \"hisat2 -S ./results/M1B.sam -x ./data/tair10.fasta -k 1 --min-intronlen 30 --max-intronlen 3000 -U ./data/SRR446028_1.fastq.gz --threads 4\"  output(args)[1:2]  ## $M1A ## $M1A$`hisat2-mapping-se` ## [1] \"./results/M1A.sam\" ## ## ## $M1B ## $M1B$`hisat2-mapping-se` ## [1] \"./results/M1B.sam\"  Subsetting SYSargs2 class slots for each workflow step.\nsubsetWF(args, slot = \"input\", subset = \"FileName\")[1:2] ## Subsetting the input files for this particular workflow  ## M1A M1B ## \"./data/SRR446027_1.fastq.gz\" \"./data/SRR446028_1.fastq.gz\"  subsetWF(args, slot = \"output\", subset = 1, index = 1)[1:2] ## Subsetting the output files for one particular step in the workflow  ## M1A M1B ## \"./results/M1A.sam\" \"./results/M1B.sam\"  subsetWF(args, slot = \"step\", subset = 1)[1] ## Subsetting the command-lines for one particular step in the workflow  ## M1A ## \"hisat2 -S ./results/M1A.sam -x ./data/tair10.fasta -k 1 --min-intronlen 30 --max-intronlen 3000 -U ./data/SRR446027_1.fastq.gz --threads 4\"  subsetWF(args, slot = \"output\", subset = 1, index = 1, delete = TRUE)[1] ## DELETING specific output files  ## The subset cannot be deleted: no such file ## M1A ## \"./results/M1A.sam\"  Build Hisat2 index.\ndir_path \u003c- system.file(\"extdata/cwl/hisat2/hisat2-idx\", package = \"systemPipeR\") idx \u003c- loadWorkflow(targets = NULL, wf_file = \"hisat2-index.cwl\", input_file = \"hisat2-index.yml\", dir_path = dir_path) idx \u003c- renderWF(idx) idx cmdlist(idx) ### Run runCommandline(idx, make_bam = FALSE)  Interactive job submissions in a single machine To simplify the short read alignment execution for the user, the command-line can be run with the runCommandline function. The execution will be on a single machine without submitting to a queuing system of a computer cluster. This way, the input FASTQ files will be processed sequentially. By default runCommandline auto detects SAM file outputs and converts them to sorted and indexed BAM files, using internally the Rsamtools package (Morgan et al. 2019). Besides, runCommandline allows the user to create a dedicated results folder for each workflow and a sub-folder for each sample defined in the targets file. This includes all the output and log files for each step. When these options are used, the output location will be updated by default and can be assigned to the same object.\nrunCommandline(args, make_bam = FALSE) ## generates alignments and writes *.sam files to ./results folder args \u003c- runCommandline(args, make_bam = TRUE) ## same as above but writes files and converts *.sam files to sorted and indexed BAM files. Assigning the new extention of the output files to the object args.  If available, multiple CPU cores can be used for processing each file. The number of CPU cores (here 4) to use for each process is defined in the *.yml file. With yamlinput(args)['thread'] one can return this value from the SYSargs2 object.\nParallelization on clusters Alternatively, the computation can be greatly accelerated by processing many files in parallel using several compute nodes of a cluster, where a scheduling/queuing system is used for load balancing. For this the clusterRun function submits the computing requests to the scheduler using the run specifications defined by runCommandline.\nTo avoid over-subscription of CPU cores on the compute nodes, the value from yamlinput(args)['thread'] is passed on to the submission command, here ncpus in the resources list object. The number of independent parallel cluster processes is defined under the Njobs argument. The following example will run 18 processes in parallel using for each 4 CPU cores. If the resources available on a cluster allow running all 18 processes at the same time then the shown sample submission will utilize in total 72 CPU cores. Note, clusterRun can be used with most queueing systems as it is based on utilities from the batchtools package which supports the use of template files (*.tmpl) for defining the run parameters of different schedulers. To run the following code, one needs to have both a conf file (see .batchtools.conf.R samples here) and a template file (see *.tmpl samples here) for the queueing available on a system. The following example uses the sample conf and template files for the Slurm scheduler provided by this package.\nlibrary(batchtools) resources \u003c- list(walltime = 120, ntasks = 1, ncpus = 4, memory = 1024) reg \u003c- clusterRun(args, FUN = runCommandline, more.args = list(args = args, make_bam = TRUE, dir = FALSE), conffile = \".batchtools.conf.R\", template = \"batchtools.slurm.tmpl\", Njobs = 18, runid = \"01\", resourceList = resources) getStatus(reg = reg) waitForJobs(reg = reg)  Check and update the output location if necessary.\nargs \u003c- output_update(args, dir = FALSE, replace = TRUE, extension = c(\".sam\", \".bam\")) ## Updates the output(args) to the right location in the subfolders output(args)  Create new targets file To establish the connectivity to the next workflow step, one can write a new targets file with the writeTargetsout function. The new targets file serves as input to the next loadWorkflow and renderWF call.\nnames(clt(args)) writeTargetsout(x = args, file = \"default\", step = 1, new_col = \"FileName\", new_col_output_index = 1, overwrite = TRUE)  Alignment with HISAT2 and SAMtools Alternatively, it possible to build an workflow with HISAT2 and SAMtools.\ntargets \u003c- system.file(\"extdata\", \"targets.txt\", package = \"systemPipeR\") dir_path \u003c- system.file(\"extdata/cwl/workflow-hisat2/workflow-hisat2-se\", package = \"systemPipeR\") WF \u003c- loadWorkflow(targets = targets, wf_file = \"workflow_hisat2-se.cwl\", input_file = \"workflow_hisat2-se.yml\", dir_path = dir_path) WF \u003c- renderWF(WF, inputvars = c(FileName = \"_FASTQ_PATH1_\", SampleName = \"_SampleName_\")) WF cmdlist(WF)[1:2] output(WF)[1:2]  Alignment with Tophat2 The NGS reads of this project can also be aligned against the reference genome sequence using Bowtie2/TopHat2 (Kim et al. 2013; Langmead and Salzberg 2012).\nBuild Bowtie2 index.\ndir_path \u003c- system.file(\"extdata/cwl/bowtie2/bowtie2-idx\", package = \"systemPipeR\") idx \u003c- loadWorkflow(targets = NULL, wf_file = \"bowtie2-index.cwl\", input_file = \"bowtie2-index.yml\", dir_path = dir_path) idx \u003c- renderWF(idx) idx cmdlist(idx) ### Run in single machine runCommandline(idx, make_bam = FALSE)  The parameter settings of the aligner are defined in the tophat2-mapping-pe.cwl and tophat2-mapping-pe.yml files. The following shows how to construct the corresponding SYSargs2 object, here tophat2PE.\ntargetsPE \u003c- system.file(\"extdata\", \"targetsPE.txt\", package = \"systemPipeR\") dir_path \u003c- system.file(\"extdata/cwl/tophat2/tophat2-pe\", package = \"systemPipeR\") tophat2PE \u003c- loadWorkflow(targets = targetsPE, wf_file = \"tophat2-mapping-pe.cwl\", input_file = \"tophat2-mapping-pe.yml\", dir_path = dir_path) tophat2PE \u003c- renderWF(tophat2PE, inputvars = c(FileName1 = \"_FASTQ_PATH1_\", FileName2 = \"_FASTQ_PATH2_\", SampleName = \"_SampleName_\")) tophat2PE cmdlist(tophat2PE)[1:2] output(tophat2PE)[1:2] ### Run in single machine tophat2PE \u003c- runCommandline(tophat2PE[1], make_bam = TRUE)  Parallelization on clusters.\nresources \u003c- list(walltime = 120, ntasks = 1, ncpus = 4, memory = 1024) reg \u003c- clusterRun(tophat2PE, FUN = runCommandline, more.args = list(args = tophat2PE, make_bam = TRUE, dir = FALSE), conffile = \".batchtools.conf.R\", template = \"batchtools.slurm.tmpl\", Njobs = 18, runid = \"01\", resourceList = resources) waitForJobs(reg = reg)  Create new targets file\nnames(clt(tophat2PE)) writeTargetsout(x = tophat2PE, file = \"default\", step = 1, new_col = \"tophat2PE\", new_col_output_index = 1, overwrite = TRUE)  Alignment with Bowtie2 (e.g. for miRNA profiling) The following example runs Bowtie2 as a single process without submitting it to a cluster.\nBuilding the index:\ndir_path \u003c- system.file(\"extdata/cwl/bowtie2/bowtie2-idx\", package = \"systemPipeR\") idx \u003c- loadWorkflow(targets = NULL, wf_file = \"bowtie2-index.cwl\", input_file = \"bowtie2-index.yml\", dir_path = dir_path) idx \u003c- renderWF(idx) idx cmdlist(idx) ### Run in single machine runCommandline(idx, make_bam = FALSE)  Building all the command-line:\ntargetsPE \u003c- system.file(\"extdata\", \"targetsPE.txt\", package = \"systemPipeR\") dir_path \u003c- system.file(\"extdata/cwl/bowtie2/bowtie2-pe\", package = \"systemPipeR\") bowtiePE \u003c- loadWorkflow(targets = targetsPE, wf_file = \"bowtie2-mapping-pe.cwl\", input_file = \"bowtie2-mapping-pe.yml\", dir_path = dir_path) bowtiePE \u003c- renderWF(bowtiePE, inputvars = c(FileName1 = \"_FASTQ_PATH1_\", FileName2 = \"_FASTQ_PATH2_\", SampleName = \"_SampleName_\")) bowtiePE cmdlist(bowtiePE)[1:2] output(bowtiePE)[1:2]  Running all the jobs to computing nodes.\nresources \u003c- list(walltime = 120, ntasks = 1, ncpus = 4, memory = 1024) reg \u003c- clusterRun(bowtiePE, FUN = runCommandline, more.args = list(args = bowtiePE, dir = FALSE), conffile = \".batchtools.conf.R\", template = \"batchtools.slurm.tmpl\", Njobs = 18, runid = \"01\", resourceList = resources) getStatus(reg = reg)  Alternatively, it possible to run all the jobs in a single machine.\nbowtiePE \u003c- runCommandline(bowtiePE)  Create new targets file.\nnames(clt(bowtiePE)) writeTargetsout(x = bowtiePE, file = \"default\", step = 1, new_col = \"bowtiePE\", new_col_output_index = 1, overwrite = TRUE)  Alignment with BWA-MEM (e.g. for VAR-Seq) The following example runs BWA-MEM as a single process without submitting it to a cluster. ##TODO: add reference\nBuild the index:\ndir_path \u003c- system.file(\"extdata/cwl/bwa/bwa-idx\", package = \"systemPipeR\") idx \u003c- loadWorkflow(targets = NULL, wf_file = \"bwa-index.cwl\", input_file = \"bwa-index.yml\", dir_path = dir_path) idx \u003c- renderWF(idx) idx cmdlist(idx) # Indexes reference genome ### Run runCommandline(idx, make_bam = FALSE)  Running the alignment:\ntargetsPE \u003c- system.file(\"extdata\", \"targetsPE.txt\", package = \"systemPipeR\") dir_path \u003c- system.file(\"extdata/cwl/bwa/bwa-pe\", package = \"systemPipeR\") bwaPE \u003c- loadWorkflow(targets = targetsPE, wf_file = \"bwa-pe.cwl\", input_file = \"bwa-pe.yml\", dir_path = dir_path) bwaPE \u003c- renderWF(bwaPE, inputvars = c(FileName1 = \"_FASTQ_PATH1_\", FileName2 = \"_FASTQ_PATH2_\", SampleName = \"_SampleName_\")) bwaPE cmdlist(bwaPE)[1:2] output(bwaPE)[1:2] ### Single Machine bwaPE \u003c- runCommandline(args = bwaPE, make_bam = FALSE) ### Cluster library(batchtools) resources \u003c- list(walltime = 120, ntasks = 1, ncpus = 4, memory = 1024) reg \u003c- clusterRun(bwaPE, FUN = runCommandline, more.args = list(args = bwaPE, dir = FALSE), conffile = \".batchtools.conf.R\", template = \"batchtools.slurm.tmpl\", Njobs = 18, runid = \"01\", resourceList = resources) getStatus(reg = reg)  Create new targets file.\nnames(clt(bwaPE)) writeTargetsout(x = bwaPE, file = \"default\", step = 1, new_col = \"bwaPE\", new_col_output_index = 1, overwrite = TRUE)  Alignment with Rsubread (e.g. for RNA-Seq) The following example shows how one can use within the environment the R-based aligner , allowing running from R or command-line.\n### Build the index: dir_path \u003c- system.file(\"extdata/cwl/rsubread/rsubread-idx\", package = \"systemPipeR\") idx \u003c- loadWorkflow(targets = NULL, wf_file = \"rsubread-index.cwl\", input_file = \"rsubread-index.yml\", dir_path = dir_path) idx \u003c- renderWF(idx) idx cmdlist(idx) runCommandline(args = idx, make_bam = FALSE) ### Running the alignment: targets \u003c- system.file(\"extdata\", \"targets.txt\", package = \"systemPipeR\") dir_path \u003c- system.file(\"extdata/cwl/rsubread/rsubread-se\", package = \"systemPipeR\") rsubread \u003c- loadWorkflow(targets = targets, wf_file = \"rsubread-mapping-se.cwl\", input_file = \"rsubread-mapping-se.yml\", dir_path = dir_path) rsubread \u003c- renderWF(rsubread, inputvars = c(FileName = \"_FASTQ_PATH1_\", SampleName = \"_SampleName_\")) rsubread cmdlist(rsubread)[1] ### Single Machine rsubread \u003c- runCommandline(args = rsubread[1])  Create new targets file.\nnames(clt(rsubread)) writeTargetsout(x = rsubread, file = \"default\", step = 1, new_col = \"rsubread\", new_col_output_index = 1, overwrite = TRUE)  Alignment with gsnap (e.g. for VAR-Seq and RNA-Seq) Another R-based short read aligner is gsnap from the gmapR package (Wu and Nacu 2010). The code sample below introduces how to run this aligner on multiple nodes of a compute cluster.\n### Build the index: dir_path \u003c- system.file(\"extdata/cwl/gsnap/gsnap-idx\", package = \"systemPipeR\") idx \u003c- loadWorkflow(targets = NULL, wf_file = \"gsnap-index.cwl\", input_file = \"gsnap-index.yml\", dir_path = dir_path) idx \u003c- renderWF(idx) idx cmdlist(idx) runCommandline(args = idx, make_bam = FALSE) ### Running the alignment: targetsPE \u003c- system.file(\"extdata\", \"targetsPE.txt\", package = \"systemPipeR\") dir_path \u003c- system.file(\"extdata/cwl/gsnap/gsnap-pe\", package = \"systemPipeR\") gsnap \u003c- loadWorkflow(targets = targetsPE, wf_file = \"gsnap-mapping-pe.cwl\", input_file = \"gsnap-mapping-pe.yml\", dir_path = dir_path) gsnap \u003c- renderWF(gsnap, inputvars = c(FileName1 = \"_FASTQ_PATH1_\", FileName2 = \"_FASTQ_PATH2_\", SampleName = \"_SampleName_\")) gsnap cmdlist(gsnap)[1] output(gsnap)[1] ### Cluster library(batchtools) resources \u003c- list(walltime = 120, ntasks = 1, ncpus = 4, memory = 1024) reg \u003c- clusterRun(gsnap, FUN = runCommandline, more.args = list(args = gsnap, make_bam = FALSE), conffile = \".batchtools.conf.R\", template = \"batchtools.slurm.tmpl\", Njobs = 18, runid = \"01\", resourceList = resources) getStatus(reg = reg) gsnap \u003c- output_update(gsnap, dir = FALSE, replace = TRUE, extension = c(\".sam\", \".bam\"))  Create new targets file.\nnames(clt(gsnap)) writeTargetsout(x = gsnap, file = \"default\", step = 1, new_col = \"gsnap\", new_col_output_index = 1, overwrite = TRUE)  Create symbolic links for viewing BAM files in IGV The genome browser IGV supports reading of indexed/sorted BAM files via web URLs. This way it can be avoided to create unnecessary copies of these large files. To enable this approach, an HTML directory with Http access needs to be available in the user account (e.g. home/publichtml) of a system. If this is not the case then the BAM files need to be moved or copied to the system where IGV runs. In the following, htmldir defines the path to the HTML directory with http access where the symbolic links to the BAM files will be stored. The corresponding URLs will be written to a text file specified under the _urlfile_ argument.\nsymLink2bam(sysargs = args, htmldir = c(\"~/.html/\", \"somedir/\"), urlbase = \"http://myserver.edu/~username/\", urlfile = \"IGVurl.txt\")  Read counting for mRNA profiling experiments Create txdb (needs to be done only once).\nlibrary(GenomicFeatures) txdb \u003c- makeTxDbFromGFF(file = \"data/tair10.gff\", format = \"gff\", dataSource = \"TAIR\", organism = \"Arabidopsis thaliana\") saveDb(txdb, file = \"./data/tair10.sqlite\")  The following performs read counting with summarizeOverlaps in parallel mode with multiple cores.\nlibrary(BiocParallel) txdb \u003c- loadDb(\"./data/tair10.sqlite\") eByg \u003c- exonsBy(txdb, by = \"gene\") outpaths \u003c- subsetWF(args, slot = \"output\", subset = 1, index = 1) bfl \u003c- BamFileList(outpaths, yieldSize = 50000, index = character()) multicoreParam \u003c- MulticoreParam(workers = 4) register(multicoreParam) registered() counteByg \u003c- bplapply(bfl, function(x) summarizeOverlaps(eByg, x, mode = \"Union\", ignore.strand = TRUE, inter.feature = TRUE, singleEnd = TRUE)) ## Note: for strand-specific RNA-Seq set 'ignore.strand=FALSE' and for PE data set ## 'singleEnd=FALSE' countDFeByg \u003c- sapply(seq(along = counteByg), function(x) assays(counteByg[[x]])$counts) rownames(countDFeByg) \u003c- names(rowRanges(counteByg[[1]])) colnames(countDFeByg) \u003c- names(bfl) rpkmDFeByg \u003c- apply(countDFeByg, 2, function(x) returnRPKM(counts = x, ranges = eByg)) write.table(countDFeByg, \"results/countDFeByg.xls\", col.names = NA, quote = FALSE, sep = \"\\t\") write.table(rpkmDFeByg, \"results/rpkmDFeByg.xls\", col.names = NA, quote = FALSE, sep = \"\\t\")  Please note, in addition to read counts this step generates RPKM normalized expression values. For most statistical differential expression or abundance analysis methods, such as edgeR or DESeq2, the raw count values should be used as input. The usage of RPKM values should be restricted to specialty applications required by some users, e.g. manually comparing the expression levels of different genes or features.\nRead counting with summarizeOverlaps using multiple nodes of a cluster.\nlibrary(BiocParallel) f \u003c- function(x) { library(systemPipeR) library(BiocParallel) library(GenomicFeatures) txdb \u003c- loadDb(\"./data/tair10.sqlite\") eByg \u003c- exonsBy(txdb, by = \"gene\") args \u003c- systemArgs(sysma = \"param/tophat.param\", mytargets = \"targets.txt\") outpaths \u003c- subsetWF(args, slot = \"output\", subset = 1, index = 1) bfl \u003c- BamFileList(outpaths, yieldSize = 50000, index = character()) summarizeOverlaps(eByg, bfl[x], mode = \"Union\", ignore.strand = TRUE, inter.feature = TRUE, singleEnd = TRUE) } resources \u003c- list(walltime = 120, ntasks = 1, ncpus = 4, memory = 1024) param \u003c- BatchtoolsParam(workers = 4, cluster = \"slurm\", template = \"batchtools.slurm.tmpl\", resources = resources) counteByg \u003c- bplapply(seq(along = args), f, BPPARAM = param) countDFeByg \u003c- sapply(seq(along = counteByg), function(x) assays(counteByg[[x]])$counts) rownames(countDFeByg) \u003c- names(rowRanges(counteByg[[1]])) colnames(countDFeByg) \u003c- names(outpaths)  Useful commands for monitoring the progress of submitted jobs\ngetStatus(reg = reg) outpaths \u003c- subsetWF(args, slot = \"output\", subset = 1, index = 1) file.exists(outpaths) sapply(1:length(outpaths), function(x) loadResult(reg, id = x)) # Works after job completion  Read and alignment count stats Generate a table of read and alignment counts for all samples.\nread_statsDF \u003c- alignStats(args) write.table(read_statsDF, \"results/alignStats.xls\", row.names = FALSE, quote = FALSE, sep = \"\\t\")  The following shows the first four lines of the sample alignment stats file provided by the systemPipeR package. For simplicity the number of PE reads is multiplied here by 2 to approximate proper alignment frequencies where each read in a pair is counted.\nread.table(system.file(\"extdata\", \"alignStats.xls\", package = \"systemPipeR\"), header = TRUE)[1:4, ]  ## FileName Nreads2x Nalign Perc_Aligned Nalign_Primary Perc_Aligned_Primary ## 1 M1A 192918 177961 92.24697 177961 92.24697 ## 2 M1B 197484 159378 80.70426 159378 80.70426 ## 3 A1A 189870 176055 92.72397 176055 92.72397 ## 4 A1B 188854 147768 78.24457 147768 78.24457  Parallelization of read/alignment stats on single machine with multiple cores.\nf \u003c- function(x) alignStats(args[x]) read_statsList \u003c- bplapply(seq(along = args), f, BPPARAM = MulticoreParam(workers = 8)) read_statsDF \u003c- do.call(\"rbind\", read_statsList)  Parallelization of read/alignment stats via scheduler (e.g. Slurm) across several compute nodes.\nlibrary(BiocParallel) library(batchtools) f \u003c- function(x) { library(systemPipeR) targets \u003c- system.file(\"extdata\", \"targets.txt\", package = \"systemPipeR\") dir_path \u003c- \"param/cwl/hisat2/hisat2-se\" ## TODO: replace path to system.file args \u003c- loadWorkflow(targets = targets, wf_file = \"hisat2-mapping-se.cwl\", input_file = \"hisat2-mapping-se.yml\", dir_path = dir_path) args \u003c- renderWF(args, inputvars = c(FileName = \"_FASTQ_PATH1_\", SampleName = \"_SampleName_\")) args \u003c- output_update(args, dir = FALSE, replace = TRUE, extension = c(\".sam\", \".bam\")) alignStats(args[x]) } resources \u003c- list(walltime = 120, ntasks = 1, ncpus = 4, memory = 1024) param \u003c- BatchtoolsParam(workers = 4, cluster = \"slurm\", template = \"batchtools.slurm.tmpl\", resources = resources) read_statsList \u003c- bplapply(seq(along = args), f, BPPARAM = param) read_statsDF \u003c- do.call(\"rbind\", read_statsList)  Read counting for miRNA profiling experiments Download miRNA genes from miRBase.\nsystem(\"wget ftp://mirbase.org/pub/mirbase/19/genomes/My_species.gff3 -P ./data/\") gff \u003c- import.gff(\"./data/My_species.gff3\") gff \u003c- split(gff, elementMetadata(gff)$ID) bams \u003c- names(bampaths) names(bams) \u003c- targets$SampleName bfl \u003c- BamFileList(bams, yieldSize = 50000, index = character()) countDFmiR \u003c- summarizeOverlaps(gff, bfl, mode = \"Union\", ignore.strand = FALSE, inter.feature = FALSE) # Note: inter.feature=FALSE important since pre and mature miRNA ranges overlap rpkmDFmiR \u003c- apply(countDFmiR, 2, function(x) returnRPKM(counts = x, gffsub = gff)) write.table(assays(countDFmiR)$counts, \"results/countDFmiR.xls\", col.names = NA, quote = FALSE, sep = \"\\t\") write.table(rpkmDFmiR, \"results/rpkmDFmiR.xls\", col.names = NA, quote = FALSE, sep = \"\\t\")  Correlation analysis of samples The following computes the sample-wise Spearman correlation coefficients from the rlog (regularized-logarithm) transformed expression values generated with the DESeq2 package. After transformation to a distance matrix, hierarchical clustering is performed with the hclust function and the result is plotted as a dendrogram (sample_tree.pdf).\nlibrary(DESeq2, warn.conflicts = FALSE, quietly = TRUE) library(ape, warn.conflicts = FALSE) countDFpath \u003c- system.file(\"extdata\", \"countDFeByg.xls\", package = \"systemPipeR\") countDF \u003c- as.matrix(read.table(countDFpath)) colData \u003c- data.frame(row.names = targets.as.df(targets(args))$SampleName, condition = targets.as.df(targets(args))$Factor) dds \u003c- DESeqDataSetFromMatrix(countData = countDF, colData = colData, design = ~condition)  ## Warning in DESeqDataSet(se, design = design, ignoreRank): some variables in ## design formula are characters, converting to factors  d \u003c- cor(assay(rlog(dds)), method = \"spearman\") hc \u003c- hclust(dist(1 - d)) plot.phylo(as.phylo(hc), type = \"p\", edge.col = 4, edge.width = 3, show.node.label = TRUE, no.margin = TRUE)  Figure 6: Correlation dendrogram of samples for rlog values.\n  Alternatively, the clustering can be performed with RPKM normalized expression values. In combination with Spearman correlation the results of the two clustering methods are often relatively similar.\nrpkmDFeBygpath \u003c- system.file(\"extdata\", \"rpkmDFeByg.xls\", package = \"systemPipeR\") rpkmDFeByg \u003c- read.table(rpkmDFeBygpath, check.names = FALSE) rpkmDFeByg \u003c- rpkmDFeByg[rowMeans(rpkmDFeByg) \u003e 50, ] d \u003c- cor(rpkmDFeByg, method = \"spearman\") hc \u003c- hclust(as.dist(1 - d)) plot.phylo(as.phylo(hc), type = \"p\", edge.col = \"blue\", edge.width = 2, show.node.label = TRUE, no.margin = TRUE)  DEG analysis with edgeR The following *run_edgeR* function is a convenience wrapper for identifying differentially expressed genes (DEGs) in batch mode with *edgeR’s GML method (Robinson, McCarthy, and Smyth 2010) for any number of pairwise sample comparisons specified under the cmp* argument. Users are strongly encouraged to consult the edgeR vignette for more detailed information on this topic and how to properly run edgeR on data sets with more complex experimental designs.\ntargets \u003c- read.delim(targetspath, comment = \"#\") cmp \u003c- readComp(file = targetspath, format = \"matrix\", delim = \"-\") cmp[[1]]  ## [,1] [,2] ## [1,] \"M1\" \"A1\" ## [2,] \"M1\" \"V1\" ## [3,] \"A1\" \"V1\" ## [4,] \"M6\" \"A6\" ## [5,] \"M6\" \"V6\" ## [6,] \"A6\" \"V6\" ## [7,] \"M12\" \"A12\" ## [8,] \"M12\" \"V12\" ## [9,] \"A12\" \"V12\"  countDFeBygpath \u003c- system.file(\"extdata\", \"countDFeByg.xls\", package = \"systemPipeR\") countDFeByg \u003c- read.delim(countDFeBygpath, row.names = 1) edgeDF \u003c- run_edgeR(countDF = countDFeByg, targets = targets, cmp = cmp[[1]], independent = FALSE, mdsplot = \"\")  ## Disp = 0.21829 , BCV = 0.4672  Filter and plot DEG results for up and down-regulated genes. Because of the small size of the toy data set used by this vignette, the FDR value has been set to a relatively high threshold (here 10%). More commonly used FDR cutoffs are 1% or 5%. The definition of ‘up’ and ‘down’ is given in the corresponding help file. To open it, type ?filterDEGs in the R console.\nDEG_list \u003c- filterDEGs(degDF = edgeDF, filter = c(Fold = 2, FDR = 10))  Figure 7: Up and down regulated DEGs identified by edgeR.\n  names(DEG_list)  ## [1] \"UporDown\" \"Up\" \"Down\" \"Summary\"  DEG_list$Summary[1:4, ]  ## Comparisons Counts_Up_or_Down Counts_Up Counts_Down ## M1-A1 M1-A1 0 0 0 ## M1-V1 M1-V1 1 1 0 ## A1-V1 A1-V1 1 1 0 ## M6-A6 M6-A6 0 0 0  DEG analysis with DESeq2 The following *run_DESeq2* function is a convenience wrapper for identifying DEGs in batch mode with DESeq2* (Love, Huber, and Anders 2014) for any number of pairwise sample comparisons specified under the cmp* argument. Users are strongly encouraged to consult the DESeq2 vignette for more detailed information on this topic and how to properly run DESeq2 on data sets with more complex experimental designs.\ndegseqDF \u003c- run_DESeq2(countDF = countDFeByg, targets = targets, cmp = cmp[[1]], independent = FALSE)  ## Warning in DESeqDataSet(se, design = design, ignoreRank): some variables in ## design formula are characters, converting to factors  Filter and plot DEG results for up and down-regulated genes.\nDEG_list2 \u003c- filterDEGs(degDF = degseqDF, filter = c(Fold = 2, FDR = 10))  Figure 8: Up and down regulated DEGs identified by DESeq2.\n  Venn Diagrams The function overLapper can compute Venn intersects for large numbers of sample sets (up to 20 or more) and vennPlot can plot 2-5 way Venn diagrams. A useful feature is the possibility to combine the counts from several Venn comparisons with the same number of sample sets in a single Venn diagram (here for 4 up and down DEG sets).\nvennsetup \u003c- overLapper(DEG_list$Up[6:9], type = \"vennsets\") vennsetdown \u003c- overLapper(DEG_list$Down[6:9], type = \"vennsets\") vennPlot(list(vennsetup, vennsetdown), mymain = \"\", mysub = \"\", colmode = 2, ccol = c(\"blue\", \"red\"))  Figure 9: Venn Diagram for 4 Up and Down DEG Sets.\n  GO term enrichment analysis of DEGs Obtain gene-to-GO mappings The following shows how to obtain gene-to-GO mappings from biomaRt (here for A. thaliana) and how to organize them for the downstream GO term enrichment analysis. Alternatively, the gene-to-GO mappings can be obtained for many organisms from Bioconductor’s *.db genome annotation packages or GO annotation files provided by various genome databases. For each annotation, this relatively slow preprocessing step needs to be performed only once. Subsequently, the preprocessed data can be loaded with the load function as shown in the next subsection.\nlibrary(\"biomaRt\") listMarts() # To choose BioMart database listMarts(host = \"plants.ensembl.org\") m \u003c- useMart(\"plants_mart\", host = \"plants.ensembl.org\") listDatasets(m) m \u003c- useMart(\"plants_mart\", dataset = \"athaliana_eg_gene\", host = \"plants.ensembl.org\") listAttributes(m) # Choose data types you want to download go \u003c- getBM(attributes = c(\"go_id\", \"tair_locus\", \"namespace_1003\"), mart = m) go \u003c- go[go[, 3] != \"\", ] go[, 3] \u003c- as.character(go[, 3]) go[go[, 3] == \"molecular_function\", 3] \u003c- \"F\" go[go[, 3] == \"biological_process\", 3] \u003c- \"P\" go[go[, 3] == \"cellular_component\", 3] \u003c- \"C\" go[1:4, ] dir.create(\"./data/GO\") write.table(go, \"data/GO/GOannotationsBiomart_mod.txt\", quote = FALSE, row.names = FALSE, col.names = FALSE, sep = \"\\t\") catdb \u003c- makeCATdb(myfile = \"data/GO/GOannotationsBiomart_mod.txt\", lib = NULL, org = \"\", colno = c(1, 2, 3), idconv = NULL) save(catdb, file = \"data/GO/catdb.RData\")  Batch GO term enrichment analysis Apply the enrichment analysis to the DEG sets obtained in the above differential expression analysis. Note, in the following example the FDR filter is set here to an unreasonably high value, simply because of the small size of the toy data set used in this vignette. Batch enrichment analysis of many gene sets is performed with the GOCluster_Report function. When method=\"all\", it returns all GO terms passing the p-value cutoff specified under the cutoff arguments. When method=\"slim\", it returns only the GO terms specified under the myslimv argument. The given example shows how one can obtain such a GO slim vector from BioMart for a specific organism.\nload(\"data/GO/catdb.RData\") DEG_list \u003c- filterDEGs(degDF = edgeDF, filter = c(Fold = 2, FDR = 50), plot = FALSE) up_down \u003c- DEG_list$UporDown names(up_down) \u003c- paste(names(up_down), \"_up_down\", sep = \"\") up \u003c- DEG_list$Up names(up) \u003c- paste(names(up), \"_up\", sep = \"\") down \u003c- DEG_list$Down names(down) \u003c- paste(names(down), \"_down\", sep = \"\") DEGlist \u003c- c(up_down, up, down) DEGlist \u003c- DEGlist[sapply(DEGlist, length) \u003e 0] BatchResult \u003c- GOCluster_Report(catdb = catdb, setlist = DEGlist, method = \"all\", id_type = \"gene\", CLSZ = 2, cutoff = 0.9, gocats = c(\"MF\", \"BP\", \"CC\"), recordSpecGO = NULL) library(\"biomaRt\") m \u003c- useMart(\"plants_mart\", dataset = \"athaliana_eg_gene\", host = \"plants.ensembl.org\") goslimvec \u003c- as.character(getBM(attributes = c(\"goslim_goa_accession\"), mart = m)[, 1]) BatchResultslim \u003c- GOCluster_Report(catdb = catdb, setlist = DEGlist, method = \"slim\", id_type = \"gene\", myslimv = goslimvec, CLSZ = 10, cutoff = 0.01, gocats = c(\"MF\", \"BP\", \"CC\"), recordSpecGO = NULL)  Plot batch GO term results The data.frame generated by GOCluster_Report can be plotted with the goBarplot function. Because of the variable size of the sample sets, it may not always be desirable to show the results from different DEG sets in the same bar plot. Plotting single sample sets is achieved by subsetting the input data frame as shown in the first line of the following example.\ngos \u003c- BatchResultslim[grep(\"M6-V6_up_down\", BatchResultslim$CLID), ] gos \u003c- BatchResultslim pdf(\"GOslimbarplotMF.pdf\", height = 8, width = 10) goBarplot(gos, gocat = \"MF\") dev.off() goBarplot(gos, gocat = \"BP\") goBarplot(gos, gocat = \"CC\")  Figure 10: GO Slim Barplot for MF Ontology.\n  Clustering and heat maps The following example performs hierarchical clustering on the rlog transformed expression matrix subsetted by the DEGs identified in the above differential expression analysis. It uses a Pearson correlation-based distance measure and complete linkage for cluster join.\nlibrary(pheatmap) geneids \u003c- unique(as.character(unlist(DEG_list[[1]]))) y \u003c- assay(rlog(dds))[geneids, ] pdf(\"heatmap1.pdf\") pheatmap(y, scale = \"row\", clustering_distance_rows = \"correlation\", clustering_distance_cols = \"correlation\") dev.off()    Figure 11: Heat map with hierarchical clustering dendrograms of DEGs.\n  Workflow templates The intended way of running systemPipeR workflows is via *.Rmd files, which can be executed either line-wise in interactive mode or with a single command from R or the command-line. This way comprehensive and reproducible analysis reports can be generated in PDF or HTML format in a fully automated manner by making use of the highly functional reporting utilities available for R. The following shows how to execute a workflow (e.g., systemPipeRNAseq.Rmd) from the command-line.\nRscript -e \"rmarkdown::render('systemPipeRNAseq.Rmd')\"  Templates for setting up custom project reports are provided as **.Rmd* files by the helper package *systemPipeRdata* and in the vignettes subdirectory of systemPipeR. The corresponding HTML of these report templates are available here: systemPipeRNAseq, systemPipeRIBOseq, systemPipeChIPseq and systemPipeVARseq. To work with *.Rnw* or *.Rmd* files efficiently, basic knowledge of Sweave or knitr and Latex or R Markdown v2 is required.\nRNA-Seq sample Load the RNA-Seq sample workflow into your current working directory.\nlibrary(systemPipeRdata) genWorkenvir(workflow = \"rnaseq\") setwd(\"rnaseq\")  Run workflow Next, run the chosen sample workflow systemPipeRNAseq (PDF, Rmd) by executing from the command-line make -B within the rnaseq directory. Alternatively, one can run the code from the provided *.Rmd template file from within R interactively.\nThe workflow includes following steps:\n Read preprocessing  Quality filtering (trimming) FASTQ quality report   Alignments: Tophat2 (or any other RNA-Seq aligner) Alignment stats Read counting Sample-wise correlation analysis Analysis of differentially expressed genes (DEGs) GO term enrichment analysis Gene-wise clustering  ChIP-Seq sample Load the ChIP-Seq sample workflow into your current working directory.\nlibrary(systemPipeRdata) genWorkenvir(workflow = \"chipseq\") setwd(\"chipseq\")  Run workflow Next, run the chosen sample workflow systemPipeChIPseq_single (PDF, Rmd) by executing from the command-line make -B within the chipseq directory. Alternatively, one can run the code from the provided *.Rmd template file from within R interactively.\nThe workflow includes the following steps:\n Read preprocessing  Quality filtering (trimming) FASTQ quality report   Alignments: Bowtie2 or rsubread Alignment stats Peak calling: MACS2, BayesPeak Peak annotation with genomic context Differential binding analysis GO term enrichment analysis Motif analysis  VAR-Seq sample VAR-Seq workflow for the single machine Load the VAR-Seq sample workflow into your current working directory.\nlibrary(systemPipeRdata) genWorkenvir(workflow = \"varseq\") setwd(\"varseq\")  Run workflow Next, run the chosen sample workflow systemPipeVARseq_single (PDF, Rmd) by executing from the command-line make -B within the varseq directory. Alternatively, one can run the code from the provided *.Rmd template file from within R interactively.\nThe workflow includes following steps:\n Read preprocessing  Quality filtering (trimming) FASTQ quality report   Alignments: gsnap, bwa Variant calling: VariantTools, GATK, BCFtools Variant filtering: VariantTools and VariantAnnotation Variant annotation: VariantAnnotation Combine results from many samples Summary statistics of samples  VAR-Seq workflow for computer cluster The workflow template provided for this step is called systemPipeVARseq.Rmd (PDF, Rmd). It runs the above VAR-Seq workflow in parallel on multiple compute nodes of an HPC system using Slurm as the scheduler.\nRibo-Seq sample Load the Ribo-Seq sample workflow into your current working directory.\nlibrary(systemPipeRdata) genWorkenvir(workflow = \"riboseq\") setwd(\"riboseq\")  Run workflow Next, run the chosen sample workflow systemPipeRIBOseq (PDF, Rmd) by executing from the command-line make -B within the ribseq directory. Alternatively, one can run the code from the provided *.Rmd template file from within R interactively.\nThe workflow includes following steps:\n Read preprocessing  Adaptor trimming and quality filtering FASTQ quality report   Alignments: Tophat2 (or any other RNA-Seq aligner) Alignment stats Compute read distribution across genomic features Adding custom features to the workflow (e.g. uORFs) Genomic read coverage along with transcripts Read counting Sample-wise correlation analysis Analysis of differentially expressed genes (DEGs) GO term enrichment analysis Gene-wise clustering Differential ribosome binding (translational efficiency)  Version information Note: the most recent version of this tutorial can be found here.\nsessionInfo()  ## R version 4.0.5 (2021-03-31) ## Platform: x86_64-pc-linux-gnu (64-bit) ## Running under: Debian GNU/Linux 10 (buster) ## ## Matrix products: default ## BLAS: /usr/lib/x86_64-linux-gnu/blas/libblas.so.3.8.0 ## LAPACK: /usr/lib/x86_64-linux-gnu/lapack/liblapack.so.3.8.0 ## ## locale: ## [1] LC_CTYPE=en_US.UTF-8 LC_NUMERIC=C ## [3] LC_TIME=en_US.UTF-8 LC_COLLATE=en_US.UTF-8 ## [5] LC_MONETARY=en_US.UTF-8 LC_MESSAGES=en_US.UTF-8 ## [7] LC_PAPER=en_US.UTF-8 LC_NAME=C ## [9] LC_ADDRESS=C LC_TELEPHONE=C ## [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C ## ## attached base packages: ## [1] stats4 parallel stats graphics grDevices utils datasets ## [8] methods base ## ## other attached packages: ## [1] DESeq2_1.30.0 kableExtra_1.3.4 ## [3] dplyr_1.0.2 magrittr_2.0.1 ## [5] batchtools_0.9.14 ape_5.4-1 ## [7] ggplot2_3.3.2 systemPipeR_1.24.2 ## [9] ShortRead_1.48.0 GenomicAlignments_1.26.0 ## [11] SummarizedExperiment_1.20.0 Biobase_2.50.0 ## [13] MatrixGenerics_1.2.0 matrixStats_0.57.0 ## [15] BiocParallel_1.24.1 Rsamtools_2.6.0 ## [17] Biostrings_2.58.0 XVector_0.30.0 ## [19] GenomicRanges_1.42.0 GenomeInfoDb_1.26.1 ## [21] IRanges_2.24.0 S4Vectors_0.28.0 ## [23] BiocGenerics_0.36.0 BiocStyle_2.18.0 ## ## loaded via a namespace (and not attached): ## [1] GOstats_2.56.0 backports_1.2.0 BiocFileCache_1.14.0 ## [4] systemfonts_1.0.1 GSEABase_1.52.0 splines_4.0.5 ## [7] digest_0.6.27 htmltools_0.5.1.1 GO.db_3.12.1 ## [10] checkmate_2.0.0 memoise_1.1.0 BSgenome_1.58.0 ## [13] base64url_1.4 limma_3.46.0 annotate_1.68.0 ## [16] svglite_2.0.0 askpass_1.1 prettyunits_1.1.1 ## [19] jpeg_0.1-8.1 colorspace_2.0-0 blob_1.2.1 ## [22] rvest_0.3.6 rappdirs_0.3.1 xfun_0.22 ## [25] crayon_1.3.4 RCurl_1.98-1.2 jsonlite_1.7.1 ## [28] graph_1.68.0 genefilter_1.72.0 brew_1.0-6 ## [31] survival_3.2-10 VariantAnnotation_1.36.0 glue_1.4.2 ## [34] gtable_0.3.0 zlibbioc_1.36.0 webshot_0.5.2 ## [37] DelayedArray_0.16.0 V8_3.4.0 Rgraphviz_2.34.0 ## [40] scales_1.1.1 pheatmap_1.0.12 DBI_1.1.0 ## [43] edgeR_3.32.0 Rcpp_1.0.5 viridisLite_0.3.0 ## [46] xtable_1.8-4 progress_1.2.2 bit_4.0.4 ## [49] rsvg_2.1 AnnotationForge_1.32.0 httr_1.4.2 ## [52] RColorBrewer_1.1-2 ellipsis_0.3.1 farver_2.0.3 ## [55] pkgconfig_2.0.3 XML_3.99-0.5 sass_0.3.1 ## [58] dbplyr_2.0.0 locfit_1.5-9.4 labeling_0.4.2 ## [61] tidyselect_1.1.0 rlang_0.4.8 AnnotationDbi_1.52.0 ## [64] munsell_0.5.0 tools_4.0.5 generics_0.1.0 ## [67] RSQLite_2.2.1 evaluate_0.14 stringr_1.4.0 ## [70] yaml_2.2.1 knitr_1.30 bit64_4.0.5 ## [73] purrr_0.3.4 RBGL_1.66.0 nlme_3.1-149 ## [76] formatR_1.7 xml2_1.3.2 biomaRt_2.46.0 ## [79] compiler_4.0.5 rstudioapi_0.13 curl_4.3 ## [82] png_0.1-7 tibble_3.0.4 geneplotter_1.68.0 ## [85] bslib_0.2.4 stringi_1.5.3 blogdown_1.2 ## [88] GenomicFeatures_1.42.1 lattice_0.20-41 Matrix_1.3-2 ## [91] vctrs_0.3.5 pillar_1.4.7 lifecycle_0.2.0 ## [94] BiocManager_1.30.10 jquerylib_0.1.3 data.table_1.13.2 ## [97] bitops_1.0-6 rtracklayer_1.50.0 R6_2.5.0 ## [100] latticeExtra_0.6-29 hwriter_1.3.2 bookdown_0.21 ## [103] codetools_0.2-18 assertthat_0.2.1 openssl_1.4.3 ## [106] Category_2.56.0 rjson_0.2.20 withr_2.3.0 ## [109] GenomeInfoDbData_1.2.4 hms_0.5.3 grid_4.0.5 ## [112] DOT_0.1 rmarkdown_2.7  Funding This project is funded by NSF award ABI-1661152.\nReferences H Backman, Tyler W, and Thomas Girke. 2016. “systemPipeR: NGS workflow and report generation environment.” BMC Bioinformatics 17 (1): 388. https://doi.org/10.1186/s12859-016-1241-0.\n Howard, Brian E, Qiwen Hu, Ahmet Can Babaoglu, Manan Chandra, Monica Borghi, Xiaoping Tan, Luyan He, et al. 2013. “High-Throughput RNA Sequencing of Pseudomonas-Infected Arabidopsis Reveals Hidden Transcriptome Complexity and Novel Splice Variants.” PLoS One 8 (10): e74183. https://doi.org/10.1371/journal.pone.0074183.\n Kim, Daehwan, Ben Langmead, and Steven L Salzberg. 2015. “HISAT: A Fast Spliced Aligner with Low Memory Requirements.” Nat. Methods 12 (4): 357–60.\n Kim, Daehwan, Geo Pertea, Cole Trapnell, Harold Pimentel, Ryan Kelley, and Steven L Salzberg. 2013. “TopHat2: Accurate Alignment of Transcriptomes in the Presence of Insertions, Deletions and Gene Fusions.” Genome Biol. 14 (4): R36. https://doi.org/10.1186/gb-2013-14-4-r36.\n Langmead, Ben, and Steven L Salzberg. 2012. “Fast Gapped-Read Alignment with Bowtie 2.” Nat. Methods 9 (4): 357–59. https://doi.org/10.1038/nmeth.1923.\n Lawrence, Michael, Wolfgang Huber, Hervé Pagès, Patrick Aboyoun, Marc Carlson, Robert Gentleman, Martin T Morgan, and Vincent J Carey. 2013. “Software for Computing and Annotating Genomic Ranges.” PLoS Comput. Biol. 9 (8): e1003118. https://doi.org/10.1371/journal.pcbi.1003118.\n Li, H, and R Durbin. 2009. “Fast and Accurate Short Read Alignment with Burrows-Wheeler Transform.” Bioinformatics 25 (14): 1754–60. https://doi.org/10.1093/bioinformatics/btp324.\n Li, Heng. 2013. “Aligning Sequence Reads, Clone Sequences and Assembly Contigs with BWA-MEM.” arXiv [q-Bio.GN], March. http://arxiv.org/abs/1303.3997.\n Liao, Yang, Gordon K Smyth, and Wei Shi. 2013. “The Subread Aligner: Fast, Accurate and Scalable Read Mapping by Seed-and-Vote.” Nucleic Acids Res. 41 (10): e108. https://doi.org/10.1093/nar/gkt214.\n Love, Michael, Wolfgang Huber, and Simon Anders. 2014. “Moderated Estimation of Fold Change and Dispersion for RNA-seq Data with DESeq2.” Genome Biol. 15 (12): 550. https://doi.org/10.1186/s13059-014-0550-8.\n Morgan, Martin, Hervé Pagès, Valerie Obenchain, and Nathaniel Hayden. 2019. Rsamtools: Binary Alignment (BAM), FASTA, Variant Call (BCF), and Tabix File Import. http://bioconductor.org/packages/Rsamtools.\n Robinson, M D, D J McCarthy, and G K Smyth. 2010. “edgeR: A Bioconductor Package for Differential Expression Analysis of Digital Gene Expression Data.” Bioinformatics 26 (1): 139–40. https://doi.org/10.1093/bioinformatics/btp616.\n Wu, T D, and S Nacu. 2010. “Fast and SNP-tolerant Detection of Complex Variants and Splicing in Short Reads.” Bioinformatics 26 (7): 873–81. https://doi.org/10.1093/bioinformatics/btq057.\n  ","categories":"","description":"","excerpt":" pre code { white-space: pre !important; overflow-x: scroll …","ref":"/manuals/systempiper/systempiper/","tags":"","title":"systemPipeR: Workflow design and reporting generation environment"},{"body":" pre code { white-space: pre !important; overflow-x: scroll !important; word-break: keep-all !important; word-wrap: initial !important; }  document.addEventListener(\"DOMContentLoaded\", function() { document.querySelector(\"h1\").className = \"title\"; });  document.addEventListener(\"DOMContentLoaded\", function() { var links = document.links; for (var i = 0, linksLength = links.length; i Source code downloads: [ .Rmd ] [ .R ]\n Introduction systemPipeR is provides flexible utilities for building and running automated end-to-end analysis workflows for a wide range of research applications, including next-generation sequencing (NGS) experiments, such as RNA-Seq, ChIP-Seq, VAR-Seq and Ribo-Seq (H Backman and Girke 2016). Important features include a uniform workflow interface across different data analysis applications, automated report generation, and support for running both R and command-line software, such as NGS aligners or peak/variant callers, on local computers or compute clusters (Figure 1). The latter supports interactive job submissions and batch submissions to queuing systems of clusters. For instance, systemPipeR can be used with any command-line aligners such as BWA (Heng Li 2013; H. Li and Durbin 2009), HISAT2 (Kim, Langmead, and Salzberg 2015), TopHat2 (Kim et al. 2013) and Bowtie2 (Langmead and Salzberg 2012), as well as the R-based NGS aligners Rsubread (Liao, Smyth, and Shi 2013) and gsnap (gmapR) (Wu and Nacu 2010). Efficient handling of complex sample sets (e.g. FASTQ/BAM files) and experimental designs are facilitated by a well-defined sample annotation infrastructure which improves reproducibility and user-friendliness of many typical analysis workflows in the NGS area (Lawrence et al. 2013).\nThe main motivation and advantages of using systemPipeR for complex data analysis tasks are:\n Facilitates the design of complex data analysis workflows Consistent workflow interface for different large-scale data types Makes NGS analysis with Bioconductor utilities more accessible to new users Simplifies usage of command-line software from within R Reduces the complexity of using compute clusters for R and command-line software Accelerates runtime of workflows via parallelization on computer systems with multiple CPU cores and/or multiple compute nodes Improves reproducibility by automating analyses and generation of analysis reports    Figure 1: Relevant features in systemPipeR. Workflow design concepts are illustrated under (A \u0026 B). Examples of systemPipeR’s visualization functionalities are given under (C). \nA central concept for designing workflows within the systemPipeR environment is the use of workflow management containers. They support the widely used community standard Common Workflow Language (CWL) for describing analysis workflows in a generic and reproducible manner, introducing SYSargs2 workflow control class (see Figure 2). Using this community standard in systemPipeR has many advantages. For instance, the integration of CWL allows running systemPipeR workflows from a single specification instance either entirely from within R, from various command-line wrappers (e.g., cwl-runner) or from other languages (, e.g., Bash or Python). systemPipeR includes support for both command-line and R/Bioconductor software as well as resources for containerization, parallel evaluations on computer clusters along with the automated generation of interactive analysis reports.\nAn important feature of systemPipeR's CWL interface is that it provides two options to run command-line tools and workflows based on CWL. First, one can run CWL in its native way via an R-based wrapper utility for cwl-runner or cwl-tools (CWL-based approach). Second, one can run workflows using CWL’s command-line and workflow instructions from within R (R-based approach). In the latter case the same CWL workflow definition files (e.g. *.cwl and *.yml) are used but rendered and executed entirely with R functions defined by systemPipeR, and thus use CWL mainly as a command-line and workflow definition format rather than execution software to run workflows. In this regard systemPipeR also provides several convenience functions that are useful for designing and debugging workflows, such as a command-line rendering function to retrieve the exact command-line strings for each data set and processing step prior to running a command-line.\nThis overview introduces the design of a new CWL S4 class in systemPipeR, as well as the custom command-line interface, combined with the overview of all the common analysis steps of NGS experiments.\nWorkflow design structure using SYSargs2 The flexibility of systemPipeR's workflow control class scales to any number of analysis steps necessary in a workflow. This can include variable combinations of steps requiring command-line or R-based software executions. The connectivity among all workflow steps is achieved by the SYSargs2 workflow control class (see Figure 3). This S4 class is a list-like container where each instance stores all the input/output paths and parameter components required for a particular data analysis step. SYSargs2 instances are generated by two constructor functions, loadWorkflow and renderWF, using as data input so called targets or yaml files as well as two cwl parameter files (for details see below). When running preconfigured workflows, the only input the user needs to provide is the initial targets file containing the paths to the input files (e.g. FASTQ) along with unique sample labels. Subsequent targets instances are created automatically. The parameters required for running command-line software is provided by the parameter (.cwl) files described below.\nTo support one or many workflow steps in a single container the SYSargsList class capturing all information required to run, control and monitor complex workflows from start to finish.\n  Figure 2: Workflow steps with input/output file operations are controlled by SYSargs2 objects. Each SYSargs2 instance is constructed from one targets and two param files. The only input provided by the user is the initial targets file. Subsequent targets instances are created automatically, from the previous output files. Any number of predefined or custom workflow steps are supported. One or many SYSargs2 objects are organized in an SYSargsList container.\nWorkflow Management with SYSargsList In systemPipeR allows to create (multi-step analyses) and run workflows directly from R or the command-line using local systems, HPC cluster or cloud platforms.\n  Figure 3: Workflow Management using SYSargsList.\nGetting Started Installation The R software for running systemPipeR can be downloaded from CRAN. The systemPipeR environment can be installed from the R console using the BiocManager::install command. The associated data package systemPipeRdata can be installed the same way. The latter is a helper package for generating systemPipeR workflow environments with a single command containing all parameter files and sample data required to quickly test and run workflows.\nif (!requireNamespace(\"BiocManager\", quietly = TRUE)) install.packages(\"BiocManager\") BiocManager::install(\"systemPipeR\") BiocManager::install(\"systemPipeRdata\")  Please note that if you desire to use a third-party command line tool, the particular tool and dependencies need to be installed and executable. See details.\nLoading package and documentation library(\"systemPipeR\") # Loads the package library(help = \"systemPipeR\") # Lists package info vignette(\"systemPipeR\") # Opens vignette  Load sample data and workflow templates The mini sample FASTQ files used by this overview vignette as well as the associated workflow reporting vignettes can be loaded via the systemPipeRdata package as shown below. The chosen data set SRP010938 obtains 18 paired-end (PE) read sets from Arabidposis thaliana (Howard et al. 2013). To minimize processing time during testing, each FASTQ file has been subsetted to 90,000-100,000 randomly sampled PE reads that map to the first 100,000 nucleotides of each chromosome of the A. thalina genome. The corresponding reference genome sequence (FASTA) and its GFF annotation files (provided in the same download) have been truncated accordingly. This way the entire test sample data set requires less than 200MB disk storage space. A PE read set has been chosen for this test data set for flexibility, because it can be used for testing both types of analysis routines requiring either SE (single-end) reads or PE reads.\nThe following generates a fully populated systemPipeR workflow environment (here for RNA-Seq) in the current working directory of an R session. At this time the package includes workflow templates for RNA-Seq, ChIP-Seq, VAR-Seq, and Ribo-Seq. Templates for additional NGS applications will be provided in the future.\nDirectory structure The working environment of the sample data loaded in the previous step contains the following pre-configured directory structure (Figure 4). Directory names are indicated in green. Users can change this structure as needed, but need to adjust the code in their workflows accordingly.\n workflow/ (e.g. rnaseq/)  This is the root directory of the R session running the workflow. Run script ( *.Rmd) and sample annotation (targets.txt) files are located here. Note, this directory can have any name (e.g. rnaseq, varseq). Changing its name does not require any modifications in the run script(s). Important subdirectories:  param/  Stores non-CWL parameter files such as: *.param, *.tmpl and *.run.sh. These files are only required for backwards compatibility to run old workflows using the previous custom command-line interface. param/cwl/: This subdirectory stores all the CWL parameter files. To organize workflows, each can have its own subdirectory, where all CWL param and input.yml files need to be in the same subdirectory.   data/   FASTQ files FASTA file of reference (e.g. reference genome) Annotation files etc.   results/  Analysis results are usually written to this directory, including: alignment, variant and peak files (BAM, VCF, BED); tabular result files; and image/plot files Note, the user has the option to organize results files for a given sample and analysis step in a separate subdirectory.          Figure 5: systemPipeR’s preconfigured directory structure.\nThe following parameter files are included in each workflow template:\n targets.txt: initial one provided by user; downstream targets_*.txt files are generated automatically *.param/cwl: defines parameter for input/output file operations, e.g.:  hisat2-se/hisat2-mapping-se.cwl hisat2-se/hisat2-mapping-se.yml   *_run.sh: optional bash scripts Configuration files for computer cluster environments (skip on single machines):  .batchtools.conf.R: defines the type of scheduler for batchtools pointing to template file of cluster, and located in user’s home directory *.tmpl: specifies parameters of scheduler used by a system, e.g. Torque, SGE, Slurm, etc.    Structure of targets file The targets file defines all input files (e.g. FASTQ, BAM, BCF) and sample comparisons of an analysis workflow. The following shows the format of a sample targets file included in the package. It also can be viewed and downloaded from systemPipeR’s GitHub repository here. In a target file with a single type of input files, here FASTQ files of single-end (SE) reads, the first three columns are mandatory including their column names, while it is four mandatory columns for FASTQ files of PE reads. All subsequent columns are optional and any number of additional columns can be added as needed.\nUsers should note here, the usage of targets files is optional when using systemPipeR’s new CWL interface. They can be replaced by a standard YAML input file used by CWL. Since for organizing experimental variables targets files are extremely useful and user-friendly. Thus, we encourage users to keep using them.\nStructure of targets file for single-end (SE) samples library(systemPipeR) targetspath \u003c- system.file(\"extdata\", \"targets.txt\", package = \"systemPipeR\") read.delim(targetspath, comment.char = \"#\")[1:4, ]  ## FileName SampleName Factor SampleLong Experiment ## 1 ./data/SRR446027_1.fastq.gz M1A M1 Mock.1h.A 1 ## 2 ./data/SRR446028_1.fastq.gz M1B M1 Mock.1h.B 1 ## 3 ./data/SRR446029_1.fastq.gz A1A A1 Avr.1h.A 1 ## 4 ./data/SRR446030_1.fastq.gz A1B A1 Avr.1h.B 1 ## Date ## 1 23-Mar-2012 ## 2 23-Mar-2012 ## 3 23-Mar-2012 ## 4 23-Mar-2012  To work with custom data, users need to generate a targets file containing the paths to their own FASTQ files and then provide under targetspath the path to the corresponding targets file.\nStructure of targets file for paired-end (PE) samples For paired-end (PE) samples, the structure of the targets file is similar, where users need to provide two FASTQ path columns: FileName1 and FileName2 with the paths to the PE FASTQ files.\ntargetspath \u003c- system.file(\"extdata\", \"targetsPE.txt\", package = \"systemPipeR\") read.delim(targetspath, comment.char = \"#\")[1:2, 1:6]  ## FileName1 FileName2 SampleName Factor ## 1 ./data/SRR446027_1.fastq.gz ./data/SRR446027_2.fastq.gz M1A M1 ## 2 ./data/SRR446028_1.fastq.gz ./data/SRR446028_2.fastq.gz M1B M1 ## SampleLong Experiment ## 1 Mock.1h.A 1 ## 2 Mock.1h.B 1  Sample comparisons Sample comparisons are defined in the header lines of the targets file starting with ‘# \u003cCMP\u003e.’\nreadLines(targetspath)[1:4]  ## [1] \"# Project ID: Arabidopsis - Pseudomonas alternative splicing study (SRA: SRP010938; PMID: 24098335)\" ## [2] \"# The following line(s) allow to specify the contrasts needed for comparative analyses, such as DEG identification. All possible comparisons can be specified with 'CMPset: ALL'.\" ## [3] \"# \u003cCMP\u003e CMPset1: M1-A1, M1-V1, A1-V1, M6-A6, M6-V6, A6-V6, M12-A12, M12-V12, A12-V12\" ## [4] \"# \u003cCMP\u003e CMPset2: ALL\"  The function readComp imports the comparison information and stores it in a list. Alternatively, readComp can obtain the comparison information from the corresponding SYSargs object (see below). Note, these header lines are optional. They are mainly useful for controlling comparative analyses according to certain biological expectations, such as identifying differentially expressed genes in RNA-Seq experiments based on simple pair-wise comparisons.\nreadComp(file = targetspath, format = \"vector\", delim = \"-\")  ## $CMPset1 ## [1] \"M1-A1\" \"M1-V1\" \"A1-V1\" \"M6-A6\" \"M6-V6\" \"A6-V6\" \"M12-A12\" ## [8] \"M12-V12\" \"A12-V12\" ## ## $CMPset2 ## [1] \"M1-A1\" \"M1-V1\" \"M1-M6\" \"M1-A6\" \"M1-V6\" \"M1-M12\" \"M1-A12\" ## [8] \"M1-V12\" \"A1-V1\" \"A1-M6\" \"A1-A6\" \"A1-V6\" \"A1-M12\" \"A1-A12\" ## [15] \"A1-V12\" \"V1-M6\" \"V1-A6\" \"V1-V6\" \"V1-M12\" \"V1-A12\" \"V1-V12\" ## [22] \"M6-A6\" \"M6-V6\" \"M6-M12\" \"M6-A12\" \"M6-V12\" \"A6-V6\" \"A6-M12\" ## [29] \"A6-A12\" \"A6-V12\" \"V6-M12\" \"V6-A12\" \"V6-V12\" \"M12-A12\" \"M12-V12\" ## [36] \"A12-V12\"  Structure and initialization of SYSargs2 SYSargs2 stores all the information and instructions needed for processing a set of input files with a single or many command-line steps within a workflow (i.e. several components of the software or several independent software tools). The SYSargs2 object is created and fully populated with the loadWF and renderWF functions, respectively.\nIn CWL, files with the extension .cwl define the parameters of a chosen command-line step or workflow, while files with the extension .yml define the input variables of command-line steps. Note, input variables provided by a targets file can be passed on to a SYSargs2 instance via the inputvars argument of the renderWF function.\nThe following imports a .cwl file (here hisat2-mapping-se.cwl) for running the short read aligner HISAT2 (Kim, Langmead, and Salzberg 2015). The loadWF and renderWF functions render the proper command-line strings for each sample and software tool.\nlibrary(systemPipeR) targets \u003c- system.file(\"extdata\", \"targets.txt\", package = \"systemPipeR\") dir_path \u003c- system.file(\"extdata/cwl/hisat2/hisat2-se\", package = \"systemPipeR\") WF \u003c- loadWF(targets = targets, wf_file = \"hisat2-mapping-se.cwl\", input_file = \"hisat2-mapping-se.yml\", dir_path = dir_path) WF \u003c- renderWF(WF, inputvars = c(FileName = \"_FASTQ_PATH1_\", SampleName = \"_SampleName_\"))  Several accessor methods are available that are named after the slot names of the SYSargs2 object.\nnames(WF)  ## [1] \"targets\" \"targetsheader\" \"modules\" \"wf\" ## [5] \"clt\" \"yamlinput\" \"cmdlist\" \"input\" ## [9] \"output\" \"cwlfiles\" \"inputvars\"  Of particular interest is the cmdlist() method. It constructs the system commands for running command-line software as specified by a given .cwl file combined with the paths to the input samples (e.g. FASTQ files) provided by a targets file. The example below shows the cmdlist() output for running HISAT2 on the first SE read sample. Evaluating the output of cmdlist() can be very helpful for designing and debugging .cwl files of new command-line software or changing the parameter settings of existing ones.\ncmdlist(WF)[1]  ## $M1A ## $M1A$`hisat2-mapping-se` ## [1] \"hisat2 -S ./results/M1A.sam -x ./data/tair10.fasta -k 1 --min-intronlen 30 --max-intronlen 3000 -U ./data/SRR446027_1.fastq.gz --threads 4\"  The output components of SYSargs2 define the expected output files for each step in the workflow; some of which are the input for the next workflow step, here next SYSargs2 instance (see Figure 2).\noutput(WF)[1]  ## $M1A ## $M1A$`hisat2-mapping-se` ## [1] \"./results/M1A.sam\"  modules(WF)  ## module1 ## \"hisat2/2.1.0\"  targets(WF)[1]  ## $M1A ## $M1A$FileName ## [1] \"./data/SRR446027_1.fastq.gz\" ## ## $M1A$SampleName ## [1] \"M1A\" ## ## $M1A$Factor ## [1] \"M1\" ## ## $M1A$SampleLong ## [1] \"Mock.1h.A\" ## ## $M1A$Experiment ## [1] 1 ## ## $M1A$Date ## [1] \"23-Mar-2012\"  targets.as.df(targets(WF))[1:4, 1:4]  ## FileName SampleName Factor SampleLong ## 1 ./data/SRR446027_1.fastq.gz M1A M1 Mock.1h.A ## 2 ./data/SRR446028_1.fastq.gz M1B M1 Mock.1h.B ## 3 ./data/SRR446029_1.fastq.gz A1A A1 Avr.1h.A ## 4 ./data/SRR446030_1.fastq.gz A1B A1 Avr.1h.B  output(WF)[1]  ## $M1A ## $M1A$`hisat2-mapping-se` ## [1] \"./results/M1A.sam\"  cwlfiles(WF)  ## $cwl ## [1] \"/home/tgirke/R/x86_64-pc-linux-gnu-library/4.0/systemPipeR/extdata/cwl/hisat2/hisat2-se/hisat2-mapping-se.cwl\" ## ## $yml ## [1] \"/home/tgirke/R/x86_64-pc-linux-gnu-library/4.0/systemPipeR/extdata/cwl/hisat2/hisat2-se/hisat2-mapping-se.yml\" ## ## $steps ## [1] \"hisat2-mapping-se\"  inputvars(WF)  ## $FileName ## [1] \"_FASTQ_PATH1_\" ## ## $SampleName ## [1] \"_SampleName_\"  In an ‘R-centric’ rather than a ‘CWL-centric’ workflow design the connectivity among workflow steps is established by writing all relevant output with the writeTargetsout function to a new targets file that serves as input to the next loadWorkflow and renderWF call. By chaining several SYSargs2 steps together one can construct complex workflows involving many sample-level input/output file operations with any combination of command-line or R-based software. Alternatively, a CWL-centric workflow design can be used that defines all/most workflow steps with CWL workflow and parameter files. Due to time and space restrictions, the CWL-centric approach is not covered by this tutorial.\nThird-party software tools Current, systemPipeR provides the param file templates for third-party software tools. A list is provided in the following table.\n  Tool Name  Description  Step      bwa  BWA is a software package for mapping low-divergent sequences against a large reference genome, such as the human genome.  Alignment    Bowtie2  Bowtie 2 is an ultrafast and memory-efficient tool for aligning sequencing reads to long reference sequences.  Alignment    FASTX-Toolkit  FASTX-Toolkit is a collection of command line tools for Short-Reads FASTA/FASTQ files preprocessing.  Read Preprocessing    TransRate  Transrate is software for de-novo transcriptome assembly quality analysis.  Quality    Gsnap  GSNAP is a genomic short-read nucleotide alignment program.  Alignment    Samtools  Samtools is a suite of programs for interacting with high-throughput sequencing data.  Post-processing    Trimmomatic  Trimmomatic is a flexible read trimming tool for Illumina NGS data.  Read Preprocessing    Rsubread  Rsubread is a Bioconductor software package that provides high-performance alignment and read counting functions for RNA-seq reads.  Alignment    Picard  Picard is a set of command line tools for manipulating high-throughput sequencing (HTS) data and formats such as SAM/BAM/CRAM and VCF.  Manipulating HTS data    Busco  BUSCO assesses genome assembly and annotation completeness with Benchmarking Universal Single-Copy Orthologs.  Quality    Hisat2  HISAT2 is a fast and sensitive alignment program for mapping NGS reads (both DNA and RNA) to reference genomes.  Alignment    Tophat2  TopHat is a fast splice junction mapper for RNA-Seq reads.  Alignment    GATK  Variant Discovery in High-Throughput Sequencing Data.  Variant Discovery    STAR  STAR is an ultrafast universal RNA-seq aligner.  Alignment    Trim\\_galore  Trim Galore is a wrapper around Cutadapt and FastQC to consistently apply adapter and quality trimming to FastQ files.  Read Preprocessing    TransDecoder  TransDecoder identifies candidate coding regions within transcript sequences.  Find Coding Regions    Trinity  Trinity assembles transcript sequences from Illumina RNA-Seq data.  denovo Transcriptome Assembly    Trinotate  Trinotate is a comprehensive annotation suite designed for automatic functional annotation of transcriptomes.  Transcriptome Functional Annotation    MACS2  MACS2 identifies transcription factor binding sites in ChIP-seq data.  Peak calling    Kallisto  kallisto is a program for quantifying abundances of transcripts from RNA-Seq data.  Read counting    BCFtools  BCFtools is a program for variant calling and manipulating files in the Variant Call Format (VCF) and its binary counterpart BCF.  Variant Discovery    Bismark  Bismark is a program to map bisulfite treated sequencing reads to a genome of interest and perform methylation calls in a single step.  Bisulfite mapping    Fastqc  FastQC is a quality control tool for high throughput sequence data.  Quality    Blast  BLAST finds regions of similarity between biological sequences.  Blast      Remember, if you desire to run any of these tools, make sure to have the respective software installed on your system and configure in the PATH. You can check as follows:\ntryCL(command = \"grep\")  How to run a Workflow This tutorial introduces the basic ideas and tools needed to build a specific workflow from preconfigured templates.\nLoad sample data and workflow templates library(systemPipeRdata) genWorkenvir(workflow = \"rnaseq\") setwd(\"rnaseq\")  Setup and Requirements To go through this tutorial, you need the following software installed:\n R (version \u003e=3.6.2) systemPipeR package (version \u003e=1.22) Hisat2 (version \u003e= 2.1.0)  If you desire to build your pipeline with any different software, make sure to have the respective software installed and available in your PATH. To make sure if the configuration is correct, on test it with:\ntryCL(command = \"hisat2\") ## 'All set up, proceed!'  Project initialization A SYSargsList object containing all relevant information for running a workflow (here RNA-Seq example) can be constructed as follows.\ngetwd() ## rnaseq script \u003c- \"systemPipeRNAseq.Rmd\" targetspath \u003c- \"targets.txt\" sysargslist \u003c- initWF(script = script, targets = targetspath)  Workflow execution To run workflows from R, there are several possibilities. First, one can run each line in an Rmd or R interactively, or use the runWF functions that allows to run workflows step-wise or from start to finish.\nsysargslist \u003c- configWF(x = sysargslist, input_steps = \"1:3\") sysargslist \u003c- runWF(sysargslist = sysargslist, steps = \"1:2\")  Alternatively, R pipes (%\u003e%) are supported to run individual workflow steps.\nsysargslist \u003c- initWF(script = \"systemPipeRNAseq.Rmd\", overwrite = TRUE) %\u003e% configWF(input_steps = \"1:3\") %\u003e% runWF(steps = \"1:2\")  How to run the workflow on a cluster This section of the tutorial provides an introduction to the usage of the systemPipeR features on a cluster.\nNow open the R markdown script *.Rmdin your R IDE (_e.g._vim-r or RStudio) and run the workflow as outlined below. If you work under Vim-R-Tmux, the following command sequence will connect the user in an interactive session with a node on the cluster. The code of the Rmd script can then be sent from Vim on the login (head) node to an open R session running on the corresponding computer node. This is important since Tmux sessions should not be run on the computer nodes.\nq(\"no\") # closes R session on head node  srun --x11 --partition=short --mem=2gb --cpus-per-task 4 --ntasks 1 --time 2:00:00 --pty bash -l module load R/4.0.3 R  Now check whether your R session is running on a computer node of the cluster and not on a head node.\nsystem(\"hostname\") # should return name of a compute node starting with i or c getwd() # checks current working directory of R session dir() # returns content of current working directory  Parallelization on clusters Alternatively, the computation can be greatly accelerated by processing many files in parallel using several compute nodes of a cluster, where a scheduling/queuing system is used for load balancing. For this the clusterRun function submits the computing requests to the scheduler using the run specifications defined by runCommandline.\nTo avoid over-subscription of CPU cores on the compute nodes, the value from yamlinput(args)['thread'] is passed on to the submission command, here ncpus in the resources list object. The number of independent parallel cluster processes is defined under the Njobs argument. The following example will run 18 processes in parallel using for each 4 CPU cores. If the resources available on a cluster allow running all 18 processes at the same time then the shown sample submission will utilize in total 72 CPU cores. Note, clusterRun can be used with most queueing systems as it is based on utilities from the batchtools package which supports the use of template files (*.tmpl) for defining the run parameters of different schedulers. To run the following code, one needs to have both a conf file (see .batchtools.conf.R samples here) and a template file (see *.tmpl samples here) for the queueing available on a system. The following example uses the sample conf and template files for the Slurm scheduler provided by this package.\nlibrary(batchtools) targetspath \u003c- system.file(\"extdata\", \"targetsPE.txt\", package = \"systemPipeR\") dir_path \u003c- system.file(\"extdata/cwl/hisat2/hisat2-pe\", package = \"systemPipeR\") args \u003c- loadWorkflow(targets = targetspath, wf_file = \"hisat2-mapping-pe.cwl\", input_file = \"hisat2-mapping-pe.yml\", dir_path = dir_path) args \u003c- renderWF(args, inputvars = c(FileName1 = \"_FASTQ_PATH1_\", FileName2 = \"_FASTQ_PATH2_\", SampleName = \"_SampleName_\")) resources \u003c- list(walltime = 120, ntasks = 1, ncpus = 4, memory = 1024) reg \u003c- clusterRun(args, FUN = runCommandline, more.args = list(args = args, make_bam = TRUE, dir = FALSE), conffile = \".batchtools.conf.R\", template = \"batchtools.slurm.tmpl\", Njobs = 18, runid = \"01\", resourceList = resources) getStatus(reg = reg) waitForJobs(reg = reg)  Workflow initialization with templates Workflow templates are provided via systemPipeRdata and GitHub. Instances of these workflows can be created with a single command.\nRNA-Seq sample Load the RNA-Seq sample workflow into your current working directory.\nlibrary(systemPipeRdata) genWorkenvir(workflow = \"rnaseq\") setwd(\"rnaseq\")  Run workflow Next, run the chosen sample workflow systemPipeRNAseq (PDF, Rmd) by executing from the command-line make -B within the rnaseq directory. Alternatively, one can run the code from the provided *.Rmd template file from within R interactively.\nThe workflow includes following steps:\n Read preprocessing  Quality filtering (trimming) FASTQ quality report   Alignments: Tophat2 (or any other RNA-Seq aligner) Alignment stats Read counting Sample-wise correlation analysis Analysis of differentially expressed genes (DEGs) GO term enrichment analysis Gene-wise clustering  ChIP-Seq sample Load the ChIP-Seq sample workflow into your current working directory.\nlibrary(systemPipeRdata) genWorkenvir(workflow = \"chipseq\") setwd(\"chipseq\")  Run workflow Next, run the chosen sample workflow systemPipeChIPseq_single (PDF, Rmd) by executing from the command-line make -B within the chipseq directory. Alternatively, one can run the code from the provided *.Rmd template file from within R interactively.\nThe workflow includes the following steps:\n Read preprocessing  Quality filtering (trimming) FASTQ quality report   Alignments: Bowtie2 or rsubread Alignment stats Peak calling: MACS2, BayesPeak Peak annotation with genomic context Differential binding analysis GO term enrichment analysis Motif analysis  VAR-Seq sample VAR-Seq workflow for the single machine Load the VAR-Seq sample workflow into your current working directory.\nlibrary(systemPipeRdata) genWorkenvir(workflow = \"varseq\") setwd(\"varseq\")  Run workflow Next, run the chosen sample workflow systemPipeVARseq_single (PDF, Rmd) by executing from the command-line make -B within the varseq directory. Alternatively, one can run the code from the provided *.Rmd template file from within R interactively.\nThe workflow includes following steps:\n Read preprocessing  Quality filtering (trimming) FASTQ quality report   Alignments: gsnap, bwa Variant calling: VariantTools, GATK, BCFtools Variant filtering: VariantTools and VariantAnnotation Variant annotation: VariantAnnotation Combine results from many samples Summary statistics of samples  VAR-Seq workflow for computer cluster The workflow template provided for this step is called systemPipeVARseq.Rmd (PDF, Rmd). It runs the above VAR-Seq workflow in parallel on multiple compute nodes of an HPC system using Slurm as the scheduler.\nRibo-Seq sample Load the Ribo-Seq sample workflow into your current working directory.\nlibrary(systemPipeRdata) genWorkenvir(workflow = \"riboseq\") setwd(\"riboseq\")  Run workflow Next, run the chosen sample workflow systemPipeRIBOseq (PDF, Rmd) by executing from the command-line make -B within the ribseq directory. Alternatively, one can run the code from the provided *.Rmd template file from within R interactively.\nThe workflow includes following steps:\n Read preprocessing  Adaptor trimming and quality filtering FASTQ quality report   Alignments: Tophat2 (or any other RNA-Seq aligner) Alignment stats Compute read distribution across genomic features Adding custom features to the workflow (e.g. uORFs) Genomic read coverage along with transcripts Read counting Sample-wise correlation analysis Analysis of differentially expressed genes (DEGs) GO term enrichment analysis Gene-wise clustering Differential ribosome binding (translational efficiency)  Version information Note: the most recent version of this tutorial can be found here.\nsessionInfo()  ## R version 4.0.5 (2021-03-31) ## Platform: x86_64-pc-linux-gnu (64-bit) ## Running under: Debian GNU/Linux 10 (buster) ## ## Matrix products: default ## BLAS: /usr/lib/x86_64-linux-gnu/blas/libblas.so.3.8.0 ## LAPACK: /usr/lib/x86_64-linux-gnu/lapack/liblapack.so.3.8.0 ## ## locale: ## [1] LC_CTYPE=en_US.UTF-8 LC_NUMERIC=C ## [3] LC_TIME=en_US.UTF-8 LC_COLLATE=en_US.UTF-8 ## [5] LC_MONETARY=en_US.UTF-8 LC_MESSAGES=en_US.UTF-8 ## [7] LC_PAPER=en_US.UTF-8 LC_NAME=C ## [9] LC_ADDRESS=C LC_TELEPHONE=C ## [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C ## ## attached base packages: ## [1] stats4 parallel stats graphics grDevices utils datasets ## [8] methods base ## ## other attached packages: ## [1] magrittr_2.0.1 batchtools_0.9.14 ## [3] ape_5.4-1 ggplot2_3.3.2 ## [5] systemPipeR_1.24.5 ShortRead_1.48.0 ## [7] GenomicAlignments_1.26.0 SummarizedExperiment_1.20.0 ## [9] Biobase_2.50.0 MatrixGenerics_1.2.0 ## [11] matrixStats_0.57.0 BiocParallel_1.24.1 ## [13] Rsamtools_2.6.0 Biostrings_2.58.0 ## [15] XVector_0.30.0 GenomicRanges_1.42.0 ## [17] GenomeInfoDb_1.26.1 IRanges_2.24.0 ## [19] S4Vectors_0.28.0 BiocGenerics_0.36.0 ## [21] BiocStyle_2.18.0 ## ## loaded via a namespace (and not attached): ## [1] colorspace_2.0-0 rjson_0.2.20 hwriter_1.3.2 ## [4] ellipsis_0.3.1 rstudioapi_0.13 bit64_4.0.5 ## [7] AnnotationDbi_1.52.0 xml2_1.3.2 codetools_0.2-18 ## [10] splines_4.0.5 knitr_1.30 jsonlite_1.7.1 ## [13] annotate_1.68.0 GO.db_3.12.1 dbplyr_2.0.0 ## [16] png_0.1-7 pheatmap_1.0.12 graph_1.68.0 ## [19] BiocManager_1.30.10 compiler_4.0.5 httr_1.4.2 ## [22] backports_1.2.0 GOstats_2.56.0 assertthat_0.2.1 ## [25] Matrix_1.3-2 limma_3.46.0 formatR_1.7 ## [28] htmltools_0.5.1.1 prettyunits_1.1.1 tools_4.0.5 ## [31] gtable_0.3.0 glue_1.4.2 GenomeInfoDbData_1.2.4 ## [34] Category_2.56.0 dplyr_1.0.2 rsvg_2.1 ## [37] rappdirs_0.3.1 V8_3.4.0 Rcpp_1.0.5 ## [40] jquerylib_0.1.3 vctrs_0.3.5 svglite_2.0.0 ## [43] nlme_3.1-149 blogdown_1.2 rtracklayer_1.50.0 ## [46] xfun_0.22 stringr_1.4.0 rvest_0.3.6 ## [49] lifecycle_0.2.0 XML_3.99-0.5 edgeR_3.32.0 ## [52] zlibbioc_1.36.0 scales_1.1.1 BSgenome_1.58.0 ## [55] VariantAnnotation_1.36.0 hms_0.5.3 RBGL_1.66.0 ## [58] RColorBrewer_1.1-2 yaml_2.2.1 curl_4.3 ## [61] memoise_1.1.0 sass_0.3.1 biomaRt_2.46.0 ## [64] latticeExtra_0.6-29 stringi_1.5.3 RSQLite_2.2.1 ## [67] genefilter_1.72.0 checkmate_2.0.0 GenomicFeatures_1.42.1 ## [70] DOT_0.1 systemfonts_1.0.1 rlang_0.4.8 ## [73] pkgconfig_2.0.3 bitops_1.0-6 evaluate_0.14 ## [76] lattice_0.20-41 purrr_0.3.4 bit_4.0.4 ## [79] tidyselect_1.1.0 GSEABase_1.52.0 AnnotationForge_1.32.0 ## [82] bookdown_0.21 R6_2.5.0 generics_0.1.0 ## [85] base64url_1.4 DelayedArray_0.16.0 DBI_1.1.0 ## [88] withr_2.3.0 pillar_1.4.7 survival_3.2-10 ## [91] RCurl_1.98-1.2 tibble_3.0.4 crayon_1.3.4 ## [94] BiocFileCache_1.14.0 rmarkdown_2.7 jpeg_0.1-8.1 ## [97] progress_1.2.2 locfit_1.5-9.4 grid_4.0.5 ## [100] data.table_1.13.2 blob_1.2.1 Rgraphviz_2.34.0 ## [103] webshot_0.5.2 digest_0.6.27 xtable_1.8-4 ## [106] brew_1.0-6 openssl_1.4.3 munsell_0.5.0 ## [109] viridisLite_0.3.0 kableExtra_1.3.4 bslib_0.2.4 ## [112] askpass_1.1  Funding This project is funded by NSF award ABI-1661152.\nReferences H Backman, Tyler W, and Thomas Girke. 2016. “systemPipeR: NGS workflow and report generation environment.” BMC Bioinformatics 17 (1): 388. https://doi.org/10.1186/s12859-016-1241-0.\n Howard, Brian E, Qiwen Hu, Ahmet Can Babaoglu, Manan Chandra, Monica Borghi, Xiaoping Tan, Luyan He, et al. 2013. “High-Throughput RNA Sequencing of Pseudomonas-Infected Arabidopsis Reveals Hidden Transcriptome Complexity and Novel Splice Variants.” PLoS One 8 (10): e74183. https://doi.org/10.1371/journal.pone.0074183.\n Kim, Daehwan, Ben Langmead, and Steven L Salzberg. 2015. “HISAT: A Fast Spliced Aligner with Low Memory Requirements.” Nat. Methods 12 (4): 357–60.\n Kim, Daehwan, Geo Pertea, Cole Trapnell, Harold Pimentel, Ryan Kelley, and Steven L Salzberg. 2013. “TopHat2: Accurate Alignment of Transcriptomes in the Presence of Insertions, Deletions and Gene Fusions.” Genome Biol. 14 (4): R36. https://doi.org/10.1186/gb-2013-14-4-r36.\n Langmead, Ben, and Steven L Salzberg. 2012. “Fast Gapped-Read Alignment with Bowtie 2.” Nat. Methods 9 (4): 357–59. https://doi.org/10.1038/nmeth.1923.\n Lawrence, Michael, Wolfgang Huber, Hervé Pagès, Patrick Aboyoun, Marc Carlson, Robert Gentleman, Martin T Morgan, and Vincent J Carey. 2013. “Software for Computing and Annotating Genomic Ranges.” PLoS Comput. Biol. 9 (8): e1003118. https://doi.org/10.1371/journal.pcbi.1003118.\n Li, H, and R Durbin. 2009. “Fast and Accurate Short Read Alignment with Burrows-Wheeler Transform.” Bioinformatics 25 (14): 1754–60. https://doi.org/10.1093/bioinformatics/btp324.\n Li, Heng. 2013. “Aligning Sequence Reads, Clone Sequences and Assembly Contigs with BWA-MEM.” arXiv [q-Bio.GN], March. http://arxiv.org/abs/1303.3997.\n Liao, Yang, Gordon K Smyth, and Wei Shi. 2013. “The Subread Aligner: Fast, Accurate and Scalable Read Mapping by Seed-and-Vote.” Nucleic Acids Res. 41 (10): e108. https://doi.org/10.1093/nar/gkt214.\n Wu, T D, and S Nacu. 2010. “Fast and SNP-tolerant Detection of Complex Variants and Splicing in Short Reads.” Bioinformatics 26 (7): 873–81. https://doi.org/10.1093/bioinformatics/btq057.\n  ","categories":"","description":"","excerpt":" pre code { white-space: pre !important; overflow-x: scroll …","ref":"/tutorials/systempiper/systempiper/","tags":"","title":"systemPipeR: Workflow design and reporting generation environment"},{"body":"pre code { white-space: pre !important; overflow-x: scroll !important; word-break: keep-all !important; word-wrap: initial !important; }  document.addEventListener(\"DOMContentLoaded\", function() { document.querySelector(\"h1\").className = \"title\"; });  document.addEventListener(\"DOMContentLoaded\", function() { var links = document.links; for (var i = 0, linksLength = links.length; i Introduction Users want to provide here background information about the design of their RNA-Seq project.\nSamples and environment settings Environment settings and input data Typically, the user wants to record here the sources and versions of the reference genome sequence along with the corresponding annotations. In the provided sample data set all data inputs are stored in a data subdirectory and all results will be written to a separate results directory, while the systemPipeRNAseq.Rmd script and the targets file are expected to be located in the parent directory. The R session is expected to run from this parent directory.\nsystemPipeRdata package is a helper package to generate a fully populated systemPipeR workflow environment in the current working directory with a single command. All the instruction for generating the workflow are provide in the systemPipeRdata vignette here.\nThe mini sample FASTQ files used by this report as well as the associated reference genome files can be loaded via the systemPipeRdata package. The chosen data set SRP010938 contains 18 paired-end (PE) read sets from Arabidposis thaliana (Howard et al. 2013). To minimize processing time during testing, each FASTQ file has been subsetted to 90,000-100,000 randomly sampled PE reads that map to the first 100,000 nucleotides of each chromosome of the A. thalina genome. The corresponding reference genome sequence (FASTA) and its GFF annotation files have been truncated accordingly. This way the entire test sample data set is less than 200MB in storage space. A PE read set has been chosen for this test data set for flexibility, because it can be used for testing both types of analysis routines requiring either SE (single end) reads or PE reads.\nRequired packages and resources The systemPipeR package needs to be loaded to perform the analysis steps shown in this report (H Backman and Girke 2016).\nlibrary(systemPipeR)  To apply workflows to custom data, the user needs to modify the targets file and if necessary update the corresponding parameter (.cwl and .yml) files. A collection of pre-generated .cwl and .yml files are provided in the param/cwl subdirectory of each workflow template. They are also viewable in the GitHub repository of systemPipeRdata (see here). For more information of the structure of the targets file, please consult the documentation here. More details about the new parameter files from systemPipeR can be found here.\nExperiment definition provided by targets file The targets file defines all FASTQ files and sample comparisons of the analysis workflow.\ntargetspath \u003c- system.file(\"extdata\", \"targetsPE.txt\", package = \"systemPipeR\") targets \u003c- read.delim(targetspath, comment.char = \"#\")[, 1:4] targets  ## FileName1 FileName2 ## 1 ./data/SRR446027_1.fastq.gz ./data/SRR446027_2.fastq.gz ## 2 ./data/SRR446028_1.fastq.gz ./data/SRR446028_2.fastq.gz ## 3 ./data/SRR446029_1.fastq.gz ./data/SRR446029_2.fastq.gz ## 4 ./data/SRR446030_1.fastq.gz ./data/SRR446030_2.fastq.gz ## 5 ./data/SRR446031_1.fastq.gz ./data/SRR446031_2.fastq.gz ## 6 ./data/SRR446032_1.fastq.gz ./data/SRR446032_2.fastq.gz ## 7 ./data/SRR446033_1.fastq.gz ./data/SRR446033_2.fastq.gz ## 8 ./data/SRR446034_1.fastq.gz ./data/SRR446034_2.fastq.gz ## 9 ./data/SRR446035_1.fastq.gz ./data/SRR446035_2.fastq.gz ## 10 ./data/SRR446036_1.fastq.gz ./data/SRR446036_2.fastq.gz ## 11 ./data/SRR446037_1.fastq.gz ./data/SRR446037_2.fastq.gz ## 12 ./data/SRR446038_1.fastq.gz ./data/SRR446038_2.fastq.gz ## 13 ./data/SRR446039_1.fastq.gz ./data/SRR446039_2.fastq.gz ## 14 ./data/SRR446040_1.fastq.gz ./data/SRR446040_2.fastq.gz ## 15 ./data/SRR446041_1.fastq.gz ./data/SRR446041_2.fastq.gz ## 16 ./data/SRR446042_1.fastq.gz ./data/SRR446042_2.fastq.gz ## 17 ./data/SRR446043_1.fastq.gz ./data/SRR446043_2.fastq.gz ## 18 ./data/SRR446044_1.fastq.gz ./data/SRR446044_2.fastq.gz ## SampleName Factor ## 1 M1A M1 ## 2 M1B M1 ## 3 A1A A1 ## 4 A1B A1 ## 5 V1A V1 ## 6 V1B V1 ## 7 M6A M6 ## 8 M6B M6 ## 9 A6A A6 ## 10 A6B A6 ## 11 V6A V6 ## 12 V6B V6 ## 13 M12A M12 ## 14 M12B M12 ## 15 A12A A12 ## 16 A12B A12 ## 17 V12A V12 ## 18 V12B V12  Read preprocessing Read quality filtering and trimming The function preprocessReads allows to apply predefined or custom read preprocessing functions to all FASTQ files referenced in a SYSargs2 container, such as quality filtering or adapter trimming routines. The paths to the resulting output FASTQ files are stored in the output slot of the SYSargs2 object. The following example performs adapter trimming with the trimLRPatterns function from the Biostrings package. After the trimming step a new targets file is generated (here targets_trim.txt) containing the paths to the trimmed FASTQ files. The new targets file can be used for the next workflow step with an updated SYSargs2 instance, e.g. running the NGS alignments using the trimmed FASTQ files.\nConstruct SYSargs2 object from cwl and yml param and targets files.\ndir_path \u003c- system.file(\"extdata/cwl/preprocessReads/trim-pe\", package = \"systemPipeR\") trim \u003c- loadWorkflow(targets = targetspath, wf_file = \"trim-pe.cwl\", input_file = \"trim-pe.yml\", dir_path = dir_path) trim \u003c- renderWF(trim, inputvars = c(FileName1 = \"_FASTQ_PATH1_\", FileName2 = \"_FASTQ_PATH2_\", SampleName = \"_SampleName_\")) trim output(trim)[1:2]  preprocessReads(args = trim, Fct = \"trimLRPatterns(Rpattern='GCCCGGGTAA', subject=fq)\", batchsize = 1e+05, overwrite = TRUE, compress = TRUE) writeTargetsout(x = trim, file = \"targets_trim.txt\", step = 1, new_col = c(\"FileName1\", \"FileName2\"), new_col_output_index = c(1, 2), overwrite = TRUE)  FASTQ quality report The following seeFastq and seeFastqPlot functions generate and plot a series of useful quality statistics for a set of FASTQ files including per cycle quality box plots, base proportions, base-level quality trends, relative k-mer diversity, length and occurrence distribution of reads, number of reads above quality cutoffs and mean quality distribution. The results are written to a PDF file named fastqReport.pdf.\nfqlist \u003c- seeFastq(fastq = infile1(trim), batchsize = 10000, klength = 8) pdf(\"./results/fastqReport.pdf\", height = 18, width = 4 * length(fqlist)) seeFastqPlot(fqlist) dev.off()  Figure 1: FASTQ quality report for 18 samples\n  Alignments Read mapping with HISAT2 The following steps will demonstrate how to use the short read aligner Hisat2 (Kim, Langmead, and Salzberg 2015) in both interactive job submissions and batch submissions to queuing systems of clusters using the systemPipeR's new CWL command-line interface.\nBuild Hisat2 index.\ndir_path \u003c- system.file(\"extdata/cwl/hisat2/hisat2-idx\", package = \"systemPipeR\") idx \u003c- loadWorkflow(targets = NULL, wf_file = \"hisat2-index.cwl\", input_file = \"hisat2-index.yml\", dir_path = dir_path) idx \u003c- renderWF(idx) idx cmdlist(idx) ### Run runCommandline(idx, make_bam = FALSE)  The parameter settings of the aligner are defined in the hisat2-mapping-se.cwl and hisat2-mapping-se.yml files. The following shows how to construct the corresponding SYSargs2 object, here args.\ndir_path \u003c- system.file(\"extdata/cwl/hisat2/hisat2-pe\", package = \"systemPipeR\") args \u003c- loadWorkflow(targets = targetspath, wf_file = \"hisat2-mapping-pe.cwl\", input_file = \"hisat2-mapping-pe.yml\", dir_path = dir_path) args \u003c- renderWF(args, inputvars = c(FileName1 = \"_FASTQ_PATH1_\", FileName2 = \"_FASTQ_PATH2_\", SampleName = \"_SampleName_\")) args  ## Instance of 'SYSargs2': ## Slot names/accessors: ## targets: 18 (M1A...V12B), targetsheader: 4 (lines) ## modules: 1 ## wf: 0, clt: 1, yamlinput: 8 (components) ## input: 18, output: 18 ## cmdlist: 18 ## WF Steps: ## 1. hisat2-mapping-pe (rendered: TRUE)  cmdlist(args)[1:2]  ## $M1A ## $M1A$`hisat2-mapping-pe` ## [1] \"hisat2 -S ./results/M1A.sam -x ./data/tair10.fasta -k 1 --min-intronlen 30 --max-intronlen 3000 -1 ./data/SRR446027_1.fastq.gz -2 ./data/SRR446027_2.fastq.gz --threads 4\" ## ## ## $M1B ## $M1B$`hisat2-mapping-pe` ## [1] \"hisat2 -S ./results/M1B.sam -x ./data/tair10.fasta -k 1 --min-intronlen 30 --max-intronlen 3000 -1 ./data/SRR446028_1.fastq.gz -2 ./data/SRR446028_2.fastq.gz --threads 4\"  output(args)[1:2]  ## $M1A ## $M1A$`hisat2-mapping-pe` ## [1] \"./results/M1A.sam\" ## ## ## $M1B ## $M1B$`hisat2-mapping-pe` ## [1] \"./results/M1B.sam\"  Interactive job submissions in a single machine To simplify the short read alignment execution for the user, the command-line can be run with the runCommandline function. The execution will be on a single machine without submitting to a queuing system of a computer cluster. This way, the input FASTQ files will be processed sequentially. By default runCommandline auto detects SAM file outputs and converts them to sorted and indexed BAM files, using internally the Rsamtools package. Besides, runCommandline allows the user to create a dedicated results folder for each workflow and a sub-folder for each sample defined in the targets file. This includes all the output and log files for each step. When these options are used, the output location will be updated by default and can be assigned to the same object.\n### Run single Machine args \u003c- runCommandline(args)  Parallelization on clusters Alternatively, the computation can be greatly accelerated by processing many files in parallel using several compute nodes of a cluster, where a scheduling/queuing system is used for load balancing. For this the clusterRun function submits the computing requests to the scheduler using the run specifications defined by runCommandline.\nTo avoid over-subscription of CPU cores on the compute nodes, the value from yamlinput(args)['thread'] is passed on to the submission command, here ncpus in the resources list object. The number of independent parallel cluster processes is defined under the Njobs argument. The following example will run 18 processes in parallel using for each 4 CPU cores. If the resources available on a cluster allow running all 18 processes at the same time then the shown sample submission will utilize in total 72 CPU cores. Note, clusterRun can be used with most queueing systems as it is based on utilities from the batchtools package which supports the use of template files (*.tmpl) for defining the run parameters of different schedulers. To run the following code, one needs to have both a conf file (see .batchtools.conf.R samples here) and a template file (see *.tmpl samples here) for the queueing available on a system. The following example uses the sample conf and template files for the Slurm scheduler provided by this package.\nlibrary(batchtools) resources \u003c- list(walltime = 120, ntasks = 1, ncpus = 4, memory = 1024) reg \u003c- clusterRun(args, FUN = runCommandline, more.args = list(args = args, make_bam = TRUE, dir = FALSE), conffile = \".batchtools.conf.R\", template = \"batchtools.slurm.tmpl\", Njobs = 18, runid = \"01\", resourceList = resources) getStatus(reg = reg) waitForJobs(reg = reg) args \u003c- output_update(args, dir = FALSE, replace = TRUE, extension = c(\".sam\", \".bam\")) ## Updates the output(args) to the right location in the subfolders output(args)  Check whether all BAM files have been created.\noutpaths \u003c- subsetWF(args, slot = \"output\", subset = 1, index = 1) file.exists(outpaths)  Read and alignment stats The following provides an overview of the number of reads in each sample and how many of them aligned to the reference.\nread_statsDF \u003c- alignStats(args = args) write.table(read_statsDF, \"results/alignStats.xls\", row.names = FALSE, quote = FALSE, sep = \"\\t\")  The following shows the alignment statistics for a sample file provided by the systemPipeR package.\nread.table(system.file(\"extdata\", \"alignStats.xls\", package = \"systemPipeR\"), header = TRUE)[1:4, ]  ## FileName Nreads2x Nalign Perc_Aligned Nalign_Primary ## 1 M1A 192918 177961 92.24697 177961 ## 2 M1B 197484 159378 80.70426 159378 ## 3 A1A 189870 176055 92.72397 176055 ## 4 A1B 188854 147768 78.24457 147768 ## Perc_Aligned_Primary ## 1 92.24697 ## 2 80.70426 ## 3 92.72397 ## 4 78.24457  Create symbolic links for viewing BAM files in IGV The symLink2bam function creates symbolic links to view the BAM alignment files in a genome browser such as IGV. The corresponding URLs are written to a file with a path specified under urlfile in the results directory.\nsymLink2bam(sysargs = args, htmldir = c(\"~/.html/\", \"somedir/\"), urlbase = \"http://cluster.hpcc.ucr.edu/~tgirke/\", urlfile = \"./results/IGVurl.txt\")  Read quantification Read counting with summarizeOverlaps in parallel mode using multiple cores Reads overlapping with annotation ranges of interest are counted for each sample using the summarizeOverlaps function (Lawrence et al. 2013). The read counting is preformed for exonic gene regions in a non-strand-specific manner while ignoring overlaps among different genes. Subsequently, the expression count values are normalized by reads per kp per million mapped reads (RPKM). The raw read count table (countDFeByg.xls) and the corresponding RPKM table (rpkmDFeByg.xls) are written to separate files in the directory of this project. Parallelization is achieved with the BiocParallel package, here using 8 CPU cores.\nlibrary(\"GenomicFeatures\") library(BiocParallel) txdb \u003c- makeTxDbFromGFF(file = \"data/tair10.gff\", format = \"gff\", dataSource = \"TAIR\", organism = \"Arabidopsis thaliana\") saveDb(txdb, file = \"./data/tair10.sqlite\") txdb \u003c- loadDb(\"./data/tair10.sqlite\") outpaths \u003c- subsetWF(args, slot = \"output\", subset = 1, index = 1) (align \u003c- readGAlignments(outpaths[1])) # Demonstrates how to read bam file into R eByg \u003c- exonsBy(txdb, by = c(\"gene\")) bfl \u003c- BamFileList(outpaths, yieldSize = 50000, index = character()) multicoreParam \u003c- MulticoreParam(workers = 2) register(multicoreParam) registered() counteByg \u003c- bplapply(bfl, function(x) summarizeOverlaps(eByg, x, mode = \"Union\", ignore.strand = TRUE, inter.feature = FALSE, singleEnd = TRUE)) countDFeByg \u003c- sapply(seq(along = counteByg), function(x) assays(counteByg[[x]])$counts) rownames(countDFeByg) \u003c- names(rowRanges(counteByg[[1]])) colnames(countDFeByg) \u003c- names(bfl) rpkmDFeByg \u003c- apply(countDFeByg, 2, function(x) returnRPKM(counts = x, ranges = eByg)) write.table(countDFeByg, \"results/countDFeByg.xls\", col.names = NA, quote = FALSE, sep = \"\\t\") write.table(rpkmDFeByg, \"results/rpkmDFeByg.xls\", col.names = NA, quote = FALSE, sep = \"\\t\")  Sample of data slice of count table\nread.delim(\"results/countDFeByg.xls\", row.names = 1, check.names = FALSE)[1:4, 1:5]  Sample of data slice of RPKM table\nread.delim(\"results/rpkmDFeByg.xls\", row.names = 1, check.names = FALSE)[1:4, 1:4]  Note, for most statistical differential expression or abundance analysis methods, such as edgeR or DESeq2, the raw count values should be used as input. The usage of RPKM values should be restricted to specialty applications required by some users, e.g. manually comparing the expression levels among different genes or features.\nSample-wise correlation analysis The following computes the sample-wise Spearman correlation coefficients from the rlog transformed expression values generated with the DESeq2 package. After transformation to a distance matrix, hierarchical clustering is performed with the hclust function and the result is plotted as a dendrogram (also see file sample_tree.pdf).\nlibrary(DESeq2, quietly = TRUE) library(ape, warn.conflicts = FALSE) countDF \u003c- as.matrix(read.table(\"./results/countDFeByg.xls\")) colData \u003c- data.frame(row.names = targets.as.df(targets(args))$SampleName, condition = targets.as.df(targets(args))$Factor) dds \u003c- DESeqDataSetFromMatrix(countData = countDF, colData = colData, design = ~condition) d \u003c- cor(assay(rlog(dds)), method = \"spearman\") hc \u003c- hclust(dist(1 - d)) pdf(\"results/sample_tree.pdf\") plot.phylo(as.phylo(hc), type = \"p\", edge.col = \"blue\", edge.width = 2, show.node.label = TRUE, no.margin = TRUE) dev.off()  Figure 2: Correlation dendrogram of samples\n  Analysis of DEGs The analysis of differentially expressed genes (DEGs) is performed with the glm method of the edgeR package (Robinson, McCarthy, and Smyth 2010). The sample comparisons used by this analysis are defined in the header lines of the targets.txt file starting with \u003cCMP\u003e.\nRun edgeR library(edgeR) countDF \u003c- read.delim(\"results/countDFeByg.xls\", row.names = 1, check.names = FALSE) targets \u003c- read.delim(\"targetsPE.txt\", comment = \"#\") cmp \u003c- readComp(file = \"targetsPE.txt\", format = \"matrix\", delim = \"-\") edgeDF \u003c- run_edgeR(countDF = countDF, targets = targets, cmp = cmp[[1]], independent = FALSE, mdsplot = \"\")  Add gene descriptions\nlibrary(\"biomaRt\") m \u003c- useMart(\"plants_mart\", dataset = \"athaliana_eg_gene\", host = \"plants.ensembl.org\") desc \u003c- getBM(attributes = c(\"tair_locus\", \"description\"), mart = m) desc \u003c- desc[!duplicated(desc[, 1]), ] descv \u003c- as.character(desc[, 2]) names(descv) \u003c- as.character(desc[, 1]) edgeDF \u003c- data.frame(edgeDF, Desc = descv[rownames(edgeDF)], check.names = FALSE) write.table(edgeDF, \"./results/edgeRglm_allcomp.xls\", quote = FALSE, sep = \"\\t\", col.names = NA)  Plot DEG results Filter and plot DEG results for up and down regulated genes. The definition of up and down is given in the corresponding help file. To open it, type ?filterDEGs in the R console.\nedgeDF \u003c- read.delim(\"results/edgeRglm_allcomp.xls\", row.names = 1, check.names = FALSE) pdf(\"results/DEGcounts.pdf\") DEG_list \u003c- filterDEGs(degDF = edgeDF, filter = c(Fold = 2, FDR = 20)) dev.off() write.table(DEG_list$Summary, \"./results/DEGcounts.xls\", quote = FALSE, sep = \"\\t\", row.names = FALSE)  Figure 3: Up and down regulated DEGs with FDR of 1%\n  Venn diagrams of DEG sets The overLapper function can compute Venn intersects for large numbers of sample sets (up to 20 or more) and plots 2-5 way Venn diagrams. A useful feature is the possibility to combine the counts from several Venn comparisons with the same number of sample sets in a single Venn diagram (here for 4 up and down DEG sets).\nvennsetup \u003c- overLapper(DEG_list$Up[6:9], type = \"vennsets\") vennsetdown \u003c- overLapper(DEG_list$Down[6:9], type = \"vennsets\") pdf(\"results/vennplot.pdf\") vennPlot(list(vennsetup, vennsetdown), mymain = \"\", mysub = \"\", colmode = 2, ccol = c(\"blue\", \"red\")) dev.off()  Figure 4: Venn Diagram for 4 Up and Down DEG Sets\n  GO term enrichment analysis Obtain gene-to-GO mappings The following shows how to obtain gene-to-GO mappings from biomaRt (here for A. thaliana) and how to organize them for the downstream GO term enrichment analysis. Alternatively, the gene-to-GO mappings can be obtained for many organisms from Bioconductor’s *.db genome annotation packages or GO annotation files provided by various genome databases. For each annotation this relatively slow preprocessing step needs to be performed only once. Subsequently, the preprocessed data can be loaded with the load function as shown in the next subsection.\nlibrary(\"biomaRt\") listMarts() # To choose BioMart database listMarts(host = \"plants.ensembl.org\") m \u003c- useMart(\"plants_mart\", host = \"plants.ensembl.org\") listDatasets(m) m \u003c- useMart(\"plants_mart\", dataset = \"athaliana_eg_gene\", host = \"plants.ensembl.org\") listAttributes(m) # Choose data types you want to download go \u003c- getBM(attributes = c(\"go_id\", \"tair_locus\", \"namespace_1003\"), mart = m) go \u003c- go[go[, 3] != \"\", ] go[, 3] \u003c- as.character(go[, 3]) go[go[, 3] == \"molecular_function\", 3] \u003c- \"F\" go[go[, 3] == \"biological_process\", 3] \u003c- \"P\" go[go[, 3] == \"cellular_component\", 3] \u003c- \"C\" go[1:4, ] dir.create(\"./data/GO\") write.table(go, \"data/GO/GOannotationsBiomart_mod.txt\", quote = FALSE, row.names = FALSE, col.names = FALSE, sep = \"\\t\") catdb \u003c- makeCATdb(myfile = \"data/GO/GOannotationsBiomart_mod.txt\", lib = NULL, org = \"\", colno = c(1, 2, 3), idconv = NULL) save(catdb, file = \"data/GO/catdb.RData\")  Batch GO term enrichment analysis Apply the enrichment analysis to the DEG sets obtained the above differential expression analysis. Note, in the following example the FDR filter is set here to an unreasonably high value, simply because of the small size of the toy data set used in this vignette. Batch enrichment analysis of many gene sets is performed with the function. When method=all, it returns all GO terms passing the p-value cutoff specified under the cutoff arguments. When method=slim, it returns only the GO terms specified under the myslimv argument. The given example shows how a GO slim vector for a specific organism can be obtained from BioMart.\nlibrary(\"biomaRt\") load(\"data/GO/catdb.RData\") DEG_list \u003c- filterDEGs(degDF = edgeDF, filter = c(Fold = 2, FDR = 50), plot = FALSE) up_down \u003c- DEG_list$UporDown names(up_down) \u003c- paste(names(up_down), \"_up_down\", sep = \"\") up \u003c- DEG_list$Up names(up) \u003c- paste(names(up), \"_up\", sep = \"\") down \u003c- DEG_list$Down names(down) \u003c- paste(names(down), \"_down\", sep = \"\") DEGlist \u003c- c(up_down, up, down) DEGlist \u003c- DEGlist[sapply(DEGlist, length) \u003e 0] BatchResult \u003c- GOCluster_Report(catdb = catdb, setlist = DEGlist, method = \"all\", id_type = \"gene\", CLSZ = 2, cutoff = 0.9, gocats = c(\"MF\", \"BP\", \"CC\"), recordSpecGO = NULL) library(\"biomaRt\") m \u003c- useMart(\"plants_mart\", dataset = \"athaliana_eg_gene\", host = \"plants.ensembl.org\") goslimvec \u003c- as.character(getBM(attributes = c(\"goslim_goa_accession\"), mart = m)[, 1]) BatchResultslim \u003c- GOCluster_Report(catdb = catdb, setlist = DEGlist, method = \"slim\", id_type = \"gene\", myslimv = goslimvec, CLSZ = 10, cutoff = 0.01, gocats = c(\"MF\", \"BP\", \"CC\"), recordSpecGO = NULL)  Plot batch GO term results The data.frame generated by GOCluster can be plotted with the goBarplot function. Because of the variable size of the sample sets, it may not always be desirable to show the results from different DEG sets in the same bar plot. Plotting single sample sets is achieved by subsetting the input data frame as shown in the first line of the following example.\ngos \u003c- BatchResultslim[grep(\"M6-V6_up_down\", BatchResultslim$CLID), ] gos \u003c- BatchResultslim pdf(\"GOslimbarplotMF.pdf\", height = 8, width = 10) goBarplot(gos, gocat = \"MF\") dev.off() goBarplot(gos, gocat = \"BP\") goBarplot(gos, gocat = \"CC\")  Figure 5: GO Slim Barplot for MF Ontology\n  Clustering and heat maps The following example performs hierarchical clustering on the rlog transformed expression matrix subsetted by the DEGs identified in the above differential expression analysis. It uses a Pearson correlation-based distance measure and complete linkage for cluster joining.\nlibrary(pheatmap) geneids \u003c- unique(as.character(unlist(DEG_list[[1]]))) y \u003c- assay(rlog(dds))[geneids, ] pdf(\"heatmap1.pdf\") pheatmap(y, scale = \"row\", clustering_distance_rows = \"correlation\", clustering_distance_cols = \"correlation\") dev.off()  Figure 6: Heat Map with Hierarchical Clustering Dendrograms of DEGs\n  Version Information sessionInfo()  ## R version 4.0.5 (2021-03-31) ## Platform: x86_64-pc-linux-gnu (64-bit) ## Running under: Debian GNU/Linux 10 (buster) ## ## Matrix products: default ## BLAS: /usr/lib/x86_64-linux-gnu/blas/libblas.so.3.8.0 ## LAPACK: /usr/lib/x86_64-linux-gnu/lapack/liblapack.so.3.8.0 ## ## locale: ## [1] LC_CTYPE=en_US.UTF-8 LC_NUMERIC=C ## [3] LC_TIME=en_US.UTF-8 LC_COLLATE=en_US.UTF-8 ## [5] LC_MONETARY=en_US.UTF-8 LC_MESSAGES=en_US.UTF-8 ## [7] LC_PAPER=en_US.UTF-8 LC_NAME=C ## [9] LC_ADDRESS=C LC_TELEPHONE=C ## [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C ## ## attached base packages: ## [1] stats4 parallel stats graphics grDevices ## [6] utils datasets methods base ## ## other attached packages: ## [1] batchtools_0.9.14 ape_5.4-1 ## [3] ggplot2_3.3.2 systemPipeR_1.24.2 ## [5] ShortRead_1.48.0 GenomicAlignments_1.26.0 ## [7] SummarizedExperiment_1.20.0 Biobase_2.50.0 ## [9] MatrixGenerics_1.2.0 matrixStats_0.57.0 ## [11] BiocParallel_1.24.1 Rsamtools_2.6.0 ## [13] Biostrings_2.58.0 XVector_0.30.0 ## [15] GenomicRanges_1.42.0 GenomeInfoDb_1.26.1 ## [17] IRanges_2.24.0 S4Vectors_0.28.0 ## [19] BiocGenerics_0.36.0 BiocStyle_2.18.0 ## ## loaded via a namespace (and not attached): ## [1] colorspace_2.0-0 rjson_0.2.20 ## [3] hwriter_1.3.2 ellipsis_0.3.1 ## [5] bit64_4.0.5 AnnotationDbi_1.52.0 ## [7] xml2_1.3.2 codetools_0.2-18 ## [9] splines_4.0.5 knitr_1.30 ## [11] jsonlite_1.7.1 annotate_1.68.0 ## [13] GO.db_3.12.1 dbplyr_2.0.0 ## [15] png_0.1-7 pheatmap_1.0.12 ## [17] graph_1.68.0 BiocManager_1.30.10 ## [19] compiler_4.0.5 httr_1.4.2 ## [21] backports_1.2.0 GOstats_2.56.0 ## [23] assertthat_0.2.1 Matrix_1.3-2 ## [25] limma_3.46.0 formatR_1.7 ## [27] htmltools_0.5.1.1 prettyunits_1.1.1 ## [29] tools_4.0.5 gtable_0.3.0 ## [31] glue_1.4.2 GenomeInfoDbData_1.2.4 ## [33] Category_2.56.0 dplyr_1.0.2 ## [35] rsvg_2.1 rappdirs_0.3.1 ## [37] V8_3.4.0 Rcpp_1.0.5 ## [39] jquerylib_0.1.3 vctrs_0.3.5 ## [41] nlme_3.1-149 blogdown_1.2 ## [43] rtracklayer_1.50.0 xfun_0.22 ## [45] stringr_1.4.0 lifecycle_0.2.0 ## [47] XML_3.99-0.5 edgeR_3.32.0 ## [49] zlibbioc_1.36.0 scales_1.1.1 ## [51] BSgenome_1.58.0 VariantAnnotation_1.36.0 ## [53] hms_0.5.3 RBGL_1.66.0 ## [55] RColorBrewer_1.1-2 yaml_2.2.1 ## [57] curl_4.3 memoise_1.1.0 ## [59] sass_0.3.1 biomaRt_2.46.0 ## [61] latticeExtra_0.6-29 stringi_1.5.3 ## [63] RSQLite_2.2.1 genefilter_1.72.0 ## [65] checkmate_2.0.0 GenomicFeatures_1.42.1 ## [67] DOT_0.1 rlang_0.4.8 ## [69] pkgconfig_2.0.3 bitops_1.0-6 ## [71] evaluate_0.14 lattice_0.20-41 ## [73] purrr_0.3.4 bit_4.0.4 ## [75] tidyselect_1.1.0 GSEABase_1.52.0 ## [77] AnnotationForge_1.32.0 magrittr_2.0.1 ## [79] bookdown_0.21 R6_2.5.0 ## [81] generics_0.1.0 base64url_1.4 ## [83] DelayedArray_0.16.0 DBI_1.1.0 ## [85] withr_2.3.0 pillar_1.4.7 ## [87] survival_3.2-10 RCurl_1.98-1.2 ## [89] tibble_3.0.4 crayon_1.3.4 ## [91] BiocFileCache_1.14.0 rmarkdown_2.7 ## [93] jpeg_0.1-8.1 progress_1.2.2 ## [95] locfit_1.5-9.4 grid_4.0.5 ## [97] data.table_1.13.2 blob_1.2.1 ## [99] Rgraphviz_2.34.0 digest_0.6.27 ## [101] xtable_1.8-4 brew_1.0-6 ## [103] openssl_1.4.3 munsell_0.5.0 ## [105] bslib_0.2.4 askpass_1.1  Funding This project is funded by NSF award ABI-1661152.\nReferences H Backman, Tyler W, and Thomas Girke. 2016. “systemPipeR: NGS workflow and report generation environment.” BMC Bioinformatics 17 (1): 388. https://doi.org/10.1186/s12859-016-1241-0.\n Howard, Brian E, Qiwen Hu, Ahmet Can Babaoglu, Manan Chandra, Monica Borghi, Xiaoping Tan, Luyan He, et al. 2013. “High-Throughput RNA Sequencing of Pseudomonas-Infected Arabidopsis Reveals Hidden Transcriptome Complexity and Novel Splice Variants.” PLoS One 8 (10): e74183. https://doi.org/10.1371/journal.pone.0074183.\n Kim, Daehwan, Ben Langmead, and Steven L Salzberg. 2015. “HISAT: A Fast Spliced Aligner with Low Memory Requirements.” Nat. Methods 12 (4): 357–60.\n Lawrence, Michael, Wolfgang Huber, Hervé Pagès, Patrick Aboyoun, Marc Carlson, Robert Gentleman, Martin T Morgan, and Vincent J Carey. 2013. “Software for Computing and Annotating Genomic Ranges.” PLoS Comput. Biol. 9 (8): e1003118. https://doi.org/10.1371/journal.pcbi.1003118.\n Robinson, M D, D J McCarthy, and G K Smyth. 2010. “edgeR: A Bioconductor Package for Differential Expression Analysis of Digital Gene Expression Data.” Bioinformatics 26 (1): 139–40. https://doi.org/10.1093/bioinformatics/btp616.\n  ","categories":"","description":"","excerpt":"pre code { white-space: pre !important; overflow-x: scroll !important; …","ref":"/manuals/sprnaseq/sprnaseq/","tags":"","title":"RNA-Seq Workflow Template"},{"body":"pre code { white-space: pre !important; overflow-x: scroll !important; word-break: keep-all !important; word-wrap: initial !important; }  document.addEventListener(\"DOMContentLoaded\", function() { document.querySelector(\"h1\").className = \"title\"; });  document.addEventListener(\"DOMContentLoaded\", function() { var links = document.links; for (var i = 0, linksLength = links.length; i Source code downloads: [ .Rmd ] [ .R ]\n Introduction Users want to provide here background information about the design of their ChIP-Seq project.\nBackground and objectives This report describes the analysis of several ChIP-Seq experiments studying the DNA binding patterns of the transcriptions factors … from organism ….\nExperimental design Typically, users want to specify here all information relevant for the analysis of their NGS study. This includes detailed descriptions of FASTQ files, experimental design, reference genome, gene annotations, etc.\nNote: the mini sample FASTQ files (toy data set) used by this report as well as the associated reference genome files are loaded below via the genWorkenvir function from the systemPipeRdata package. The chosen data set SRP010938 contains 18 paired-end (PE) read sets from Arabidposis thaliana (Howard et al. 2013). To minimize processing time during testing, each FASTQ file has been subsetted to 90,000-100,000 randomly sampled PE reads that map to the first 100,000 nucleotides of each chromosome of the A. thalina genome. The corresponding reference genome sequence (FASTA) and its GFF annotation files have been truncated accordingly. This way the entire test sample data set is less than 200MB in storage space. A PE read set has been chosen for this test data set for flexibility, because it can be used for testing both types of analysis routines requiring either SE (single end) reads or PE reads.\nWorkflow environment NOTE: this section describes how to set up the proper environment (directory structure) for running systemPipeR workflows. After mastering this task the workflow run instructions can be deleted since they are not expected to be included in a final HTML/PDF report of a workflow.\n  If a remote system or cluster is used, then users need to log in to the remote system first. The following applies to an HPC cluster (e.g. HPCC cluster).\nA terminal application needs to be used to log in to a user’s cluster account. Next, one can open an interactive session on a computer node with srun. More details about argument settings for srun are available in this HPCC manual or the HPCC section of this website here. Next, load the R version required for running the workflow with module load. Sometimes it may be necessary to first unload an active software version before loading another version, e.g. module unload R.\n  srun --x11 --partition=short --mem=8gb --cpus-per-task 4 --ntasks 1 --time 2:00:00 --pty bash -l module load R/4.0.3  Load a workflow template with the genWorkenvir function. This can be done from the command-line or from within R. However, only one of the two options needs to be used.  From command-line\n$ Rscript -e \"systemPipeRdata::genWorkenvir(workflow='rnaseq')\" $ cd rnaseq  From R\nlibrary(systemPipeRdata) genWorkenvir(workflow = \"rnaseq\") setwd(\"rnaseq\")   Optional: if the user wishes to use another Rmd file than the template instance provided by the genWorkenvir function, then it can be copied or downloaded into the root directory of the workflow environment (e.g. with cp or wget).\n  Now one can open from the root directory of the workflow the corresponding R Markdown script (e.g. systemPipeChIPseq.Rmd) using an R IDE, such as nvim-r, ESS or RStudio. Subsequently, the workflow can be run as outlined below. For learning purposes it is recommended to run workflows for the first time interactively. Once all workflow steps are understood and possibly modified to custom needs, one can run the workflow from start to finish with a single command using rmarkdown::render() or runWF().\n  Required packages and resources The systemPipeR package needs to be loaded to perform the analysis steps shown in this report (H Backman and Girke 2016).\nlibrary(systemPipeR)  To apply workflows to custom data, the user needs to modify the targets file and if necessary update the corresponding parameter (.cwl and .yml) files. A collection of pre-generated .cwl and .yml files are provided in the param/cwl subdirectory of each workflow template. They are also viewable in the GitHub repository of systemPipeRdata (see here). For more information of the structure of the targets file, please consult the documentation here. More details about the new parameter files from systemPipeR can be found here.\nExperiment definition provided by targets file The targets file defines all FASTQ files and sample comparisons of the analysis workflow.\ntargetspath \u003c- system.file(\"extdata\", \"targetsPE.txt\", package = \"systemPipeR\") targets \u003c- read.delim(targetspath, comment.char = \"#\")[, 1:4] targets  ## FileName1 FileName2 ## 1 ./data/SRR446027_1.fastq.gz ./data/SRR446027_2.fastq.gz ## 2 ./data/SRR446028_1.fastq.gz ./data/SRR446028_2.fastq.gz ## 3 ./data/SRR446029_1.fastq.gz ./data/SRR446029_2.fastq.gz ## 4 ./data/SRR446030_1.fastq.gz ./data/SRR446030_2.fastq.gz ## 5 ./data/SRR446031_1.fastq.gz ./data/SRR446031_2.fastq.gz ## 6 ./data/SRR446032_1.fastq.gz ./data/SRR446032_2.fastq.gz ## 7 ./data/SRR446033_1.fastq.gz ./data/SRR446033_2.fastq.gz ## 8 ./data/SRR446034_1.fastq.gz ./data/SRR446034_2.fastq.gz ## 9 ./data/SRR446035_1.fastq.gz ./data/SRR446035_2.fastq.gz ## 10 ./data/SRR446036_1.fastq.gz ./data/SRR446036_2.fastq.gz ## 11 ./data/SRR446037_1.fastq.gz ./data/SRR446037_2.fastq.gz ## 12 ./data/SRR446038_1.fastq.gz ./data/SRR446038_2.fastq.gz ## 13 ./data/SRR446039_1.fastq.gz ./data/SRR446039_2.fastq.gz ## 14 ./data/SRR446040_1.fastq.gz ./data/SRR446040_2.fastq.gz ## 15 ./data/SRR446041_1.fastq.gz ./data/SRR446041_2.fastq.gz ## 16 ./data/SRR446042_1.fastq.gz ./data/SRR446042_2.fastq.gz ## 17 ./data/SRR446043_1.fastq.gz ./data/SRR446043_2.fastq.gz ## 18 ./data/SRR446044_1.fastq.gz ./data/SRR446044_2.fastq.gz ## SampleName Factor ## 1 M1A M1 ## 2 M1B M1 ## 3 A1A A1 ## 4 A1B A1 ## 5 V1A V1 ## 6 V1B V1 ## 7 M6A M6 ## 8 M6B M6 ## 9 A6A A6 ## 10 A6B A6 ## 11 V6A V6 ## 12 V6B V6 ## 13 M12A M12 ## 14 M12B M12 ## 15 A12A A12 ## 16 A12B A12 ## 17 V12A V12 ## 18 V12B V12  Read preprocessing Read quality filtering and trimming The function preprocessReads allows to apply predefined or custom read preprocessing functions to all FASTQ files referenced in a SYSargs2 container, such as quality filtering or adapter trimming routines. The paths to the resulting output FASTQ files are stored in the output slot of the SYSargs2 object. The following example performs adapter trimming with the trimLRPatterns function from the Biostrings package. After the trimming step a new targets file is generated (here targets_trim.txt) containing the paths to the trimmed FASTQ files. The new targets file can be used for the next workflow step with an updated SYSargs2 instance, e.g. running the NGS alignments using the trimmed FASTQ files.\nConstruct SYSargs2 object from cwl and yml param and targets files.\ndir_path \u003c- system.file(\"extdata/cwl/preprocessReads/trim-pe\", package = \"systemPipeR\") trim \u003c- loadWorkflow(targets = targetspath, wf_file = \"trim-pe.cwl\", input_file = \"trim-pe.yml\", dir_path = dir_path) trim \u003c- renderWF(trim, inputvars = c(FileName1 = \"_FASTQ_PATH1_\", FileName2 = \"_FASTQ_PATH2_\", SampleName = \"_SampleName_\")) trim output(trim)[1:2]  preprocessReads(args = trim, Fct = \"trimLRPatterns(Rpattern='GCCCGGGTAA', subject=fq)\", batchsize = 1e+05, overwrite = TRUE, compress = TRUE) writeTargetsout(x = trim, file = \"targets_trim.txt\", step = 1, new_col = c(\"FileName1\", \"FileName2\"), new_col_output_index = c(1, 2), overwrite = TRUE)  FASTQ quality report The following seeFastq and seeFastqPlot functions generate and plot a series of useful quality statistics for a set of FASTQ files including per cycle quality box plots, base proportions, base-level quality trends, relative k-mer diversity, length and occurrence distribution of reads, number of reads above quality cutoffs and mean quality distribution. The results are written to a PDF file named fastqReport.pdf.\nfqlist \u003c- seeFastq(fastq = infile1(trim), batchsize = 10000, klength = 8) pdf(\"./results/fastqReport.pdf\", height = 18, width = 4 * length(fqlist)) seeFastqPlot(fqlist) dev.off()  Figure 1: FASTQ quality report for 18 samples\n  Alignments Read mapping with HISAT2 The following steps will demonstrate how to use the short read aligner Hisat2 (Kim, Langmead, and Salzberg 2015) in both interactive job submissions and batch submissions to queuing systems of clusters using the systemPipeR's new CWL command-line interface.\nBuild Hisat2 index.\ndir_path \u003c- system.file(\"extdata/cwl/hisat2/hisat2-idx\", package = \"systemPipeR\") idx \u003c- loadWorkflow(targets = NULL, wf_file = \"hisat2-index.cwl\", input_file = \"hisat2-index.yml\", dir_path = dir_path) idx \u003c- renderWF(idx) idx cmdlist(idx) ### Run runCommandline(idx, make_bam = FALSE)  The parameter settings of the aligner are defined in the hisat2-mapping-se.cwl and hisat2-mapping-se.yml files. The following shows how to construct the corresponding SYSargs2 object, here args.\ndir_path \u003c- system.file(\"extdata/cwl/hisat2/hisat2-pe\", package = \"systemPipeR\") args \u003c- loadWorkflow(targets = targetspath, wf_file = \"hisat2-mapping-pe.cwl\", input_file = \"hisat2-mapping-pe.yml\", dir_path = dir_path) args \u003c- renderWF(args, inputvars = c(FileName1 = \"_FASTQ_PATH1_\", FileName2 = \"_FASTQ_PATH2_\", SampleName = \"_SampleName_\")) args  ## Instance of 'SYSargs2': ## Slot names/accessors: ## targets: 18 (M1A...V12B), targetsheader: 4 (lines) ## modules: 1 ## wf: 0, clt: 1, yamlinput: 8 (components) ## input: 18, output: 18 ## cmdlist: 18 ## WF Steps: ## 1. hisat2-mapping-pe (rendered: TRUE)  cmdlist(args)[1:2]  ## $M1A ## $M1A$`hisat2-mapping-pe` ## [1] \"hisat2 -S ./results/M1A.sam -x ./data/tair10.fasta -k 1 --min-intronlen 30 --max-intronlen 3000 -1 ./data/SRR446027_1.fastq.gz -2 ./data/SRR446027_2.fastq.gz --threads 4\" ## ## ## $M1B ## $M1B$`hisat2-mapping-pe` ## [1] \"hisat2 -S ./results/M1B.sam -x ./data/tair10.fasta -k 1 --min-intronlen 30 --max-intronlen 3000 -1 ./data/SRR446028_1.fastq.gz -2 ./data/SRR446028_2.fastq.gz --threads 4\"  output(args)[1:2]  ## $M1A ## $M1A$`hisat2-mapping-pe` ## [1] \"./results/M1A.sam\" ## ## ## $M1B ## $M1B$`hisat2-mapping-pe` ## [1] \"./results/M1B.sam\"  Interactive job submissions in a single machine To simplify the short read alignment execution for the user, the command-line can be run with the runCommandline function. The execution will be on a single machine without submitting to a queuing system of a computer cluster. This way, the input FASTQ files will be processed sequentially. By default runCommandline auto detects SAM file outputs and converts them to sorted and indexed BAM files, using internally the Rsamtools package. Besides, runCommandline allows the user to create a dedicated results folder for each workflow and a sub-folder for each sample defined in the targets file. This includes all the output and log files for each step. When these options are used, the output location will be updated by default and can be assigned to the same object.\n### Run single Machine args \u003c- runCommandline(args)  Parallelization on clusters Alternatively, the computation can be greatly accelerated by processing many files in parallel using several compute nodes of a cluster, where a scheduling/queuing system is used for load balancing. For this the clusterRun function submits the computing requests to the scheduler using the run specifications defined by runCommandline.\nTo avoid over-subscription of CPU cores on the compute nodes, the value from yamlinput(args)['thread'] is passed on to the submission command, here ncpus in the resources list object. The number of independent parallel cluster processes is defined under the Njobs argument. The following example will run 18 processes in parallel using for each 4 CPU cores. If the resources available on a cluster allow running all 18 processes at the same time then the shown sample submission will utilize in total 72 CPU cores. Note, clusterRun can be used with most queueing systems as it is based on utilities from the batchtools package which supports the use of template files (*.tmpl) for defining the run parameters of different schedulers. To run the following code, one needs to have both a conf file (see .batchtools.conf.R samples here) and a template file (see *.tmpl samples here) for the queueing available on a system. The following example uses the sample conf and template files for the Slurm scheduler provided by this package.\nlibrary(batchtools) resources \u003c- list(walltime = 120, ntasks = 1, ncpus = 4, memory = 1024) reg \u003c- clusterRun(args, FUN = runCommandline, more.args = list(args = args, make_bam = TRUE, dir = FALSE), conffile = \".batchtools.conf.R\", template = \"batchtools.slurm.tmpl\", Njobs = 18, runid = \"01\", resourceList = resources) getStatus(reg = reg) waitForJobs(reg = reg) args \u003c- output_update(args, dir = FALSE, replace = TRUE, extension = c(\".sam\", \".bam\")) ## Updates the output(args) to the right location in the subfolders output(args)  Check whether all BAM files have been created.\noutpaths \u003c- subsetWF(args, slot = \"output\", subset = 1, index = 1) file.exists(outpaths)  Read and alignment stats The following provides an overview of the number of reads in each sample and how many of them aligned to the reference.\nread_statsDF \u003c- alignStats(args = args) write.table(read_statsDF, \"results/alignStats.xls\", row.names = FALSE, quote = FALSE, sep = \"\\t\")  The following shows the alignment statistics for a sample file provided by the systemPipeR package.\nread.table(system.file(\"extdata\", \"alignStats.xls\", package = \"systemPipeR\"), header = TRUE)[1:4, ]  ## FileName Nreads2x Nalign Perc_Aligned Nalign_Primary ## 1 M1A 192918 177961 92.24697 177961 ## 2 M1B 197484 159378 80.70426 159378 ## 3 A1A 189870 176055 92.72397 176055 ## 4 A1B 188854 147768 78.24457 147768 ## Perc_Aligned_Primary ## 1 92.24697 ## 2 80.70426 ## 3 92.72397 ## 4 78.24457  Create symbolic links for viewing BAM files in IGV The symLink2bam function creates symbolic links to view the BAM alignment files in a genome browser such as IGV. The corresponding URLs are written to a file with a path specified under urlfile in the results directory.\nsymLink2bam(sysargs = args, htmldir = c(\"~/.html/\", \"somedir/\"), urlbase = \"http://cluster.hpcc.ucr.edu/~tgirke/\", urlfile = \"./results/IGVurl.txt\")  Read quantification Read counting with summarizeOverlaps in parallel mode using multiple cores Reads overlapping with annotation ranges of interest are counted for each sample using the summarizeOverlaps function (Lawrence et al. 2013). The read counting is preformed for exonic gene regions in a non-strand-specific manner while ignoring overlaps among different genes. Subsequently, the expression count values are normalized by reads per kp per million mapped reads (RPKM). The raw read count table (countDFeByg.xls) and the corresponding RPKM table (rpkmDFeByg.xls) are written to separate files in the directory of this project. Parallelization is achieved with the BiocParallel package, here using 8 CPU cores.\nlibrary(\"GenomicFeatures\") library(BiocParallel) txdb \u003c- makeTxDbFromGFF(file = \"data/tair10.gff\", format = \"gff\", dataSource = \"TAIR\", organism = \"Arabidopsis thaliana\") saveDb(txdb, file = \"./data/tair10.sqlite\") txdb \u003c- loadDb(\"./data/tair10.sqlite\") outpaths \u003c- subsetWF(args, slot = \"output\", subset = 1, index = 1) (align \u003c- readGAlignments(outpaths[1])) # Demonstrates how to read bam file into R eByg \u003c- exonsBy(txdb, by = c(\"gene\")) bfl \u003c- BamFileList(outpaths, yieldSize = 50000, index = character()) multicoreParam \u003c- MulticoreParam(workers = 2) register(multicoreParam) registered() counteByg \u003c- bplapply(bfl, function(x) summarizeOverlaps(eByg, x, mode = \"Union\", ignore.strand = TRUE, inter.feature = FALSE, singleEnd = TRUE)) countDFeByg \u003c- sapply(seq(along = counteByg), function(x) assays(counteByg[[x]])$counts) rownames(countDFeByg) \u003c- names(rowRanges(counteByg[[1]])) colnames(countDFeByg) \u003c- names(bfl) rpkmDFeByg \u003c- apply(countDFeByg, 2, function(x) returnRPKM(counts = x, ranges = eByg)) write.table(countDFeByg, \"results/countDFeByg.xls\", col.names = NA, quote = FALSE, sep = \"\\t\") write.table(rpkmDFeByg, \"results/rpkmDFeByg.xls\", col.names = NA, quote = FALSE, sep = \"\\t\")  Sample of data slice of count table\nread.delim(\"results/countDFeByg.xls\", row.names = 1, check.names = FALSE)[1:4, 1:5]  Sample of data slice of RPKM table\nread.delim(\"results/rpkmDFeByg.xls\", row.names = 1, check.names = FALSE)[1:4, 1:4]  Note, for most statistical differential expression or abundance analysis methods, such as edgeR or DESeq2, the raw count values should be used as input. The usage of RPKM values should be restricted to specialty applications required by some users, e.g. manually comparing the expression levels among different genes or features.\nSample-wise correlation analysis The following computes the sample-wise Spearman correlation coefficients from the rlog transformed expression values generated with the DESeq2 package. After transformation to a distance matrix, hierarchical clustering is performed with the hclust function and the result is plotted as a dendrogram (also see file sample_tree.pdf).\nlibrary(DESeq2, quietly = TRUE) library(ape, warn.conflicts = FALSE) countDF \u003c- as.matrix(read.table(\"./results/countDFeByg.xls\")) colData \u003c- data.frame(row.names = targets.as.df(targets(args))$SampleName, condition = targets.as.df(targets(args))$Factor) dds \u003c- DESeqDataSetFromMatrix(countData = countDF, colData = colData, design = ~condition) d \u003c- cor(assay(rlog(dds)), method = \"spearman\") hc \u003c- hclust(dist(1 - d)) pdf(\"results/sample_tree.pdf\") plot.phylo(as.phylo(hc), type = \"p\", edge.col = \"blue\", edge.width = 2, show.node.label = TRUE, no.margin = TRUE) dev.off()  Figure 2: Correlation dendrogram of samples\n  Analysis of DEGs The analysis of differentially expressed genes (DEGs) is performed with the glm method of the edgeR package (Robinson, McCarthy, and Smyth 2010). The sample comparisons used by this analysis are defined in the header lines of the targets.txt file starting with \u003cCMP\u003e.\nRun edgeR library(edgeR) countDF \u003c- read.delim(\"results/countDFeByg.xls\", row.names = 1, check.names = FALSE) targets \u003c- read.delim(\"targetsPE.txt\", comment = \"#\") cmp \u003c- readComp(file = \"targetsPE.txt\", format = \"matrix\", delim = \"-\") edgeDF \u003c- run_edgeR(countDF = countDF, targets = targets, cmp = cmp[[1]], independent = FALSE, mdsplot = \"\")  Add gene descriptions\nlibrary(\"biomaRt\") m \u003c- useMart(\"plants_mart\", dataset = \"athaliana_eg_gene\", host = \"plants.ensembl.org\") desc \u003c- getBM(attributes = c(\"tair_locus\", \"description\"), mart = m) desc \u003c- desc[!duplicated(desc[, 1]), ] descv \u003c- as.character(desc[, 2]) names(descv) \u003c- as.character(desc[, 1]) edgeDF \u003c- data.frame(edgeDF, Desc = descv[rownames(edgeDF)], check.names = FALSE) write.table(edgeDF, \"./results/edgeRglm_allcomp.xls\", quote = FALSE, sep = \"\\t\", col.names = NA)  Plot DEG results Filter and plot DEG results for up and down regulated genes. The definition of up and down is given in the corresponding help file. To open it, type ?filterDEGs in the R console.\nedgeDF \u003c- read.delim(\"results/edgeRglm_allcomp.xls\", row.names = 1, check.names = FALSE) pdf(\"results/DEGcounts.pdf\") DEG_list \u003c- filterDEGs(degDF = edgeDF, filter = c(Fold = 2, FDR = 20)) dev.off() write.table(DEG_list$Summary, \"./results/DEGcounts.xls\", quote = FALSE, sep = \"\\t\", row.names = FALSE)  Figure 3: Up and down regulated DEGs with FDR of 1%\n  Venn diagrams of DEG sets The overLapper function can compute Venn intersects for large numbers of sample sets (up to 20 or more) and plots 2-5 way Venn diagrams. A useful feature is the possibility to combine the counts from several Venn comparisons with the same number of sample sets in a single Venn diagram (here for 4 up and down DEG sets).\nvennsetup \u003c- overLapper(DEG_list$Up[6:9], type = \"vennsets\") vennsetdown \u003c- overLapper(DEG_list$Down[6:9], type = \"vennsets\") pdf(\"results/vennplot.pdf\") vennPlot(list(vennsetup, vennsetdown), mymain = \"\", mysub = \"\", colmode = 2, ccol = c(\"blue\", \"red\")) dev.off()  Figure 4: Venn Diagram for 4 Up and Down DEG Sets\n  GO term enrichment analysis Obtain gene-to-GO mappings The following shows how to obtain gene-to-GO mappings from biomaRt (here for A. thaliana) and how to organize them for the downstream GO term enrichment analysis. Alternatively, the gene-to-GO mappings can be obtained for many organisms from Bioconductor’s *.db genome annotation packages or GO annotation files provided by various genome databases. For each annotation this relatively slow preprocessing step needs to be performed only once. Subsequently, the preprocessed data can be loaded with the load function as shown in the next subsection.\nlibrary(\"biomaRt\") listMarts() # To choose BioMart database listMarts(host = \"plants.ensembl.org\") m \u003c- useMart(\"plants_mart\", host = \"plants.ensembl.org\") listDatasets(m) m \u003c- useMart(\"plants_mart\", dataset = \"athaliana_eg_gene\", host = \"plants.ensembl.org\") listAttributes(m) # Choose data types you want to download go \u003c- getBM(attributes = c(\"go_id\", \"tair_locus\", \"namespace_1003\"), mart = m) go \u003c- go[go[, 3] != \"\", ] go[, 3] \u003c- as.character(go[, 3]) go[go[, 3] == \"molecular_function\", 3] \u003c- \"F\" go[go[, 3] == \"biological_process\", 3] \u003c- \"P\" go[go[, 3] == \"cellular_component\", 3] \u003c- \"C\" go[1:4, ] dir.create(\"./data/GO\") write.table(go, \"data/GO/GOannotationsBiomart_mod.txt\", quote = FALSE, row.names = FALSE, col.names = FALSE, sep = \"\\t\") catdb \u003c- makeCATdb(myfile = \"data/GO/GOannotationsBiomart_mod.txt\", lib = NULL, org = \"\", colno = c(1, 2, 3), idconv = NULL) save(catdb, file = \"data/GO/catdb.RData\")  Batch GO term enrichment analysis Apply the enrichment analysis to the DEG sets obtained the above differential expression analysis. Note, in the following example the FDR filter is set here to an unreasonably high value, simply because of the small size of the toy data set used in this vignette. Batch enrichment analysis of many gene sets is performed with the function. When method=all, it returns all GO terms passing the p-value cutoff specified under the cutoff arguments. When method=slim, it returns only the GO terms specified under the myslimv argument. The given example shows how a GO slim vector for a specific organism can be obtained from BioMart.\nlibrary(\"biomaRt\") load(\"data/GO/catdb.RData\") DEG_list \u003c- filterDEGs(degDF = edgeDF, filter = c(Fold = 2, FDR = 50), plot = FALSE) up_down \u003c- DEG_list$UporDown names(up_down) \u003c- paste(names(up_down), \"_up_down\", sep = \"\") up \u003c- DEG_list$Up names(up) \u003c- paste(names(up), \"_up\", sep = \"\") down \u003c- DEG_list$Down names(down) \u003c- paste(names(down), \"_down\", sep = \"\") DEGlist \u003c- c(up_down, up, down) DEGlist \u003c- DEGlist[sapply(DEGlist, length) \u003e 0] BatchResult \u003c- GOCluster_Report(catdb = catdb, setlist = DEGlist, method = \"all\", id_type = \"gene\", CLSZ = 2, cutoff = 0.9, gocats = c(\"MF\", \"BP\", \"CC\"), recordSpecGO = NULL) library(\"biomaRt\") m \u003c- useMart(\"plants_mart\", dataset = \"athaliana_eg_gene\", host = \"plants.ensembl.org\") goslimvec \u003c- as.character(getBM(attributes = c(\"goslim_goa_accession\"), mart = m)[, 1]) BatchResultslim \u003c- GOCluster_Report(catdb = catdb, setlist = DEGlist, method = \"slim\", id_type = \"gene\", myslimv = goslimvec, CLSZ = 10, cutoff = 0.01, gocats = c(\"MF\", \"BP\", \"CC\"), recordSpecGO = NULL)  Plot batch GO term results The data.frame generated by GOCluster can be plotted with the goBarplot function. Because of the variable size of the sample sets, it may not always be desirable to show the results from different DEG sets in the same bar plot. Plotting single sample sets is achieved by subsetting the input data frame as shown in the first line of the following example.\ngos \u003c- BatchResultslim[grep(\"M6-V6_up_down\", BatchResultslim$CLID), ] gos \u003c- BatchResultslim pdf(\"GOslimbarplotMF.pdf\", height = 8, width = 10) goBarplot(gos, gocat = \"MF\") dev.off() goBarplot(gos, gocat = \"BP\") goBarplot(gos, gocat = \"CC\")  Figure 5: GO Slim Barplot for MF Ontology\n  Clustering and heat maps The following example performs hierarchical clustering on the rlog transformed expression matrix subsetted by the DEGs identified in the above differential expression analysis. It uses a Pearson correlation-based distance measure and complete linkage for cluster joining.\nlibrary(pheatmap) geneids \u003c- unique(as.character(unlist(DEG_list[[1]]))) y \u003c- assay(rlog(dds))[geneids, ] pdf(\"heatmap1.pdf\") pheatmap(y, scale = \"row\", clustering_distance_rows = \"correlation\", clustering_distance_cols = \"correlation\") dev.off()  Figure 6: Heat Map with Hierarchical Clustering Dendrograms of DEGs\n  Version Information sessionInfo()  ## R version 4.0.5 (2021-03-31) ## Platform: x86_64-pc-linux-gnu (64-bit) ## Running under: Debian GNU/Linux 10 (buster) ## ## Matrix products: default ## BLAS: /usr/lib/x86_64-linux-gnu/blas/libblas.so.3.8.0 ## LAPACK: /usr/lib/x86_64-linux-gnu/lapack/liblapack.so.3.8.0 ## ## locale: ## [1] LC_CTYPE=en_US.UTF-8 LC_NUMERIC=C ## [3] LC_TIME=en_US.UTF-8 LC_COLLATE=en_US.UTF-8 ## [5] LC_MONETARY=en_US.UTF-8 LC_MESSAGES=en_US.UTF-8 ## [7] LC_PAPER=en_US.UTF-8 LC_NAME=C ## [9] LC_ADDRESS=C LC_TELEPHONE=C ## [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C ## ## attached base packages: ## [1] stats4 parallel stats graphics grDevices ## [6] utils datasets methods base ## ## other attached packages: ## [1] batchtools_0.9.14 ape_5.4-1 ## [3] ggplot2_3.3.2 systemPipeR_1.24.5 ## [5] ShortRead_1.48.0 GenomicAlignments_1.26.0 ## [7] SummarizedExperiment_1.20.0 Biobase_2.50.0 ## [9] MatrixGenerics_1.2.0 matrixStats_0.57.0 ## [11] BiocParallel_1.24.1 Rsamtools_2.6.0 ## [13] Biostrings_2.58.0 XVector_0.30.0 ## [15] GenomicRanges_1.42.0 GenomeInfoDb_1.26.1 ## [17] IRanges_2.24.0 S4Vectors_0.28.0 ## [19] BiocGenerics_0.36.0 BiocStyle_2.18.0 ## ## loaded via a namespace (and not attached): ## [1] colorspace_2.0-0 rjson_0.2.20 ## [3] hwriter_1.3.2 ellipsis_0.3.1 ## [5] bit64_4.0.5 AnnotationDbi_1.52.0 ## [7] xml2_1.3.2 codetools_0.2-18 ## [9] splines_4.0.5 knitr_1.30 ## [11] jsonlite_1.7.1 annotate_1.68.0 ## [13] GO.db_3.12.1 dbplyr_2.0.0 ## [15] png_0.1-7 pheatmap_1.0.12 ## [17] graph_1.68.0 BiocManager_1.30.10 ## [19] compiler_4.0.5 httr_1.4.2 ## [21] backports_1.2.0 GOstats_2.56.0 ## [23] assertthat_0.2.1 Matrix_1.3-2 ## [25] limma_3.46.0 formatR_1.7 ## [27] htmltools_0.5.1.1 prettyunits_1.1.1 ## [29] tools_4.0.5 gtable_0.3.0 ## [31] glue_1.4.2 GenomeInfoDbData_1.2.4 ## [33] Category_2.56.0 dplyr_1.0.2 ## [35] rsvg_2.1 rappdirs_0.3.1 ## [37] V8_3.4.0 Rcpp_1.0.5 ## [39] jquerylib_0.1.3 vctrs_0.3.5 ## [41] nlme_3.1-149 blogdown_1.2 ## [43] rtracklayer_1.50.0 xfun_0.22 ## [45] stringr_1.4.0 lifecycle_0.2.0 ## [47] XML_3.99-0.5 edgeR_3.32.0 ## [49] zlibbioc_1.36.0 scales_1.1.1 ## [51] BSgenome_1.58.0 VariantAnnotation_1.36.0 ## [53] hms_0.5.3 RBGL_1.66.0 ## [55] RColorBrewer_1.1-2 yaml_2.2.1 ## [57] curl_4.3 memoise_1.1.0 ## [59] sass_0.3.1 biomaRt_2.46.0 ## [61] latticeExtra_0.6-29 stringi_1.5.3 ## [63] RSQLite_2.2.1 genefilter_1.72.0 ## [65] checkmate_2.0.0 GenomicFeatures_1.42.1 ## [67] DOT_0.1 rlang_0.4.8 ## [69] pkgconfig_2.0.3 bitops_1.0-6 ## [71] evaluate_0.14 lattice_0.20-41 ## [73] purrr_0.3.4 bit_4.0.4 ## [75] tidyselect_1.1.0 GSEABase_1.52.0 ## [77] AnnotationForge_1.32.0 magrittr_2.0.1 ## [79] bookdown_0.21 R6_2.5.0 ## [81] generics_0.1.0 base64url_1.4 ## [83] DelayedArray_0.16.0 DBI_1.1.0 ## [85] withr_2.3.0 pillar_1.4.7 ## [87] survival_3.2-10 RCurl_1.98-1.2 ## [89] tibble_3.0.4 crayon_1.3.4 ## [91] BiocFileCache_1.14.0 rmarkdown_2.7 ## [93] jpeg_0.1-8.1 progress_1.2.2 ## [95] locfit_1.5-9.4 grid_4.0.5 ## [97] data.table_1.13.2 blob_1.2.1 ## [99] Rgraphviz_2.34.0 digest_0.6.27 ## [101] xtable_1.8-4 brew_1.0-6 ## [103] openssl_1.4.3 munsell_0.5.0 ## [105] bslib_0.2.4 askpass_1.1  Funding This project is funded by NSF award ABI-1661152.\nReferences H Backman, Tyler W, and Thomas Girke. 2016. “systemPipeR: NGS workflow and report generation environment.” BMC Bioinformatics 17 (1): 388. https://doi.org/10.1186/s12859-016-1241-0.\n Howard, Brian E, Qiwen Hu, Ahmet Can Babaoglu, Manan Chandra, Monica Borghi, Xiaoping Tan, Luyan He, et al. 2013. “High-Throughput RNA Sequencing of Pseudomonas-Infected Arabidopsis Reveals Hidden Transcriptome Complexity and Novel Splice Variants.” PLoS One 8 (10): e74183. https://doi.org/10.1371/journal.pone.0074183.\n Kim, Daehwan, Ben Langmead, and Steven L Salzberg. 2015. “HISAT: A Fast Spliced Aligner with Low Memory Requirements.” Nat. Methods 12 (4): 357–60.\n Lawrence, Michael, Wolfgang Huber, Hervé Pagès, Patrick Aboyoun, Marc Carlson, Robert Gentleman, Martin T Morgan, and Vincent J Carey. 2013. “Software for Computing and Annotating Genomic Ranges.” PLoS Comput. Biol. 9 (8): e1003118. https://doi.org/10.1371/journal.pcbi.1003118.\n Robinson, M D, D J McCarthy, and G K Smyth. 2010. “edgeR: A Bioconductor Package for Differential Expression Analysis of Digital Gene Expression Data.” Bioinformatics 26 (1): 139–40. https://doi.org/10.1093/bioinformatics/btp616.\n  ","categories":"","description":"","excerpt":"pre code { white-space: pre !important; overflow-x: scroll !important; …","ref":"/tutorials/sprnaseq/sprnaseq/","tags":"","title":"RNA-Seq Workflow Template"},{"body":"pre code { white-space: pre !important; overflow-x: scroll !important; word-break: keep-all !important; word-wrap: initial !important; }  document.addEventListener(\"DOMContentLoaded\", function() { document.querySelector(\"h1\").className = \"title\"; });  document.addEventListener(\"DOMContentLoaded\", function() { var links = document.links; for (var i = 0, linksLength = links.length; i Introduction Users want to provide here background information about the design of their ChIP-Seq project.\nBackground and objectives This report describes the analysis of several ChIP-Seq experiments studying the DNA binding patterns of the transcriptions factors … from organism ….\nExperimental design Typically, users want to specify here all information relevant for the analysis of their NGS study. This includes detailed descriptions of FASTQ files, experimental design, reference genome, gene annotations, etc.\nWorkflow environment NOTE: this section describes how to set up the proper environment (directory structure) for running systemPipeR workflows. After mastering this task the workflow run instructions can be deleted since they are not expected to be included in a final HTML/PDF report of a workflow.\n  If a remote system or cluster is used, then users need to log in to the remote system first. The following applies to an HPC cluster (e.g. HPCC cluster).\nA terminal application needs to be used to log in to a user’s cluster account. Next, one can open an interactive session on a computer node with srun. More details about argument settings for srun are available in this HPCC manual or the HPCC section of this website here. Next, load the R version required for running the workflow with module load. Sometimes it may be necessary to first unload an active software version before loading another version, e.g. module unload R.\n  srun --x11 --partition=short --mem=8gb --cpus-per-task 4 --ntasks 1 --time 2:00:00 --pty bash -l module load R/4.0.3  Load a workflow template with the genWorkenvir function. This can be done from the command-line or from within R. However, only one of the two options needs to be used.  From command-line\n$ Rscript -e \"systemPipeRdata::genWorkenvir(workflow='chipseq')\" $ cd chipseq  From R\nlibrary(systemPipeRdata) genWorkenvir(workflow = \"chipseq\") setwd(\"chipseq\")   Optional: if the user wishes to use another Rmd file than the template instance provided by the genWorkenvir function, then it can be copied or downloaded into the root directory of the workflow environment (e.g. with cp or wget).\n  Now one can open from the root directory of the workflow the corresponding R Markdown script (e.g. systemPipeChIPseq.Rmd) using an R IDE, such as nvim-r, ESS or RStudio. Subsequently, the workflow can be run as outlined below. For learning purposes it is recommended to run workflows for the first time interactively. Once all workflow steps are understood and possibly modified to custom needs, one can run the workflow from start to finish with a single command using rmarkdown::render() or runWF().\n  Load packages The systemPipeR package needs to be loaded to perform the analysis steps shown in this report (H Backman and Girke 2016). The package allows users to run the entire analysis workflow interactively or with a single command while also generating the corresponding analysis report. For details see systemPipeR's main vignette.\nlibrary(systemPipeR)  Read preprocessing Experiment definition provided by targets file The targets file defines all FASTQ files and sample comparisons of the analysis workflow.\ntargetspath \u003c- system.file(\"extdata\", \"targetsPE_chip.txt\", package = \"systemPipeR\") targets \u003c- read.delim(targetspath, comment.char = \"#\") targets[1:4, -c(5, 6)]  ## FileName1 FileName2 ## 1 ./data/SRR446027_1.fastq.gz ./data/SRR446027_2.fastq.gz ## 2 ./data/SRR446028_1.fastq.gz ./data/SRR446028_2.fastq.gz ## 3 ./data/SRR446029_1.fastq.gz ./data/SRR446029_2.fastq.gz ## 4 ./data/SRR446030_1.fastq.gz ./data/SRR446030_2.fastq.gz ## SampleName Factor Date SampleReference ## 1 M1A M1 23-Mar-2012 ## 2 M1B M1 23-Mar-2012 ## 3 A1A A1 23-Mar-2012 M1A ## 4 A1B A1 23-Mar-2012 M1B  Read quality filtering and trimming The following example shows how one can design a custom read preprocessing function using utilities provided by the ShortRead package, and then apply it with preprocessReads in batch mode to all FASTQ samples referenced in the corresponding SYSargs2 instance (trim object below). More detailed information on read preprocessing is provided in systemPipeR's main vignette.\nFirst, we construct SYSargs2 object from cwl and yml param and targets files.\ndir_path \u003c- system.file(\"extdata/cwl/preprocessReads/trim-pe\", package = \"systemPipeR\") trim \u003c- loadWF(targets = targetspath, wf_file = \"trim-pe.cwl\", input_file = \"trim-pe.yml\", dir_path = dir_path) trim \u003c- renderWF(trim, inputvars = c(FileName1 = \"_FASTQ_PATH1_\", FileName2 = \"_FASTQ_PATH2_\", SampleName = \"_SampleName_\")) trim output(trim)[1:2]  Next, we execute the code for trimming all the raw data.\nfilterFct \u003c- function(fq, cutoff = 20, Nexceptions = 0) { qcount \u003c- rowSums(as(quality(fq), \"matrix\") \u003c= cutoff, na.rm = TRUE) fq[qcount \u003c= Nexceptions] # Retains reads where Phred scores are \u003e= cutoff with N # exceptions } preprocessReads(args = trim, Fct = \"filterFct(fq, cutoff=20, Nexceptions=0)\", batchsize = 1e+05) writeTargetsout(x = trim, file = \"targets_chip_trimPE.txt\", step = 1, new_col = c(\"FileName1\", \"FileName2\"), new_col_output_index = c(1, 2), overwrite = TRUE)  FASTQ quality report The following seeFastq and seeFastqPlot functions generate and plot a series of useful quality statistics for a set of FASTQ files including per cycle quality box plots, base proportions, base-level quality trends, relative k-mer diversity, length and occurrence distribution of reads, number of reads above quality cutoffs and mean quality distribution. The results are written to a PDF file named fastqReport.pdf. Parallelization of FASTQ quality report via scheduler (e.g. Slurm) across several compute nodes.\nlibrary(BiocParallel) library(batchtools) f \u003c- function(x) { library(systemPipeR) targets \u003c- system.file(\"extdata\", \"targetsPE_chip.txt\", package = \"systemPipeR\") dir_path \u003c- system.file(\"extdata/cwl/preprocessReads/trim-pe\", package = \"systemPipeR\") trim \u003c- loadWorkflow(targets = targets, wf_file = \"trim-pe.cwl\", input_file = \"trim-pe.yml\", dir_path = dir_path) trim \u003c- renderWF(trim, inputvars = c(FileName1 = \"_FASTQ_PATH1_\", FileName2 = \"_FASTQ_PATH2_\", SampleName = \"_SampleName_\")) seeFastq(fastq = infile1(trim)[x], batchsize = 1e+05, klength = 8) } resources \u003c- list(walltime = 120, ntasks = 1, ncpus = 4, memory = 1024) param \u003c- BatchtoolsParam(workers = 4, cluster = \"slurm\", template = \"batchtools.slurm.tmpl\", resources = resources) fqlist \u003c- bplapply(seq(along = trim), f, BPPARAM = param) pdf(\"./results/fastqReport.pdf\", height = 18, width = 4 * length(fqlist)) seeFastqPlot(unlist(fqlist, recursive = FALSE)) dev.off()  Figure 1: FASTQ quality report for 18 samples\n  Alignments Read mapping with Bowtie2 The NGS reads of this project will be aligned with Bowtie2 against the reference genome sequence (Langmead and Salzberg 2012). The parameter settings of the aligner are defined in the bowtie2-index.cwl and bowtie2-index.yml files. In ChIP-Seq experiments it is usually more appropriate to eliminate reads mapping to multiple locations. To achieve this, users want to remove the argument setting -k 50 non-deterministic in the configuration files.\nBuilding the index:\ndir_path \u003c- system.file(\"extdata/cwl/bowtie2/bowtie2-idx\", package = \"systemPipeR\") idx \u003c- loadWorkflow(targets = NULL, wf_file = \"bowtie2-index.cwl\", input_file = \"bowtie2-index.yml\", dir_path = dir_path) idx \u003c- renderWF(idx) idx cmdlist(idx) ### Run in single machine runCommandline(idx, make_bam = FALSE)  The following submits 18 alignment jobs via a scheduler to a computer cluster.\ntargets \u003c- system.file(\"extdata\", \"targetsPE_chip.txt\", package = \"systemPipeR\") dir_path \u003c- system.file(\"extdata/cwl/bowtie2/bowtie2-pe\", package = \"systemPipeR\") args \u003c- loadWF(targets = targets, wf_file = \"bowtie2-mapping-pe.cwl\", input_file = \"bowtie2-mapping-pe.yml\", dir_path = dir_path) args \u003c- renderWF(args, inputvars = c(FileName1 = \"_FASTQ_PATH1_\", FileName2 = \"_FASTQ_PATH2_\", SampleName = \"_SampleName_\")) args cmdlist(args)[1:2] output(args)[1:2]  moduleload(modules(args)) # Skip if a module system is not used resources \u003c- list(walltime = 120, ntasks = 1, ncpus = 4, memory = 1024) reg \u003c- clusterRun(args, FUN = runCommandline, more.args = list(args = args, dir = FALSE), conffile = \".batchtools.conf.R\", template = \"batchtools.slurm.tmpl\", Njobs = 18, runid = \"01\", resourceList = resources) getStatus(reg = reg) waitForJobs(reg = reg) args \u003c- output_update(args, dir = FALSE, replace = TRUE, extension = c(\".sam\", \".bam\")) ## Updates the output(args) to the right location in the subfolders output(args)  Alternatively, one can run the alignments sequentially on a single system.\nargs \u003c- runCommandline(args, force = F)  Check whether all BAM files have been created and write out the new targets file.\nwriteTargetsout(x = args, file = \"targets_bam.txt\", step = 1, new_col = \"FileName\", new_col_output_index = 1, overwrite = TRUE, remove = TRUE) outpaths \u003c- subsetWF(args, slot = \"output\", subset = 1, index = 1) file.exists(outpaths)  Read and alignment stats The following provides an overview of the number of reads in each sample and how many of them aligned to the reference.\nread_statsDF \u003c- alignStats(args = args) write.table(read_statsDF, \"results/alignStats.xls\", row.names = FALSE, quote = FALSE, sep = \"\\t\") read.delim(\"results/alignStats.xls\")  Create symbolic links for viewing BAM files in IGV The symLink2bam function creates symbolic links to view the BAM alignment files in a genome browser such as IGV without moving these large files to a local system. The corresponding URLs are written to a file with a path specified under urlfile, here IGVurl.txt. Please replace the directory and the user name.\nsymLink2bam(sysargs = args, htmldir = c(\"~/.html/\", \"somedir/\"), urlbase = \"http://cluster.hpcc.ucr.edu/~tgirke/\", urlfile = \"./results/IGVurl.txt\")  Utilities for coverage data The following introduces several utilities useful for ChIP-Seq data. They are not part of the actual workflow.\nRle object stores coverage information library(rtracklayer) library(GenomicRanges) library(Rsamtools) library(GenomicAlignments) outpaths \u003c- subsetWF(args, slot = \"output\", subset = 1, index = 1) aligns \u003c- readGAlignments(outpaths[1]) cov \u003c- coverage(aligns) cov  Resizing aligned reads trim(resize(as(aligns, \"GRanges\"), width = 200))  Naive peak calling islands \u003c- slice(cov, lower = 15) islands[[1]]  Plot coverage for defined region library(ggbio) myloc \u003c- c(\"Chr1\", 1, 1e+05) ga \u003c- readGAlignments(outpaths[1], use.names = TRUE, param = ScanBamParam(which = GRanges(myloc[1], IRanges(as.numeric(myloc[2]), as.numeric(myloc[3]))))) autoplot(ga, aes(color = strand, fill = strand), facets = strand ~ seqnames, stat = \"coverage\")  Peak calling with MACS2 Merge BAM files of replicates prior to peak calling Merging BAM files of technical and/or biological replicates can improve the sensitivity of the peak calling by increasing the depth of read coverage. The mergeBamByFactor function merges BAM files based on grouping information specified by a factor, here the Factor column of the imported targets file. It also returns an updated SYSargs2 object containing the paths to the merged BAM files as well as to any unmerged files without replicates. This step can be skipped if merging of BAM files is not desired.\ndir_path \u003c- system.file(\"extdata/cwl/mergeBamByFactor\", package = \"systemPipeR\") args \u003c- loadWF(targets = \"targets_bam.txt\", wf_file = \"merge-bam.cwl\", input_file = \"merge-bam.yml\", dir_path = dir_path) args \u003c- renderWF(args, inputvars = c(FileName = \"_BAM_PATH_\", SampleName = \"_SampleName_\")) args_merge \u003c- mergeBamByFactor(args = args, overwrite = TRUE) writeTargetsout(x = args_merge, file = \"targets_mergeBamByFactor.txt\", step = 1, new_col = \"FileName\", new_col_output_index = 1, overwrite = TRUE, remove = TRUE)  Peak calling without input/reference sample MACS2 can perform peak calling on ChIP-Seq data with and without input samples (Zhang et al. 2008). The following performs peak calling without input on all samples specified in the corresponding args object. Note, due to the small size of the sample data, MACS2 needs to be run here with the nomodel setting. For real data sets, users want to remove this parameter in the corresponding *.param file(s).\ndir_path \u003c- system.file(\"extdata/cwl/MACS2/MACS2-noinput/\", package = \"systemPipeR\") args \u003c- loadWF(targets = \"targets_mergeBamByFactor.txt\", wf_file = \"macs2.cwl\", input_file = \"macs2.yml\", dir_path = dir_path) args \u003c- renderWF(args, inputvars = c(FileName = \"_FASTQ_PATH1_\", SampleName = \"_SampleName_\")) runCommandline(args, make_bam = FALSE, force = T) outpaths \u003c- subsetWF(args, slot = \"output\", subset = 1, index = 1) file.exists(outpaths) writeTargetsout(x = args, file = \"targets_macs.txt\", step = 1, new_col = \"FileName\", new_col_output_index = 1, overwrite = TRUE)  Peak calling with input/reference sample To perform peak calling with input samples, they can be most conveniently specified in the SampleReference column of the initial targets file. The writeTargetsRef function uses this information to create a targets file intermediate for running MACS2 with the corresponding input samples.\nwriteTargetsRef(infile = \"targets_mergeBamByFactor.txt\", outfile = \"targets_bam_ref.txt\", silent = FALSE, overwrite = TRUE) dir_path \u003c- system.file(\"extdata/cwl/MACS2/MACS2-input/\", package = \"systemPipeR\") args_input \u003c- loadWF(targets = \"targets_bam_ref.txt\", wf_file = \"macs2-input.cwl\", input_file = \"macs2.yml\", dir_path = dir_path) args_input \u003c- renderWF(args_input, inputvars = c(FileName1 = \"_FASTQ_PATH1_\", FileName2 = \"_FASTQ_PATH2_\", SampleName = \"_SampleName_\")) cmdlist(args_input)[1] ### Run args_input \u003c- runCommandline(args_input, make_bam = FALSE, force = T) outpaths_input \u003c- subsetWF(args_input, slot = \"output\", subset = 1, index = 1) file.exists(outpaths_input) writeTargetsout(x = args_input, file = \"targets_macs_input.txt\", step = 1, new_col = \"FileName\", new_col_output_index = 1, overwrite = TRUE)  The peak calling results from MACS2 are written for each sample to separate files in the results directory. They are named after the corresponding files with extensions used by MACS2.\nIdentify consensus peaks The following example shows how one can identify consensus preaks among two peak sets sharing either a minimum absolute overlap and/or minimum relative overlap using the subsetByOverlaps or olRanges functions, respectively.\noutpaths \u003c- subsetWF(args, slot = \"output\", subset = 1, index = 1) ## escolher um dos outputs index peak_M1A \u003c- outpaths[\"M1A\"] peak_M1A \u003c- as(read.delim(peak_M1A, comment = \"#\")[, 1:3], \"GRanges\") peak_A1A \u003c- outpaths[\"A1A\"] peak_A1A \u003c- as(read.delim(peak_A1A, comment = \"#\")[, 1:3], \"GRanges\") (myol1 \u003c- subsetByOverlaps(peak_M1A, peak_A1A, minoverlap = 1)) # Returns any overlap myol2 \u003c- olRanges(query = peak_M1A, subject = peak_A1A, output = \"gr\") # Returns any overlap with OL length information myol2[values(myol2)[\"OLpercQ\"][, 1] \u003e= 50] # Returns only query peaks with a minimum overlap of 50%  Annotate peaks with genomic context Annotation with ChIPpeakAnno package The following annotates the identified peaks with genomic context information using the ChIPpeakAnno and ChIPseeker packages, respectively (Zhu et al. 2010; Yu, Wang, and He 2015).\nlibrary(ChIPpeakAnno) library(GenomicFeatures) dir_path \u003c- system.file(\"extdata/cwl/annotate_peaks\", package = \"systemPipeR\") args \u003c- loadWF(targets = \"targets_macs.txt\", wf_file = \"annotate-peaks.cwl\", input_file = \"annotate-peaks.yml\", dir_path = dir_path) args \u003c- renderWF(args, inputvars = c(FileName = \"_FASTQ_PATH1_\", SampleName = \"_SampleName_\")) txdb \u003c- makeTxDbFromGFF(file = \"data/tair10.gff\", format = \"gff\", dataSource = \"TAIR\", organism = \"Arabidopsis thaliana\") ge \u003c- genes(txdb, columns = c(\"tx_name\", \"gene_id\", \"tx_type\")) for (i in seq(along = args)) { peaksGR \u003c- as(read.delim(infile1(args)[i], comment = \"#\"), \"GRanges\") annotatedPeak \u003c- annotatePeakInBatch(peaksGR, AnnotationData = genes(txdb)) df \u003c- data.frame(as.data.frame(annotatedPeak), as.data.frame(values(ge[values(annotatedPeak)$feature, ]))) outpaths \u003c- subsetWF(args, slot = \"output\", subset = 1, index = 1) write.table(df, outpaths[i], quote = FALSE, row.names = FALSE, sep = \"\\t\") } writeTargetsout(x = args, file = \"targets_peakanno.txt\", step = 1, new_col = \"FileName\", new_col_output_index = 1, overwrite = TRUE)  The peak annotation results are written for each peak set to separate files in the results directory. They are named after the corresponding peak files with extensions specified in the annotate_peaks.param file, here *.peaks.annotated.xls.\nAnnotation with ChIPseeker package Same as in previous step but using the ChIPseeker package for annotating the peaks.\nlibrary(ChIPseeker) for (i in seq(along = args)) { peakAnno \u003c- annotatePeak(infile1(args)[i], TxDb = txdb, verbose = FALSE) df \u003c- as.data.frame(peakAnno) outpaths \u003c- subsetWF(args, slot = \"output\", subset = 1, index = 1) write.table(df, outpaths[i], quote = FALSE, row.names = FALSE, sep = \"\\t\") } writeTargetsout(x = args, file = \"targets_peakanno.txt\", step = 1, new_col = \"FileName\", new_col_output_index = 1, overwrite = TRUE)  Summary plots provided by the ChIPseeker package. Here applied only to one sample for demonstration purposes.\npeak \u003c- readPeakFile(infile1(args)[1]) covplot(peak, weightCol = \"X.log10.pvalue.\") outpaths \u003c- subsetWF(args, slot = \"output\", subset = 1, index = 1) peakHeatmap(outpaths[1], TxDb = txdb, upstream = 1000, downstream = 1000, color = \"red\") plotAvgProf2(outpaths[1], TxDb = txdb, upstream = 1000, downstream = 1000, xlab = \"Genomic Region (5'-\u003e3')\", ylab = \"Read Count Frequency\")  Count reads overlapping peaks The countRangeset function is a convenience wrapper to perform read counting iteratively over serveral range sets, here peak range sets. Internally, the read counting is performed with the summarizeOverlaps function from the GenomicAlignments package. The resulting count tables are directly saved to files, one for each peak set.\nlibrary(GenomicRanges) dir_path \u003c- system.file(\"extdata/cwl/count_rangesets\", package = \"systemPipeR\") args \u003c- loadWF(targets = \"targets_macs.txt\", wf_file = \"count_rangesets.cwl\", input_file = \"count_rangesets.yml\", dir_path = dir_path) args \u003c- renderWF(args, inputvars = c(FileName = \"_FASTQ_PATH1_\", SampleName = \"_SampleName_\")) ### Bam Files targets \u003c- system.file(\"extdata\", \"targetsPE_chip.txt\", package = \"systemPipeR\") dir_path \u003c- system.file(\"extdata/cwl/bowtie2/bowtie2-pe\", package = \"systemPipeR\") args_bam \u003c- loadWF(targets = targets, wf_file = \"bowtie2-mapping-pe.cwl\", input_file = \"bowtie2-mapping-pe.yml\", dir_path = dir_path) args_bam \u003c- renderWF(args_bam, inputvars = c(FileName1 = \"_FASTQ_PATH1_\", SampleName = \"_SampleName_\")) args_bam \u003c- output_update(args_bam, dir = FALSE, replace = TRUE, extension = c(\".sam\", \".bam\")) outpaths \u003c- subsetWF(args_bam, slot = \"output\", subset = 1, index = 1) bfl \u003c- BamFileList(outpaths, yieldSize = 50000, index = character()) countDFnames \u003c- countRangeset(bfl, args, mode = \"Union\", ignore.strand = TRUE) writeTargetsout(x = args, file = \"targets_countDF.txt\", step = 1, new_col = \"FileName\", new_col_output_index = 1, overwrite = TRUE)  Differential binding analysis The runDiff function performs differential binding analysis in batch mode for several count tables using edgeR or DESeq2 (Robinson, McCarthy, and Smyth 2010; Love, Huber, and Anders 2014). Internally, it calls the functions run_edgeR and run_DESeq2. It also returns the filtering results and plots from the downstream filterDEGs function using the fold change and FDR cutoffs provided under the dbrfilter argument.\ndir_path \u003c- system.file(\"extdata/cwl/rundiff\", package = \"systemPipeR\") args_diff \u003c- loadWF(targets = \"targets_countDF.txt\", wf_file = \"rundiff.cwl\", input_file = \"rundiff.yml\", dir_path = dir_path) args_diff \u003c- renderWF(args_diff, inputvars = c(FileName = \"_FASTQ_PATH1_\", SampleName = \"_SampleName_\")) cmp \u003c- readComp(file = args_bam, format = \"matrix\") dbrlist \u003c- runDiff(args = args_diff, diffFct = run_edgeR, targets = targets.as.df(targets(args_bam)), cmp = cmp[[1]], independent = TRUE, dbrfilter = c(Fold = 2, FDR = 1)) writeTargetsout(x = args_diff, file = \"targets_rundiff.txt\", step = 1, new_col = \"FileName\", new_col_output_index = 1, overwrite = TRUE)  GO term enrichment analysis The following performs GO term enrichment analysis for each annotated peak set.\ndir_path \u003c- system.file(\"extdata/cwl/annotate_peaks\", package = \"systemPipeR\") args \u003c- loadWF(targets = \"targets_bam_ref.txt\", wf_file = \"annotate-peaks.cwl\", input_file = \"annotate-peaks.yml\", dir_path = dir_path) args \u003c- renderWF(args, inputvars = c(FileName1 = \"_FASTQ_PATH1_\", FileName2 = \"_FASTQ_PATH2_\", SampleName = \"_SampleName_\")) args_anno \u003c- loadWF(targets = \"targets_macs.txt\", wf_file = \"annotate-peaks.cwl\", input_file = \"annotate-peaks.yml\", dir_path = dir_path) args_anno \u003c- renderWF(args_anno, inputvars = c(FileName = \"_FASTQ_PATH1_\", SampleName = \"_SampleName_\")) annofiles \u003c- subsetWF(args_anno, slot = \"output\", subset = 1, index = 1) gene_ids \u003c- sapply(names(annofiles), function(x) unique(as.character(read.delim(annofiles[x])[, \"geneId\"])), simplify = FALSE) load(\"data/GO/catdb.RData\") BatchResult \u003c- GOCluster_Report(catdb = catdb, setlist = gene_ids, method = \"all\", id_type = \"gene\", CLSZ = 2, cutoff = 0.9, gocats = c(\"MF\", \"BP\", \"CC\"), recordSpecGO = NULL)  Motif analysis Parse DNA sequences of peak regions from genome Enrichment analysis of known DNA binding motifs or de novo discovery of novel motifs requires the DNA sequences of the identified peak regions. To parse the corresponding sequences from the reference genome, the getSeq function from the Biostrings package can be used. The following example parses the sequences for each peak set and saves the results to separate FASTA files, one for each peak set. In addition, the sequences in the FASTA files are ranked (sorted) by increasing p-values as expected by some motif discovery tools, such as BCRANK.\nlibrary(Biostrings) library(seqLogo) library(BCRANK) dir_path \u003c- system.file(\"extdata/cwl/annotate_peaks\", package = \"systemPipeR\") args \u003c- loadWF(targets = \"targets_macs.txt\", wf_file = \"annotate-peaks.cwl\", input_file = \"annotate-peaks.yml\", dir_path = dir_path) args \u003c- renderWF(args, inputvars = c(FileName = \"_FASTQ_PATH1_\", SampleName = \"_SampleName_\")) rangefiles \u003c- infile1(args) for (i in seq(along = rangefiles)) { df \u003c- read.delim(rangefiles[i], comment = \"#\") peaks \u003c- as(df, \"GRanges\") names(peaks) \u003c- paste0(as.character(seqnames(peaks)), \"_\", start(peaks), \"-\", end(peaks)) peaks \u003c- peaks[order(values(peaks)$X.log10.pvalue., decreasing = TRUE)] pseq \u003c- getSeq(FaFile(\"./data/tair10.fasta\"), peaks) names(pseq) \u003c- names(peaks) writeXStringSet(pseq, paste0(rangefiles[i], \".fasta\")) }  Motif discovery with BCRANK The Bioconductor package BCRANK is one of the many tools available for de novo discovery of DNA binding motifs in peak regions of ChIP-Seq experiments. The given example applies this method on the first peak sample set and plots the sequence logo of the highest ranking motif.\nset.seed(0) BCRANKout \u003c- bcrank(paste0(rangefiles[1], \".fasta\"), restarts = 25, use.P1 = TRUE, use.P2 = TRUE) toptable(BCRANKout) topMotif \u003c- toptable(BCRANKout, 1) weightMatrix \u003c- pwm(topMotif, normalize = FALSE) weightMatrixNormalized \u003c- pwm(topMotif, normalize = TRUE) pdf(\"results/seqlogo.pdf\") seqLogo(weightMatrixNormalized) dev.off()  Figure 2: One of the motifs identified by BCRANK\n  Version Information sessionInfo()  ## R version 4.0.5 (2021-03-31) ## Platform: x86_64-pc-linux-gnu (64-bit) ## Running under: Debian GNU/Linux 10 (buster) ## ## Matrix products: default ## BLAS: /usr/lib/x86_64-linux-gnu/blas/libblas.so.3.8.0 ## LAPACK: /usr/lib/x86_64-linux-gnu/lapack/liblapack.so.3.8.0 ## ## locale: ## [1] LC_CTYPE=en_US.UTF-8 LC_NUMERIC=C ## [3] LC_TIME=en_US.UTF-8 LC_COLLATE=en_US.UTF-8 ## [5] LC_MONETARY=en_US.UTF-8 LC_MESSAGES=en_US.UTF-8 ## [7] LC_PAPER=en_US.UTF-8 LC_NAME=C ## [9] LC_ADDRESS=C LC_TELEPHONE=C ## [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C ## ## attached base packages: ## [1] stats4 parallel stats graphics grDevices ## [6] utils datasets methods base ## ## other attached packages: ## [1] systemPipeR_1.24.5 ShortRead_1.48.0 ## [3] GenomicAlignments_1.26.0 SummarizedExperiment_1.20.0 ## [5] Biobase_2.50.0 MatrixGenerics_1.2.0 ## [7] matrixStats_0.57.0 BiocParallel_1.24.1 ## [9] Rsamtools_2.6.0 Biostrings_2.58.0 ## [11] XVector_0.30.0 GenomicRanges_1.42.0 ## [13] GenomeInfoDb_1.26.1 IRanges_2.24.0 ## [15] S4Vectors_0.28.0 BiocGenerics_0.36.0 ## [17] BiocStyle_2.18.0 ## ## loaded via a namespace (and not attached): ## [1] colorspace_2.0-0 rjson_0.2.20 ## [3] hwriter_1.3.2 ellipsis_0.3.1 ## [5] bit64_4.0.5 AnnotationDbi_1.52.0 ## [7] xml2_1.3.2 codetools_0.2-18 ## [9] splines_4.0.5 knitr_1.30 ## [11] jsonlite_1.7.1 annotate_1.68.0 ## [13] GO.db_3.12.1 dbplyr_2.0.0 ## [15] png_0.1-7 pheatmap_1.0.12 ## [17] graph_1.68.0 BiocManager_1.30.10 ## [19] compiler_4.0.5 httr_1.4.2 ## [21] backports_1.2.0 GOstats_2.56.0 ## [23] assertthat_0.2.1 Matrix_1.3-2 ## [25] limma_3.46.0 formatR_1.7 ## [27] htmltools_0.5.1.1 prettyunits_1.1.1 ## [29] tools_4.0.5 gtable_0.3.0 ## [31] glue_1.4.2 GenomeInfoDbData_1.2.4 ## [33] Category_2.56.0 dplyr_1.0.2 ## [35] rsvg_2.1 batchtools_0.9.14 ## [37] rappdirs_0.3.1 V8_3.4.0 ## [39] Rcpp_1.0.5 jquerylib_0.1.3 ## [41] vctrs_0.3.5 blogdown_1.2 ## [43] rtracklayer_1.50.0 xfun_0.22 ## [45] stringr_1.4.0 lifecycle_0.2.0 ## [47] XML_3.99-0.5 edgeR_3.32.0 ## [49] zlibbioc_1.36.0 scales_1.1.1 ## [51] BSgenome_1.58.0 VariantAnnotation_1.36.0 ## [53] hms_0.5.3 RBGL_1.66.0 ## [55] RColorBrewer_1.1-2 yaml_2.2.1 ## [57] curl_4.3 memoise_1.1.0 ## [59] ggplot2_3.3.2 sass_0.3.1 ## [61] biomaRt_2.46.0 latticeExtra_0.6-29 ## [63] stringi_1.5.3 RSQLite_2.2.1 ## [65] genefilter_1.72.0 checkmate_2.0.0 ## [67] GenomicFeatures_1.42.1 DOT_0.1 ## [69] rlang_0.4.8 pkgconfig_2.0.3 ## [71] bitops_1.0-6 evaluate_0.14 ## [73] lattice_0.20-41 purrr_0.3.4 ## [75] bit_4.0.4 tidyselect_1.1.0 ## [77] GSEABase_1.52.0 AnnotationForge_1.32.0 ## [79] magrittr_2.0.1 bookdown_0.21 ## [81] R6_2.5.0 generics_0.1.0 ## [83] base64url_1.4 DelayedArray_0.16.0 ## [85] DBI_1.1.0 withr_2.3.0 ## [87] pillar_1.4.7 survival_3.2-10 ## [89] RCurl_1.98-1.2 tibble_3.0.4 ## [91] crayon_1.3.4 BiocFileCache_1.14.0 ## [93] rmarkdown_2.7 jpeg_0.1-8.1 ## [95] progress_1.2.2 locfit_1.5-9.4 ## [97] grid_4.0.5 data.table_1.13.2 ## [99] blob_1.2.1 Rgraphviz_2.34.0 ## [101] digest_0.6.27 xtable_1.8-4 ## [103] brew_1.0-6 openssl_1.4.3 ## [105] munsell_0.5.0 bslib_0.2.4 ## [107] askpass_1.1  Funding This project is funded by NSF award ABI-1661152.\nReferences H Backman, Tyler W, and Thomas Girke. 2016. “systemPipeR: NGS workflow and report generation environment.” BMC Bioinformatics 17 (1): 388. https://doi.org/10.1186/s12859-016-1241-0.\n Langmead, Ben, and Steven L Salzberg. 2012. “Fast Gapped-Read Alignment with Bowtie 2.” Nat. Methods 9 (4): 357–59. https://doi.org/10.1038/nmeth.1923.\n Love, Michael, Wolfgang Huber, and Simon Anders. 2014. “Moderated Estimation of Fold Change and Dispersion for RNA-seq Data with DESeq2.” Genome Biol. 15 (12): 550. https://doi.org/10.1186/s13059-014-0550-8.\n Robinson, M D, D J McCarthy, and G K Smyth. 2010. “edgeR: A Bioconductor Package for Differential Expression Analysis of Digital Gene Expression Data.” Bioinformatics 26 (1): 139–40. https://doi.org/10.1093/bioinformatics/btp616.\n Yu, Guangchuang, Li-Gen Wang, and Qing-Yu He. 2015. “ChIPseeker: An R/Bioconductor Package for ChIP Peak Annotation, Comparison and Visualization.” Bioinformatics 31 (14): 2382–83. https://doi.org/10.1093/bioinformatics/btv145.\n Zhang, Y, T Liu, C A Meyer, J Eeckhoute, D S Johnson, B E Bernstein, C Nussbaum, et al. 2008. “Model-Based Analysis of ChIP-Seq (MACS).” Genome Biol. 9 (9). https://doi.org/10.1186/gb-2008-9-9-r137.\n Zhu, Lihua J, Claude Gazin, Nathan D Lawson, Hervé Pagès, Simon M Lin, David S Lapointe, and Michael R Green. 2010. “ChIPpeakAnno: A Bioconductor Package to Annotate ChIP-seq and ChIP-chip Data.” BMC Bioinformatics 11: 237. https://doi.org/10.1186/1471-2105-11-237.\n  ","categories":"","description":"","excerpt":"pre code { white-space: pre !important; overflow-x: scroll !important; …","ref":"/manuals/spchipseq/spchipseq/","tags":"","title":"ChIP-Seq Workflow Template"},{"body":"pre code { white-space: pre !important; overflow-x: scroll !important; word-break: keep-all !important; word-wrap: initial !important; }  document.addEventListener(\"DOMContentLoaded\", function() { document.querySelector(\"h1\").className = \"title\"; });  document.addEventListener(\"DOMContentLoaded\", function() { var links = document.links; for (var i = 0, linksLength = links.length; i Source code downloads: [ .Rmd ] [ .R ]\n Introduction Users want to provide here background information about the design of their ChIP-Seq project.\nBackground and objectives This report describes the analysis of several ChIP-Seq experiments studying the DNA binding patterns of the transcriptions factors … from organism ….\nExperimental design Typically, users want to specify here all information relevant for the analysis of their NGS study. This includes detailed descriptions of FASTQ files, experimental design, reference genome, gene annotations, etc.\nWorkflow environment NOTE: this section describes how to set up the proper environment (directory structure) for running systemPipeR workflows. After mastering this task the workflow run instructions can be deleted since they are not expected to be included in a final HTML/PDF report of a workflow.\n  If a remote system or cluster is used, then users need to log in to the remote system first. The following applies to an HPC cluster (e.g. HPCC cluster).\nA terminal application needs to be used to log in to a user’s cluster account. Next, one can open an interactive session on a computer node with srun. More details about argument settings for srun are available in this HPCC manual or the HPCC section of this website here. Next, load the R version required for running the workflow with module load. Sometimes it may be necessary to first unload an active software version before loading another version, e.g. module unload R.\n  srun --x11 --partition=short --mem=8gb --cpus-per-task 4 --ntasks 1 --time 2:00:00 --pty bash -l module load R/4.0.3  Load a workflow template with the genWorkenvir function. This can be done from the command-line or from within R. However, only one of the two options needs to be used.  From command-line\n$ Rscript -e \"systemPipeRdata::genWorkenvir(workflow='chipseq')\" $ cd chipseq  From R\nlibrary(systemPipeRdata) genWorkenvir(workflow = \"chipseq\") setwd(\"chipseq\")   Optional: if the user wishes to use another Rmd file than the template instance provided by the genWorkenvir function, then it can be copied or downloaded into the root directory of the workflow environment (e.g. with cp or wget).\n  Now one can open from the root directory of the workflow the corresponding R Markdown script (e.g. systemPipeChIPseq.Rmd) using an R IDE, such as nvim-r, ESS or RStudio. Subsequently, the workflow can be run as outlined below. For learning purposes it is recommended to run workflows for the first time interactively. Once all workflow steps are understood and possibly modified to custom needs, one can run the workflow from start to finish with a single command using rmarkdown::render() or runWF().\n  Load packages The systemPipeR package needs to be loaded to perform the analysis steps shown in this report (H Backman and Girke 2016). The package allows users to run the entire analysis workflow interactively or with a single command while also generating the corresponding analysis report. For details see systemPipeR's main vignette.\nlibrary(systemPipeR)  Read preprocessing Experiment definition provided by targets file The targets file defines all FASTQ files and sample comparisons of the analysis workflow.\ntargetspath \u003c- system.file(\"extdata\", \"targetsPE_chip.txt\", package = \"systemPipeR\") targets \u003c- read.delim(targetspath, comment.char = \"#\") targets[1:4, -c(5, 6)]  ## FileName1 FileName2 ## 1 ./data/SRR446027_1.fastq.gz ./data/SRR446027_2.fastq.gz ## 2 ./data/SRR446028_1.fastq.gz ./data/SRR446028_2.fastq.gz ## 3 ./data/SRR446029_1.fastq.gz ./data/SRR446029_2.fastq.gz ## 4 ./data/SRR446030_1.fastq.gz ./data/SRR446030_2.fastq.gz ## SampleName Factor Date SampleReference ## 1 M1A M1 23-Mar-2012 ## 2 M1B M1 23-Mar-2012 ## 3 A1A A1 23-Mar-2012 M1A ## 4 A1B A1 23-Mar-2012 M1B  Read quality filtering and trimming The following example shows how one can design a custom read preprocessing function using utilities provided by the ShortRead package, and then apply it with preprocessReads in batch mode to all FASTQ samples referenced in the corresponding SYSargs2 instance (trim object below). More detailed information on read preprocessing is provided in systemPipeR's main vignette.\nFirst, we construct SYSargs2 object from cwl and yml param and targets files.\ndir_path \u003c- system.file(\"extdata/cwl/preprocessReads/trim-pe\", package = \"systemPipeR\") trim \u003c- loadWF(targets = targetspath, wf_file = \"trim-pe.cwl\", input_file = \"trim-pe.yml\", dir_path = dir_path) trim \u003c- renderWF(trim, inputvars = c(FileName1 = \"_FASTQ_PATH1_\", FileName2 = \"_FASTQ_PATH2_\", SampleName = \"_SampleName_\")) trim output(trim)[1:2]  Next, we execute the code for trimming all the raw data.\nfilterFct \u003c- function(fq, cutoff = 20, Nexceptions = 0) { qcount \u003c- rowSums(as(quality(fq), \"matrix\") \u003c= cutoff, na.rm = TRUE) fq[qcount \u003c= Nexceptions] # Retains reads where Phred scores are \u003e= cutoff with N # exceptions } preprocessReads(args = trim, Fct = \"filterFct(fq, cutoff=20, Nexceptions=0)\", batchsize = 1e+05) writeTargetsout(x = trim, file = \"targets_chip_trimPE.txt\", step = 1, new_col = c(\"FileName1\", \"FileName2\"), new_col_output_index = c(1, 2), overwrite = TRUE)  FASTQ quality report The following seeFastq and seeFastqPlot functions generate and plot a series of useful quality statistics for a set of FASTQ files including per cycle quality box plots, base proportions, base-level quality trends, relative k-mer diversity, length and occurrence distribution of reads, number of reads above quality cutoffs and mean quality distribution. The results are written to a PDF file named fastqReport.pdf. Parallelization of FASTQ quality report via scheduler (e.g. Slurm) across several compute nodes.\nlibrary(BiocParallel) library(batchtools) f \u003c- function(x) { library(systemPipeR) targets \u003c- system.file(\"extdata\", \"targetsPE_chip.txt\", package = \"systemPipeR\") dir_path \u003c- system.file(\"extdata/cwl/preprocessReads/trim-pe\", package = \"systemPipeR\") trim \u003c- loadWorkflow(targets = targets, wf_file = \"trim-pe.cwl\", input_file = \"trim-pe.yml\", dir_path = dir_path) trim \u003c- renderWF(trim, inputvars = c(FileName1 = \"_FASTQ_PATH1_\", FileName2 = \"_FASTQ_PATH2_\", SampleName = \"_SampleName_\")) seeFastq(fastq = infile1(trim)[x], batchsize = 1e+05, klength = 8) } resources \u003c- list(walltime = 120, ntasks = 1, ncpus = 4, memory = 1024) param \u003c- BatchtoolsParam(workers = 4, cluster = \"slurm\", template = \"batchtools.slurm.tmpl\", resources = resources) fqlist \u003c- bplapply(seq(along = trim), f, BPPARAM = param) pdf(\"./results/fastqReport.pdf\", height = 18, width = 4 * length(fqlist)) seeFastqPlot(unlist(fqlist, recursive = FALSE)) dev.off()  Figure 1: FASTQ quality report for 18 samples\n  Alignments Read mapping with Bowtie2 The NGS reads of this project will be aligned with Bowtie2 against the reference genome sequence (Langmead and Salzberg 2012). The parameter settings of the aligner are defined in the bowtie2-index.cwl and bowtie2-index.yml files. In ChIP-Seq experiments it is usually more appropriate to eliminate reads mapping to multiple locations. To achieve this, users want to remove the argument setting -k 50 non-deterministic in the configuration files.\nBuilding the index:\ndir_path \u003c- system.file(\"extdata/cwl/bowtie2/bowtie2-idx\", package = \"systemPipeR\") idx \u003c- loadWorkflow(targets = NULL, wf_file = \"bowtie2-index.cwl\", input_file = \"bowtie2-index.yml\", dir_path = dir_path) idx \u003c- renderWF(idx) idx cmdlist(idx) ### Run in single machine runCommandline(idx, make_bam = FALSE)  The following submits 18 alignment jobs via a scheduler to a computer cluster.\ntargets \u003c- system.file(\"extdata\", \"targetsPE_chip.txt\", package = \"systemPipeR\") dir_path \u003c- system.file(\"extdata/cwl/bowtie2/bowtie2-pe\", package = \"systemPipeR\") args \u003c- loadWF(targets = targets, wf_file = \"bowtie2-mapping-pe.cwl\", input_file = \"bowtie2-mapping-pe.yml\", dir_path = dir_path) args \u003c- renderWF(args, inputvars = c(FileName1 = \"_FASTQ_PATH1_\", FileName2 = \"_FASTQ_PATH2_\", SampleName = \"_SampleName_\")) args cmdlist(args)[1:2] output(args)[1:2]  moduleload(modules(args)) # Skip if a module system is not used resources \u003c- list(walltime = 120, ntasks = 1, ncpus = 4, memory = 1024) reg \u003c- clusterRun(args, FUN = runCommandline, more.args = list(args = args, dir = FALSE), conffile = \".batchtools.conf.R\", template = \"batchtools.slurm.tmpl\", Njobs = 18, runid = \"01\", resourceList = resources) getStatus(reg = reg) waitForJobs(reg = reg) args \u003c- output_update(args, dir = FALSE, replace = TRUE, extension = c(\".sam\", \".bam\")) ## Updates the output(args) to the right location in the subfolders output(args)  Alternatively, one can run the alignments sequentially on a single system.\nargs \u003c- runCommandline(args, force = F)  Check whether all BAM files have been created and write out the new targets file.\nwriteTargetsout(x = args, file = \"targets_bam.txt\", step = 1, new_col = \"FileName\", new_col_output_index = 1, overwrite = TRUE, remove = TRUE) outpaths \u003c- subsetWF(args, slot = \"output\", subset = 1, index = 1) file.exists(outpaths)  Read and alignment stats The following provides an overview of the number of reads in each sample and how many of them aligned to the reference.\nread_statsDF \u003c- alignStats(args = args) write.table(read_statsDF, \"results/alignStats.xls\", row.names = FALSE, quote = FALSE, sep = \"\\t\") read.delim(\"results/alignStats.xls\")  Create symbolic links for viewing BAM files in IGV The symLink2bam function creates symbolic links to view the BAM alignment files in a genome browser such as IGV without moving these large files to a local system. The corresponding URLs are written to a file with a path specified under urlfile, here IGVurl.txt. Please replace the directory and the user name.\nsymLink2bam(sysargs = args, htmldir = c(\"~/.html/\", \"somedir/\"), urlbase = \"http://cluster.hpcc.ucr.edu/~tgirke/\", urlfile = \"./results/IGVurl.txt\")  Utilities for coverage data The following introduces several utilities useful for ChIP-Seq data. They are not part of the actual workflow.\nRle object stores coverage information library(rtracklayer) library(GenomicRanges) library(Rsamtools) library(GenomicAlignments) outpaths \u003c- subsetWF(args, slot = \"output\", subset = 1, index = 1) aligns \u003c- readGAlignments(outpaths[1]) cov \u003c- coverage(aligns) cov  Resizing aligned reads trim(resize(as(aligns, \"GRanges\"), width = 200))  Naive peak calling islands \u003c- slice(cov, lower = 15) islands[[1]]  Plot coverage for defined region library(ggbio) myloc \u003c- c(\"Chr1\", 1, 1e+05) ga \u003c- readGAlignments(outpaths[1], use.names = TRUE, param = ScanBamParam(which = GRanges(myloc[1], IRanges(as.numeric(myloc[2]), as.numeric(myloc[3]))))) autoplot(ga, aes(color = strand, fill = strand), facets = strand ~ seqnames, stat = \"coverage\")  Peak calling with MACS2 Merge BAM files of replicates prior to peak calling Merging BAM files of technical and/or biological replicates can improve the sensitivity of the peak calling by increasing the depth of read coverage. The mergeBamByFactor function merges BAM files based on grouping information specified by a factor, here the Factor column of the imported targets file. It also returns an updated SYSargs2 object containing the paths to the merged BAM files as well as to any unmerged files without replicates. This step can be skipped if merging of BAM files is not desired.\ndir_path \u003c- system.file(\"extdata/cwl/mergeBamByFactor\", package = \"systemPipeR\") args \u003c- loadWF(targets = \"targets_bam.txt\", wf_file = \"merge-bam.cwl\", input_file = \"merge-bam.yml\", dir_path = dir_path) args \u003c- renderWF(args, inputvars = c(FileName = \"_BAM_PATH_\", SampleName = \"_SampleName_\")) args_merge \u003c- mergeBamByFactor(args = args, overwrite = TRUE) writeTargetsout(x = args_merge, file = \"targets_mergeBamByFactor.txt\", step = 1, new_col = \"FileName\", new_col_output_index = 1, overwrite = TRUE, remove = TRUE)  Peak calling without input/reference sample MACS2 can perform peak calling on ChIP-Seq data with and without input samples (Zhang et al. 2008). The following performs peak calling without input on all samples specified in the corresponding args object. Note, due to the small size of the sample data, MACS2 needs to be run here with the nomodel setting. For real data sets, users want to remove this parameter in the corresponding *.param file(s).\ndir_path \u003c- system.file(\"extdata/cwl/MACS2/MACS2-noinput/\", package = \"systemPipeR\") args \u003c- loadWF(targets = \"targets_mergeBamByFactor.txt\", wf_file = \"macs2.cwl\", input_file = \"macs2.yml\", dir_path = dir_path) args \u003c- renderWF(args, inputvars = c(FileName = \"_FASTQ_PATH1_\", SampleName = \"_SampleName_\")) runCommandline(args, make_bam = FALSE, force = T) outpaths \u003c- subsetWF(args, slot = \"output\", subset = 1, index = 1) file.exists(outpaths) writeTargetsout(x = args, file = \"targets_macs.txt\", step = 1, new_col = \"FileName\", new_col_output_index = 1, overwrite = TRUE)  Peak calling with input/reference sample To perform peak calling with input samples, they can be most conveniently specified in the SampleReference column of the initial targets file. The writeTargetsRef function uses this information to create a targets file intermediate for running MACS2 with the corresponding input samples.\nwriteTargetsRef(infile = \"targets_mergeBamByFactor.txt\", outfile = \"targets_bam_ref.txt\", silent = FALSE, overwrite = TRUE) dir_path \u003c- system.file(\"extdata/cwl/MACS2/MACS2-input/\", package = \"systemPipeR\") args_input \u003c- loadWF(targets = \"targets_bam_ref.txt\", wf_file = \"macs2-input.cwl\", input_file = \"macs2.yml\", dir_path = dir_path) args_input \u003c- renderWF(args_input, inputvars = c(FileName1 = \"_FASTQ_PATH1_\", FileName2 = \"_FASTQ_PATH2_\", SampleName = \"_SampleName_\")) cmdlist(args_input)[1] ### Run args_input \u003c- runCommandline(args_input, make_bam = FALSE, force = T) outpaths_input \u003c- subsetWF(args_input, slot = \"output\", subset = 1, index = 1) file.exists(outpaths_input) writeTargetsout(x = args_input, file = \"targets_macs_input.txt\", step = 1, new_col = \"FileName\", new_col_output_index = 1, overwrite = TRUE)  The peak calling results from MACS2 are written for each sample to separate files in the results directory. They are named after the corresponding files with extensions used by MACS2.\nIdentify consensus peaks The following example shows how one can identify consensus preaks among two peak sets sharing either a minimum absolute overlap and/or minimum relative overlap using the subsetByOverlaps or olRanges functions, respectively.\noutpaths \u003c- subsetWF(args, slot = \"output\", subset = 1, index = 1) ## escolher um dos outputs index peak_M1A \u003c- outpaths[\"M1A\"] peak_M1A \u003c- as(read.delim(peak_M1A, comment = \"#\")[, 1:3], \"GRanges\") peak_A1A \u003c- outpaths[\"A1A\"] peak_A1A \u003c- as(read.delim(peak_A1A, comment = \"#\")[, 1:3], \"GRanges\") (myol1 \u003c- subsetByOverlaps(peak_M1A, peak_A1A, minoverlap = 1)) # Returns any overlap myol2 \u003c- olRanges(query = peak_M1A, subject = peak_A1A, output = \"gr\") # Returns any overlap with OL length information myol2[values(myol2)[\"OLpercQ\"][, 1] \u003e= 50] # Returns only query peaks with a minimum overlap of 50%  Annotate peaks with genomic context Annotation with ChIPpeakAnno package The following annotates the identified peaks with genomic context information using the ChIPpeakAnno and ChIPseeker packages, respectively (Zhu et al. 2010; Yu, Wang, and He 2015).\nlibrary(ChIPpeakAnno) library(GenomicFeatures) dir_path \u003c- system.file(\"extdata/cwl/annotate_peaks\", package = \"systemPipeR\") args \u003c- loadWF(targets = \"targets_macs.txt\", wf_file = \"annotate-peaks.cwl\", input_file = \"annotate-peaks.yml\", dir_path = dir_path) args \u003c- renderWF(args, inputvars = c(FileName = \"_FASTQ_PATH1_\", SampleName = \"_SampleName_\")) txdb \u003c- makeTxDbFromGFF(file = \"data/tair10.gff\", format = \"gff\", dataSource = \"TAIR\", organism = \"Arabidopsis thaliana\") ge \u003c- genes(txdb, columns = c(\"tx_name\", \"gene_id\", \"tx_type\")) for (i in seq(along = args)) { peaksGR \u003c- as(read.delim(infile1(args)[i], comment = \"#\"), \"GRanges\") annotatedPeak \u003c- annotatePeakInBatch(peaksGR, AnnotationData = genes(txdb)) df \u003c- data.frame(as.data.frame(annotatedPeak), as.data.frame(values(ge[values(annotatedPeak)$feature, ]))) outpaths \u003c- subsetWF(args, slot = \"output\", subset = 1, index = 1) write.table(df, outpaths[i], quote = FALSE, row.names = FALSE, sep = \"\\t\") } writeTargetsout(x = args, file = \"targets_peakanno.txt\", step = 1, new_col = \"FileName\", new_col_output_index = 1, overwrite = TRUE)  The peak annotation results are written for each peak set to separate files in the results directory. They are named after the corresponding peak files with extensions specified in the annotate_peaks.param file, here *.peaks.annotated.xls.\nAnnotation with ChIPseeker package Same as in previous step but using the ChIPseeker package for annotating the peaks.\nlibrary(ChIPseeker) for (i in seq(along = args)) { peakAnno \u003c- annotatePeak(infile1(args)[i], TxDb = txdb, verbose = FALSE) df \u003c- as.data.frame(peakAnno) outpaths \u003c- subsetWF(args, slot = \"output\", subset = 1, index = 1) write.table(df, outpaths[i], quote = FALSE, row.names = FALSE, sep = \"\\t\") } writeTargetsout(x = args, file = \"targets_peakanno.txt\", step = 1, new_col = \"FileName\", new_col_output_index = 1, overwrite = TRUE)  Summary plots provided by the ChIPseeker package. Here applied only to one sample for demonstration purposes.\npeak \u003c- readPeakFile(infile1(args)[1]) covplot(peak, weightCol = \"X.log10.pvalue.\") outpaths \u003c- subsetWF(args, slot = \"output\", subset = 1, index = 1) peakHeatmap(outpaths[1], TxDb = txdb, upstream = 1000, downstream = 1000, color = \"red\") plotAvgProf2(outpaths[1], TxDb = txdb, upstream = 1000, downstream = 1000, xlab = \"Genomic Region (5'-\u003e3')\", ylab = \"Read Count Frequency\")  Count reads overlapping peaks The countRangeset function is a convenience wrapper to perform read counting iteratively over serveral range sets, here peak range sets. Internally, the read counting is performed with the summarizeOverlaps function from the GenomicAlignments package. The resulting count tables are directly saved to files, one for each peak set.\nlibrary(GenomicRanges) dir_path \u003c- system.file(\"extdata/cwl/count_rangesets\", package = \"systemPipeR\") args \u003c- loadWF(targets = \"targets_macs.txt\", wf_file = \"count_rangesets.cwl\", input_file = \"count_rangesets.yml\", dir_path = dir_path) args \u003c- renderWF(args, inputvars = c(FileName = \"_FASTQ_PATH1_\", SampleName = \"_SampleName_\")) ### Bam Files targets \u003c- system.file(\"extdata\", \"targetsPE_chip.txt\", package = \"systemPipeR\") dir_path \u003c- system.file(\"extdata/cwl/bowtie2/bowtie2-pe\", package = \"systemPipeR\") args_bam \u003c- loadWF(targets = targets, wf_file = \"bowtie2-mapping-pe.cwl\", input_file = \"bowtie2-mapping-pe.yml\", dir_path = dir_path) args_bam \u003c- renderWF(args_bam, inputvars = c(FileName1 = \"_FASTQ_PATH1_\", SampleName = \"_SampleName_\")) args_bam \u003c- output_update(args_bam, dir = FALSE, replace = TRUE, extension = c(\".sam\", \".bam\")) outpaths \u003c- subsetWF(args_bam, slot = \"output\", subset = 1, index = 1) bfl \u003c- BamFileList(outpaths, yieldSize = 50000, index = character()) countDFnames \u003c- countRangeset(bfl, args, mode = \"Union\", ignore.strand = TRUE) writeTargetsout(x = args, file = \"targets_countDF.txt\", step = 1, new_col = \"FileName\", new_col_output_index = 1, overwrite = TRUE)  Differential binding analysis The runDiff function performs differential binding analysis in batch mode for several count tables using edgeR or DESeq2 (Robinson, McCarthy, and Smyth 2010; Love, Huber, and Anders 2014). Internally, it calls the functions run_edgeR and run_DESeq2. It also returns the filtering results and plots from the downstream filterDEGs function using the fold change and FDR cutoffs provided under the dbrfilter argument.\ndir_path \u003c- system.file(\"extdata/cwl/rundiff\", package = \"systemPipeR\") args_diff \u003c- loadWF(targets = \"targets_countDF.txt\", wf_file = \"rundiff.cwl\", input_file = \"rundiff.yml\", dir_path = dir_path) args_diff \u003c- renderWF(args_diff, inputvars = c(FileName = \"_FASTQ_PATH1_\", SampleName = \"_SampleName_\")) cmp \u003c- readComp(file = args_bam, format = \"matrix\") dbrlist \u003c- runDiff(args = args_diff, diffFct = run_edgeR, targets = targets.as.df(targets(args_bam)), cmp = cmp[[1]], independent = TRUE, dbrfilter = c(Fold = 2, FDR = 1)) writeTargetsout(x = args_diff, file = \"targets_rundiff.txt\", step = 1, new_col = \"FileName\", new_col_output_index = 1, overwrite = TRUE)  GO term enrichment analysis The following performs GO term enrichment analysis for each annotated peak set.\ndir_path \u003c- system.file(\"extdata/cwl/annotate_peaks\", package = \"systemPipeR\") args \u003c- loadWF(targets = \"targets_bam_ref.txt\", wf_file = \"annotate-peaks.cwl\", input_file = \"annotate-peaks.yml\", dir_path = dir_path) args \u003c- renderWF(args, inputvars = c(FileName1 = \"_FASTQ_PATH1_\", FileName2 = \"_FASTQ_PATH2_\", SampleName = \"_SampleName_\")) args_anno \u003c- loadWF(targets = \"targets_macs.txt\", wf_file = \"annotate-peaks.cwl\", input_file = \"annotate-peaks.yml\", dir_path = dir_path) args_anno \u003c- renderWF(args_anno, inputvars = c(FileName = \"_FASTQ_PATH1_\", SampleName = \"_SampleName_\")) annofiles \u003c- subsetWF(args_anno, slot = \"output\", subset = 1, index = 1) gene_ids \u003c- sapply(names(annofiles), function(x) unique(as.character(read.delim(annofiles[x])[, \"geneId\"])), simplify = FALSE) load(\"data/GO/catdb.RData\") BatchResult \u003c- GOCluster_Report(catdb = catdb, setlist = gene_ids, method = \"all\", id_type = \"gene\", CLSZ = 2, cutoff = 0.9, gocats = c(\"MF\", \"BP\", \"CC\"), recordSpecGO = NULL)  Motif analysis Parse DNA sequences of peak regions from genome Enrichment analysis of known DNA binding motifs or de novo discovery of novel motifs requires the DNA sequences of the identified peak regions. To parse the corresponding sequences from the reference genome, the getSeq function from the Biostrings package can be used. The following example parses the sequences for each peak set and saves the results to separate FASTA files, one for each peak set. In addition, the sequences in the FASTA files are ranked (sorted) by increasing p-values as expected by some motif discovery tools, such as BCRANK.\nlibrary(Biostrings) library(seqLogo) library(BCRANK) dir_path \u003c- system.file(\"extdata/cwl/annotate_peaks\", package = \"systemPipeR\") args \u003c- loadWF(targets = \"targets_macs.txt\", wf_file = \"annotate-peaks.cwl\", input_file = \"annotate-peaks.yml\", dir_path = dir_path) args \u003c- renderWF(args, inputvars = c(FileName = \"_FASTQ_PATH1_\", SampleName = \"_SampleName_\")) rangefiles \u003c- infile1(args) for (i in seq(along = rangefiles)) { df \u003c- read.delim(rangefiles[i], comment = \"#\") peaks \u003c- as(df, \"GRanges\") names(peaks) \u003c- paste0(as.character(seqnames(peaks)), \"_\", start(peaks), \"-\", end(peaks)) peaks \u003c- peaks[order(values(peaks)$X.log10.pvalue., decreasing = TRUE)] pseq \u003c- getSeq(FaFile(\"./data/tair10.fasta\"), peaks) names(pseq) \u003c- names(peaks) writeXStringSet(pseq, paste0(rangefiles[i], \".fasta\")) }  Motif discovery with BCRANK The Bioconductor package BCRANK is one of the many tools available for de novo discovery of DNA binding motifs in peak regions of ChIP-Seq experiments. The given example applies this method on the first peak sample set and plots the sequence logo of the highest ranking motif.\nset.seed(0) BCRANKout \u003c- bcrank(paste0(rangefiles[1], \".fasta\"), restarts = 25, use.P1 = TRUE, use.P2 = TRUE) toptable(BCRANKout) topMotif \u003c- toptable(BCRANKout, 1) weightMatrix \u003c- pwm(topMotif, normalize = FALSE) weightMatrixNormalized \u003c- pwm(topMotif, normalize = TRUE) pdf(\"results/seqlogo.pdf\") seqLogo(weightMatrixNormalized) dev.off()  Figure 2: One of the motifs identified by BCRANK\n  Version Information sessionInfo()  ## R version 4.0.5 (2021-03-31) ## Platform: x86_64-pc-linux-gnu (64-bit) ## Running under: Debian GNU/Linux 10 (buster) ## ## Matrix products: default ## BLAS: /usr/lib/x86_64-linux-gnu/blas/libblas.so.3.8.0 ## LAPACK: /usr/lib/x86_64-linux-gnu/lapack/liblapack.so.3.8.0 ## ## locale: ## [1] LC_CTYPE=en_US.UTF-8 LC_NUMERIC=C ## [3] LC_TIME=en_US.UTF-8 LC_COLLATE=en_US.UTF-8 ## [5] LC_MONETARY=en_US.UTF-8 LC_MESSAGES=en_US.UTF-8 ## [7] LC_PAPER=en_US.UTF-8 LC_NAME=C ## [9] LC_ADDRESS=C LC_TELEPHONE=C ## [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C ## ## attached base packages: ## [1] stats4 parallel stats graphics grDevices ## [6] utils datasets methods base ## ## other attached packages: ## [1] systemPipeR_1.24.5 ShortRead_1.48.0 ## [3] GenomicAlignments_1.26.0 SummarizedExperiment_1.20.0 ## [5] Biobase_2.50.0 MatrixGenerics_1.2.0 ## [7] matrixStats_0.57.0 BiocParallel_1.24.1 ## [9] Rsamtools_2.6.0 Biostrings_2.58.0 ## [11] XVector_0.30.0 GenomicRanges_1.42.0 ## [13] GenomeInfoDb_1.26.1 IRanges_2.24.0 ## [15] S4Vectors_0.28.0 BiocGenerics_0.36.0 ## [17] BiocStyle_2.18.0 ## ## loaded via a namespace (and not attached): ## [1] colorspace_2.0-0 rjson_0.2.20 ## [3] hwriter_1.3.2 ellipsis_0.3.1 ## [5] bit64_4.0.5 AnnotationDbi_1.52.0 ## [7] xml2_1.3.2 codetools_0.2-18 ## [9] splines_4.0.5 knitr_1.30 ## [11] jsonlite_1.7.1 annotate_1.68.0 ## [13] GO.db_3.12.1 dbplyr_2.0.0 ## [15] png_0.1-7 pheatmap_1.0.12 ## [17] graph_1.68.0 BiocManager_1.30.10 ## [19] compiler_4.0.5 httr_1.4.2 ## [21] backports_1.2.0 GOstats_2.56.0 ## [23] assertthat_0.2.1 Matrix_1.3-2 ## [25] limma_3.46.0 formatR_1.7 ## [27] htmltools_0.5.1.1 prettyunits_1.1.1 ## [29] tools_4.0.5 gtable_0.3.0 ## [31] glue_1.4.2 GenomeInfoDbData_1.2.4 ## [33] Category_2.56.0 dplyr_1.0.2 ## [35] rsvg_2.1 batchtools_0.9.14 ## [37] rappdirs_0.3.1 V8_3.4.0 ## [39] Rcpp_1.0.5 jquerylib_0.1.3 ## [41] vctrs_0.3.5 blogdown_1.2 ## [43] rtracklayer_1.50.0 xfun_0.22 ## [45] stringr_1.4.0 lifecycle_0.2.0 ## [47] XML_3.99-0.5 edgeR_3.32.0 ## [49] zlibbioc_1.36.0 scales_1.1.1 ## [51] BSgenome_1.58.0 VariantAnnotation_1.36.0 ## [53] hms_0.5.3 RBGL_1.66.0 ## [55] RColorBrewer_1.1-2 yaml_2.2.1 ## [57] curl_4.3 memoise_1.1.0 ## [59] ggplot2_3.3.2 sass_0.3.1 ## [61] biomaRt_2.46.0 latticeExtra_0.6-29 ## [63] stringi_1.5.3 RSQLite_2.2.1 ## [65] genefilter_1.72.0 checkmate_2.0.0 ## [67] GenomicFeatures_1.42.1 DOT_0.1 ## [69] rlang_0.4.8 pkgconfig_2.0.3 ## [71] bitops_1.0-6 evaluate_0.14 ## [73] lattice_0.20-41 purrr_0.3.4 ## [75] bit_4.0.4 tidyselect_1.1.0 ## [77] GSEABase_1.52.0 AnnotationForge_1.32.0 ## [79] magrittr_2.0.1 bookdown_0.21 ## [81] R6_2.5.0 generics_0.1.0 ## [83] base64url_1.4 DelayedArray_0.16.0 ## [85] DBI_1.1.0 withr_2.3.0 ## [87] pillar_1.4.7 survival_3.2-10 ## [89] RCurl_1.98-1.2 tibble_3.0.4 ## [91] crayon_1.3.4 BiocFileCache_1.14.0 ## [93] rmarkdown_2.7 jpeg_0.1-8.1 ## [95] progress_1.2.2 locfit_1.5-9.4 ## [97] grid_4.0.5 data.table_1.13.2 ## [99] blob_1.2.1 Rgraphviz_2.34.0 ## [101] digest_0.6.27 xtable_1.8-4 ## [103] brew_1.0-6 openssl_1.4.3 ## [105] munsell_0.5.0 bslib_0.2.4 ## [107] askpass_1.1  Funding This project is funded by NSF award ABI-1661152.\nReferences H Backman, Tyler W, and Thomas Girke. 2016. “systemPipeR: NGS workflow and report generation environment.” BMC Bioinformatics 17 (1): 388. https://doi.org/10.1186/s12859-016-1241-0.\n Langmead, Ben, and Steven L Salzberg. 2012. “Fast Gapped-Read Alignment with Bowtie 2.” Nat. Methods 9 (4): 357–59. https://doi.org/10.1038/nmeth.1923.\n Love, Michael, Wolfgang Huber, and Simon Anders. 2014. “Moderated Estimation of Fold Change and Dispersion for RNA-seq Data with DESeq2.” Genome Biol. 15 (12): 550. https://doi.org/10.1186/s13059-014-0550-8.\n Robinson, M D, D J McCarthy, and G K Smyth. 2010. “edgeR: A Bioconductor Package for Differential Expression Analysis of Digital Gene Expression Data.” Bioinformatics 26 (1): 139–40. https://doi.org/10.1093/bioinformatics/btp616.\n Yu, Guangchuang, Li-Gen Wang, and Qing-Yu He. 2015. “ChIPseeker: An R/Bioconductor Package for ChIP Peak Annotation, Comparison and Visualization.” Bioinformatics 31 (14): 2382–83. https://doi.org/10.1093/bioinformatics/btv145.\n Zhang, Y, T Liu, C A Meyer, J Eeckhoute, D S Johnson, B E Bernstein, C Nussbaum, et al. 2008. “Model-Based Analysis of ChIP-Seq (MACS).” Genome Biol. 9 (9). https://doi.org/10.1186/gb-2008-9-9-r137.\n Zhu, Lihua J, Claude Gazin, Nathan D Lawson, Hervé Pagès, Simon M Lin, David S Lapointe, and Michael R Green. 2010. “ChIPpeakAnno: A Bioconductor Package to Annotate ChIP-seq and ChIP-chip Data.” BMC Bioinformatics 11: 237. https://doi.org/10.1186/1471-2105-11-237.\n  ","categories":"","description":"","excerpt":"pre code { white-space: pre !important; overflow-x: scroll !important; …","ref":"/tutorials/spchipseq/spchipseq/","tags":"","title":"ChIP-Seq Workflow Template"},{"body":"document.addEventListener(\"DOMContentLoaded\", function() { document.querySelector(\"h1\").className = \"title\"; });  document.addEventListener(\"DOMContentLoaded\", function() { var links = document.links; for (var i = 0, linksLength = links.length; i Introduction  What is Clustering?  Clustering is the classification of data objects into similarity groups (clusters) according to a defined distance measure. It is used in many fields, such as machine learning, data mining, pattern recognition, image analysis, genomics, systems biology, etc. Machine learning typically regards data clustering as a form of unsupervised learning.   Why Clustering and Data Mining in R?}  Efficient data structures and functions for clustering Reproducible and programmable Comprehensive set of clustering and machine learning libraries Integration with many other data analysis tools   Useful Links  Cluster Task Views Machine Learning Task Views UCR Manual    Data Preprocessing Data Transformations Choice depends on data set!\n  Center and standardize\n Center: subtract from each value the mean of the corresponding vector Standardize: devide by standard deviation   Result: Mean = 0 and STDEV = 1    Center and scale with the scale() function\n Center: subtract from each value the mean of the corresponding vector Scale: divide centered vector by their root mean square (rms): $$ x_{rms} = \\sqrt[]{\\frac{1}{n-1}\\sum_{i=1}^{n}{x_{i}{^2}}} $$   Result: Mean = 0 and STDEV = 1    Log transformation\n  Rank transformation: replace measured values by ranks\n  No transformation\n  Distance Methods List of most common ones!\n Euclidean distance for two profiles X and Y: $$ d(X,Y) = \\sqrt[]{ \\sum_{i=1}^{n}{(x_{i}-y_{i})^2} }$$  Disadvantages: not scale invariant, not for negative correlations   Maximum, Manhattan, Canberra, binary, Minowski, … Correlation-based distance: 1-r  Pearson correlation coefficient (PCC): $$r = \\frac{n\\sum_{i=1}^{n}{x_{i}y_{i}} - \\sum_{i=1}^{n}{x_{i}} \\sum_{i=1}^{n}{y_{i}}}{ \\sqrt[]{(\\sum_{i=1}^{n}{x_{i}^2} - (\\sum_{i=1}^{n}{x_{i})^2}) (\\sum_{i=1}^{n}{y_{i}^2} - (\\sum_{i=1}^{n}{y_{i})^2})} }$$  Disadvantage: outlier sensitive   Spearman correlation coefficient (SCC)  Same calculation as PCC but with ranked values!      There are many more distance measures\n If the distances among items are quantifiable, then clustering is possible. Choose the most accurate and meaningful distance measure for a given field of application. If uncertain then choose several distance measures and compare the results.  Cluster Linkage   Clustering Algorithms Hierarchical Clustering Overview of algorithm  Identify clusters (items) with closest distance Join them to new clusters Compute distance between clusters (items) Return to step 1  Hierarchical clustering: agglomerative Approach   Hierarchical Clustering with Heatmap    A heatmap is a color coded table. To visually identify patterns, the rows and columns of a heatmap are often sorted by hierarchical clustering trees. In case of gene expression data, the row tree usually represents the genes, the column tree the treatments and the colors in the heat table represent the intensities or ratios of the underlying gene expression data set.  Hierarchical Clustering Approaches  Agglomerative approach (bottom-up)  R functions: hclust() and agnes()   Divisive approach (top-down)  R function: diana()    Tree Cutting to Obtain Discrete Clusters  Node height in tree Number of clusters Search tree nodes by distance cutoff  Examples Using hclust and heatmap.2 library(gplots) y \u003c- matrix(rnorm(500), 100, 5, dimnames=list(paste(\"g\", 1:100, sep=\"\"), paste(\"t\", 1:5, sep=\"\"))) heatmap.2(y) # Shortcut to final result  Stepwise Approach with Tree Cutting ## Row- and column-wise clustering hr \u003c- hclust(as.dist(1-cor(t(y), method=\"pearson\")), method=\"complete\") hc \u003c- hclust(as.dist(1-cor(y, method=\"spearman\")), method=\"complete\") ## Tree cutting mycl \u003c- cutree(hr, h=max(hr$height)/1.5); mycolhc \u003c- rainbow(length(unique(mycl)), start=0.1, end=0.9); mycolhc \u003c- mycolhc[as.vector(mycl)] ## Plot heatmap mycol \u003c- colorpanel(40, \"darkblue\", \"yellow\", \"white\") # or try redgreen(75) heatmap.2(y, Rowv=as.dendrogram(hr), Colv=as.dendrogram(hc), col=mycol, scale=\"row\", density.info=\"none\", trace=\"none\", RowSideColors=mycolhc)  K-Means Clustering Overview of algorithm  Choose the number of k clusters Randomly assign items to the k clusters Calculate new centroid for each of the k clusters Calculate the distance of all items to the k centroids Assign items to closest centroid Repeat until clusters assignments are stable    Examples km \u003c- kmeans(t(scale(t(y))), 3) km$cluster  ## g1 g2 g3 g4 g5 g6 g7 g8 g9 g10 g11 g12 g13 g14 g15 g16 g17 g18 g19 g20 ## 3 3 1 1 3 1 1 2 3 2 2 1 2 3 1 3 3 3 3 2 ## g21 g22 g23 g24 g25 g26 g27 g28 g29 g30 g31 g32 g33 g34 g35 g36 g37 g38 g39 g40 ## 3 2 3 2 2 3 2 1 1 1 2 2 3 3 1 1 3 3 2 3 ## g41 g42 g43 g44 g45 g46 g47 g48 g49 g50 g51 g52 g53 g54 g55 g56 g57 g58 g59 g60 ## 1 2 2 3 1 1 3 3 3 2 1 2 2 3 3 3 3 2 2 2 ## g61 g62 g63 g64 g65 g66 g67 g68 g69 g70 g71 g72 g73 g74 g75 g76 g77 g78 g79 g80 ## 3 1 1 1 3 1 3 2 2 2 3 2 3 2 1 3 2 2 2 3 ## g81 g82 g83 g84 g85 g86 g87 g88 g89 g90 g91 g92 g93 g94 g95 g96 g97 g98 g99 g100 ## 1 1 1 2 2 3 3 1 1 3 2 3 2 3 1 3 2 3 1 3  Fuzzy C-Means Clustering  In contrast to strict (hard) clustering approaches, fuzzy (soft) clustering methods allow multiple cluster memberships of the clustered items (Hathaway, Bezdek, and Pal 1996). This is commonly achieved by assigning to each item a weight of belonging to each cluster. Thus, items at the edge of a cluster, may be in a cluster to a lesser degree than items at the center of a cluster. Typically, each item has as many coefficients (weights) as there are clusters that sum up for each item to one.  Examples Fuzzy Clustering with fanny library(cluster) # Loads the cluster library. fannyy \u003c- fanny(y, k=4, metric = \"euclidean\", memb.exp = 1.2) round(fannyy$membership, 2)[1:4,]  ## [,1] [,2] [,3] [,4] ## g1 0.81 0.03 0.15 0.01 ## g2 0.84 0.03 0.11 0.02 ## g3 0.02 0.71 0.19 0.07 ## g4 0.09 0.04 0.80 0.06  fannyy$clustering  ## g1 g2 g3 g4 g5 g6 g7 g8 g9 g10 g11 g12 g13 g14 g15 g16 g17 g18 g19 g20 ## 1 1 2 3 1 3 3 2 1 1 2 3 2 4 4 1 1 1 4 2 ## g21 g22 g23 g24 g25 g26 g27 g28 g29 g30 g31 g32 g33 g34 g35 g36 g37 g38 g39 g40 ## 4 4 1 4 4 1 1 3 4 2 2 2 1 4 4 2 4 4 2 3 ## g41 g42 g43 g44 g45 g46 g47 g48 g49 g50 g51 g52 g53 g54 g55 g56 g57 g58 g59 g60 ## 3 2 4 3 3 2 1 3 4 2 4 1 2 1 1 4 4 4 4 2 ## g61 g62 g63 g64 g65 g66 g67 g68 g69 g70 g71 g72 g73 g74 g75 g76 g77 g78 g79 g80 ## 3 3 4 3 3 3 3 2 2 4 4 4 3 1 3 1 1 2 2 4 ## g81 g82 g83 g84 g85 g86 g87 g88 g89 g90 g91 g92 g93 g94 g95 g96 g97 g98 g99 g100 ## 3 3 3 2 4 4 1 4 3 3 1 1 1 1 4 1 2 1 3 1  Principal Component Analysis (PCA) Principal components analysis (PCA) is a data reduction technique that allows to simplify multidimensional data sets to 2 or 3 dimensions for plotting purposes and visual variance analysis.\nBasic Steps  Center (and standardize) data First principal component axis  Across centroid of data cloud Distance of each point to that line is minimized, so that it crosses the maximum variation of the data cloud   Second principal component axis  Orthogonal to first principal component Along maximum variation in the data   First PCA axis becomes x-axis and second PCA axis y-axis Continue process until the necessary number of principal components is obtained    Example pca \u003c- prcomp(y, scale=T) summary(pca) # Prints variance summary for all principal components  ## Importance of components: ## PC1 PC2 PC3 PC4 PC5 ## Standard deviation 1.1557 1.1185 1.0100 0.8769 0.7901 ## Proportion of Variance 0.2671 0.2502 0.2040 0.1538 0.1249 ## Cumulative Proportion 0.2671 0.5173 0.7213 0.8751 1.0000  plot(pca$x, pch=20, col=\"blue\", type=\"n\") # To plot dots, drop type=\"n\" text(pca$x, rownames(pca$x), cex=0.8)  1st and 2nd principal components explain x% of variance in data.\nMultidimensional Scaling (MDS)  Alternative dimensionality reduction approach Represents distances in 2D or 3D space Starts from distance matrix (PCA uses data points)  Example The following example performs MDS analysis with cmdscale on the geographic distances among European cities.\nloc \u003c- cmdscale(eurodist) plot(loc[,1], -loc[,2], type=\"n\", xlab=\"\", ylab=\"\", main=\"cmdscale(eurodist)\") text(loc[,1], -loc[,2], rownames(loc), cex=0.8)  Biclustering Finds in matrix subgroups of rows and columns which are as similar as possible to each other and as different as possible to the remaining data points.\n   Unclustered ————————–\u003e Clustered  Similarity Measures for Clusters  Compare the numbers of identical and unique item pairs appearing in cluster sets Achieved by counting the number of item pairs found in both clustering sets (a) as well as the pairs appearing only in the first (b) or the second (c) set. With this a similarity coefficient, such as the Jaccard index, can be computed. The latter is defined as the size of the intersect divided by the size of the union of two sample sets: a/(a+b+c). In case of partitioning results, the Jaccard Index measures how frequently pairs of items are joined together in two clustering data sets and how often pairs are observed only in one set. Related coefficient are the Rand Index and the Adjusted Rand Index. These indices also consider the number of pairs (d) that are not joined together in any of the clusters in both sets.  Example: Jaccard index for cluster sets The following imports the cindex() function and computes the Jaccard Index for two sample clusters.\nsource(\"http://faculty.ucr.edu/~tgirke/Documents/R_BioCond/My_R_Scripts/clusterIndex.R\") library(cluster); y \u003c- matrix(rnorm(5000), 1000, 5, dimnames=list(paste(\"g\", 1:1000, sep=\"\"), paste(\"t\", 1:5, sep=\"\"))); clarax \u003c- clara(y, 49); clV1 \u003c- clarax$clustering; clarax \u003c- clara(y, 50); clV2 \u003c- clarax$clustering ci \u003c- cindex(clV1=clV1, clV2=clV2, self=FALSE, minSZ=1, method=\"jaccard\") ci[2:3] # Returns Jaccard index and variables used to compute it  ## $variables ## a b c ## 4982 8034 8594 ## ## $Jaccard_Index ## [1] 0.2305414  Clustering cluster sets with Jaccard index The following example shows how one can cluster entire cluster result sets. First, 10 sample cluster results are created with Clara using k-values from 3 to 12. The results are stored as named clustering vectors in a list object. Then a nested sapply loop is used to generate a similarity matrix of Jaccard Indices for the clustering results. After converting the result into a distance matrix, hierarchical clustering is performed with hclust.}\nclVlist \u003c- lapply(3:12, function(x) clara(y[1:30, ], k=x)$clustering); names(clVlist) \u003c- paste(\"k\", \"=\", 3:12) d \u003c- sapply(names(clVlist), function(x) sapply(names(clVlist), function(y) cindex(clV1=clVlist[[y]], clV2=clVlist[[x]], method=\"jaccard\")[[3]])) hv \u003c- hclust(as.dist(1-d)) plot(as.dendrogram(hv), edgePar=list(col=3, lwd=4), horiz=T, main=\"Similarities of 10 Clara Clustering Results for k: 3-12\")   Remember: there are many additional clustering algorithms. Additional details can be found in the Clustering Section of the R/Bioconductor Manual.  Clustering Exercises Data Preprocessing Scaling ## Sample data set set.seed(1410) y \u003c- matrix(rnorm(50), 10, 5, dimnames=list(paste(\"g\", 1:10, sep=\"\"), paste(\"t\", 1:5, sep=\"\"))) dim(y)  ## [1] 10 5  ## Scaling yscaled \u003c- t(scale(t(y))) # Centers and scales y row-wise apply(yscaled, 1, sd)  ## g1 g2 g3 g4 g5 g6 g7 g8 g9 g10 ## 1 1 1 1 1 1 1 1 1 1  Distance Matrices Euclidean distance matrix dist(y[1:4,], method = \"euclidean\")  ## g1 g2 g3 ## g2 4.793697 ## g3 4.932658 6.354978 ## g4 4.033789 4.788508 1.671968  Correlation-based distance matrix Correlation matrix\nc \u003c- cor(t(y), method=\"pearson\") as.matrix(c)[1:4,1:4]  ## g1 g2 g3 g4 ## g1 1.00000000 -0.2965885 -0.00206139 -0.4042011 ## g2 -0.29658847 1.0000000 -0.91661118 -0.4512912 ## g3 -0.00206139 -0.9166112 1.00000000 0.7435892 ## g4 -0.40420112 -0.4512912 0.74358925 1.0000000  Correlation-based distance matrix\nd \u003c- as.dist(1-c) as.matrix(d)[1:4,1:4]  ## g1 g2 g3 g4 ## g1 0.000000 1.296588 1.0020614 1.4042011 ## g2 1.296588 0.000000 1.9166112 1.4512912 ## g3 1.002061 1.916611 0.0000000 0.2564108 ## g4 1.404201 1.451291 0.2564108 0.0000000  Hierarchical Clustering with hclust Hierarchical clustering with complete linkage and basic tree plotting\nhr \u003c- hclust(d, method = \"complete\", members=NULL) names(hr)  ## [1] \"merge\" \"height\" \"order\" \"labels\" \"method\" \"call\" ## [7] \"dist.method\"  par(mfrow = c(1, 2)); plot(hr, hang = 0.1); plot(hr, hang = -1)  Tree plotting I plot(as.dendrogram(hr), edgePar=list(col=3, lwd=4), horiz=T)  Tree plotting II The ape library provides more advanced features for tree plotting\nlibrary(ape) plot.phylo(as.phylo(hr), type=\"p\", edge.col=4, edge.width=2, show.node.label=TRUE, no.margin=TRUE)  Tree Cutting Accessing information in hclust objects\nhr  ## ## Call: ## hclust(d = d, method = \"complete\", members = NULL) ## ## Cluster method : complete ## Number of objects: 10  ## Print row labels in the order they appear in the tree hr$labels[hr$order]  ## [1] \"g10\" \"g3\" \"g4\" \"g2\" \"g9\" \"g6\" \"g7\" \"g1\" \"g5\" \"g8\"  Tree cutting with cutree\nmycl \u003c- cutree(hr, h=max(hr$height)/2) mycl[hr$labels[hr$order]]  ## g10 g3 g4 g2 g9 g6 g7 g1 g5 g8 ## 3 3 3 2 2 5 5 1 4 4  Heatmaps With heatmap.2 All in one step: clustering and heatmap plotting\nlibrary(gplots) heatmap.2(y, col=redgreen(75))  With pheatmap All in one step: clustering and heatmap plotting\nlibrary(pheatmap); library(\"RColorBrewer\") pheatmap(y, color=brewer.pal(9,\"Blues\"))  Customizing heatmaps Customizes row and column clustering and shows tree cutting result in row color bar. Additional color schemes can be found here.\nhc \u003c- hclust(as.dist(1-cor(y, method=\"spearman\")), method=\"complete\") mycol \u003c- colorpanel(40, \"darkblue\", \"yellow\", \"white\") heatmap.2(y, Rowv=as.dendrogram(hr), Colv=as.dendrogram(hc), col=mycol, scale=\"row\", density.info=\"none\", trace=\"none\", RowSideColors=as.character(mycl))  K-Means Clustering with PAM Runs K-means clustering with PAM (partitioning around medoids) algorithm and shows result in color bar of hierarchical clustering result from before.\nlibrary(cluster) pamy \u003c- pam(d, 4) (kmcol \u003c- pamy$clustering)  ## g1 g2 g3 g4 g5 g6 g7 g8 g9 g10 ## 1 2 3 3 4 4 4 4 2 3  heatmap.2(y, Rowv=as.dendrogram(hr), Colv=as.dendrogram(hc), col=mycol, scale=\"row\", density.info=\"none\", trace=\"none\", RowSideColors=as.character(kmcol))  K-Means Fuzzy Clustering Performs k-means fuzzy clustering\nlibrary(cluster) fannyy \u003c- fanny(d, k=4, memb.exp = 1.5) round(fannyy$membership, 2)[1:4,]  ## [,1] [,2] [,3] [,4] ## g1 1.00 0.00 0.00 0.00 ## g2 0.00 0.99 0.00 0.00 ## g3 0.02 0.01 0.95 0.03 ## g4 0.00 0.00 0.99 0.01  fannyy$clustering  ## g1 g2 g3 g4 g5 g6 g7 g8 g9 g10 ## 1 2 3 3 4 4 4 4 2 3  ## Returns multiple cluster memberships for coefficient above a certain ## value (here \u003e0.1) fannyyMA \u003c- round(fannyy$membership, 2) \u003e 0.10 apply(fannyyMA, 1, function(x) paste(which(x), collapse=\"_\"))  ## g1 g2 g3 g4 g5 g6 g7 g8 g9 g10 ## \"1\" \"2\" \"3\" \"3\" \"4\" \"4\" \"4\" \"2_4\" \"2\" \"3\"  Multidimensional Scaling (MDS) Performs MDS analysis on the geographic distances between European cities\nloc \u003c- cmdscale(eurodist) ## Plots the MDS results in 2D plot. The minus is required in this example to ## flip the plotting orientation. plot(loc[,1], -loc[,2], type=\"n\", xlab=\"\", ylab=\"\", main=\"cmdscale(eurodist)\") text(loc[,1], -loc[,2], rownames(loc), cex=0.8)  Principal Component Analysis (PCA) Performs PCA analysis after scaling the data. It returns a list with class prcomp that contains five components: (1) the standard deviations (sdev) of the principal components, (2) the matrix of eigenvectors (rotation), (3) the principal component data (x), (4) the centering (center) and (5) scaling (scale) used.\nlibrary(scatterplot3d) pca \u003c- prcomp(y, scale=TRUE) names(pca)  ## [1] \"sdev\" \"rotation\" \"center\" \"scale\" \"x\"  summary(pca) # Prints variance summary for all principal components.  ## Importance of components: ## PC1 PC2 PC3 PC4 PC5 ## Standard deviation 1.3611 1.1777 1.0420 0.69264 0.4416 ## Proportion of Variance 0.3705 0.2774 0.2172 0.09595 0.0390 ## Cumulative Proportion 0.3705 0.6479 0.8650 0.96100 1.0000  scatterplot3d(pca$x[,1:3], pch=20, color=\"blue\")  Additional Exercises See here\nVersion Information sessionInfo()  ## R version 4.0.5 (2021-03-31) ## Platform: x86_64-pc-linux-gnu (64-bit) ## Running under: Debian GNU/Linux 10 (buster) ## ## Matrix products: default ## BLAS: /usr/lib/x86_64-linux-gnu/blas/libblas.so.3.8.0 ## LAPACK: /usr/lib/x86_64-linux-gnu/lapack/liblapack.so.3.8.0 ## ## locale: ## [1] LC_CTYPE=en_US.UTF-8 LC_NUMERIC=C LC_TIME=en_US.UTF-8 ## [4] LC_COLLATE=en_US.UTF-8 LC_MONETARY=en_US.UTF-8 LC_MESSAGES=en_US.UTF-8 ## [7] LC_PAPER=en_US.UTF-8 LC_NAME=C LC_ADDRESS=C ## [10] LC_TELEPHONE=C LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C ## ## attached base packages: ## [1] stats graphics grDevices utils datasets methods base ## ## other attached packages: ## [1] scatterplot3d_0.3-41 RColorBrewer_1.1-2 pheatmap_1.0.12 cluster_2.1.1 ## [5] gplots_3.1.1 ape_5.4-1 ggplot2_3.3.2 BiocStyle_2.18.0 ## ## loaded via a namespace (and not attached): ## [1] Rcpp_1.0.5 bslib_0.2.4 compiler_4.0.5 pillar_1.4.7 ## [5] BiocManager_1.30.10 jquerylib_0.1.3 bitops_1.0-6 tools_4.0.5 ## [9] digest_0.6.27 nlme_3.1-149 lattice_0.20-41 jsonlite_1.7.1 ## [13] evaluate_0.14 lifecycle_0.2.0 tibble_3.0.4 gtable_0.3.0 ## [17] pkgconfig_2.0.3 rlang_0.4.8 parallel_4.0.5 yaml_2.2.1 ## [21] blogdown_1.2 xfun_0.22 withr_2.3.0 stringr_1.4.0 ## [25] dplyr_1.0.2 knitr_1.30 caTools_1.18.1 gtools_3.8.2 ## [29] generics_0.1.0 sass_0.3.1 vctrs_0.3.5 grid_4.0.5 ## [33] tidyselect_1.1.0 glue_1.4.2 R6_2.5.0 rmarkdown_2.7 ## [37] bookdown_0.21 purrr_0.3.4 magrittr_2.0.1 codetools_0.2-18 ## [41] scales_1.1.1 htmltools_0.5.1.1 ellipsis_0.3.1 colorspace_2.0-0 ## [45] KernSmooth_2.23-18 stringi_1.5.3 munsell_0.5.0 crayon_1.3.4  References Hathaway, R J, J C Bezdek, and N R Pal. 1996. “Sequential Competitive Learning and the Fuzzy c-Means Clustering Algorithms.” Neural Netw. 9 (5): 787–96. http://www.hubmed.org/display.cgi?uids=12662563.\n  ","categories":"","description":"","excerpt":"document.addEventListener(\"DOMContentLoaded\", function() { …","ref":"/manuals/rclustering/rclustering/","tags":"","title":"Cluster Analysis in R"},{"body":"document.addEventListener(\"DOMContentLoaded\", function() { document.querySelector(\"h1\").className = \"title\"; });  document.addEventListener(\"DOMContentLoaded\", function() { var links = document.links; for (var i = 0, linksLength = links.length; i Overview Graphics in R  Powerful environment for visualizing scientific data Integrated graphics and statistics infrastructure Publication quality graphics Fully programmable Highly reproducible Full LaTeX, Sweave, knitr and R Markdown support. Vast number of R packages with graphics utilities  Documentation on Graphics in R  General  Graphics Task Page R Graph Gallery R Graphical Manual Paul Murrell’s book R (Grid) Graphics   Interactive graphics  rggobi (GGobi) iplots Open GL (rgl)    Graphics Environments  Viewing and savings graphics in R  On-screen graphics postscript, pdf, svg jpeg/png/wmf/tiff/…   Four major graphics environments  Low-level infrastructure  R Base Graphics (low- and high-level) grid: Manual, Book   High-level infrastructure  lattice: Manual, Intro, Book ggplot2: Manual, Intro, Book      Base Graphics Overview  Important high-level plotting functions  plot: generic x-y plotting barplot: bar plots boxplot: box-and-whisker plot hist: histograms pie: pie charts dotchart: cleveland dot plots image, heatmap, contour, persp: functions to generate image-like plots qqnorm, qqline, qqplot: distribution comparison plots pairs, coplot: display of multivariant data   Help on these functions  ?myfct ?plot ?par    Preferred Input Data Objects  Matrices and data frames Vectors Named vectors  Scatter Plots Basic scatter plots Sample data set for subsequent plots\nset.seed(1410) y \u003c- matrix(runif(30), ncol=3, dimnames=list(letters[1:10], LETTERS[1:3])) plot(y[,1], y[,2])  All pairs pairs(y)  Plot labels plot(y[,1], y[,2], pch=20, col=\"red\", main=\"Symbols and Labels\") text(y[,1]+0.03, y[,2], rownames(y))  More examples Print instead of symbols the row names\nplot(y[,1], y[,2], type=\"n\", main=\"Plot of Labels\") text(y[,1], y[,2], rownames(y))  Usage of important plotting parameters\ngrid(5, 5, lwd = 2) op \u003c- par(mar=c(8,8,8,8), bg=\"lightblue\") plot(y[,1], y[,2], type=\"p\", col=\"red\", cex.lab=1.2, cex.axis=1.2, cex.main=1.2, cex.sub=1, lwd=4, pch=20, xlab=\"x label\", ylab=\"y label\", main=\"My Main\", sub=\"My Sub\") par(op)  Important arguments}\n mar: specifies the margin sizes around the plotting area in order: c(bottom, left, top, right) col: color of symbols pch: type of symbols, samples: example(points) lwd: size of symbols cex.*: control font sizes For details see ?par  Add a regression line to a plot\nplot(y[,1], y[,2]) myline \u003c- lm(y[,2]~y[,1]); abline(myline, lwd=2)  summary(myline)  ## ## Call: ## lm(formula = y[, 2] ~ y[, 1]) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.40357 -0.17912 -0.04299 0.22147 0.46623 ## ## Coefficients: ## Estimate Std. Error t value Pr(\u003e|t|) ## (Intercept) 0.5764 0.2110 2.732 0.0258 * ## y[, 1] -0.3647 0.3959 -0.921 0.3839 ## --- ## Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ## ## Residual standard error: 0.3095 on 8 degrees of freedom ## Multiple R-squared: 0.09589, Adjusted R-squared: -0.01712 ## F-statistic: 0.8485 on 1 and 8 DF, p-value: 0.3839  Same plot as above, but on log scale\nplot(y[,1], y[,2], log=\"xy\")  Add a mathematical expression to a plot\nplot(y[,1], y[,2]); text(y[1,1], y[1,2], expression(sum(frac(1,sqrt(x^2*pi)))), cex=1.3)  Exercise 1  Task 1: Generate scatter plot for first two columns in iris data frame and color dots by its Species column. Task 2: Use the xlim/ylim arguments to set limits on the x- and y-axes so that all data points are restricted to the left bottom quadrant of the plot.  Structure of iris data set:\nclass(iris)  ## [1] \"data.frame\"  iris[1:4,]  ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 1 5.1 3.5 1.4 0.2 setosa ## 2 4.9 3.0 1.4 0.2 setosa ## 3 4.7 3.2 1.3 0.2 setosa ## 4 4.6 3.1 1.5 0.2 setosa  table(iris$Species)  ## ## setosa versicolor virginica ## 50 50 50  Line Plots Single Data Set plot(y[,1], type=\"l\", lwd=2, col=\"blue\")  Many Data Sets Plots line graph for all columns in data frame y. The split.screen function is used in this example in a for loop to overlay several line graphs in the same plot.\nsplit.screen(c(1,1))  ## [1] 1  plot(y[,1], ylim=c(0,1), xlab=\"Measurement\", ylab=\"Intensity\", type=\"l\", lwd=2, col=1) for(i in 2:length(y[1,])) { screen(1, new=FALSE) plot(y[,i], ylim=c(0,1), type=\"l\", lwd=2, col=i, xaxt=\"n\", yaxt=\"n\", ylab=\"\", xlab=\"\", main=\"\", bty=\"n\") }  close.screen(all=TRUE)  Bar Plots Basics barplot(y[1:4,], ylim=c(0, max(y[1:4,])+0.3), beside=TRUE, legend=letters[1:4]) text(labels=round(as.vector(as.matrix(y[1:4,])),2), x=seq(1.5, 13, by=1) +sort(rep(c(0,1,2), 4)), y=as.vector(as.matrix(y[1:4,]))+0.04)  Error bars bar \u003c- barplot(m \u003c- rowMeans(y) * 10, ylim=c(0, 10)) stdev \u003c- sd(t(y)) arrows(bar, m, bar, m + stdev, length=0.15, angle = 90)  Mirrored bar plot df \u003c- data.frame(group = rep(c(\"Above\", \"Below\"), each=10), x = rep(1:10, 2), y = c(runif(10, 0, 1), runif(10, -1, 0))) plot(c(0,12),range(df$y),type = \"n\") barplot(height = df$y[df$group == \"Above\"], add = TRUE,axes = FALSE) barplot(height = df$y[df$group == \"Below\"], add = TRUE,axes = FALSE)  Histograms hist(y, freq=TRUE, breaks=10)  Density Plots} plot(density(y), col=\"red\")  Pie Charts pie(y[,1], col=rainbow(length(y[,1]), start=0.1, end=0.8), clockwise=TRUE) legend(\"topright\", legend=row.names(y), cex=1.3, bty=\"n\", pch=15, pt.cex=1.8, col=rainbow(length(y[,1]), start=0.1, end=0.8), ncol=1)  Color Selection Utilities Default color palette and how to change it\npalette()  ## [1] \"black\" \"#DF536B\" \"#61D04F\" \"#2297E6\" \"#28E2E5\" \"#CD0BBC\" \"#F5C710\" \"gray62\"  palette(rainbow(5, start=0.1, end=0.2)) palette()  ## [1] \"#FF9900\" \"#FFBF00\" \"#FFE600\" \"#F2FF00\" \"#CCFF00\"  palette(\"default\")  The gray function allows to select any type of gray shades by providing values from 0 to 1\ngray(seq(0.1, 1, by= 0.2))  ## [1] \"#1A1A1A\" \"#4D4D4D\" \"#808080\" \"#B3B3B3\" \"#E6E6E6\"  Color gradients with colorpanel function from gplots library\nlibrary(gplots) colorpanel(5, \"darkblue\", \"yellow\", \"white\")  Much more on colors in R see Earl Glynn’s color chart\nArranging Several Plots on Single Page With par(mfrow=c(nrow,ncol)) one can define how several plots are arranged next to each other.\npar(mfrow=c(2,3)); for(i in 1:6) { plot(1:10) }  Arranging Plots with Variable Width The layout function allows to divide the plotting device into variable numbers of rows and columns with the column-widths and the row-heights specified in the respective arguments.\nnf \u003c- layout(matrix(c(1,2,3,3), 2, 2, byrow=TRUE), c(3,7), c(5,5), respect=TRUE) # layout.show(nf) for(i in 1:3) { barplot(1:10) }  Saving Graphics to Files After the pdf() command all graphs are redirected to file test.pdf. Works for all common formats similarly: jpeg, png, ps, tiff, …\npdf(\"test.pdf\"); plot(1:10, 1:10); dev.off()  Generates Scalable Vector Graphics (SVG) files that can be edited in vector graphics programs, such as InkScape.\nsvg(\"test.svg\"); plot(1:10, 1:10); dev.off()  Exercise 2 Bar plots\n Task 1: Calculate the mean values for the Species components of the first four columns in the iris data set. Organize the results in a matrix where the row names are the unique values from the iris Species column and the column names are the same as in the first four iris columns. Task 2: Generate two bar plots: one with stacked bars and one with horizontally arranged bars.  Structure of iris data set:\nclass(iris)  ## [1] \"data.frame\"  iris[1:4,]  ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 1 5.1 3.5 1.4 0.2 setosa ## 2 4.9 3.0 1.4 0.2 setosa ## 3 4.7 3.2 1.3 0.2 setosa ## 4 4.6 3.1 1.5 0.2 setosa  table(iris$Species)  ## ## setosa versicolor virginica ## 50 50 50  Grid Graphics  What is grid?  Low-level graphics system Highly flexible and controllable system Does not provide high-level functions Intended as development environment for custom plotting functions Pre-installed on new R distributions   Documentation and Help  Manual Book    lattice Graphics  What is lattice?  High-level graphics system Developed by Deepayan Sarkar Implements Trellis graphics system from S-Plus Simplifies high-level plotting tasks: arranging complex graphical features Syntax similar to R’s base graphics   Documentation and Help  Manual Intro Book    Open a list of all functions available in the lattice package\nlibrary(help=lattice)  Accessing and changing global parameters:\n?lattice.options ?trellis.device  Scatter Plot Sample library(lattice) p1 \u003c- xyplot(1:8 ~ 1:8 | rep(LETTERS[1:4], each=2), as.table=TRUE) plot(p1)  Line Plot Sample library(lattice) p2 \u003c- parallelplot(~iris[1:4] | Species, iris, horizontal.axis = FALSE, layout = c(1, 3, 1)) plot(p2)  ggplot2 Graphics  What is ggplot2?  High-level graphics system developed by Hadley Wickham Implements grammar of graphics from Leland Wilkinson Streamlines many graphics workflows for complex plots Syntax centered around main ggplot function Simpler qplot function provides many shortcuts   Documentation and Help  Manual Intro Book Cookbook for R    ggplot2 Usage  ggplot function accepts two arguments  Data set to be plotted Aesthetic mappings provided by aes function   Additional parameters such as geometric objects (e.g. points, lines, bars) are passed on by appending them with + as separator. List of available geom_* functions see here Settings of plotting theme can be accessed with the command theme_get() and its settings can be changed with theme(). Preferred input data object  qplot: data.frame or tibble (support for vector, matrix, ...) ggplot: data.frame or tibble   Packages with convenience utilities to create expected inputs  plyr reshape    qplot Function The syntax of qplot is similar as R’s basic plot function\n Arguments  x: x-coordinates (e.g. col1) y: y-coordinates (e.g. col2) data: data.frame or tibble with corresponding column names xlim, ylim: e.g. xlim=c(0,10) log: e.g. log=\"x\" or log=\"xy\" main: main title; see ?plotmath for mathematical formula xlab, ylab: labels for the x- and y-axes color, shape, size ...: many arguments accepted by plot function    qplot: scatter plot basics Create sample data\nlibrary(ggplot2) x \u003c- sample(1:10, 10); y \u003c- sample(1:10, 10); cat \u003c- rep(c(\"A\", \"B\"), 5)  Simple scatter plot\nqplot(x, y, geom=\"point\")  Prints dots with different sizes and colors\nqplot(x, y, geom=\"point\", size=x, color=cat, main=\"Dot Size and Color Relative to Some Values\")  Drops legend\nqplot(x, y, geom=\"point\", size=x, color=cat) + theme(legend.position = \"none\")  Plot different shapes\nqplot(x, y, geom=\"point\", size=5, shape=cat)  Colored groups p \u003c- qplot(x, y, geom=\"point\", size=x, color=cat, main=\"Dot Size and Color Relative to Some Values\") + theme(legend.position = \"none\") print(p)  Regression line set.seed(1410) dsmall \u003c- diamonds[sample(nrow(diamonds), 1000), ] p \u003c- qplot(carat, price, data = dsmall) + geom_smooth(method=\"lm\") print(p)  Local regression curve (loess) p \u003c- qplot(carat, price, data=dsmall, geom=c(\"point\", \"smooth\")) print(p) # Setting se=FALSE removes error shade  ggplot Function  More important than qplot to access full functionality of ggplot2 Main arguments  data set, usually a data.frame or tibble aesthetic mappings provided by aes function   General ggplot syntax  ggplot(data, aes(...)) + geom() + ... + stat() + ...   Layer specifications  geom(mapping, data, ..., geom, position) stat(mapping, data, ..., stat, position)   Additional components  scales coordinates facet   aes() mappings can be passed on to all components (ggplot, geom, etc.). Effects are global when passed on to ggplot() and local for other components.  x, y color: grouping vector (factor) group: grouping vector (factor)    Changing Plotting Themes in ggplot  Theme settings can be accessed with theme_get() Their settings can be changed with theme()  Example how to change background color to white\n... + theme(panel.background=element_rect(fill = \"white\", colour = \"black\"))  Storing ggplot Specifications Plots and layers can be stored in variables\np \u003c- ggplot(dsmall, aes(carat, price)) + geom_point() p # or print(p)  Returns information about data and aesthetic mappings followed by each layer\nsummary(p)  Print dots with different sizes and colors\nbestfit \u003c- geom_smooth(method = \"lm\", se = F, color = alpha(\"steelblue\", 0.5), size = 2) p + bestfit # Plot with custom regression line  Syntax to pass on other data sets\np %+% diamonds[sample(nrow(diamonds), 100),]  Saves plot stored in variable p to file\nggsave(p, file=\"myplot.pdf\")  ggplot: scatter plots Basic example set.seed(1410) dsmall \u003c- as.data.frame(diamonds[sample(nrow(diamonds), 1000), ]) p \u003c- ggplot(dsmall, aes(carat, price, color=color)) + geom_point(size=4) print(p)  Regression line p \u003c- ggplot(dsmall, aes(carat, price)) + geom_point() + geom_smooth(method=\"lm\", se=FALSE) + theme(panel.background=element_rect(fill = \"white\", colour = \"black\")) print(p)  Several regression lines p \u003c- ggplot(dsmall, aes(carat, price, group=color)) + geom_point(aes(color=color), size=2) + geom_smooth(aes(color=color), method = \"lm\", se=FALSE) print(p)  Local regression curve (loess) p \u003c- ggplot(dsmall, aes(carat, price)) + geom_point() + geom_smooth() print(p) # Setting se=FALSE removes error shade  ggplot: line plot p \u003c- ggplot(iris, aes(Petal.Length, Petal.Width, group=Species, color=Species)) + geom_line() print(p)  Faceting p \u003c- ggplot(iris, aes(Sepal.Length, Sepal.Width)) + geom_line(aes(color=Species), size=1) + facet_wrap(~Species, ncol=1) print(p)  Exercise 3 Scatter plots with ggplot2\n Task 1: Generate scatter plot for first two columns in iris data frame and color dots by its Species column. Task 2: Use the xlim and ylim arguments to set limits on the x- and y-axes so that all data points are restricted to the left bottom quadrant of the plot. Task 3: Generate corresponding line plot with faceting show individual data sets in saparate plots.  Structure of iris data set\nclass(iris)  ## [1] \"data.frame\"  iris[1:4,]  ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 1 5.1 3.5 1.4 0.2 setosa ## 2 4.9 3.0 1.4 0.2 setosa ## 3 4.7 3.2 1.3 0.2 setosa ## 4 4.6 3.1 1.5 0.2 setosa  table(iris$Species)  ## ## setosa versicolor virginica ## 50 50 50  Bar Plots Sample Set: the following transforms the iris data set into a ggplot2-friendly format.\nCalculate mean values for aggregates given by Species column in iris data set\niris_mean \u003c- aggregate(iris[,1:4], by=list(Species=iris$Species), FUN=mean)  Calculate standard deviations for aggregates given by Species column in iris data set\niris_sd \u003c- aggregate(iris[,1:4], by=list(Species=iris$Species), FUN=sd)  Reformat iris_mean with melt\nlibrary(reshape2) # Defines melt function df_mean \u003c- melt(iris_mean, id.vars=c(\"Species\"), variable.name = \"Samples\", value.name=\"Values\")  Reformat iris_sd with melt\ndf_sd \u003c- melt(iris_sd, id.vars=c(\"Species\"), variable.name = \"Samples\", value.name=\"Values\")  Define standard deviation limits\nlimits \u003c- aes(ymax = df_mean[,\"Values\"] + df_sd[,\"Values\"], ymin=df_mean[,\"Values\"] - df_sd[,\"Values\"])  Verical orientation p \u003c- ggplot(df_mean, aes(Samples, Values, fill = Species)) + geom_bar(position=\"dodge\", stat=\"identity\") print(p)  To enforce that the bars are plotted in the order specified in the input data, one can instruct ggplot to do so by turning the corresponding column (here Species) into an ordered factor as follows.\ndf_mean$Species \u003c- factor(df_mean$Species, levels=unique(df_mean$Species), ordered=TRUE)  In the above example this is not necessary since ggplot uses this order already.\nHorizontal orientation p \u003c- ggplot(df_mean, aes(Samples, Values, fill = Species)) + geom_bar(position=\"dodge\", stat=\"identity\") + coord_flip() + theme(axis.text.y=element_text(angle=0, hjust=1)) print(p)  Faceting p \u003c- ggplot(df_mean, aes(Samples, Values)) + geom_bar(aes(fill = Species), stat=\"identity\") + facet_wrap(~Species, ncol=1) print(p)  Error bars p \u003c- ggplot(df_mean, aes(Samples, Values, fill = Species)) + geom_bar(position=\"dodge\", stat=\"identity\") + geom_errorbar(limits, position=\"dodge\") print(p)  Mirrored df \u003c- data.frame(group = rep(c(\"Above\", \"Below\"), each=10), x = rep(1:10, 2), y = c(runif(10, 0, 1), runif(10, -1, 0))) p \u003c- ggplot(df, aes(x=x, y=y, fill=group)) + geom_bar(stat=\"identity\", position=\"identity\") print(p)  Changing Color Settings library(RColorBrewer) # display.brewer.all() p \u003c- ggplot(df_mean, aes(Samples, Values, fill=Species, color=Species)) + geom_bar(position=\"dodge\", stat=\"identity\") + geom_errorbar(limits, position=\"dodge\") + scale_fill_brewer(palette=\"Blues\") + scale_color_brewer(palette = \"Greys\") print(p)  Using standard colors p \u003c- ggplot(df_mean, aes(Samples, Values, fill=Species, color=Species)) + geom_bar(position=\"dodge\", stat=\"identity\") + geom_errorbar(limits, position=\"dodge\") + scale_fill_manual(values=c(\"red\", \"green3\", \"blue\")) + scale_color_manual(values=c(\"red\", \"green3\", \"blue\")) print(p)  Exercise 4 Bar plots\n Task 1: Calculate the mean values for the Species components of the first four columns in the iris data set. Use the melt function from the reshape2 package to bring the data into the expected format for ggplot. Task 2: Generate two bar plots: one with stacked bars and one with horizontally arranged bars.  Structure of iris data set\nclass(iris)  ## [1] \"data.frame\"  iris[1:4,]  ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 1 5.1 3.5 1.4 0.2 setosa ## 2 4.9 3.0 1.4 0.2 setosa ## 3 4.7 3.2 1.3 0.2 setosa ## 4 4.6 3.1 1.5 0.2 setosa  table(iris$Species)  ## ## setosa versicolor virginica ## 50 50 50  Data reformatting example Here for line plot\ny \u003c- matrix(rnorm(500), 100, 5, dimnames=list(paste(\"g\", 1:100, sep=\"\"), paste(\"Sample\", 1:5, sep=\"\"))) y \u003c- data.frame(Position=1:length(y[,1]), y) y[1:4, ] # First rows of input format expected by melt()  ## Position Sample1 Sample2 Sample3 Sample4 Sample5 ## g1 1 1.5336975 -1.0365027 -2.0276195 -0.4580396 -0.06460952 ## g2 2 -2.0960304 2.1878704 0.7260334 0.8274617 0.24192162 ## g3 3 -0.8233125 0.4250477 0.6526331 -0.4509962 -1.06778801 ## g4 4 1.0961555 0.8101104 -0.3403762 -0.7222191 -0.72737741  df \u003c- melt(y, id.vars=c(\"Position\"), variable.name = \"Samples\", value.name=\"Values\") p \u003c- ggplot(df, aes(Position, Values)) + geom_line(aes(color=Samples)) + facet_wrap(~Samples, ncol=1) print(p)  Same data can be represented in box plot as follows\nggplot(df, aes(Samples, Values, fill=Samples)) + geom_boxplot()  Jitter Plots p \u003c- ggplot(dsmall, aes(color, price/carat)) + geom_jitter(alpha = I(1 / 2), aes(color=color)) print(p)  Box plots p \u003c- ggplot(dsmall, aes(color, price/carat, fill=color)) + geom_boxplot() print(p)  Violin plots p \u003c- ggplot(dsmall, aes(color, price/carat, fill=color)) + geom_violin() print(p)  Density plots Line coloring p \u003c- ggplot(dsmall, aes(carat)) + geom_density(aes(color = color)) print(p)  Area coloring p \u003c- ggplot(dsmall, aes(carat)) + geom_density(aes(fill = color)) print(p)  Histograms p \u003c- ggplot(iris, aes(x=Sepal.Width)) + geom_histogram(aes(y = ..density.., fill = ..count..), binwidth=0.2) + geom_density() print(p)  Pie Chart df \u003c- data.frame(variable=rep(c(\"cat\", \"mouse\", \"dog\", \"bird\", \"fly\")), value=c(1,3,3,4,2)) p \u003c- ggplot(df, aes(x = \"\", y = value, fill = variable)) + geom_bar(width = 1, stat=\"identity\") + coord_polar(\"y\", start=pi / 3) + ggtitle(\"Pie Chart\") print(p)  Wind Rose Pie Chart p \u003c- ggplot(df, aes(x = variable, y = value, fill = variable)) + geom_bar(width = 1, stat=\"identity\") + coord_polar(\"y\", start=pi / 3) + ggtitle(\"Pie Chart\") print(p)  Arranging Graphics on Page Using grid package\nlibrary(grid) a \u003c- ggplot(dsmall, aes(color, price/carat)) + geom_jitter(size=4, alpha = I(1 / 1.5), aes(color=color)) b \u003c- ggplot(dsmall, aes(color, price/carat, color=color)) + geom_boxplot() c \u003c- ggplot(dsmall, aes(color, price/carat, fill=color)) + geom_boxplot() + theme(legend.position = \"none\") grid.newpage() # Open a new page on grid device pushViewport(viewport(layout = grid.layout(2, 2))) # Assign to device viewport with 2 by 2 grid layout print(a, vp = viewport(layout.pos.row = 1, layout.pos.col = 1:2)) print(b, vp = viewport(layout.pos.row = 2, layout.pos.col = 1)) print(c, vp = viewport(layout.pos.row = 2, layout.pos.col = 2, width=0.3, height=0.3, x=0.8, y=0.8))  Using gridExtra package\nlibrary(gridExtra) grid.arrange(a, b, c, nrow = 2, ncol=2)  Inserting Graphics into Plots library(grid) print(a) print(b, vp=viewport(width=0.3, height=0.3, x=0.8, y=0.8))  Specialty Graphics Venn Diagrams library(systemPipeR) setlist5 \u003c- list(A=sample(letters, 18), B=sample(letters, 16), C=sample(letters, 20), D=sample(letters, 22), E=sample(letters, 18)) OLlist5 \u003c- overLapper(setlist=setlist5, sep=\"_\", type=\"vennsets\") vennPlot(OLlist5, mymain=\"\", mysub=\"\", colmode=2, ccol=c(\"blue\", \"red\"))  Compound Structures Plots depictions of small molecules with ChemmineR package\nlibrary(ChemmineR) data(sdfsample) plot(sdfsample[1], print=FALSE)  ROC Plots A variety of libraries are available for plotting receiver operating characteristic (ROC) curves in R:\n ROCR ROC pROC ggplot2  Example Most commonly, in an ROC we plot the true positive rate (y-axis) against the false positive rate (x-axis) at decreasing thresholds. An illustrative example is provided in the ROCR package where one wants to inspect the content of the ROCR.simple object defining the structure of the input data in two vectors.\n# install.packages(\"ROCR\") # Install if necessary on your laptop library(ROCR) data(ROCR.simple) ROCR.simple  ## $predictions ## [1] 0.612547843 0.364270971 0.432136142 0.140291078 0.384895941 0.244415489 0.970641299 ## [8] 0.890172812 0.781781371 0.868751832 0.716680598 0.360168796 0.547983407 0.385240464 ## [15] 0.423739359 0.101699993 0.628095575 0.744769966 0.657732644 0.490119891 0.072369921 ## [22] 0.172741714 0.105722115 0.890078186 0.945548941 0.984667270 0.360180429 0.448687336 ## [29] 0.014823599 0.543533783 0.292368449 0.701561487 0.715459280 0.714985914 0.120604738 ## [36] 0.319672178 0.911723615 0.757325590 0.090988280 0.529402244 0.257402979 0.589909284 ## [43] 0.708412104 0.326672910 0.086546283 0.879459891 0.362693564 0.230157183 0.779771989 ## [50] 0.876086217 0.353281048 0.212014560 0.703293499 0.689075677 0.627012496 0.240911145 ## [57] 0.402801992 0.134794140 0.120473353 0.665444679 0.536339509 0.623494622 0.885179651 ## [64] 0.353777439 0.408939895 0.265686095 0.932159806 0.248500489 0.858876675 0.491735594 ## [71] 0.151350957 0.694457482 0.496513160 0.123504905 0.499788081 0.310718619 0.907651100 ## [78] 0.340078180 0.195097957 0.371936985 0.517308606 0.419560072 0.865639036 0.018527600 ## [85] 0.539086009 0.005422562 0.772728821 0.703885141 0.348213542 0.277656869 0.458674210 ## [92] 0.059045866 0.133257805 0.083685883 0.531958184 0.429650397 0.717845453 0.537091350 ## [99] 0.212404891 0.930846938 0.083048377 0.468610247 0.393378108 0.663367560 0.349540913 ## [106] 0.194398425 0.844415442 0.959417835 0.211378771 0.943432189 0.598162949 0.834803976 ## [113] 0.576836208 0.380396459 0.161874325 0.912325837 0.642933593 0.392173971 0.122284044 ## [120] 0.586857799 0.180631658 0.085993218 0.700501359 0.060413627 0.531464015 0.084254795 ## [127] 0.448484671 0.938583020 0.531006532 0.785213140 0.905121019 0.748438143 0.605235403 ## [134] 0.842974300 0.835981859 0.364288579 0.492596896 0.488179708 0.259278968 0.991096434 ## [141] 0.757364019 0.288258273 0.773336236 0.040906997 0.110241034 0.760726142 0.984599159 ## [148] 0.253271061 0.697235328 0.620501132 0.814586047 0.300973098 0.378092079 0.016694412 ## [155] 0.698826511 0.658692553 0.470206008 0.501489336 0.239143340 0.050999138 0.088450984 ## [162] 0.107031842 0.746588080 0.480100183 0.336592126 0.579511087 0.118555284 0.233160827 ## [169] 0.461150807 0.370549294 0.770178504 0.537336015 0.463227453 0.790240205 0.883431431 ## [176] 0.745110673 0.007746305 0.012653524 0.868331219 0.439399995 0.540221346 0.567043171 ## [183] 0.035815400 0.806543942 0.248707470 0.696702150 0.081439129 0.336315317 0.126480399 ## [190] 0.636728451 0.030235062 0.268138293 0.983494405 0.728536415 0.739554341 0.522384507 ## [197] 0.858970526 0.383807972 0.606960209 0.138387070 ## ## $labels ## [1] 1 1 0 0 0 1 1 1 1 0 1 0 1 0 0 0 1 1 1 0 0 0 0 1 0 1 0 0 1 1 0 1 1 1 0 0 1 1 0 1 0 1 0 1 0 1 0 ## [48] 1 0 1 1 0 1 0 1 0 0 0 0 1 1 1 1 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 1 1 0 0 1 0 0 1 0 ## [95] 1 0 1 1 0 1 0 0 0 1 0 0 1 0 0 1 1 1 0 0 0 1 1 0 0 1 0 0 1 0 1 0 0 1 1 1 1 1 0 1 1 0 0 0 0 1 1 ## [142] 0 1 0 1 0 1 1 1 1 1 0 0 0 1 1 0 1 0 0 0 0 1 0 0 1 0 0 0 0 1 1 0 1 1 1 0 1 1 0 1 1 0 1 0 0 0 1 ## [189] 0 0 0 1 0 1 1 0 1 0 1 0  pred \u003c- prediction(ROCR.simple$predictions, ROCR.simple$labels) perf \u003c- performance( pred, \"tpr\", \"fpr\" ) plot(perf)  Obtain area under the curve (AUC)\nauc \u003c- performance( pred, \"tpr\", \"fpr\", measure = \"auc\") auc@y.values[[1]]  ## [1] 0.8341875  Trees The ape package provides many useful utilities for phylogenetic analysis and tree plotting. Another useful package for plotting trees is ggtree. The following example plots two trees face to face with links to identical leaf labels.\nlibrary(ape) tree1 \u003c- rtree(40) tree2 \u003c- rtree(20) association \u003c- cbind(tree2$tip.label, tree2$tip.label) cophyloplot(tree1, tree2, assoc = association, length.line = 4, space = 28, gap = 3)  Genome Graphics ggbio  What is ggbio?  A programmable genome browser environment   Genome broswer concepts  A genome browser is a visulalization tool for plotting different types of genomic data in separate tracks along chromosomes. The ggbio package (Yin, Cook, and Lawrence 2012) facilitates plotting of complex genome data objects, such as read alignments (SAM/BAM), genomic context/annotation information (gff/txdb), variant calls (VCF/BCF), and more. To easily compare these data sets, it extends the faceting facility of ggplot2 to genome browser-like tracks. Most of the core object types for handling genomic data with R/Bioconductor are supported: GRanges, GAlignments, VCF, etc. For more details, see Table 1.1 of the ggbio vignette here. ggbio’s convenience plotting function is autoplot. For more customizable plots, one can use the generic ggplot function. Apart from the standard ggplot2 plotting components, ggbio defines serval new components useful for genomic data visualization. A detailed list is given in Table 1.2 of the vignette here. Useful web sites: - ggbio manual  ggbio functions autoplot demo      Tracks: aligning plots along chromosomes library(ggbio) df1 \u003c- data.frame(time = 1:100, score = sin((1:100)/20)*10) p1 \u003c- qplot(data = df1, x = time, y = score, geom = \"line\") df2 \u003c- data.frame(time = 30:120, score = sin((30:120)/20)*10, value = rnorm(120-30 +1)) p2 \u003c- ggplot(data = df2, aes(x = time, y = score)) + geom_line() + geom_point(size = 2, aes(color = value)) tracks(time1 = p1, time2 = p2) + xlim(1, 40) + theme_tracks_sunset()  Plotting genomic ranges GRanges objects are essential for storing alignment or annotation ranges in R/Bioconductor. The following creates a sample GRanges object and plots its content.\nlibrary(GenomicRanges) set.seed(1); N \u003c- 100; gr \u003c- GRanges(seqnames = sample(c(\"chr1\", \"chr2\", \"chr3\"), size = N, replace = TRUE), IRanges(start = sample(1:300, size = N, replace = TRUE), width = sample(70:75, size = N,replace = TRUE)), strand = sample(c(\"+\", \"-\"), size = N, replace = TRUE), value = rnorm(N, 10, 3), score = rnorm(N, 100, 30), sample = sample(c(\"Normal\", \"Tumor\"), size = N, replace = TRUE), pair = sample(letters, size = N, replace = TRUE)) autoplot(gr, aes(color = strand, fill = strand), facets = strand ~ seqnames)  Plotting coverage autoplot(gr, aes(color = strand, fill = strand), facets = strand ~ seqnames, stat = \"coverage\")  Mirrored coverage pos \u003c- sapply(coverage(gr[strand(gr)==\"+\"]), as.numeric) pos \u003c- data.frame(Chr=rep(names(pos), sapply(pos, length)), Strand=rep(\"+\", length(unlist(pos))), Position=unlist(sapply(pos, function(x) 1:length(x))), Coverage=as.numeric(unlist(pos))) neg \u003c- sapply(coverage(gr[strand(gr)==\"-\"]), as.numeric) neg \u003c- data.frame(Chr=rep(names(neg), sapply(neg, length)), Strand=rep(\"-\", length(unlist(neg))), Position=unlist(sapply(neg, function(x) 1:length(x))), Coverage=-as.numeric(unlist(neg))) covdf \u003c- rbind(pos, neg) p \u003c- ggplot(covdf, aes(Position, Coverage, fill=Strand)) + geom_bar(stat=\"identity\", position=\"identity\") + facet_wrap(~Chr) p  Circular genome plots ggplot(gr) + layout_circle(aes(fill = seqnames), geom = \"rect\")  More complex circular example\nseqlengths(gr) \u003c- c(400, 500, 700) values(gr)$to.gr \u003c- gr[sample(1:length(gr), size = length(gr))] idx \u003c- sample(1:length(gr), size = 50) gr \u003c- gr[idx] ggplot() + layout_circle(gr, geom = \"ideo\", fill = \"gray70\", radius = 7, trackWidth = 3) + layout_circle(gr, geom = \"bar\", radius = 10, trackWidth = 4, aes(fill = score, y = score)) + layout_circle(gr, geom = \"point\", color = \"red\", radius = 14, trackWidth = 3, grid = TRUE, aes(y = score)) + layout_circle(gr, geom = \"link\", linked.to = \"to.gr\", radius = 6, trackWidth = 1)    Alignments and variants To make the following example work, please download and unpack this data archive containing GFF, BAM and VCF sample files.\nlibrary(rtracklayer); library(GenomicFeatures); library(Rsamtools); library(GenomicAlignments); library(VariantAnnotation) ga \u003c- readGAlignments(\"./data/SRR064167.fastq.bam\", use.names=TRUE, param=ScanBamParam(which=GRanges(\"Chr5\", IRanges(4000, 8000)))) p1 \u003c- autoplot(ga, geom = \"rect\") p2 \u003c- autoplot(ga, geom = \"line\", stat = \"coverage\") vcf \u003c- readVcf(file=\"data/varianttools_gnsap.vcf\", genome=\"ATH1\") p3 \u003c- autoplot(vcf[seqnames(vcf)==\"Chr5\"], type = \"fixed\") + xlim(4000, 8000) + theme(legend.position = \"none\", axis.text.y = element_blank(), axis.ticks.y=element_blank()) txdb \u003c- makeTxDbFromGFF(file=\"./data/TAIR10_GFF3_trunc.gff\", format=\"gff3\") p4 \u003c- autoplot(txdb, which=GRanges(\"Chr5\", IRanges(4000, 8000)), names.expr = \"gene_id\") tracks(Reads=p1, Coverage=p2, Variant=p3, Transcripts=p4, heights = c(0.3, 0.2, 0.1, 0.35)) + ylab(\"\")  Additional examples See autoplot demo here\nAdditional genome graphics  Gviz RCircos (Zhang, Meltzer, and Davis 2013) Genome Graphs genoPlotR  Genome Browser: IGV View genome data in IGV\n Download and open IGV Select in menu in top left corner A. thaliana (TAIR10) Upload the following indexed/sorted Bam files with File -\u003e Load from URL...  http://faculty.ucr.edu/~tgirke/HTML_Presentations/Manuals/Workshop_Dec_6_10_2012/Rrnaseq/results/SRR064154.fastq.bam http://faculty.ucr.edu/~tgirke/HTML_Presentations/Manuals/Workshop_Dec_6_10_2012/Rrnaseq/results/SRR064155.fastq.bam http://faculty.ucr.edu/~tgirke/HTML_Presentations/Manuals/Workshop_Dec_6_10_2012/Rrnaseq/results/SRR064166.fastq.bam http://faculty.ucr.edu/~tgirke/HTML_Presentations/Manuals/Workshop_Dec_6_10_2012/Rrnaseq/results/SRR064167.fastq.bam   To view area of interest, enter its coordinates Chr1:49,457-51,457 in position menu on top.    Create symbolic links For viewing BAM files in IGV as part of systemPipeR workflows.\n systemPipeR: utilities for building NGS analysis pipelines.  library(\"systemPipeR\") symLink2bam(sysargs=args, htmldir=c(\"~/.html/\", \"somedir/\"), urlbase=\"http://myserver.edu/~username/\", urlfile=\"IGVurl.txt\")  Controlling IGV from R Open IGV before running the following routine. Alternatively, open IGV from within R with startIGV(\"lm\") . Note this may not work on all systems.\nlibrary(SRAdb) myurls \u003c- readLines(\"http://biocluster.ucr.edu/~tgirke/Documents/R_BioCond/Samples/bam_urls.txt\") #startIGV(\"lm\") # opens IGV sock \u003c- IGVsocket() session \u003c- IGVsession(files=myurls, sessionFile=\"session.xml\", genome=\"A. thaliana (TAIR10)\") IGVload(sock, session) IGVgoto(sock, 'Chr1:45296-47019')  References Yin, T, D Cook, and M Lawrence. 2012. “Ggbio: An R Package for Extending the Grammar of Graphics for Genomic Data.” Genome Biol. 13 (8). https://doi.org/10.1186/gb-2012-13-8-r77.\n Zhang, H, P Meltzer, and S Davis. 2013. “RCircos: An R Package for Circos 2d Track Plots.” BMC Bioinformatics 14: 244–44. https://doi.org/10.1186/1471-2105-14-244.\n  ","categories":"","description":"","excerpt":"document.addEventListener(\"DOMContentLoaded\", function() { …","ref":"/manuals/rgraphics/rgraphics/","tags":"","title":"Graphics and Data Visualization in R"},{"body":"       Source code downloads: [ .Rmd ] [ .R ]\n R Markdown Overview R Markdown combines markdown (an easy to write plain text format) with embedded R code chunks. When compiling R Markdown documents, the code components can be evaluated so that both the code and its output can be included in the final document. This makes analysis reports highly reproducible by allowing to automatically regenerate them when the underlying R code or data changes. R Markdown documents (.Rmd files) can be rendered to various formats including HTML and PDF. The R code in an .Rmd document is processed by knitr, while the resulting .md file is rendered by pandoc to the final output formats (e.g. HTML or PDF). Historically, R Markdown is an extension of the older Sweave/Latex environment. Rendering of mathematical expressions and reference management is also supported by R Markdown using embedded Latex syntax and Bibtex, respectively.\nQuick Start Install R Markdown install.packages(\"rmarkdown\")  Initialize a new R Markdown (Rmd) script To minimize typing, it can be helful to start with an R Markdown template and then modify it as needed. Note the file name of an R Markdown scirpt needs to have the extension .Rmd. Template files for the following examples are available here:\n R Markdown sample script: sample.Rmd Bibtex file for handling citations and reference section: bibtex.bib  Users want to download these files, open the sample.Rmd file with their preferred R IDE (e.g. RStudio, vim or emacs), initilize an R session and then direct their R session to the location of these two files.\nMetadata section The metadata section (YAML header) in an R Markdown script defines how it will be processed and rendered. The metadata section also includes both title, author, and date information as well as options for customizing the output format. For instance, PDF and HTML output can be defined with pdf_document and html_document, respectively. The BiocStyle:: prefix will use the formatting style of the BiocStyle package from Bioconductor.\n --- title: \"My First R Markdown Document\" author: \"Author: First Last\" date: \"Last update: 03 May, 2021\" output: BiocStyle::html_document: toc: true toc_depth: 3 fig_caption: yes fontsize: 14pt bibliography: bibtex.bib ---  Render Rmd script An R Markdown script can be evaluated and rendered with the following render command or by pressing the knit button in RStudio. The output_format argument defines the format of the output (e.g. html_document or pdf_document). The setting output_format=\"all\" will generate all supported output formats. Alternatively, one can specify several output formats in the metadata section.\nrmarkdown::render(\"sample.Rmd\", clean=TRUE, output_format=\"html_document\")  The following shows two options how to run the rendering from the command-line.\n$ Rscript -e \"rmarkdown::render('sample.Rmd', output_format='html_document', clean=TRUE)\"  Alternatively, one can use a Makefile to evaluate and render an R Markdown script. A sample Makefile for rendering the above sample.Rmd can be downloaded here. To apply it to a custom Rmd file, one needs open the Makefile in a text editor and change the value assigned to MAIN (line 13) to the base name of the corresponding .Rmd file (e.g. assign systemPipeRNAseq if the file name is systemPipeRNAseq.Rmd). To execute the Makefile, run the following command from the command-line.\n$ make -B  R code chunks R Code Chunks can be embedded in an R Markdown script by using three backticks at the beginning of a new line along with arguments enclosed in curly braces controlling the behavior of the code. The following lines contain the plain R code. A code chunk is terminated by a new line starting with three backticks. The following shows an example of such a code chunk. Note the backslashes are not part of it. They have been added to print the code chunk syntax in this document.\n ```\\{r code_chunk_name, eval=FALSE\\} x \u003c- 1:10 ```  The following lists the most important arguments to control the behavior of R code chunks:\n r: specifies language for code chunk, here R chode_chunk_name: name of code chunk; this name needs to be unique eval: if assigned TRUE the code will be evaluated warning: if assigned FALSE warnings will not be shown message: if assigned FALSE messages will not be shown cache: if assigned TRUE results will be cached to reuse in future rendering instances fig.height: allows to specify height of figures in inches fig.width: allows to specify width of figures in inches  For more details on code chunk options see here.\nLearning Markdown The basic syntax of Markdown and derivatives like kramdown is extremely easy to learn. Rather than providing another introduction on this topic, here are some useful sites for learning Markdown:\n R Markdown Online Book Markdown Intro on GitHub Markdown Cheet Sheet Markdown Basics from RStudio R Markdown Cheat Sheet kramdown Syntax  Tables There are several ways to render tables. First, they can be printed within the R code chunks. Second, much nicer formatted tables can be generated with the functions kable, pander or xtable. The following example uses kable from the knitr package.\nWith knitr::kable library(knitr) kable(iris[1:12,])     Sepal.Length Sepal.Width Petal.Length Petal.Width Species     5.1 3.5 1.4 0.2 setosa   4.9 3.0 1.4 0.2 setosa   4.7 3.2 1.3 0.2 setosa   4.6 3.1 1.5 0.2 setosa   5.0 3.6 1.4 0.2 setosa   5.4 3.9 1.7 0.4 setosa   4.6 3.4 1.4 0.3 setosa   5.0 3.4 1.5 0.2 setosa   4.4 2.9 1.4 0.2 setosa   4.9 3.1 1.5 0.1 setosa   5.4 3.7 1.5 0.2 setosa   4.8 3.4 1.6 0.2 setosa    A much more elegant and powerful solution is to create fully interactive tables with the DT package. This JavaScirpt based environment provides a wrapper to the DataTables library using jQuery. The resulting tables can be sorted, queried and resized by the user.\nWith DT::datatable library(DT) datatable(iris, filter = 'top', options = list( pageLength = 100, scrollX = TRUE, scrollY = \"600px\", autoWidth = TRUE ))   {\"x\":{\"filter\":\"top\",\"filterHTML\":\"\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n\",\"data\":[[\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\",\"11\",\"12\",\"13\",\"14\",\"15\",\"16\",\"17\",\"18\",\"19\",\"20\",\"21\",\"22\",\"23\",\"24\",\"25\",\"26\",\"27\",\"28\",\"29\",\"30\",\"31\",\"32\",\"33\",\"34\",\"35\",\"36\",\"37\",\"38\",\"39\",\"40\",\"41\",\"42\",\"43\",\"44\",\"45\",\"46\",\"47\",\"48\",\"49\",\"50\",\"51\",\"52\",\"53\",\"54\",\"55\",\"56\",\"57\",\"58\",\"59\",\"60\",\"61\",\"62\",\"63\",\"64\",\"65\",\"66\",\"67\",\"68\",\"69\",\"70\",\"71\",\"72\",\"73\",\"74\",\"75\",\"76\",\"77\",\"78\",\"79\",\"80\",\"81\",\"82\",\"83\",\"84\",\"85\",\"86\",\"87\",\"88\",\"89\",\"90\",\"91\",\"92\",\"93\",\"94\",\"95\",\"96\",\"97\",\"98\",\"99\",\"100\",\"101\",\"102\",\"103\",\"104\",\"105\",\"106\",\"107\",\"108\",\"109\",\"110\",\"111\",\"112\",\"113\",\"114\",\"115\",\"116\",\"117\",\"118\",\"119\",\"120\",\"121\",\"122\",\"123\",\"124\",\"125\",\"126\",\"127\",\"128\",\"129\",\"130\",\"131\",\"132\",\"133\",\"134\",\"135\",\"136\",\"137\",\"138\",\"139\",\"140\",\"141\",\"142\",\"143\",\"144\",\"145\",\"146\",\"147\",\"148\",\"149\",\"150\"],[5.1,4.9,4.7,4.6,5,5.4,4.6,5,4.4,4.9,5.4,4.8,4.8,4.3,5.8,5.7,5.4,5.1,5.7,5.1,5.4,5.1,4.6,5.1,4.8,5,5,5.2,5.2,4.7,4.8,5.4,5.2,5.5,4.9,5,5.5,4.9,4.4,5.1,5,4.5,4.4,5,5.1,4.8,5.1,4.6,5.3,5,7,6.4,6.9,5.5,6.5,5.7,6.3,4.9,6.6,5.2,5,5.9,6,6.1,5.6,6.7,5.6,5.8,6.2,5.6,5.9,6.1,6.3,6.1,6.4,6.6,6.8,6.7,6,5.7,5.5,5.5,5.8,6,5.4,6,6.7,6.3,5.6,5.5,5.5,6.1,5.8,5,5.6,5.7,5.7,6.2,5.1,5.7,6.3,5.8,7.1,6.3,6.5,7.6,4.9,7.3,6.7,7.2,6.5,6.4,6.8,5.7,5.8,6.4,6.5,7.7,7.7,6,6.9,5.6,7.7,6.3,6.7,7.2,6.2,6.1,6.4,7.2,7.4,7.9,6.4,6.3,6.1,7.7,6.3,6.4,6,6.9,6.7,6.9,5.8,6.8,6.7,6.7,6.3,6.5,6.2,5.9],[3.5,3,3.2,3.1,3.6,3.9,3.4,3.4,2.9,3.1,3.7,3.4,3,3,4,4.4,3.9,3.5,3.8,3.8,3.4,3.7,3.6,3.3,3.4,3,3.4,3.5,3.4,3.2,3.1,3.4,4.1,4.2,3.1,3.2,3.5,3.6,3,3.4,3.5,2.3,3.2,3.5,3.8,3,3.8,3.2,3.7,3.3,3.2,3.2,3.1,2.3,2.8,2.8,3.3,2.4,2.9,2.7,2,3,2.2,2.9,2.9,3.1,3,2.7,2.2,2.5,3.2,2.8,2.5,2.8,2.9,3,2.8,3,2.9,2.6,2.4,2.4,2.7,2.7,3,3.4,3.1,2.3,3,2.5,2.6,3,2.6,2.3,2.7,3,2.9,2.9,2.5,2.8,3.3,2.7,3,2.9,3,3,2.5,2.9,2.5,3.6,3.2,2.7,3,2.5,2.8,3.2,3,3.8,2.6,2.2,3.2,2.8,2.8,2.7,3.3,3.2,2.8,3,2.8,3,2.8,3.8,2.8,2.8,2.6,3,3.4,3.1,3,3.1,3.1,3.1,2.7,3.2,3.3,3,2.5,3,3.4,3],[1.4,1.4,1.3,1.5,1.4,1.7,1.4,1.5,1.4,1.5,1.5,1.6,1.4,1.1,1.2,1.5,1.3,1.4,1.7,1.5,1.7,1.5,1,1.7,1.9,1.6,1.6,1.5,1.4,1.6,1.6,1.5,1.5,1.4,1.5,1.2,1.3,1.4,1.3,1.5,1.3,1.3,1.3,1.6,1.9,1.4,1.6,1.4,1.5,1.4,4.7,4.5,4.9,4,4.6,4.5,4.7,3.3,4.6,3.9,3.5,4.2,4,4.7,3.6,4.4,4.5,4.1,4.5,3.9,4.8,4,4.9,4.7,4.3,4.4,4.8,5,4.5,3.5,3.8,3.7,3.9,5.1,4.5,4.5,4.7,4.4,4.1,4,4.4,4.6,4,3.3,4.2,4.2,4.2,4.3,3,4.1,6,5.1,5.9,5.6,5.8,6.6,4.5,6.3,5.8,6.1,5.1,5.3,5.5,5,5.1,5.3,5.5,6.7,6.9,5,5.7,4.9,6.7,4.9,5.7,6,4.8,4.9,5.6,5.8,6.1,6.4,5.6,5.1,5.6,6.1,5.6,5.5,4.8,5.4,5.6,5.1,5.1,5.9,5.7,5.2,5,5.2,5.4,5.1],[0.2,0.2,0.2,0.2,0.2,0.4,0.3,0.2,0.2,0.1,0.2,0.2,0.1,0.1,0.2,0.4,0.4,0.3,0.3,0.3,0.2,0.4,0.2,0.5,0.2,0.2,0.4,0.2,0.2,0.2,0.2,0.4,0.1,0.2,0.2,0.2,0.2,0.1,0.2,0.2,0.3,0.3,0.2,0.6,0.4,0.3,0.2,0.2,0.2,0.2,1.4,1.5,1.5,1.3,1.5,1.3,1.6,1,1.3,1.4,1,1.5,1,1.4,1.3,1.4,1.5,1,1.5,1.1,1.8,1.3,1.5,1.2,1.3,1.4,1.4,1.7,1.5,1,1.1,1,1.2,1.6,1.5,1.6,1.5,1.3,1.3,1.3,1.2,1.4,1.2,1,1.3,1.2,1.3,1.3,1.1,1.3,2.5,1.9,2.1,1.8,2.2,2.1,1.7,1.8,1.8,2.5,2,1.9,2.1,2,2.4,2.3,1.8,2.2,2.3,1.5,2.3,2,2,1.8,2.1,1.8,1.8,1.8,2.1,1.6,1.9,2,2.2,1.5,1.4,2.3,2.4,1.8,1.8,2.1,2.4,2.3,1.9,2.3,2.5,2.3,1.9,2,2.3,1.8],[\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\"]],\"container\":\"\\n \\n \\n  \\n Sepal.Length\\n Sepal.Width\\n Petal.Length\\n Petal.Width\\n Species\\n \\n \\n\",\"options\":{\"pageLength\":100,\"scrollX\":true,\"scrollY\":\"600px\",\"autoWidth\":true,\"columnDefs\":[{\"className\":\"dt-right\",\"targets\":[1,2,3,4]},{\"orderable\":false,\"targets\":0}],\"order\":[],\"orderClasses\":false,\"orderCellsTop\":true}},\"evals\":[],\"jsHooks\":[]} Figures Plots generated by the R code chunks in an R Markdown document can be automatically inserted in the output file. The size of the figure can be controlled with the fig.height and fig.width arguments.\nlibrary(ggplot2) dsmall \u003c- diamonds[sample(nrow(diamonds), 1000), ] ggplot(dsmall, aes(color, price/carat)) + geom_jitter(alpha = I(1 / 2), aes(color=color))  Sometimes it can be useful to explicitly write an image to a file and then insert that image into the final document by referencing its file name in the R Markdown source. For instance, this can be useful for time consuming analyses. The following code will generate a file named myplot.png. To insert the file in the final document, one can use standard Markdown or HTML syntax, e.g.: \u003cimg src=\"myplot.png\"/\u003e.\npng(\"myplot.png\") ggplot(dsmall, aes(color, price/carat)) + geom_jitter(alpha = I(1 / 2), aes(color=color)) dev.off()  ## png ## 2    Inline R code To evaluate R code inline, one can enclose an R expression with a single back-tick followed by r and then the actual expression. For instance, the back-ticked version of ‘r 1 + 1’ evaluates to 2 and ‘r pi’ evaluates to 3.1415927.\nMathematical equations To render mathematical equations, one can use standard Latex syntax. When expressions are enclosed with single $ signs then they will be shown inline, while enclosing them with double $$ signs will show them in display mode. For instance, the following Latex syntax d(X,Y) = \\sqrt[]{ \\sum_{i=1}^{n}{(x_{i}-y_{i})^2} } renders in display mode as follows:\n$$d(X,Y) = \\sqrt[]{ \\sum_{i=1}^{n}{(x_{i}-y_{i})^2} }$$\nCitations and bibliographies Citations and bibliographies can be autogenerated in R Markdown in a similar way as in Latex/Bibtex. Reference collections should be stored in a separate file in Bibtex or other supported formats. To cite a publication in an R Markdown script, one uses the syntax [@\u003cid1\u003e] where \u003cid1\u003e needs to be replaced with a reference identifier present in the Bibtex database listed in the metadata section of the R Markdown script (e.g. bibtex.bib). For instance, to cite Lawrence et al. (2013), one uses its reference identifier (e.g. Lawrence2013-kt) as \u003cid1\u003e (Lawrence et al. 2013). This will place the citation inline in the text and add the corresponding reference to a reference list at the end of the output document. For the latter a special section called References needs to be specified at the end of the R Markdown script. To fine control the formatting of citations and reference lists, users want to consult this the corresponding R Markdown page. Also, for general reference management and outputting references in Bibtex format Paperpile can be very helpful.\nViewing R Markdown report on HPCC cluster R Markdown reports located on UCR’s HPCC Cluster can be viewed locally in a web browser (without moving the source HTML) by creating a symbolic link from a user’s .html directory. This way any updates to the report will show up immediately without creating another copy of the HTML file. For instance, if user ttest has generated an R Markdown report under ~/bigdata/today/rmarkdown/sample.html, then the symbolic link can be created as follows:\ncd ~/.html ln -s ~/bigdata/today/rmarkdown/sample.html sample.html  After this one can view the report in a web browser using this URL http://biocluster.ucr.edu/~ttest/rmarkdown/sample.html. If necessary access to the URL can be restricted with a password following the instructions here.\nSession Info sessionInfo()  ## R version 4.0.5 (2021-03-31) ## Platform: x86_64-pc-linux-gnu (64-bit) ## Running under: Debian GNU/Linux 10 (buster) ## ## Matrix products: default ## BLAS: /usr/lib/x86_64-linux-gnu/blas/libblas.so.3.8.0 ## LAPACK: /usr/lib/x86_64-linux-gnu/lapack/liblapack.so.3.8.0 ## ## locale: ## [1] LC_CTYPE=en_US.UTF-8 LC_NUMERIC=C ## [3] LC_TIME=en_US.UTF-8 LC_COLLATE=en_US.UTF-8 ## [5] LC_MONETARY=en_US.UTF-8 LC_MESSAGES=en_US.UTF-8 ## [7] LC_PAPER=en_US.UTF-8 LC_NAME=C ## [9] LC_ADDRESS=C LC_TELEPHONE=C ## [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C ## ## attached base packages: ## [1] stats graphics grDevices utils datasets methods base ## ## other attached packages: ## [1] ggplot2_3.3.2 DT_0.16 knitr_1.30 ## ## loaded via a namespace (and not attached): ## [1] bslib_0.2.4 compiler_4.0.5 pillar_1.4.7 jquerylib_0.1.3 ## [5] highr_0.8 tools_4.0.5 digest_0.6.27 viridisLite_0.3.0 ## [9] jsonlite_1.7.1 evaluate_0.14 lifecycle_0.2.0 tibble_3.0.4 ## [13] gtable_0.3.0 pkgconfig_2.0.3 rlang_0.4.8 crosstalk_1.1.0.1 ## [17] yaml_2.2.1 blogdown_1.2 xfun_0.22 withr_2.3.0 ## [21] stringr_1.4.0 dplyr_1.0.2 generics_0.1.0 htmlwidgets_1.5.2 ## [25] sass_0.3.1 vctrs_0.3.5 tidyselect_1.1.0 grid_4.0.5 ## [29] glue_1.4.2 R6_2.5.0 rmarkdown_2.7 bookdown_0.21 ## [33] farver_2.0.3 purrr_0.3.4 magrittr_2.0.1 scales_1.1.1 ## [37] htmltools_0.5.1.1 ellipsis_0.3.1 colorspace_2.0-0 labeling_0.4.2 ## [41] stringi_1.5.3 munsell_0.5.0 crayon_1.3.4  References Lawrence, Michael, Wolfgang Huber, Hervé Pagès, Patrick Aboyoun, Marc Carlson, Robert Gentleman, Martin T Morgan, and Vincent J Carey. 2013. “Software for Computing and Annotating Genomic Ranges.” PLoS Comput. Biol. 9 (8): e1003118. https://doi.org/10.1371/journal.pcbi.1003118.\n  ","categories":"","description":"","excerpt":"       Source code downloads: [ .Rmd ] [ .R ]\n R Markdown Overview R …","ref":"/tutorials/rmarkdown/rmarkdown/","tags":"","title":"R Markdown Tutorial"},{"body":"document.addEventListener(\"DOMContentLoaded\", function() { document.querySelector(\"h1\").className = \"title\"; });  document.addEventListener(\"DOMContentLoaded\", function() { var links = document.links; for (var i = 0, linksLength = links.length; i Source code downloads: .Rmd .R\n Introduction The following introduces several widely used gene and protein annotation systems that are commonly used for functional enrichment analysis (FEA). These include among many other annotation systems: Gene Ontology (GO), Disease Ontology (DO) and pathway annotations, such as KEGG and Reactome. Examples of widely used statistical enrichment methods are introduced as well. These statistical FEA methods assess whether functional annotation terms are over-represented in a query gene set. In case of so called over-represention analysis (ORA) methods, such as Fisher’s exact and hypgeometric distribution tests, the query is usually a list of unranked gene identifiers (Falcon and Gentleman 2007). In contrast to this, Gene Set Enrichment Analysis (GSEA) algorithms use as query a score ranked lists (e.g. all genes profiled by an assay) and assess whether annotation catetories are more highly enriched among the highest ranking genes in the list compared to random rankings (Subramanian et al. 2005; Sergushichev 2016; Duan et al. 2020). The sets in both the query and the annotation databases can be composed of genes, proteins, compounds or other factors. For simplicity, the term gene sets is used throughtout this text.\nFunctional Annotations Systems This section introduces a small selection of functional annotation systems, largely provided by Bioconductor packages. This includes code to inspect how the annotations are organized and how to access them.\nGene Ontology DB GO.db is a data package that stores the GO term information from the GO consortium in an SQLite database. Several accessor functions are provide to query the database. Organism specific gene to GO annotations are provied by organism data packages and/or Bioconductor’s AnntationHub. The following provide sample code for using GO.db as well as a organism database example.\n## Load GOstats library library(GOstats); library(GO.db) ## Print complete GO term information for \"GO:0003700\" GOTERM$\"GO:0003700\" ## Print parent and children terms for a GO ID GOMFPARENTS$\"GO:0003700\"; GOMFCHILDREN$\"GO:0003700\" ## Print complete lineages of parents and children for a GO ID GOMFANCESTOR$\"GO:0003700\"; GOMFOFFSPRING$\"GO:0003700\" ## Print number of GO terms in each of the 3 ontologies zz \u003c- eapply(GOTERM, function(x) x@Ontology); table(unlist(zz)) ## Gene to GO mappings for an organism (here Arabidopsis) library(org.At.tair.db) # For human use org.Hs.eg.db xx \u003c- as.list(org.At.tairGO2ALLTAIRS)  Pathway DBs KEGG KEGG.db The following load_keggList function returns the pathway annotations from the KEGG.db package for a species selected under the org argument (e.g. hsa, ath, dme, mmu, …). The resulting list object can be used for ORA or GSEA methods, e.g. by fgsea.\n## Define function to create KEGG pathway list db load_keggList \u003c- function(org=\"ath\") { suppressMessages(suppressWarnings(library(KEGG.db))) kegg_gene_list \u003c- as.list(KEGGPATHID2EXTID) # All organisms in kegg kegg_gene_list \u003c- kegg_gene_list[grepl(org, names(kegg_gene_list))] # Only human kegg_name_list \u003c- unlist(as.list(KEGGPATHID2NAME)) # All organisms in kegg kegg_name_list \u003c- kegg_name_list[gsub(paste0(\"^\", org), \"\", names(kegg_gene_list))] names(kegg_gene_list) \u003c- paste0(names(kegg_gene_list), \" (\", names(kegg_name_list), \") - \", kegg_name_list) return(kegg_gene_list) } ## Usage: keggdb \u003c- load_keggList(org=\"ath\") # org can be: hsa, ath, dme, mmu, ...  Additional packages for KEGG pathways:\n pathview: plotting pathways with quantitative information embedded KEGGREST: access via KEGG REST API Many additional packages can be found under Bioc’s KEGG View page here  Reactome The following load_reacList function returns the pathway annotations from the reactome.db package for a species selected under the org argument (e.g. R-HSA, R-MMU, R-DME, R-CEL, …). The resulting list object can be used for various ORA or GSEA methods, e.g. by fgsea.\n## Define function to create Reactome pathway list db load_reacList \u003c- function(org=\"R-HSA\") { library(reactome.db) reac_gene_list \u003c- as.list(reactomePATHID2EXTID) # All organisms in reactome reac_gene_list \u003c- reac_gene_list[grepl(org, names(reac_gene_list))] # Only human reac_name_list \u003c- unlist(as.list(reactomePATHID2NAME)) # All organisms in reactome reac_name_list \u003c- reac_name_list[names(reac_gene_list)] names(reac_gene_list) \u003c- paste0(names(reac_gene_list), \" (\", names(reac_name_list), \") - \", gsub(\"^.*: \", \"\", reac_name_list)) return(reac_gene_list) } ## Usage: reacdb \u003c- load_reacList(org=\"R-HSA\")  A very useful query interface for Reactome is the ReactomeContentService4R package. Its vignette provides many useful examples, see here. A sample plot from ReactomeContentService4R is shown below.\nFigure 1: Fireworks plot giving genome-wide pathway overview.\n  Functional Enrichment Analysis Methods Over-representation analysis (ORA) GOstats Package The GOstats package allows testing for both over and under representation of GO terms using either the standard Hypergeometric test or a conditional Hypergeometric test that uses the relationships among the GO terms for conditioning (Falcon and Gentleman 2007).\n## Load required packages library(GOstats); library(GO.db); library(org.At.tair.db) ## Define universe and test sample set geneUniverse \u003c- keys(org.At.tairGENENAME) geneSample \u003c- c(\"AT2G46210\", \"AT2G19880\", \"AT2G38910\", \"AT5G25140\", \"AT2G44525\") ## Generate params object params \u003c- new(\"GOHyperGParams\", geneIds = geneSample, universeGeneIds = geneUniverse, annotation=\"org.At.tair\", ontology = \"MF\", pvalueCutoff = 0.5, conditional = FALSE, testDirection = \"over\") ## Run enrichment test hgOver \u003c- hyperGTest(params) ## Viewing of results summary(hgOver)[1:4,] htmlReport(hgOver, file = \"MyhyperGresult.html\") # html file will be written to current working directory  GOHyperGAll and GOCluster_Report The following introduceds a GOCluster_Report convenience function from the systemPipeR package. The first part shows how to generate the proper catdb lookup data structure for any organism supported by BioMart (H Backman and Girke 2016). This more time consuming step needs to be performed only once.\n## Create a custom genome-to-GO lookup table for enrichment testing library(systemPipeR); library(biomaRt) listMarts() # To choose BioMart database listMarts(host = \"plants.ensembl.org\") ## Obtain annotations from BioMart listMarts() # To choose BioMart database m \u003c- useMart(\"plants_mart\", host = \"plants.ensembl.org\") listDatasets(m) m \u003c- useMart(\"plants_mart\", dataset = \"athaliana_eg_gene\", host = \"plants.ensembl.org\") listAttributes(m) # Choose data types you want to download go \u003c- getBM(attributes = c(\"go_id\", \"tair_locus\", \"namespace_1003\"), mart = m) go \u003c- go[go[, 3] != \"\", ]; go[, 3] \u003c- as.character(go[, 3]) go[go[, 3] == \"molecular_function\", 3] \u003c- \"F\"; go[go[, 3] == \"biological_process\", 3] \u003c- \"P\"; go[go[, 3] == \"cellular_component\", 3] \u003c- \"C\" go[1:4, ] dir.create(\"./GO\") write.table(go, \"GO/GOannotationsBiomart_mod.txt\", quote = FALSE, row.names = FALSE, col.names = FALSE, sep = \"\\t\") catdb \u003c- makeCATdb(myfile = \"GO/GOannotationsBiomart_mod.txt\", lib = NULL, org = \"\", colno = c(1, 2, 3), idconv = NULL) save(catdb, file=\"GO/catdb.RData\")  For the actual enrichment analysis one can load the catdb object from the corresponding file, and then perform batch GO term analysis where the results include all terms meeting a user-provided P-value cutoff as well as GO Slim terms.\n## Next time catDB can be loaded from file load(\"GO/catdb.RData\") ## Perform enrichment test on single gene set geneids \u003c- unique(as.character(catmap(catdb)$D_MF[,\"GeneID\"])) gene_set_list \u003c- sapply(c(\"Set1\", \"Set2\", \"Set3\"), function(x) sample(geneids, 100), simplify=FALSE) GOHyperGAll(catdb=catdb, gocat=\"MF\", sample=gene_set_list[[1]], Nannot=2)[1:20,] ## Batch analysis of many gene sets for all and slim terms goall \u003c- GOCluster_Report(catdb=catdb, setlist=gene_set_list, method=\"all\", id_type=\"gene\", CLSZ=2, cutoff=0.01, gocats=c(\"MF\", \"BP\", \"CC\"), recordSpecGO = NULL) ## GO Slim analysis by subsetting enrichment results accordingly m \u003c- useMart(\"plants_mart\", dataset = \"athaliana_eg_gene\", host = \"plants.ensembl.org\") goslimvec \u003c- as.character(getBM(attributes = c(\"goslim_goa_accession\"), mart = m)[, 1]) goslim \u003c- GOCluster_Report(catdb=catdb, setlist=gene_set_list, method=\"slim\",id_type=\"gene\", myslimv=goslimvec, CLSZ=2, cutoff=0.01, gocats = c(\"MF\", \"BP\", \"CC\"), recordSpecGO = NULL) ## Plot 'GOBatchResult' as bar plot goBarplot(goslim, gocat=\"MF\")  Figure 2: Batch ORA result of GO slim terms using 3 test gene sets.\n  Set enrichment analysis (SEA) fgsea Package The fgsea function performs gene set enrichment analysis (GSEA) on a score ranked gene list (Sergushichev 2016). Compared to other GESA implementations, fgsea is very fast. Its P-value estimation is based on an adaptive multi-level split Monte-Carlo scheme. In addition to its speed, it is very flexible in adopting custom annotation systems since it stores the gene-to-category annotations in a simple list object that is easy to create. The following uses the keegdb and reacdb lists created above as annotation systems.\n## Load packages and create sample ranked gene list library(fgsea); library(data.table); library(ggplot2); library(org.At.tair.db) set.seed(42) ## fgsea with KEGG (Arabidopsis) geneids \u003c- mappedkeys(org.At.tairCHR) exampleRanks \u003c- sort(setNames(sample(seq(-100,100, by=0.001), length(geneids)), geneids)) fgseaResKegg \u003c- fgsea(pathways=keggdb, stats=exampleRanks, minSize=15, maxSize=500) head(fgseaResKegg[order(pval), ]) plotEnrichment(keggdb[[\"ath00052 (00052) - Galactose metabolism\"]], exampleRanks) + labs(title=\"Galactose metabolism\") ## fgsea with Reactome (Human) geneids \u003c- unique(as.character(unlist(reacdb))) exampleRanks \u003c- sort(setNames(sample(seq(-100,100, by=0.001), length(geneids)), geneids)) fgseaResReac \u003c- fgsea(pathways=reacdb, stats=exampleRanks, minSize=15, maxSize=500) head(fgseaResReac[order(pval), ]) plotEnrichment(reacdb[[\"R-HSA-3247509 (R-HSA-3247509) - Chromatin modifying enzymes\"]], exampleRanks) + labs(title=\"Chromatin modifying enzymes\")  The plotEnrichment can be used to create enrichment plots. Additional examples are available in the vignette of the fgsea package here.\nFigure 3: Enrichment plot for selected pathway.\n  Version Information sessionInfo()  ## R version 4.0.5 (2021-03-31) ## Platform: x86_64-pc-linux-gnu (64-bit) ## Running under: Debian GNU/Linux 10 (buster) ## ## Matrix products: default ## BLAS: /usr/lib/x86_64-linux-gnu/blas/libblas.so.3.8.0 ## LAPACK: /usr/lib/x86_64-linux-gnu/lapack/liblapack.so.3.8.0 ## ## locale: ## [1] LC_CTYPE=en_US.UTF-8 LC_NUMERIC=C LC_TIME=en_US.UTF-8 ## [4] LC_COLLATE=en_US.UTF-8 LC_MONETARY=en_US.UTF-8 LC_MESSAGES=en_US.UTF-8 ## [7] LC_PAPER=en_US.UTF-8 LC_NAME=C LC_ADDRESS=C ## [10] LC_TELEPHONE=C LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C ## ## attached base packages: ## [1] stats graphics grDevices utils datasets methods base ## ## other attached packages: ## [1] fgsea_1.16.0 ggplot2_3.3.2 BiocStyle_2.18.0 ## ## loaded via a namespace (and not attached): ## [1] Rcpp_1.0.5 bslib_0.2.4 compiler_4.0.5 pillar_1.4.7 ## [5] BiocManager_1.30.10 jquerylib_0.1.3 tools_4.0.5 digest_0.6.27 ## [9] lattice_0.20-41 jsonlite_1.7.1 evaluate_0.14 lifecycle_0.2.0 ## [13] tibble_3.0.4 gtable_0.3.0 pkgconfig_2.0.3 rlang_0.4.8 ## [17] Matrix_1.3-2 fastmatch_1.1-0 parallel_4.0.5 yaml_2.2.1 ## [21] blogdown_1.2 xfun_0.22 gridExtra_2.3 withr_2.3.0 ## [25] stringr_1.4.0 dplyr_1.0.2 knitr_1.30 generics_0.1.0 ## [29] sass_0.3.1 vctrs_0.3.5 grid_4.0.5 tidyselect_1.1.0 ## [33] data.table_1.13.2 glue_1.4.2 R6_2.5.0 BiocParallel_1.24.1 ## [37] rmarkdown_2.7 bookdown_0.21 purrr_0.3.4 magrittr_2.0.1 ## [41] codetools_0.2-18 scales_1.1.1 htmltools_0.5.1.1 ellipsis_0.3.1 ## [45] colorspace_2.0-0 stringi_1.5.3 munsell_0.5.0 crayon_1.3.4  References Duan, Yuzhu, Daniel S Evans, Richard A Miller, Nicholas J Schork, Steven R Cummings, and Thomas Girke. 2020. “signatureSearch: environment for gene expression signature searching and functional interpretation.” Nucleic Acids Res., October. https://doi.org/10.1093/nar/gkaa878.\n Falcon, S, and R Gentleman. 2007. “Using GOstats to test gene lists for GO term association.” Bioinformatics 23 (2): 257–58. https://doi.org/10.1093/bioinformatics/btl567.\n H Backman, Tyler W, and Thomas Girke. 2016. “systemPipeR: NGS workflow and report generation environment.” BMC Bioinformatics 17 (September): 388. https://doi.org/10.1186/s12859-016-1241-0.\n Sergushichev, Alexey. 2016. “An algorithm for fast preranked gene set enrichment analysis using cumulative statistic calculation.” bioRxiv. https://doi.org/10.1101/060012.\n Subramanian, A, P Tamayo, V K Mootha, S Mukherjee, B L Ebert, M A Gillette, A Paulovich, et al. 2005. “Gene set enrichment analysis: a knowledge-based approach for interpreting genome-wide expression profiles.” Proc. Natl. Acad. Sci. U. S. A. 102 (43): 15545–50. https://doi.org/10.1073/pnas.0506580102.\n  ","categories":"","description":"","excerpt":"document.addEventListener(\"DOMContentLoaded\", function() { …","ref":"/tutorials/rfea/rfea/","tags":"","title":"Functional Enrichment Analysis"},{"body":"document.addEventListener(\"DOMContentLoaded\", function() { document.querySelector(\"h1\").className = \"title\"; });  document.addEventListener(\"DOMContentLoaded\", function() { var links = document.links; for (var i = 0, linksLength = links.length; i Source code downloads: [ .Rmd ] [ .R ]\n Introduction  What is Clustering?  Clustering is the classification of data objects into similarity groups (clusters) according to a defined distance measure. It is used in many fields, such as machine learning, data mining, pattern recognition, image analysis, genomics, systems biology, etc. Machine learning typically regards data clustering as a form of unsupervised learning.   Why Clustering and Data Mining in R?}  Efficient data structures and functions for clustering Reproducible and programmable Comprehensive set of clustering and machine learning libraries Integration with many other data analysis tools   Useful Links  Cluster Task Views Machine Learning Task Views UCR Manual    Data Preprocessing Data Transformations Choice depends on data set!\n  Center and standardize\n Center: subtract from each value the mean of the corresponding vector Standardize: devide by standard deviation   Result: Mean = 0 and STDEV = 1    Center and scale with the scale() function\n Center: subtract from each value the mean of the corresponding vector Scale: divide centered vector by their root mean square (rms): $$ x_{rms} = \\sqrt[]{\\frac{1}{n-1}\\sum_{i=1}^{n}{x_{i}{^2}}} $$   Result: Mean = 0 and STDEV = 1    Log transformation\n  Rank transformation: replace measured values by ranks\n  No transformation\n  Distance Methods List of most common ones!\n Euclidean distance for two profiles X and Y: $$ d(X,Y) = \\sqrt[]{ \\sum_{i=1}^{n}{(x_{i}-y_{i})^2} }$$  Disadvantages: not scale invariant, not for negative correlations   Maximum, Manhattan, Canberra, binary, Minowski, … Correlation-based distance: 1-r  Pearson correlation coefficient (PCC): $$r = \\frac{n\\sum_{i=1}^{n}{x_{i}y_{i}} - \\sum_{i=1}^{n}{x_{i}} \\sum_{i=1}^{n}{y_{i}}}{ \\sqrt[]{(\\sum_{i=1}^{n}{x_{i}^2} - (\\sum_{i=1}^{n}{x_{i})^2}) (\\sum_{i=1}^{n}{y_{i}^2} - (\\sum_{i=1}^{n}{y_{i})^2})} }$$  Disadvantage: outlier sensitive   Spearman correlation coefficient (SCC)  Same calculation as PCC but with ranked values!      There are many more distance measures\n If the distances among items are quantifiable, then clustering is possible. Choose the most accurate and meaningful distance measure for a given field of application. If uncertain then choose several distance measures and compare the results.  Cluster Linkage   Clustering Algorithms Hierarchical Clustering Overview of algorithm  Identify clusters (items) with closest distance Join them to new clusters Compute distance between clusters (items) Return to step 1  Hierarchical clustering: agglomerative Approach   Hierarchical Clustering with Heatmap    A heatmap is a color coded table. To visually identify patterns, the rows and columns of a heatmap are often sorted by hierarchical clustering trees. In case of gene expression data, the row tree usually represents the genes, the column tree the treatments and the colors in the heat table represent the intensities or ratios of the underlying gene expression data set.  Hierarchical Clustering Approaches  Agglomerative approach (bottom-up)  R functions: hclust() and agnes()   Divisive approach (top-down)  R function: diana()    Tree Cutting to Obtain Discrete Clusters  Node height in tree Number of clusters Search tree nodes by distance cutoff  Examples Using hclust and heatmap.2 library(gplots) y \u003c- matrix(rnorm(500), 100, 5, dimnames=list(paste(\"g\", 1:100, sep=\"\"), paste(\"t\", 1:5, sep=\"\"))) heatmap.2(y) # Shortcut to final result  Stepwise Approach with Tree Cutting ## Row- and column-wise clustering hr \u003c- hclust(as.dist(1-cor(t(y), method=\"pearson\")), method=\"complete\") hc \u003c- hclust(as.dist(1-cor(y, method=\"spearman\")), method=\"complete\") ## Tree cutting mycl \u003c- cutree(hr, h=max(hr$height)/1.5); mycolhc \u003c- rainbow(length(unique(mycl)), start=0.1, end=0.9); mycolhc \u003c- mycolhc[as.vector(mycl)] ## Plot heatmap mycol \u003c- colorpanel(40, \"darkblue\", \"yellow\", \"white\") # or try redgreen(75) heatmap.2(y, Rowv=as.dendrogram(hr), Colv=as.dendrogram(hc), col=mycol, scale=\"row\", density.info=\"none\", trace=\"none\", RowSideColors=mycolhc)  K-Means Clustering Overview of algorithm  Choose the number of k clusters Randomly assign items to the k clusters Calculate new centroid for each of the k clusters Calculate the distance of all items to the k centroids Assign items to closest centroid Repeat until clusters assignments are stable    Examples km \u003c- kmeans(t(scale(t(y))), 3) km$cluster  ## g1 g2 g3 g4 g5 g6 g7 g8 g9 g10 g11 g12 g13 g14 g15 g16 g17 g18 g19 g20 ## 1 2 1 3 3 1 1 1 3 1 1 2 1 3 3 2 2 2 1 1 ## g21 g22 g23 g24 g25 g26 g27 g28 g29 g30 g31 g32 g33 g34 g35 g36 g37 g38 g39 g40 ## 2 1 3 1 3 2 3 3 3 3 1 1 3 3 3 1 3 1 1 3 ## g41 g42 g43 g44 g45 g46 g47 g48 g49 g50 g51 g52 g53 g54 g55 g56 g57 g58 g59 g60 ## 1 2 3 2 3 3 3 3 2 1 3 2 3 3 2 2 3 1 3 1 ## g61 g62 g63 g64 g65 g66 g67 g68 g69 g70 g71 g72 g73 g74 g75 g76 g77 g78 g79 g80 ## 1 1 3 3 2 3 2 2 3 3 2 3 2 3 2 1 3 1 1 3 ## g81 g82 g83 g84 g85 g86 g87 g88 g89 g90 g91 g92 g93 g94 g95 g96 g97 g98 g99 g100 ## 3 3 2 1 2 3 1 3 1 1 1 2 1 2 1 3 1 3 3 3  Fuzzy C-Means Clustering  In contrast to strict (hard) clustering approaches, fuzzy (soft) clustering methods allow multiple cluster memberships of the clustered items (Hathaway, Bezdek, and Pal 1996). This is commonly achieved by assigning to each item a weight of belonging to each cluster. Thus, items at the edge of a cluster, may be in a cluster to a lesser degree than items at the center of a cluster. Typically, each item has as many coefficients (weights) as there are clusters that sum up for each item to one.  Examples Fuzzy Clustering with fanny library(cluster) # Loads the cluster library. fannyy \u003c- fanny(y, k=4, metric = \"euclidean\", memb.exp = 1.2) round(fannyy$membership, 2)[1:4,]  ## [,1] [,2] [,3] [,4] ## g1 0.94 0.01 0.03 0.02 ## g2 0.01 0.91 0.01 0.07 ## g3 0.04 0.02 0.92 0.02 ## g4 0.01 0.01 0.01 0.98  fannyy$clustering  ## g1 g2 g3 g4 g5 g6 g7 g8 g9 g10 g11 g12 g13 g14 g15 g16 g17 g18 g19 g20 ## 1 2 3 4 1 2 3 3 4 3 3 2 2 4 4 2 2 2 3 3 ## g21 g22 g23 g24 g25 g26 g27 g28 g29 g30 g31 g32 g33 g34 g35 g36 g37 g38 g39 g40 ## 2 3 1 1 4 4 3 3 1 1 1 1 4 4 3 2 1 3 2 4 ## g41 g42 g43 g44 g45 g46 g47 g48 g49 g50 g51 g52 g53 g54 g55 g56 g57 g58 g59 g60 ## 2 4 3 2 4 4 1 3 2 3 1 2 1 3 2 2 4 3 4 3 ## g61 g62 g63 g64 g65 g66 g67 g68 g69 g70 g71 g72 g73 g74 g75 g76 g77 g78 g79 g80 ## 1 1 3 4 2 4 2 2 4 3 2 4 2 4 4 2 1 3 1 1 ## g81 g82 g83 g84 g85 g86 g87 g88 g89 g90 g91 g92 g93 g94 g95 g96 g97 g98 g99 g100 ## 4 3 4 3 4 3 3 3 3 1 3 4 3 4 1 1 3 1 4 3  Principal Component Analysis (PCA) Principal components analysis (PCA) is a data reduction technique that allows to simplify multidimensional data sets to 2 or 3 dimensions for plotting purposes and visual variance analysis.\nBasic Steps  Center (and standardize) data First principal component axis  Across centroid of data cloud Distance of each point to that line is minimized, so that it crosses the maximum variation of the data cloud   Second principal component axis  Orthogonal to first principal component Along maximum variation in the data   First PCA axis becomes x-axis and second PCA axis y-axis Continue process until the necessary number of principal components is obtained    Example pca \u003c- prcomp(y, scale=T) summary(pca) # Prints variance summary for all principal components  ## Importance of components: ## PC1 PC2 PC3 PC4 PC5 ## Standard deviation 1.1024 1.0709 0.9954 0.9286 0.8857 ## Proportion of Variance 0.2431 0.2294 0.1982 0.1725 0.1569 ## Cumulative Proportion 0.2431 0.4724 0.6706 0.8431 1.0000  plot(pca$x, pch=20, col=\"blue\", type=\"n\") # To plot dots, drop type=\"n\" text(pca$x, rownames(pca$x), cex=0.8)  1st and 2nd principal components explain x% of variance in data.\nMultidimensional Scaling (MDS)  Alternative dimensionality reduction approach Represents distances in 2D or 3D space Starts from distance matrix (PCA uses data points)  Example The following example performs MDS analysis with cmdscale on the geographic distances among European cities.\nloc \u003c- cmdscale(eurodist) plot(loc[,1], -loc[,2], type=\"n\", xlab=\"\", ylab=\"\", main=\"cmdscale(eurodist)\") text(loc[,1], -loc[,2], rownames(loc), cex=0.8)  Biclustering Finds in matrix subgroups of rows and columns which are as similar as possible to each other and as different as possible to the remaining data points.\n   Unclustered ————————–\u003e Clustered  Similarity Measures for Clusters  Compare the numbers of identical and unique item pairs appearing in cluster sets Achieved by counting the number of item pairs found in both clustering sets (a) as well as the pairs appearing only in the first (b) or the second (c) set. With this a similarity coefficient, such as the Jaccard index, can be computed. The latter is defined as the size of the intersect divided by the size of the union of two sample sets: a/(a+b+c). In case of partitioning results, the Jaccard Index measures how frequently pairs of items are joined together in two clustering data sets and how often pairs are observed only in one set. Related coefficient are the Rand Index and the Adjusted Rand Index. These indices also consider the number of pairs (d) that are not joined together in any of the clusters in both sets.  Example: Jaccard index for cluster sets The following imports the cindex() function and computes the Jaccard Index for two sample clusters.\nsource(\"http://faculty.ucr.edu/~tgirke/Documents/R_BioCond/My_R_Scripts/clusterIndex.R\") library(cluster); y \u003c- matrix(rnorm(5000), 1000, 5, dimnames=list(paste(\"g\", 1:1000, sep=\"\"), paste(\"t\", 1:5, sep=\"\"))); clarax \u003c- clara(y, 49); clV1 \u003c- clarax$clustering; clarax \u003c- clara(y, 50); clV2 \u003c- clarax$clustering ci \u003c- cindex(clV1=clV1, clV2=clV2, self=FALSE, minSZ=1, method=\"jaccard\") ci[2:3] # Returns Jaccard index and variables used to compute it  ## $variables ## a b c ## 14537 647 807 ## ## $Jaccard_Index ## [1] 0.9090739  Clustering cluster sets with Jaccard index The following example shows how one can cluster entire cluster result sets. First, 10 sample cluster results are created with Clara using k-values from 3 to 12. The results are stored as named clustering vectors in a list object. Then a nested sapply loop is used to generate a similarity matrix of Jaccard Indices for the clustering results. After converting the result into a distance matrix, hierarchical clustering is performed with hclust.}\nclVlist \u003c- lapply(3:12, function(x) clara(y[1:30, ], k=x)$clustering); names(clVlist) \u003c- paste(\"k\", \"=\", 3:12) d \u003c- sapply(names(clVlist), function(x) sapply(names(clVlist), function(y) cindex(clV1=clVlist[[y]], clV2=clVlist[[x]], method=\"jaccard\")[[3]])) hv \u003c- hclust(as.dist(1-d)) plot(as.dendrogram(hv), edgePar=list(col=3, lwd=4), horiz=T, main=\"Similarities of 10 Clara Clustering Results for k: 3-12\")   Remember: there are many additional clustering algorithms. Additional details can be found in the Clustering Section of the R/Bioconductor Manual.  Clustering Exercises Data Preprocessing Scaling ## Sample data set set.seed(1410) y \u003c- matrix(rnorm(50), 10, 5, dimnames=list(paste(\"g\", 1:10, sep=\"\"), paste(\"t\", 1:5, sep=\"\"))) dim(y)  ## [1] 10 5  ## Scaling yscaled \u003c- t(scale(t(y))) # Centers and scales y row-wise apply(yscaled, 1, sd)  ## g1 g2 g3 g4 g5 g6 g7 g8 g9 g10 ## 1 1 1 1 1 1 1 1 1 1  Distance Matrices Euclidean distance matrix dist(y[1:4,], method = \"euclidean\")  ## g1 g2 g3 ## g2 4.793697 ## g3 4.932658 6.354978 ## g4 4.033789 4.788508 1.671968  Correlation-based distance matrix Correlation matrix\nc \u003c- cor(t(y), method=\"pearson\") as.matrix(c)[1:4,1:4]  ## g1 g2 g3 g4 ## g1 1.00000000 -0.2965885 -0.00206139 -0.4042011 ## g2 -0.29658847 1.0000000 -0.91661118 -0.4512912 ## g3 -0.00206139 -0.9166112 1.00000000 0.7435892 ## g4 -0.40420112 -0.4512912 0.74358925 1.0000000  Correlation-based distance matrix\nd \u003c- as.dist(1-c) as.matrix(d)[1:4,1:4]  ## g1 g2 g3 g4 ## g1 0.000000 1.296588 1.0020614 1.4042011 ## g2 1.296588 0.000000 1.9166112 1.4512912 ## g3 1.002061 1.916611 0.0000000 0.2564108 ## g4 1.404201 1.451291 0.2564108 0.0000000  Hierarchical Clustering with hclust Hierarchical clustering with complete linkage and basic tree plotting\nhr \u003c- hclust(d, method = \"complete\", members=NULL) names(hr)  ## [1] \"merge\" \"height\" \"order\" \"labels\" \"method\" \"call\" ## [7] \"dist.method\"  par(mfrow = c(1, 2)); plot(hr, hang = 0.1); plot(hr, hang = -1)  Tree plotting I plot(as.dendrogram(hr), edgePar=list(col=3, lwd=4), horiz=T)  Tree plotting II The ape library provides more advanced features for tree plotting\nlibrary(ape) plot.phylo(as.phylo(hr), type=\"p\", edge.col=4, edge.width=2, show.node.label=TRUE, no.margin=TRUE)  Tree Cutting Accessing information in hclust objects\nhr  ## ## Call: ## hclust(d = d, method = \"complete\", members = NULL) ## ## Cluster method : complete ## Number of objects: 10  ## Print row labels in the order they appear in the tree hr$labels[hr$order]  ## [1] \"g10\" \"g3\" \"g4\" \"g2\" \"g9\" \"g6\" \"g7\" \"g1\" \"g5\" \"g8\"  Tree cutting with cutree\nmycl \u003c- cutree(hr, h=max(hr$height)/2) mycl[hr$labels[hr$order]]  ## g10 g3 g4 g2 g9 g6 g7 g1 g5 g8 ## 3 3 3 2 2 5 5 1 4 4  Heatmaps With heatmap.2 All in one step: clustering and heatmap plotting\nlibrary(gplots) heatmap.2(y, col=redgreen(75))  With pheatmap All in one step: clustering and heatmap plotting\nlibrary(pheatmap); library(\"RColorBrewer\") pheatmap(y, color=brewer.pal(9,\"Blues\"))  Customizing heatmaps Customizes row and column clustering and shows tree cutting result in row color bar. Additional color schemes can be found here.\nhc \u003c- hclust(as.dist(1-cor(y, method=\"spearman\")), method=\"complete\") mycol \u003c- colorpanel(40, \"darkblue\", \"yellow\", \"white\") heatmap.2(y, Rowv=as.dendrogram(hr), Colv=as.dendrogram(hc), col=mycol, scale=\"row\", density.info=\"none\", trace=\"none\", RowSideColors=as.character(mycl))  K-Means Clustering with PAM Runs K-means clustering with PAM (partitioning around medoids) algorithm and shows result in color bar of hierarchical clustering result from before.\nlibrary(cluster) pamy \u003c- pam(d, 4) (kmcol \u003c- pamy$clustering)  ## g1 g2 g3 g4 g5 g6 g7 g8 g9 g10 ## 1 2 3 3 4 4 4 4 2 3  heatmap.2(y, Rowv=as.dendrogram(hr), Colv=as.dendrogram(hc), col=mycol, scale=\"row\", density.info=\"none\", trace=\"none\", RowSideColors=as.character(kmcol))  K-Means Fuzzy Clustering Performs k-means fuzzy clustering\nlibrary(cluster) fannyy \u003c- fanny(d, k=4, memb.exp = 1.5) round(fannyy$membership, 2)[1:4,]  ## [,1] [,2] [,3] [,4] ## g1 1.00 0.00 0.00 0.00 ## g2 0.00 0.99 0.00 0.00 ## g3 0.02 0.01 0.95 0.03 ## g4 0.00 0.00 0.99 0.01  fannyy$clustering  ## g1 g2 g3 g4 g5 g6 g7 g8 g9 g10 ## 1 2 3 3 4 4 4 4 2 3  ## Returns multiple cluster memberships for coefficient above a certain ## value (here \u003e0.1) fannyyMA \u003c- round(fannyy$membership, 2) \u003e 0.10 apply(fannyyMA, 1, function(x) paste(which(x), collapse=\"_\"))  ## g1 g2 g3 g4 g5 g6 g7 g8 g9 g10 ## \"1\" \"2\" \"3\" \"3\" \"4\" \"4\" \"4\" \"2_4\" \"2\" \"3\"  Multidimensional Scaling (MDS) Performs MDS analysis on the geographic distances between European cities\nloc \u003c- cmdscale(eurodist) ## Plots the MDS results in 2D plot. The minus is required in this example to ## flip the plotting orientation. plot(loc[,1], -loc[,2], type=\"n\", xlab=\"\", ylab=\"\", main=\"cmdscale(eurodist)\") text(loc[,1], -loc[,2], rownames(loc), cex=0.8)  Principal Component Analysis (PCA) Performs PCA analysis after scaling the data. It returns a list with class prcomp that contains five components: (1) the standard deviations (sdev) of the principal components, (2) the matrix of eigenvectors (rotation), (3) the principal component data (x), (4) the centering (center) and (5) scaling (scale) used.\nlibrary(scatterplot3d) pca \u003c- prcomp(y, scale=TRUE) names(pca)  ## [1] \"sdev\" \"rotation\" \"center\" \"scale\" \"x\"  summary(pca) # Prints variance summary for all principal components.  ## Importance of components: ## PC1 PC2 PC3 PC4 PC5 ## Standard deviation 1.3611 1.1777 1.0420 0.69264 0.4416 ## Proportion of Variance 0.3705 0.2774 0.2172 0.09595 0.0390 ## Cumulative Proportion 0.3705 0.6479 0.8650 0.96100 1.0000  scatterplot3d(pca$x[,1:3], pch=20, color=\"blue\")  Additional Exercises See here\nVersion Information sessionInfo()  ## R version 4.0.5 (2021-03-31) ## Platform: x86_64-pc-linux-gnu (64-bit) ## Running under: Debian GNU/Linux 10 (buster) ## ## Matrix products: default ## BLAS: /usr/lib/x86_64-linux-gnu/blas/libblas.so.3.8.0 ## LAPACK: /usr/lib/x86_64-linux-gnu/lapack/liblapack.so.3.8.0 ## ## locale: ## [1] LC_CTYPE=en_US.UTF-8 LC_NUMERIC=C LC_TIME=en_US.UTF-8 ## [4] LC_COLLATE=en_US.UTF-8 LC_MONETARY=en_US.UTF-8 LC_MESSAGES=en_US.UTF-8 ## [7] LC_PAPER=en_US.UTF-8 LC_NAME=C LC_ADDRESS=C ## [10] LC_TELEPHONE=C LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C ## ## attached base packages: ## [1] stats graphics grDevices utils datasets methods base ## ## other attached packages: ## [1] scatterplot3d_0.3-41 RColorBrewer_1.1-2 pheatmap_1.0.12 cluster_2.1.1 ## [5] gplots_3.1.1 ape_5.4-1 ggplot2_3.3.2 BiocStyle_2.18.0 ## ## loaded via a namespace (and not attached): ## [1] Rcpp_1.0.5 bslib_0.2.4 compiler_4.0.5 pillar_1.4.7 ## [5] BiocManager_1.30.10 jquerylib_0.1.3 bitops_1.0-6 tools_4.0.5 ## [9] digest_0.6.27 nlme_3.1-149 lattice_0.20-41 jsonlite_1.7.1 ## [13] evaluate_0.14 lifecycle_0.2.0 tibble_3.0.4 gtable_0.3.0 ## [17] pkgconfig_2.0.3 rlang_0.4.8 parallel_4.0.5 yaml_2.2.1 ## [21] blogdown_1.2 xfun_0.22 withr_2.3.0 stringr_1.4.0 ## [25] dplyr_1.0.2 knitr_1.30 caTools_1.18.1 gtools_3.8.2 ## [29] generics_0.1.0 sass_0.3.1 vctrs_0.3.5 grid_4.0.5 ## [33] tidyselect_1.1.0 glue_1.4.2 R6_2.5.0 rmarkdown_2.7 ## [37] bookdown_0.21 purrr_0.3.4 magrittr_2.0.1 codetools_0.2-18 ## [41] scales_1.1.1 htmltools_0.5.1.1 ellipsis_0.3.1 colorspace_2.0-0 ## [45] KernSmooth_2.23-18 stringi_1.5.3 munsell_0.5.0 crayon_1.3.4  References Hathaway, R J, J C Bezdek, and N R Pal. 1996. “Sequential Competitive Learning and the Fuzzy c-Means Clustering Algorithms.” Neural Netw. 9 (5): 787–96. http://www.hubmed.org/display.cgi?uids=12662563.\n  ","categories":"","description":"","excerpt":"document.addEventListener(\"DOMContentLoaded\", function() { …","ref":"/tutorials/rclustering/rclustering/","tags":"","title":"Cluster Analysis in R"},{"body":"document.addEventListener(\"DOMContentLoaded\", function() { document.querySelector(\"h1\").className = \"title\"; });  document.addEventListener(\"DOMContentLoaded\", function() { var links = document.links; for (var i = 0, linksLength = links.length; i Source code downloads: [ .Rmd ] [ .R ]\n Overview Graphics in R  Powerful environment for visualizing scientific data Integrated graphics and statistics infrastructure Publication quality graphics Fully programmable Highly reproducible Full LaTeX, Sweave, knitr and R Markdown support. Vast number of R packages with graphics utilities  Documentation on Graphics in R  General  Graphics Task Page R Graph Gallery R Graphical Manual Paul Murrell’s book R (Grid) Graphics   Interactive graphics  rggobi (GGobi) iplots Open GL (rgl)    Graphics Environments  Viewing and savings graphics in R  On-screen graphics postscript, pdf, svg jpeg/png/wmf/tiff/…   Four major graphics environments  Low-level infrastructure  R Base Graphics (low- and high-level) grid: Manual, Book   High-level infrastructure  lattice: Manual, Intro, Book ggplot2: Manual, Intro, Book      Base Graphics Overview  Important high-level plotting functions  plot: generic x-y plotting barplot: bar plots boxplot: box-and-whisker plot hist: histograms pie: pie charts dotchart: cleveland dot plots image, heatmap, contour, persp: functions to generate image-like plots qqnorm, qqline, qqplot: distribution comparison plots pairs, coplot: display of multivariant data   Help on these functions  ?myfct ?plot ?par    Preferred Input Data Objects  Matrices and data frames Vectors Named vectors  Scatter Plots Basic scatter plots Sample data set for subsequent plots\nset.seed(1410) y \u003c- matrix(runif(30), ncol=3, dimnames=list(letters[1:10], LETTERS[1:3])) plot(y[,1], y[,2])  All pairs pairs(y)  Plot labels plot(y[,1], y[,2], pch=20, col=\"red\", main=\"Symbols and Labels\") text(y[,1]+0.03, y[,2], rownames(y))  More examples Print instead of symbols the row names\nplot(y[,1], y[,2], type=\"n\", main=\"Plot of Labels\") text(y[,1], y[,2], rownames(y))  Usage of important plotting parameters\ngrid(5, 5, lwd = 2) op \u003c- par(mar=c(8,8,8,8), bg=\"lightblue\") plot(y[,1], y[,2], type=\"p\", col=\"red\", cex.lab=1.2, cex.axis=1.2, cex.main=1.2, cex.sub=1, lwd=4, pch=20, xlab=\"x label\", ylab=\"y label\", main=\"My Main\", sub=\"My Sub\") par(op)  Important arguments}\n mar: specifies the margin sizes around the plotting area in order: c(bottom, left, top, right) col: color of symbols pch: type of symbols, samples: example(points) lwd: size of symbols cex.*: control font sizes For details see ?par  Add a regression line to a plot\nplot(y[,1], y[,2]) myline \u003c- lm(y[,2]~y[,1]); abline(myline, lwd=2)  summary(myline)  ## ## Call: ## lm(formula = y[, 2] ~ y[, 1]) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.40357 -0.17912 -0.04299 0.22147 0.46623 ## ## Coefficients: ## Estimate Std. Error t value Pr(\u003e|t|) ## (Intercept) 0.5764 0.2110 2.732 0.0258 * ## y[, 1] -0.3647 0.3959 -0.921 0.3839 ## --- ## Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ## ## Residual standard error: 0.3095 on 8 degrees of freedom ## Multiple R-squared: 0.09589, Adjusted R-squared: -0.01712 ## F-statistic: 0.8485 on 1 and 8 DF, p-value: 0.3839  Same plot as above, but on log scale\nplot(y[,1], y[,2], log=\"xy\")  Add a mathematical expression to a plot\nplot(y[,1], y[,2]); text(y[1,1], y[1,2], expression(sum(frac(1,sqrt(x^2*pi)))), cex=1.3)  Exercise 1  Task 1: Generate scatter plot for first two columns in iris data frame and color dots by its Species column. Task 2: Use the xlim/ylim arguments to set limits on the x- and y-axes so that all data points are restricted to the left bottom quadrant of the plot.  Structure of iris data set:\nclass(iris)  ## [1] \"data.frame\"  iris[1:4,]  ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 1 5.1 3.5 1.4 0.2 setosa ## 2 4.9 3.0 1.4 0.2 setosa ## 3 4.7 3.2 1.3 0.2 setosa ## 4 4.6 3.1 1.5 0.2 setosa  table(iris$Species)  ## ## setosa versicolor virginica ## 50 50 50  Line Plots Single Data Set plot(y[,1], type=\"l\", lwd=2, col=\"blue\")  Many Data Sets Plots line graph for all columns in data frame y. The split.screen function is used in this example in a for loop to overlay several line graphs in the same plot.\nsplit.screen(c(1,1))  ## [1] 1  plot(y[,1], ylim=c(0,1), xlab=\"Measurement\", ylab=\"Intensity\", type=\"l\", lwd=2, col=1) for(i in 2:length(y[1,])) { screen(1, new=FALSE) plot(y[,i], ylim=c(0,1), type=\"l\", lwd=2, col=i, xaxt=\"n\", yaxt=\"n\", ylab=\"\", xlab=\"\", main=\"\", bty=\"n\") }  close.screen(all=TRUE)  Bar Plots Basics barplot(y[1:4,], ylim=c(0, max(y[1:4,])+0.3), beside=TRUE, legend=letters[1:4]) text(labels=round(as.vector(as.matrix(y[1:4,])),2), x=seq(1.5, 13, by=1) +sort(rep(c(0,1,2), 4)), y=as.vector(as.matrix(y[1:4,]))+0.04)  Error bars bar \u003c- barplot(m \u003c- rowMeans(y) * 10, ylim=c(0, 10)) stdev \u003c- sd(t(y)) arrows(bar, m, bar, m + stdev, length=0.15, angle = 90)  Mirrored bar plot df \u003c- data.frame(group = rep(c(\"Above\", \"Below\"), each=10), x = rep(1:10, 2), y = c(runif(10, 0, 1), runif(10, -1, 0))) plot(c(0,12),range(df$y),type = \"n\") barplot(height = df$y[df$group == \"Above\"], add = TRUE,axes = FALSE) barplot(height = df$y[df$group == \"Below\"], add = TRUE,axes = FALSE)  Histograms hist(y, freq=TRUE, breaks=10)  Density Plots} plot(density(y), col=\"red\")  Pie Charts pie(y[,1], col=rainbow(length(y[,1]), start=0.1, end=0.8), clockwise=TRUE) legend(\"topright\", legend=row.names(y), cex=1.3, bty=\"n\", pch=15, pt.cex=1.8, col=rainbow(length(y[,1]), start=0.1, end=0.8), ncol=1)  Color Selection Utilities Default color palette and how to change it\npalette()  ## [1] \"black\" \"#DF536B\" \"#61D04F\" \"#2297E6\" \"#28E2E5\" \"#CD0BBC\" \"#F5C710\" \"gray62\"  palette(rainbow(5, start=0.1, end=0.2)) palette()  ## [1] \"#FF9900\" \"#FFBF00\" \"#FFE600\" \"#F2FF00\" \"#CCFF00\"  palette(\"default\")  The gray function allows to select any type of gray shades by providing values from 0 to 1\ngray(seq(0.1, 1, by= 0.2))  ## [1] \"#1A1A1A\" \"#4D4D4D\" \"#808080\" \"#B3B3B3\" \"#E6E6E6\"  Color gradients with colorpanel function from gplots library\nlibrary(gplots) colorpanel(5, \"darkblue\", \"yellow\", \"white\")  Much more on colors in R see Earl Glynn’s color chart\nArranging Several Plots on Single Page With par(mfrow=c(nrow,ncol)) one can define how several plots are arranged next to each other.\npar(mfrow=c(2,3)); for(i in 1:6) { plot(1:10) }  Arranging Plots with Variable Width The layout function allows to divide the plotting device into variable numbers of rows and columns with the column-widths and the row-heights specified in the respective arguments.\nnf \u003c- layout(matrix(c(1,2,3,3), 2, 2, byrow=TRUE), c(3,7), c(5,5), respect=TRUE) # layout.show(nf) for(i in 1:3) { barplot(1:10) }  Saving Graphics to Files After the pdf() command all graphs are redirected to file test.pdf. Works for all common formats similarly: jpeg, png, ps, tiff, …\npdf(\"test.pdf\"); plot(1:10, 1:10); dev.off()  Generates Scalable Vector Graphics (SVG) files that can be edited in vector graphics programs, such as InkScape.\nsvg(\"test.svg\"); plot(1:10, 1:10); dev.off()  Exercise 2 Bar plots\n Task 1: Calculate the mean values for the Species components of the first four columns in the iris data set. Organize the results in a matrix where the row names are the unique values from the iris Species column and the column names are the same as in the first four iris columns. Task 2: Generate two bar plots: one with stacked bars and one with horizontally arranged bars.  Structure of iris data set:\nclass(iris)  ## [1] \"data.frame\"  iris[1:4,]  ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 1 5.1 3.5 1.4 0.2 setosa ## 2 4.9 3.0 1.4 0.2 setosa ## 3 4.7 3.2 1.3 0.2 setosa ## 4 4.6 3.1 1.5 0.2 setosa  table(iris$Species)  ## ## setosa versicolor virginica ## 50 50 50  Grid Graphics  What is grid?  Low-level graphics system Highly flexible and controllable system Does not provide high-level functions Intended as development environment for custom plotting functions Pre-installed on new R distributions   Documentation and Help  Manual Book    lattice Graphics  What is lattice?  High-level graphics system Developed by Deepayan Sarkar Implements Trellis graphics system from S-Plus Simplifies high-level plotting tasks: arranging complex graphical features Syntax similar to R’s base graphics   Documentation and Help  Manual Intro Book    Open a list of all functions available in the lattice package\nlibrary(help=lattice)  Accessing and changing global parameters:\n?lattice.options ?trellis.device  Scatter Plot Sample library(lattice) p1 \u003c- xyplot(1:8 ~ 1:8 | rep(LETTERS[1:4], each=2), as.table=TRUE) plot(p1)  Line Plot Sample library(lattice) p2 \u003c- parallelplot(~iris[1:4] | Species, iris, horizontal.axis = FALSE, layout = c(1, 3, 1)) plot(p2)  ggplot2 Graphics  What is ggplot2?  High-level graphics system developed by Hadley Wickham Implements grammar of graphics from Leland Wilkinson Streamlines many graphics workflows for complex plots Syntax centered around main ggplot function Simpler qplot function provides many shortcuts   Documentation and Help  Manual Intro Book Cookbook for R    ggplot2 Usage  ggplot function accepts two arguments  Data set to be plotted Aesthetic mappings provided by aes function   Additional parameters such as geometric objects (e.g. points, lines, bars) are passed on by appending them with + as separator. List of available geom_* functions see here Settings of plotting theme can be accessed with the command theme_get() and its settings can be changed with theme(). Preferred input data object  qplot: data.frame or tibble (support for vector, matrix, ...) ggplot: data.frame or tibble   Packages with convenience utilities to create expected inputs  plyr reshape    qplot Function The syntax of qplot is similar as R’s basic plot function\n Arguments  x: x-coordinates (e.g. col1) y: y-coordinates (e.g. col2) data: data.frame or tibble with corresponding column names xlim, ylim: e.g. xlim=c(0,10) log: e.g. log=\"x\" or log=\"xy\" main: main title; see ?plotmath for mathematical formula xlab, ylab: labels for the x- and y-axes color, shape, size ...: many arguments accepted by plot function    qplot: scatter plot basics Create sample data\nlibrary(ggplot2) x \u003c- sample(1:10, 10); y \u003c- sample(1:10, 10); cat \u003c- rep(c(\"A\", \"B\"), 5)  Simple scatter plot\nqplot(x, y, geom=\"point\")  Prints dots with different sizes and colors\nqplot(x, y, geom=\"point\", size=x, color=cat, main=\"Dot Size and Color Relative to Some Values\")  Drops legend\nqplot(x, y, geom=\"point\", size=x, color=cat) + theme(legend.position = \"none\")  Plot different shapes\nqplot(x, y, geom=\"point\", size=5, shape=cat)  Colored groups p \u003c- qplot(x, y, geom=\"point\", size=x, color=cat, main=\"Dot Size and Color Relative to Some Values\") + theme(legend.position = \"none\") print(p)  Regression line set.seed(1410) dsmall \u003c- diamonds[sample(nrow(diamonds), 1000), ] p \u003c- qplot(carat, price, data = dsmall) + geom_smooth(method=\"lm\") print(p)  Local regression curve (loess) p \u003c- qplot(carat, price, data=dsmall, geom=c(\"point\", \"smooth\")) print(p) # Setting se=FALSE removes error shade  ggplot Function  More important than qplot to access full functionality of ggplot2 Main arguments  data set, usually a data.frame or tibble aesthetic mappings provided by aes function   General ggplot syntax  ggplot(data, aes(...)) + geom() + ... + stat() + ...   Layer specifications  geom(mapping, data, ..., geom, position) stat(mapping, data, ..., stat, position)   Additional components  scales coordinates facet   aes() mappings can be passed on to all components (ggplot, geom, etc.). Effects are global when passed on to ggplot() and local for other components.  x, y color: grouping vector (factor) group: grouping vector (factor)    Changing Plotting Themes in ggplot  Theme settings can be accessed with theme_get() Their settings can be changed with theme()  Example how to change background color to white\n... + theme(panel.background=element_rect(fill = \"white\", colour = \"black\"))  Storing ggplot Specifications Plots and layers can be stored in variables\np \u003c- ggplot(dsmall, aes(carat, price)) + geom_point() p # or print(p)  Returns information about data and aesthetic mappings followed by each layer\nsummary(p)  Print dots with different sizes and colors\nbestfit \u003c- geom_smooth(method = \"lm\", se = F, color = alpha(\"steelblue\", 0.5), size = 2) p + bestfit # Plot with custom regression line  Syntax to pass on other data sets\np %+% diamonds[sample(nrow(diamonds), 100),]  Saves plot stored in variable p to file\nggsave(p, file=\"myplot.pdf\")  ggplot: scatter plots Basic example set.seed(1410) dsmall \u003c- as.data.frame(diamonds[sample(nrow(diamonds), 1000), ]) p \u003c- ggplot(dsmall, aes(carat, price, color=color)) + geom_point(size=4) print(p)  Regression line p \u003c- ggplot(dsmall, aes(carat, price)) + geom_point() + geom_smooth(method=\"lm\", se=FALSE) + theme(panel.background=element_rect(fill = \"white\", colour = \"black\")) print(p)  Several regression lines p \u003c- ggplot(dsmall, aes(carat, price, group=color)) + geom_point(aes(color=color), size=2) + geom_smooth(aes(color=color), method = \"lm\", se=FALSE) print(p)  Local regression curve (loess) p \u003c- ggplot(dsmall, aes(carat, price)) + geom_point() + geom_smooth() print(p) # Setting se=FALSE removes error shade  ggplot: line plot p \u003c- ggplot(iris, aes(Petal.Length, Petal.Width, group=Species, color=Species)) + geom_line() print(p)  Faceting p \u003c- ggplot(iris, aes(Sepal.Length, Sepal.Width)) + geom_line(aes(color=Species), size=1) + facet_wrap(~Species, ncol=1) print(p)  Exercise 3 Scatter plots with ggplot2\n Task 1: Generate scatter plot for first two columns in iris data frame and color dots by its Species column. Task 2: Use the xlim and ylim arguments to set limits on the x- and y-axes so that all data points are restricted to the left bottom quadrant of the plot. Task 3: Generate corresponding line plot with faceting show individual data sets in saparate plots.  Structure of iris data set\nclass(iris)  ## [1] \"data.frame\"  iris[1:4,]  ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 1 5.1 3.5 1.4 0.2 setosa ## 2 4.9 3.0 1.4 0.2 setosa ## 3 4.7 3.2 1.3 0.2 setosa ## 4 4.6 3.1 1.5 0.2 setosa  table(iris$Species)  ## ## setosa versicolor virginica ## 50 50 50  Bar Plots Sample Set: the following transforms the iris data set into a ggplot2-friendly format.\nCalculate mean values for aggregates given by Species column in iris data set\niris_mean \u003c- aggregate(iris[,1:4], by=list(Species=iris$Species), FUN=mean)  Calculate standard deviations for aggregates given by Species column in iris data set\niris_sd \u003c- aggregate(iris[,1:4], by=list(Species=iris$Species), FUN=sd)  Reformat iris_mean with melt\nlibrary(reshape2) # Defines melt function df_mean \u003c- melt(iris_mean, id.vars=c(\"Species\"), variable.name = \"Samples\", value.name=\"Values\")  Reformat iris_sd with melt\ndf_sd \u003c- melt(iris_sd, id.vars=c(\"Species\"), variable.name = \"Samples\", value.name=\"Values\")  Define standard deviation limits\nlimits \u003c- aes(ymax = df_mean[,\"Values\"] + df_sd[,\"Values\"], ymin=df_mean[,\"Values\"] - df_sd[,\"Values\"])  Verical orientation p \u003c- ggplot(df_mean, aes(Samples, Values, fill = Species)) + geom_bar(position=\"dodge\", stat=\"identity\") print(p)  To enforce that the bars are plotted in the order specified in the input data, one can instruct ggplot to do so by turning the corresponding column (here Species) into an ordered factor as follows.\ndf_mean$Species \u003c- factor(df_mean$Species, levels=unique(df_mean$Species), ordered=TRUE)  In the above example this is not necessary since ggplot uses this order already.\nHorizontal orientation p \u003c- ggplot(df_mean, aes(Samples, Values, fill = Species)) + geom_bar(position=\"dodge\", stat=\"identity\") + coord_flip() + theme(axis.text.y=element_text(angle=0, hjust=1)) print(p)  Faceting p \u003c- ggplot(df_mean, aes(Samples, Values)) + geom_bar(aes(fill = Species), stat=\"identity\") + facet_wrap(~Species, ncol=1) print(p)  Error bars p \u003c- ggplot(df_mean, aes(Samples, Values, fill = Species)) + geom_bar(position=\"dodge\", stat=\"identity\") + geom_errorbar(limits, position=\"dodge\") print(p)  Mirrored df \u003c- data.frame(group = rep(c(\"Above\", \"Below\"), each=10), x = rep(1:10, 2), y = c(runif(10, 0, 1), runif(10, -1, 0))) p \u003c- ggplot(df, aes(x=x, y=y, fill=group)) + geom_bar(stat=\"identity\", position=\"identity\") print(p)  Changing Color Settings library(RColorBrewer) # display.brewer.all() p \u003c- ggplot(df_mean, aes(Samples, Values, fill=Species, color=Species)) + geom_bar(position=\"dodge\", stat=\"identity\") + geom_errorbar(limits, position=\"dodge\") + scale_fill_brewer(palette=\"Blues\") + scale_color_brewer(palette = \"Greys\") print(p)  Using standard colors p \u003c- ggplot(df_mean, aes(Samples, Values, fill=Species, color=Species)) + geom_bar(position=\"dodge\", stat=\"identity\") + geom_errorbar(limits, position=\"dodge\") + scale_fill_manual(values=c(\"red\", \"green3\", \"blue\")) + scale_color_manual(values=c(\"red\", \"green3\", \"blue\")) print(p)  Exercise 4 Bar plots\n Task 1: Calculate the mean values for the Species components of the first four columns in the iris data set. Use the melt function from the reshape2 package to bring the data into the expected format for ggplot. Task 2: Generate two bar plots: one with stacked bars and one with horizontally arranged bars.  Structure of iris data set\nclass(iris)  ## [1] \"data.frame\"  iris[1:4,]  ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 1 5.1 3.5 1.4 0.2 setosa ## 2 4.9 3.0 1.4 0.2 setosa ## 3 4.7 3.2 1.3 0.2 setosa ## 4 4.6 3.1 1.5 0.2 setosa  table(iris$Species)  ## ## setosa versicolor virginica ## 50 50 50  Data reformatting example Here for line plot\ny \u003c- matrix(rnorm(500), 100, 5, dimnames=list(paste(\"g\", 1:100, sep=\"\"), paste(\"Sample\", 1:5, sep=\"\"))) y \u003c- data.frame(Position=1:length(y[,1]), y) y[1:4, ] # First rows of input format expected by melt()  ## Position Sample1 Sample2 Sample3 Sample4 Sample5 ## g1 1 1.5336975 -1.0365027 -2.0276195 -0.4580396 -0.06460952 ## g2 2 -2.0960304 2.1878704 0.7260334 0.8274617 0.24192162 ## g3 3 -0.8233125 0.4250477 0.6526331 -0.4509962 -1.06778801 ## g4 4 1.0961555 0.8101104 -0.3403762 -0.7222191 -0.72737741  df \u003c- melt(y, id.vars=c(\"Position\"), variable.name = \"Samples\", value.name=\"Values\") p \u003c- ggplot(df, aes(Position, Values)) + geom_line(aes(color=Samples)) + facet_wrap(~Samples, ncol=1) print(p)  Same data can be represented in box plot as follows\nggplot(df, aes(Samples, Values, fill=Samples)) + geom_boxplot()  Jitter Plots p \u003c- ggplot(dsmall, aes(color, price/carat)) + geom_jitter(alpha = I(1 / 2), aes(color=color)) print(p)  Box plots p \u003c- ggplot(dsmall, aes(color, price/carat, fill=color)) + geom_boxplot() print(p)  Violin plots p \u003c- ggplot(dsmall, aes(color, price/carat, fill=color)) + geom_violin() print(p)  Density plots Line coloring p \u003c- ggplot(dsmall, aes(carat)) + geom_density(aes(color = color)) print(p)  Area coloring p \u003c- ggplot(dsmall, aes(carat)) + geom_density(aes(fill = color)) print(p)  Histograms p \u003c- ggplot(iris, aes(x=Sepal.Width)) + geom_histogram(aes(y = ..density.., fill = ..count..), binwidth=0.2) + geom_density() print(p)  Pie Chart df \u003c- data.frame(variable=rep(c(\"cat\", \"mouse\", \"dog\", \"bird\", \"fly\")), value=c(1,3,3,4,2)) p \u003c- ggplot(df, aes(x = \"\", y = value, fill = variable)) + geom_bar(width = 1, stat=\"identity\") + coord_polar(\"y\", start=pi / 3) + ggtitle(\"Pie Chart\") print(p)  Wind Rose Pie Chart p \u003c- ggplot(df, aes(x = variable, y = value, fill = variable)) + geom_bar(width = 1, stat=\"identity\") + coord_polar(\"y\", start=pi / 3) + ggtitle(\"Pie Chart\") print(p)  Arranging Graphics on Page Using grid package\nlibrary(grid) a \u003c- ggplot(dsmall, aes(color, price/carat)) + geom_jitter(size=4, alpha = I(1 / 1.5), aes(color=color)) b \u003c- ggplot(dsmall, aes(color, price/carat, color=color)) + geom_boxplot() c \u003c- ggplot(dsmall, aes(color, price/carat, fill=color)) + geom_boxplot() + theme(legend.position = \"none\") grid.newpage() # Open a new page on grid device pushViewport(viewport(layout = grid.layout(2, 2))) # Assign to device viewport with 2 by 2 grid layout print(a, vp = viewport(layout.pos.row = 1, layout.pos.col = 1:2)) print(b, vp = viewport(layout.pos.row = 2, layout.pos.col = 1)) print(c, vp = viewport(layout.pos.row = 2, layout.pos.col = 2, width=0.3, height=0.3, x=0.8, y=0.8))  Using gridExtra package\nlibrary(gridExtra) grid.arrange(a, b, c, nrow = 2, ncol=2)  Inserting Graphics into Plots library(grid) print(a) print(b, vp=viewport(width=0.3, height=0.3, x=0.8, y=0.8))  Specialty Graphics Venn Diagrams library(systemPipeR) setlist5 \u003c- list(A=sample(letters, 18), B=sample(letters, 16), C=sample(letters, 20), D=sample(letters, 22), E=sample(letters, 18)) OLlist5 \u003c- overLapper(setlist=setlist5, sep=\"_\", type=\"vennsets\") vennPlot(OLlist5, mymain=\"\", mysub=\"\", colmode=2, ccol=c(\"blue\", \"red\"))  Compound Structures Plots depictions of small molecules with ChemmineR package\nlibrary(ChemmineR) data(sdfsample) plot(sdfsample[1], print=FALSE)  ROC Plots A variety of libraries are available for plotting receiver operating characteristic (ROC) curves in R:\n ROCR ROC pROC ggplot2  Example Most commonly, in an ROC we plot the true positive rate (y-axis) against the false positive rate (x-axis) at decreasing thresholds. An illustrative example is provided in the ROCR package where one wants to inspect the content of the ROCR.simple object defining the structure of the input data in two vectors.\n# install.packages(\"ROCR\") # Install if necessary on your laptop library(ROCR) data(ROCR.simple) ROCR.simple  ## $predictions ## [1] 0.612547843 0.364270971 0.432136142 0.140291078 0.384895941 0.244415489 0.970641299 ## [8] 0.890172812 0.781781371 0.868751832 0.716680598 0.360168796 0.547983407 0.385240464 ## [15] 0.423739359 0.101699993 0.628095575 0.744769966 0.657732644 0.490119891 0.072369921 ## [22] 0.172741714 0.105722115 0.890078186 0.945548941 0.984667270 0.360180429 0.448687336 ## [29] 0.014823599 0.543533783 0.292368449 0.701561487 0.715459280 0.714985914 0.120604738 ## [36] 0.319672178 0.911723615 0.757325590 0.090988280 0.529402244 0.257402979 0.589909284 ## [43] 0.708412104 0.326672910 0.086546283 0.879459891 0.362693564 0.230157183 0.779771989 ## [50] 0.876086217 0.353281048 0.212014560 0.703293499 0.689075677 0.627012496 0.240911145 ## [57] 0.402801992 0.134794140 0.120473353 0.665444679 0.536339509 0.623494622 0.885179651 ## [64] 0.353777439 0.408939895 0.265686095 0.932159806 0.248500489 0.858876675 0.491735594 ## [71] 0.151350957 0.694457482 0.496513160 0.123504905 0.499788081 0.310718619 0.907651100 ## [78] 0.340078180 0.195097957 0.371936985 0.517308606 0.419560072 0.865639036 0.018527600 ## [85] 0.539086009 0.005422562 0.772728821 0.703885141 0.348213542 0.277656869 0.458674210 ## [92] 0.059045866 0.133257805 0.083685883 0.531958184 0.429650397 0.717845453 0.537091350 ## [99] 0.212404891 0.930846938 0.083048377 0.468610247 0.393378108 0.663367560 0.349540913 ## [106] 0.194398425 0.844415442 0.959417835 0.211378771 0.943432189 0.598162949 0.834803976 ## [113] 0.576836208 0.380396459 0.161874325 0.912325837 0.642933593 0.392173971 0.122284044 ## [120] 0.586857799 0.180631658 0.085993218 0.700501359 0.060413627 0.531464015 0.084254795 ## [127] 0.448484671 0.938583020 0.531006532 0.785213140 0.905121019 0.748438143 0.605235403 ## [134] 0.842974300 0.835981859 0.364288579 0.492596896 0.488179708 0.259278968 0.991096434 ## [141] 0.757364019 0.288258273 0.773336236 0.040906997 0.110241034 0.760726142 0.984599159 ## [148] 0.253271061 0.697235328 0.620501132 0.814586047 0.300973098 0.378092079 0.016694412 ## [155] 0.698826511 0.658692553 0.470206008 0.501489336 0.239143340 0.050999138 0.088450984 ## [162] 0.107031842 0.746588080 0.480100183 0.336592126 0.579511087 0.118555284 0.233160827 ## [169] 0.461150807 0.370549294 0.770178504 0.537336015 0.463227453 0.790240205 0.883431431 ## [176] 0.745110673 0.007746305 0.012653524 0.868331219 0.439399995 0.540221346 0.567043171 ## [183] 0.035815400 0.806543942 0.248707470 0.696702150 0.081439129 0.336315317 0.126480399 ## [190] 0.636728451 0.030235062 0.268138293 0.983494405 0.728536415 0.739554341 0.522384507 ## [197] 0.858970526 0.383807972 0.606960209 0.138387070 ## ## $labels ## [1] 1 1 0 0 0 1 1 1 1 0 1 0 1 0 0 0 1 1 1 0 0 0 0 1 0 1 0 0 1 1 0 1 1 1 0 0 1 1 0 1 0 1 0 1 0 1 0 ## [48] 1 0 1 1 0 1 0 1 0 0 0 0 1 1 1 1 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 1 1 0 0 1 0 0 1 0 ## [95] 1 0 1 1 0 1 0 0 0 1 0 0 1 0 0 1 1 1 0 0 0 1 1 0 0 1 0 0 1 0 1 0 0 1 1 1 1 1 0 1 1 0 0 0 0 1 1 ## [142] 0 1 0 1 0 1 1 1 1 1 0 0 0 1 1 0 1 0 0 0 0 1 0 0 1 0 0 0 0 1 1 0 1 1 1 0 1 1 0 1 1 0 1 0 0 0 1 ## [189] 0 0 0 1 0 1 1 0 1 0 1 0  pred \u003c- prediction(ROCR.simple$predictions, ROCR.simple$labels) perf \u003c- performance( pred, \"tpr\", \"fpr\" ) plot(perf)  Obtain area under the curve (AUC)\nauc \u003c- performance( pred, \"tpr\", \"fpr\", measure = \"auc\") auc@y.values[[1]]  ## [1] 0.8341875  Trees The ape package provides many useful utilities for phylogenetic analysis and tree plotting. Another useful package for plotting trees is ggtree. The following example plots two trees face to face with links to identical leaf labels.\nlibrary(ape) tree1 \u003c- rtree(40) tree2 \u003c- rtree(20) association \u003c- cbind(tree2$tip.label, tree2$tip.label) cophyloplot(tree1, tree2, assoc = association, length.line = 4, space = 28, gap = 3)  Genome Graphics ggbio  What is ggbio?  A programmable genome browser environment   Genome broswer concepts  A genome browser is a visulalization tool for plotting different types of genomic data in separate tracks along chromosomes. The ggbio package (Yin, Cook, and Lawrence 2012) facilitates plotting of complex genome data objects, such as read alignments (SAM/BAM), genomic context/annotation information (gff/txdb), variant calls (VCF/BCF), and more. To easily compare these data sets, it extends the faceting facility of ggplot2 to genome browser-like tracks. Most of the core object types for handling genomic data with R/Bioconductor are supported: GRanges, GAlignments, VCF, etc. For more details, see Table 1.1 of the ggbio vignette here. ggbio’s convenience plotting function is autoplot. For more customizable plots, one can use the generic ggplot function. Apart from the standard ggplot2 plotting components, ggbio defines serval new components useful for genomic data visualization. A detailed list is given in Table 1.2 of the vignette here. Useful web sites: - ggbio manual  ggbio functions autoplot demo      Tracks: aligning plots along chromosomes library(ggbio) df1 \u003c- data.frame(time = 1:100, score = sin((1:100)/20)*10) p1 \u003c- qplot(data = df1, x = time, y = score, geom = \"line\") df2 \u003c- data.frame(time = 30:120, score = sin((30:120)/20)*10, value = rnorm(120-30 +1)) p2 \u003c- ggplot(data = df2, aes(x = time, y = score)) + geom_line() + geom_point(size = 2, aes(color = value)) tracks(time1 = p1, time2 = p2) + xlim(1, 40) + theme_tracks_sunset()  Plotting genomic ranges GRanges objects are essential for storing alignment or annotation ranges in R/Bioconductor. The following creates a sample GRanges object and plots its content.\nlibrary(GenomicRanges) set.seed(1); N \u003c- 100; gr \u003c- GRanges(seqnames = sample(c(\"chr1\", \"chr2\", \"chr3\"), size = N, replace = TRUE), IRanges(start = sample(1:300, size = N, replace = TRUE), width = sample(70:75, size = N,replace = TRUE)), strand = sample(c(\"+\", \"-\"), size = N, replace = TRUE), value = rnorm(N, 10, 3), score = rnorm(N, 100, 30), sample = sample(c(\"Normal\", \"Tumor\"), size = N, replace = TRUE), pair = sample(letters, size = N, replace = TRUE)) autoplot(gr, aes(color = strand, fill = strand), facets = strand ~ seqnames)  Plotting coverage autoplot(gr, aes(color = strand, fill = strand), facets = strand ~ seqnames, stat = \"coverage\")  Mirrored coverage pos \u003c- sapply(coverage(gr[strand(gr)==\"+\"]), as.numeric) pos \u003c- data.frame(Chr=rep(names(pos), sapply(pos, length)), Strand=rep(\"+\", length(unlist(pos))), Position=unlist(sapply(pos, function(x) 1:length(x))), Coverage=as.numeric(unlist(pos))) neg \u003c- sapply(coverage(gr[strand(gr)==\"-\"]), as.numeric) neg \u003c- data.frame(Chr=rep(names(neg), sapply(neg, length)), Strand=rep(\"-\", length(unlist(neg))), Position=unlist(sapply(neg, function(x) 1:length(x))), Coverage=-as.numeric(unlist(neg))) covdf \u003c- rbind(pos, neg) p \u003c- ggplot(covdf, aes(Position, Coverage, fill=Strand)) + geom_bar(stat=\"identity\", position=\"identity\") + facet_wrap(~Chr) p  Circular genome plots ggplot(gr) + layout_circle(aes(fill = seqnames), geom = \"rect\")  More complex circular example\nseqlengths(gr) \u003c- c(400, 500, 700) values(gr)$to.gr \u003c- gr[sample(1:length(gr), size = length(gr))] idx \u003c- sample(1:length(gr), size = 50) gr \u003c- gr[idx] ggplot() + layout_circle(gr, geom = \"ideo\", fill = \"gray70\", radius = 7, trackWidth = 3) + layout_circle(gr, geom = \"bar\", radius = 10, trackWidth = 4, aes(fill = score, y = score)) + layout_circle(gr, geom = \"point\", color = \"red\", radius = 14, trackWidth = 3, grid = TRUE, aes(y = score)) + layout_circle(gr, geom = \"link\", linked.to = \"to.gr\", radius = 6, trackWidth = 1)    Alignments and variants To make the following example work, please download and unpack this data archive containing GFF, BAM and VCF sample files.\nlibrary(rtracklayer); library(GenomicFeatures); library(Rsamtools); library(GenomicAlignments); library(VariantAnnotation) ga \u003c- readGAlignments(\"./data/SRR064167.fastq.bam\", use.names=TRUE, param=ScanBamParam(which=GRanges(\"Chr5\", IRanges(4000, 8000)))) p1 \u003c- autoplot(ga, geom = \"rect\") p2 \u003c- autoplot(ga, geom = \"line\", stat = \"coverage\") vcf \u003c- readVcf(file=\"data/varianttools_gnsap.vcf\", genome=\"ATH1\") p3 \u003c- autoplot(vcf[seqnames(vcf)==\"Chr5\"], type = \"fixed\") + xlim(4000, 8000) + theme(legend.position = \"none\", axis.text.y = element_blank(), axis.ticks.y=element_blank()) txdb \u003c- makeTxDbFromGFF(file=\"./data/TAIR10_GFF3_trunc.gff\", format=\"gff3\") p4 \u003c- autoplot(txdb, which=GRanges(\"Chr5\", IRanges(4000, 8000)), names.expr = \"gene_id\") tracks(Reads=p1, Coverage=p2, Variant=p3, Transcripts=p4, heights = c(0.3, 0.2, 0.1, 0.35)) + ylab(\"\")  Additional examples See autoplot demo here\nAdditional genome graphics  Gviz RCircos (Zhang, Meltzer, and Davis 2013) Genome Graphs genoPlotR  Genome Browser: IGV View genome data in IGV\n Download and open IGV Select in menu in top left corner A. thaliana (TAIR10) Upload the following indexed/sorted Bam files with File -\u003e Load from URL...  http://faculty.ucr.edu/~tgirke/HTML_Presentations/Manuals/Workshop_Dec_6_10_2012/Rrnaseq/results/SRR064154.fastq.bam http://faculty.ucr.edu/~tgirke/HTML_Presentations/Manuals/Workshop_Dec_6_10_2012/Rrnaseq/results/SRR064155.fastq.bam http://faculty.ucr.edu/~tgirke/HTML_Presentations/Manuals/Workshop_Dec_6_10_2012/Rrnaseq/results/SRR064166.fastq.bam http://faculty.ucr.edu/~tgirke/HTML_Presentations/Manuals/Workshop_Dec_6_10_2012/Rrnaseq/results/SRR064167.fastq.bam   To view area of interest, enter its coordinates Chr1:49,457-51,457 in position menu on top.    Create symbolic links For viewing BAM files in IGV as part of systemPipeR workflows.\n systemPipeR: utilities for building NGS analysis pipelines.  library(\"systemPipeR\") symLink2bam(sysargs=args, htmldir=c(\"~/.html/\", \"somedir/\"), urlbase=\"http://myserver.edu/~username/\", urlfile=\"IGVurl.txt\")  Controlling IGV from R Open IGV before running the following routine. Alternatively, open IGV from within R with startIGV(\"lm\") . Note this may not work on all systems.\nlibrary(SRAdb) myurls \u003c- readLines(\"http://biocluster.ucr.edu/~tgirke/Documents/R_BioCond/Samples/bam_urls.txt\") #startIGV(\"lm\") # opens IGV sock \u003c- IGVsocket() session \u003c- IGVsession(files=myurls, sessionFile=\"session.xml\", genome=\"A. thaliana (TAIR10)\") IGVload(sock, session) IGVgoto(sock, 'Chr1:45296-47019')  References Yin, T, D Cook, and M Lawrence. 2012. “Ggbio: An R Package for Extending the Grammar of Graphics for Genomic Data.” Genome Biol. 13 (8). https://doi.org/10.1186/gb-2012-13-8-r77.\n Zhang, H, P Meltzer, and S Davis. 2013. “RCircos: An R Package for Circos 2d Track Plots.” BMC Bioinformatics 14: 244–44. https://doi.org/10.1186/1471-2105-14-244.\n  ","categories":"","description":"","excerpt":"document.addEventListener(\"DOMContentLoaded\", function() { …","ref":"/tutorials/rgraphics/rgraphics/","tags":"","title":"Graphics and Data Visualization in R"},{"body":"","categories":"","description":"","excerpt":"","ref":"/manuals/","tags":"","title":"Manuals"},{"body":"","categories":"","description":"","excerpt":"","ref":"/blog/news/","tags":"","title":"News"},{"body":"\n\n Teaching material will be posted one day before each class meeting.\n [ Download ]\n ","categories":"","description":"","excerpt":"\n\n Teaching material will be posted one day before each class meeting. …","ref":"/slides/slides_01/","tags":"","title":"Course Introduction"},{"body":"\n\n [ Download ]\n","categories":"","description":"","excerpt":"\n\n [ Download ]\n","ref":"/slides/slides_02/","tags":"","title":"Genome Basics"},{"body":"\n\n [ Download ]\n","categories":"","description":"","excerpt":"\n\n [ Download ]\n","ref":"/slides/slides_03/","tags":"","title":"Databases and Software"},{"body":"\n\n [ Download ]\n","categories":"","description":"","excerpt":"\n\n [ Download ]\n","ref":"/slides/slides_04/","tags":"","title":"Sequencing Technologies"},{"body":"\n\n [ Download ]\n","categories":"","description":"","excerpt":"\n\n [ Download ]\n","ref":"/slides/slides_05/","tags":"","title":"Introduction to R"},{"body":"\n\n [ Download ]\n","categories":"","description":"","excerpt":"\n\n [ Download ]\n","ref":"/slides/slides_06/","tags":"","title":"Sequence Alignments and Similarity Searching"},{"body":"\n\n [ Download ]\n","categories":"","description":"","excerpt":"\n\n [ Download ]\n","ref":"/slides/slides_07/","tags":"","title":"Programming in R"},{"body":"\n\n [ Download ]\n","categories":"","description":"","excerpt":"\n\n [ Download ]\n","ref":"/slides/slides_08/","tags":"","title":"Multiple Alignments"},{"body":"\n\n [ Download ]\n","categories":"","description":"","excerpt":"\n\n [ Download ]\n","ref":"/slides/slides_09/","tags":"","title":"Short Read Alignments"},{"body":"\n\n[ View Slides in Separate Browser Tab ]\n  ","categories":"","description":"","excerpt":"\n\n[ View Slides in Separate Browser Tab ]\n  ","ref":"/slides/slides_10/","tags":"","title":"R on HPC Systems"},{"body":"\n\n [ Download ]\n","categories":"","description":"","excerpt":"\n\n [ Download ]\n","ref":"/slides/slides_11/","tags":"","title":"NGS Analysis Basics"},{"body":"\n\n [ Download ]\n","categories":"","description":"","excerpt":"\n\n [ Download ]\n","ref":"/slides/slides_12/","tags":"","title":"Analysis of Gene Expression Data"},{"body":"\n\n [ Download ]\n","categories":"","description":"","excerpt":"\n\n [ Download ]\n","ref":"/slides/slides_13/","tags":"","title":"Introduction to NGS Workflows"},{"body":"\n\n [ Download ]\n","categories":"","description":"","excerpt":"\n\n [ Download ]\n","ref":"/slides/slides_14/","tags":"","title":"ChIP-Seq Overview"},{"body":"\n\nSlide show to be posted.\n[ Download ]\n","categories":"","description":"","excerpt":"\n\nSlide show to be posted.\n[ Download ]\n","ref":"/slides/slides_15/","tags":"","title":"Gene Set Enrichment Analysis"},{"body":"\n\nSlide show to be posted.\n[ Download ]\n","categories":"","description":"","excerpt":"\n\nSlide show to be posted.\n[ Download ]\n","ref":"/slides/slides_16/","tags":"","title":"Cluster Analysis"},{"body":"\n\nSlide show to be posted.\n[ Download ]\n","categories":"","description":"","excerpt":"\n\nSlide show to be posted.\n[ Download ]\n","ref":"/slides/slides_17/","tags":"","title":"R packages, tidyverse and dplyr"},{"body":"\n\nSlide show to be posted.\n[ Download ]\n","categories":"","description":"","excerpt":"\n\nSlide show to be posted.\n[ Download ]\n","ref":"/slides/slides_18/","tags":"","title":"Shiny Apps"},{"body":"\n\nSlide show to be posted.\n[ Download ]\n","categories":"","description":"","excerpt":"\n\nSlide show to be posted.\n[ Download ]\n","ref":"/slides/slides_19/","tags":"","title":"Profile HMMs"},{"body":"\n\nSlide show to be posted.\n[ Download ]\n","categories":"","description":"","excerpt":"\n\nSlide show to be posted.\n[ Download ]\n","ref":"/slides/slides_20/","tags":"","title":"Assembly of Genomes and Transcriptomes"},{"body":"The homework assignments will be posted in this section.\n","categories":"","description":"","excerpt":"The homework assignments will be posted in this section.\n","ref":"/assignments/homework/","tags":"","title":"Homework Assignments"},{"body":"A. Online Excercise: Databases and Software Tools This is an easy warm-up homework exposing students to a variety of online databases and software tools.\n Go to http://www.ncbi.nlm.nih.gov, select Protein database in dropdown, and then run query: P450 \u0026 hydroxylase \u0026 human [organism], select under Source databases UniProtKB/Swiss-Prot  Report final query syntax from Search Details field.    \nSave GIs of the final query result to a file. For this select under Send to dropdown GI List format.  Report the number of retrieved GIs.    \nRetrieve the corresponding sequences through Batch-Entrez using GI list file as query input -\u003e save sequences in FASTA format  \nGenerate multiple alignment and tree of these sequences using MultAalin  Save multiple alignment and tree to file Identify putative heme binding cysteine in multiple alignment    \nOpen corresponding UniProt page and search for first P450 sequence in your list.  Compare putative heme binding cysteine with consensus pattern from Prosite database (Syntax) Report corresponding Pfam ID    \nBLASTP against PDF database (use again first P450 in your list); on result page click first entry in BLAST hit list (here 3K9V_A); then select ‘Identify Conserved Domains’ on side bar; click blue bar labelled ‘CYP24A1’; then select ‘Interactive View’ which will download ‘cd20645.cn3’ file.  Compare resulting alignment with result from MultAlin View 3D structure in Cn3D*, save structure (screen shot) and highlight heme binding cysteine. Note, Cn3D* can be downloaded from here.    *If there are problems in the last step (6.2) with the install of Cn3D, then please use this online only alternative: (i) click in the 3K9V_A page ‘Protein 3D Structure’ instead of ‘Identify Conserved Domains’; (ii) choose one of the two structure entries provided on the subsequent page; (iii) select option “full-featured 3D viewer” in the bottom right corner of the structure image; (iv) choose the ‘Details’ tab on the right; (v) after this the structure of the protein is shown on the left and the underlying protein sequence on the right; (vi) highlight the heme binding cysteine in the structure by selecting it in the sequence; and (vii) then save the structure view to a PNG file or take a screenshot.\nB. Homework Submission to a Private GitHub Repository To learn the basics of GitHub, this homework assignment will be uploaded to a private GitHub respository that will be shared with the instructors. To do so, follow these steps: In this homework, you are asked to create a github private repository.\n Login to your GitHub account. Click the “New” button in the sidebar on the left. Under “Repository name”, use “learn-github” as the name. Choose “Private”. Choose to add a README file (optional). Click “Create repository”. You should redirected to your new repo’s page. In the new page, click “Settings”. Click “Manage access”, and the choose “Invite a collaborator”. Invite both “tgirke” and “lz100” and send out the invitation.   Note, the creator of this demo cannot search for an invitation created by the same user (here lz100). Thus, the message ‘could not find lz100’ at the end of the video. This will not be the case for students in the class.\nPlease assemble the results of part A of HW1 in one PDF file named hw1.pdf and upload it to your private GitHub repository generated in part B. To do so, follow the upload instructions here.\nC. Homework Submission via GitHub Classroom To also submit your homework to GitHub Classroom click this link to accept the homework. This will create a private homework repository in GitHub Classroom for you. Note: this new repository is different from the repository in part A. It belongs to the GEN242-2021 Github classroom that will be used for all subsequent homework submissions.\nDue date Most homework will be due one week after they are assigned. This one is due on Thu, April 8th at 6:00 PM. You have unlimited attempts. Students can edit and re-upload files anytime before the deadline.\nHomework solution A solution for this homework is not required since the tasks are identical to the steps described above under sections HW1A-B.\n","categories":"","description":"","excerpt":"A. Online Excercise: Databases and Software Tools This is an easy …","ref":"/assignments/homework/hw01/hw01/","tags":"","title":"HW1 - Online Exercise and Basic GitHub Usage"},{"body":"Topic: Linux Basics   Download code from this page\nwget https://cluster.hpcc.ucr.edu/~tgirke/Linux.sh --no-check-certificate    Download Halobacterium proteome and inspect it\nwget https://ftp.ncbi.nlm.nih.gov/genomes/genbank/archaea/Halobacterium_salinarum/representative/GCA_004799605.1_ASM479960v1/GCA_004799605.1_ASM479960v1_protein.faa.gz gunzip GCA_004799605.1_ASM479960v1_protein.faa.gz mv GCA_004799605.1_ASM479960v1_protein.faa halobacterium.faa less halobacterium.faa # press q to quit    How many protein sequences are stored in the downloaded file?\ngrep '\u003e' halobacterium.faa | wc grep '^\u003e' halobacterium.faa --count    How many proteins contain the pattern WxHxxH or WxHxxHH?\negrep 'W.H..H{1,2}' halobacterium.faa --count    Use less to find IDs for pattern matches or use awk\nawk --posix -v RS='\u003e' '/W.H..(H){1,2}/ { print \"\u003e\" $0;}' halobacterium.faa | less awk --posix -v RS='\u003e' '/W.H..(H){1,2}/ { print \"\u003e\" $0;}' halobacterium.faa | grep '^\u003e' | cut -c 2- | cut -f 1 -d\\ \u003e myIDs    Create a BLASTable database with formatdb\nmodule load ncbi-blast makeblastdb -in halobacterium.faa -out halobacterium.faa -dbtype prot -hash_index -parse_seqids    Query BLASTable database by IDs stored in a file (e.g. myIDs)\nblastdbcmd -db halobacterium.faa -dbtype prot -entry_batch myIDs -get_dups -out myseq.fasta    Run BLAST search for sequences stored in myseq.fasta\nblastp -query myseq.fasta -db halobacterium.faa -outfmt 0 -evalue 1e-6 -out blastp.out blastp -query myseq.fasta -db halobacterium.faa -outfmt 6 -evalue 1e-6 -out blastp.tab    Return system time and host name\ndate hostname    Additional exercise material in Linux Manual\nHomework assignment Perform above analysis on the protein sequences from E. coli. A right click on the link will allow you to copy the URL so that it can be used together with wget. Record result from final BLAST command (with outfmt 6) in text file.\nHomework submission Submit your homework to GEN242-2021 HW2 on GitHub Classroom by following these stepwise instructions:\n Upload your script and name it hw2.sh. Upload the unzipped faa file from step 1, name it ecoli.faa. Upload IDs from step 5 in a file named myIDs. Upload the final file generated with outfmt 6 from step 8, and name it ecoli.txt.  Due date Most homeworks will be due one week after they are assigned. This one is due on Thu, April 8th at 6:00 PM.\nHomework solution See here.\n","categories":"","description":"","excerpt":"Topic: Linux Basics   Download code from this page\nwget …","ref":"/assignments/homework/hw02/hw02/","tags":"","title":"HW2 - Introduction to Biocluster and Linux"},{"body":"A. Object Subsetting, Import and Export  Task 1: Sort the rows of the iris data frame by its first column and sort its columns alphabetically by column names. Task 2: Subset the first 12 rows, export the result to a text file and view it in a spreadsheet program like Excel or Google Sheets. Task 3: Change some column titles in your spreadsheet program, save the result to a tab delimited text file and import it back into R. Note, for this task you only want to include the read.table command in the homework result (here R script).  Before you start it can be helpful to evaluate the structure of the iris data set with the following commands:\nclass(iris) dim(iris) colnames(iris)  B. Scatter Plots  Task 1: Generate a scatter plot for the first two columns of the iris data frame and color the dots by the Species column. Task 2: Use the xlim/ylim arguments to set limits on the x- and y-axes so that all data points are restricted to the bottom left quadrant of the plot.  Again before you start, evaluate the structure of iris data set. The following commands are useful:\niris[1:4,] table(iris$Species)  C. Bar Plots  Task 1: Calculate the mean values for the Species components of the first four columns in the iris data frame. Organize the results in a matrix where the row names are the unique values from the iris Species column and the column names are the names of the first four iris columns. Task 2: Generate two bar plots for the matrix generated in the previous step: one with stacked bars and one with horizontally arranged bars.  D-H. Analysis Worflow The instructions for these homework assignments are here.\nHomework submission Accept the homework on Github Classroom, and follow the instructions in the README.md file.\nDue date This homework is due on Thu, April 15th at 6:00 PM.\nHomework Solutions See here.\n","categories":"","description":"","excerpt":"A. Object Subsetting, Import and Export  Task 1: Sort the rows of the …","ref":"/assignments/homework/hw03/hw03/","tags":"","title":"HW3 - Introduction to R"},{"body":"\n\nA. Choice of Sequence Type  Task 1: Which sequence type - amino acid or nucleotide - is more appropriate to search databases for remotely related sequences? Provide at least three reasons for your decision.  B. Dynamic Programming for Pairwise Alignments  Task 2: Create manually (or write an R script for it) one global and one local alignment for the following two protein sequences using the Needleman-Wusch and Smith-Waterman algorithms, respectively:  O15528: PFGFGKRSCMGRRLA P98187: FIPFSAGPRNCIGQK  Use in each case BLOSUM50 as substitution matrix and 8 as gap extension penalty (no extra penalty for gap opening). Note, here is helper code in R to create the initial matrix programmatically for upload to a spreadsheet program. Alternatively, solve the entire homework by writing an R script. Your answers should contain the following components:\n Manually populated dynamic programming matrices The optimal pairwise alignments created by traceback The final scores of the alignments  C. Alignments with Different Substitution Matrices  Task 1: Load the Biostrings package in R, import the following two cytochrome P450 sequences O15528 and P98187 from NCBI (save as myseq.fasta), and create a global alignment with the pairwiseAlignment function from Biostrings as follows:  library(Biostrings) myseq \u003c- readAAStringSet(\"myseq.fasta\", \"fasta\") (p \u003c- pairwiseAlignment(myseq[[1]], myseq[[2]], type=\"global\", substitutionMatrix=\"BLOSUM50\")) writePairwiseAlignments(p)  Your answers should address the following items:\n Record the scores for the scoring matrices BLOSUM50, BLOSUM62 and BLOSUM80. How and why do the scores differ for the three scoring matrices?  Homework submission Accept the homework on Github Classroom, and follow the instructions in the README.md file.\nDue date This homework is due in two weeks on Thu, April 22 at 6:00 PM.\nHomework Solutions See here.\n","categories":"","description":"","excerpt":"\n\nA. Choice of Sequence Type  Task 1: Which sequence type - amino acid …","ref":"/assignments/homework/hw04/hw04/","tags":"","title":"HW4: Pairwise Alignments"},{"body":"\n\nSource code downloads:   [ .R ]  A. Reverse and complement of DNA Task 1: Write a RevComp function that returns the reverse and complement of a DNA sequence string. Include an argument that will allow to return only (i) the reversed sequence, (ii) the complemented sequence, or (iii) the reversed and complemented sequence. The following R functions will be useful for the implementation:\nGenerate a short test DNA sequence\nx \u003c- c(\"ATGCATTGGACGTTAG\") x  ## [1] \"ATGCATTGGACGTTAG\"  Vectorize sequence\nx \u003c- substring(x, 1:nchar(x), 1:nchar(x)) x  ## [1] \"A\" \"T\" \"G\" \"C\" \"A\" \"T\" \"T\" \"G\" \"G\" \"A\" \"C\" \"G\" \"T\" \"T\" \"A\" \"G\"  Reverse sequence\nx \u003c- rev(x) x  ## [1] \"G\" \"A\" \"T\" \"T\" \"G\" \"C\" \"A\" \"G\" \"G\" \"T\" \"T\" \"A\" \"C\" \"G\" \"T\" \"A\"  Collapse sequence back to character string\nx \u003c- paste(x, collapse=\"\") x  ## [1] \"GATTGCAGGTTACGTA\"  Form complement of sequence\nchartr(\"ATGC\", \"TACG\", x)  ## [1] \"CTAACGTCCAATGCAT\"  Task 2: Write a function that applies the RevComp function to many sequences stored in a vector.\nB. Translate DNA into Protein Task 3: Write a function that will translate one or many DNA sequences in all three reading frames into proteins. The following commands will simplify this task:\nImport lookup table of genetic code\nAAdf \u003c- read.table(file=\"http://faculty.ucr.edu/~tgirke/Documents/R_BioCond/My_R_Scripts/AA.txt\", header=TRUE, sep=\"\\t\") AAdf[1:4,]  ## Codon AA_1 AA_3 AA_Full AntiCodon ## 1 TCA S Ser Serine TGA ## 2 TCG S Ser Serine CGA ## 3 TCC S Ser Serine GGA ## 4 TCT S Ser Serine AGA  Generated named vector of relevant components\nAAv \u003c- as.character(AAdf[,2]) names(AAv) \u003c- AAdf[,1] AAv  ## TCA TCG TCC TCT TTT TTC TTA TTG TAT TAC TAA TAG TGT TGC TGA TGG CTA CTG CTC CTT CCA CCG CCC CCT CAT ## \"S\" \"S\" \"S\" \"S\" \"F\" \"F\" \"L\" \"L\" \"Y\" \"Y\" \"*\" \"*\" \"C\" \"C\" \"*\" \"W\" \"L\" \"L\" \"L\" \"L\" \"P\" \"P\" \"P\" \"P\" \"H\" ## CAC CAA CAG CGA CGG CGC CGT ATT ATC ATA ATG ACA ACG ACC ACT AAT AAC AAA AAG AGT AGC AGA AGG GTA GTG ## \"H\" \"Q\" \"Q\" \"R\" \"R\" \"R\" \"R\" \"I\" \"I\" \"I\" \"M\" \"T\" \"T\" \"T\" \"T\" \"N\" \"N\" \"K\" \"K\" \"S\" \"S\" \"R\" \"R\" \"V\" \"V\" ## GTC GTT GCA GCG GCC GCT GAT GAC GAA GAG GGA GGG GGC GGT ## \"V\" \"V\" \"A\" \"A\" \"A\" \"A\" \"D\" \"D\" \"E\" \"E\" \"G\" \"G\" \"G\" \"G\"  Tripletize sequence and translate by name subsetting/sorting of AAv\ny \u003c- gsub(\"(...)\", \"\\\\1_\", x) y \u003c- unlist(strsplit(y, \"_\")) y \u003c- y[grep(\"^...$\", y)] AAv[y]  ## GAT TGC AGG TTA CGT ## \"D\" \"C\" \"R\" \"L\" \"R\"  Homework submission Accept the homework on Github Classroom, and follow the instructions in the README.md file.\nThe tasks 1-3 of this homework can be summarized as follows: submit the 3 functions in one well structured and annotated R script. The script should include instructions on how to use the functions.\nDue date This homework is due on Thu, April 22 at 6:00 PM.\nHomework Solutions See here.\n","categories":"","description":"","excerpt":"\n\nSource code downloads:   [ .R ]  A. Reverse and complement of DNA …","ref":"/assignments/homework/hw05/hw05/","tags":"","title":"HW5 - Programming in R"},{"body":"\n\nSource code downloads:   [ .R ]  A. Demultiplexing Write a demultiplexing function that accepts any number of barcodes and splits a FASTQ file into as many subfiles as there are barcodes. At the same time the function should remove low quality tails from the reads. The following function accomplishes the first step. Expand this function so that it performs the second step as well. As test data set one can use the FASTQ test files downloaded in the corresponding tutorial section here.\ndemultiplex \u003c- function(x, barcode, nreads) { f \u003c- FastqStreamer(x, nreads) while(length(fq \u003c- yield(f))) { for(i in barcode) { pattern \u003c- paste(\"^\", i, sep=\"\") fqsub \u003c- fq[grepl(pattern, sread(fq))] if(length(fqsub) \u003e 0) { writeFastq(fqsub, paste(x, i, sep=\"_\"), mode=\"a\", compress=FALSE) } } } close(f) } demultiplex(x=fastq[1], barcode=c(\"TT\", \"AA\", \"GG\"), nreads=50)  B. Sequence Parsing  Download GFF from Halobacterium sp here Download genome sequence from Halobacterium sp here Task 1 Extract gene ranges, parse their sequences from genome and translate them into proteins Task 2 Reduce overlapping genes and parse their sequences from genome Task 3 Generate intergenic ranges and parse their sequences from genome  Useful commands\ndownload.file(\"https://ftp.ncbi.nlm.nih.gov/genomes/archive/old_genbank/Bacteria/Halobacterium_sp_uid217/AE004437.gff\", \"data/AE004437.gff\") download.file(\"https://ftp.ncbi.nlm.nih.gov/genomes/archive/old_genbank/Bacteria/Halobacterium_sp_uid217/AE004437.fna\", \"data/AE004437.fna\") chr \u003c- readDNAStringSet(\"data/AE004437.fna\") gff \u003c- import(\"data/AE004437.gff\") gffgene \u003c- gff[values(gff)[,\"type\"]==\"gene\"] gene \u003c- DNAStringSet(Views(chr[[1]], IRanges(start(gffgene), end(gffgene)))) names(gene) \u003c- values(gffgene)[,\"locus_tag\"] pos \u003c- values(gffgene[strand(gffgene) == \"+\"])[,\"locus_tag\"] p1 \u003c- translate(gene[names(gene) %in% pos]) names(p1) \u003c- names(gene[names(gene) %in% pos]) neg \u003c- values(gffgene[strand(gffgene) == \"-\"])[,\"locus_tag\"] p2 \u003c- translate(reverseComplement(gene[names(gene) %in% neg])) names(p2) \u003c- names(gene[names(gene) %in% neg]) writeXStringSet(c(p1, p2), \"./data/mypep.fasta\")  Homework submission Accept the homework on Github Classroom, and follow the instructions in the README.md file.\nPlease submit the homework results in one well structured and annotated R script to GitHub classroom. The script should include instructions on how to use the functions.\nDue date This homework is due on Thu, April 29 at 6:00 PM.\nHomework Solutions See here.\n","categories":"","description":"","excerpt":"\n\nSource code downloads:   [ .R ]  A. Demultiplexing Write a …","ref":"/assignments/homework/hw06/hw06/","tags":"","title":"HW6 - NGS Analysis Basics"},{"body":"\n\nSource code downloads:   [ .R ]  A. Unstranded and strand-specific read counting   Task 1: Rerun the RNA-Seq workflow with the toy data sets up to the read quantification step here. Note, the toy data set gets automatically loaded when intializing a workflow environment (directory structure) with the genWorkenvir function (see tutorial here). In the read quantification step with summarizeOverlaps generate count tables for exons by genes (eByg) of the following three strand modes:\n Unstranded Strand-specific for positive (sense) strand Strand-specific for negative (antisense) strand  The solution for generating the unstranded read counts is given below. Note, the upstream steps of the RNA-Seq workflow only need to be rerun to generate the proper inputs for the read counting. Thus, they are not required to be included in the homework results (see HW7.R below).\n  summarizeOverlaps(eByg, bfl, mode=\"Union\", ignore.strand=TRUE, # preprocess.reads=invertStrand, inter.feature=FALSE, singleEnd=TRUE)  Before attempting to solve this homework task please read the vignette Counting reads with summarizeOverlaps (here) from the GenomicAlignments package that defines the summarizeOverlap function. In addition, the help file for ?summarizeOverlaps provides useful information.\n  Task 2: Provide R code that demonstrates that the two strand-specific count tables sum up to the values of the unstranded count table.\n  Task 3: Explain the utility (biological relevance) of the different strand counting modes used under Task 1. Include your explanation as comment text in your homework script (see HW7.R below).\n  Note, for Tasks 1-3 only the code and/or text needs to be included in the homework submission (no data/result files). For details see below.\nB. Read counting for different feature types   Task 4: Compute strand-specific count tables for the positive (sense) strand of the following feature types. The help files of ?exonsBy and ?transcripts provide useful information for solving these tasks.\n Genes Exons Exons by genes Introns by transcripts 5'-UTRs by transcripts    Note, for Tasks 4 only include the code and/or text in your homework submission (no data/result files). For details see below.\nC. DEG analysis   Task 5: Perform the DEG analysis with edgeR as outlined under section 6 of the RNA-Seq workflow here. Use in one case for the DEG analysis the unstranded count table as input (from Task 1.1) and in another the sense strand count table (from Task 1.2). Compare the DEG result of the two methods in two separate 4-way Venn diagrams for the same sample comparisons used in the workflow example here.\n 4-way Venn diagram for unstranded count table 4-way Venn diagram for sense strand count table    Note, for Tasks 5 include both the code and the resulting images in your homework submission. For deteails see below.\nHomework submission Accept the project repos on Github Classroom\nStarting with this homework, you will use a classroom repository called project. This repository will be used until the end of this class for all remaining homework assignments as well as the course project. You are responsible to maintain this project repository including its README.md file.\n To start with HW7, accept the assignment and git clone to your user account on the HPCC cluster or your local computer. Create a directory “hw7” and upload all your HW7 script and result files to this directory. This includes the following files:  Your script file either as R or R Markdown file, here hw7.R or hw7.Rmd. Two Venn diagram plots: unstranded.png and hw7/sense.png    Auto-grading You will complete most of your HW7 on the HPCC cluster. In this and the following homeworks auto-grading will not be used.\nYour TA will manually check your homework solutions.\nDetails  If you wish then you can submit your homeworks as an R Markdown (Rmd) file. However, an R file will be sufficient. Due to dependencies of large input/result files there is also no need to make sure your code can be sourced with source(). Another option will be to add your homework code to the systemPipeRNAseq.Rmd file used in the corresponding workflow template and rename it to hw7.Rmd when you upload it to GitHub. If possible please use only one of the above format options.  For the graphis files, you can upload them either as .png or .jpg (.jpeg) files.\nGrading  Task1  Unstranded: 1 Positive: 1 Negative: 1   Task2: 1 Task3: 1 Task4  Genes: 0.5 Exons: 0.5 Exons by genes: 0.5 Introns by transcripts: 0.5 5'-UTRs by transcripts: 0.5   Task5  DEG: 1 Venn1: 1 Venn2: 1    Total: 10.5\nDue date This homework is due in one week on Thu, May 6th at 6:00 PM.\nHomework Solutions Will be posted after due date.\n","categories":"","description":"","excerpt":"\n\nSource code downloads:   [ .R ]  A. Unstranded and strand-specific …","ref":"/assignments/homework/hw07/hw07/","tags":"","title":"HW7 - RNA-Seq Analysis"},{"body":"\n\nRender R Markdown (Rmd) of your project Students will choose for this assignment the Rmd template of the workflow they are expected to complete for their challenge project, meaning either the RNA-Seq or the ChIP-Seq workflow that were both covered in class.\nTo get started with the following homework tasks, log in to your HPCC account and create under the course project path /bigdata/gen242/\u003cuser_name\u003e assigned to you the corresponding workflow template using the genWorkenvir function. Open with vim/nvim the Rmd file located in the root directory of the chosen workflow. Next make the following changes (1.-8.) to the R Markdown file, render it to HTML and PDF format, and then submit the rendered report along with the corresponding Rmd source file to GitHub Classroom as instructed below. The changes to include in the R Markdown are:\nTasks\nRead the basics of Rmarkdown formatting.\n In the section relating to your challenge project, add a short paragraph describing the analysis steps you have chosen to perform as part of your challenge project. In the challenge project section, cite the reference(s) of the paper(s) you have chosen to present in class as part of your course project. For this add the reference in BibTeX format to the bibtex.tex file located in the root directory of the workflow, and then cite it in the text of the Rmd file so that the properly rendered citation shows up in the text and the corresponding reference is get automatically added to the reference list when running rmarkdown::render. Note, references in BibTeX format can be obtained from Google Scholar, Paperpile or most other reference management software. More detailed information about managing references in R Markdown files is here. Add a mathematical equation to the challenge project section. Evaluate an R expression in the text as inline R code (see here) of your challenge project, e.g. mathematical or number from an existing R oject such as mean value of the first column of the iris data.frame. Add a code chunk that auto-generates the barplot for HW3C. This barplot should be embedded in the rendered report without saving it intermediately to a file. Insert the targets file of your workflow as an interactive table using the DT package. An example is given in the table section of the R Markdown manual here. Use the rmarkdown::render() function to render the report (details are here) and PDF format. Important: for this assignment it is not relevant to evaluate the code chunks for the actual analysis steps of the analysis workflow. Only the chunks required for the above tasks need to be evaluated. Submit the Rmd, PDF and HTML file for the report to the corresponding repos on GitHub Classroom (see below).  Homework submission Use your GitHub Classroom repository from the last time, the project repository. Create a directory /hw8 and upload your files in there.\n Your Rmarkdown file, name it hw8.Rmd. HTML rendered file, name it hw8.html. PDF rendered file, name it hw8.pdf.  bibtex file is not required.\nGrading  Upload Rmd: 1 Upload HTML: 1 Upload PDF: 1 Step 1-6: 1 each  Total 9\nDue date This homework is due in one week on Thu, May 13th at 6:00 PM.\nHomework Solutions Will be posted after due date.\n","categories":"","description":"","excerpt":"\n\nRender R Markdown (Rmd) of your project Students will choose for …","ref":"/assignments/homework/hw08/hw08/","tags":"","title":"HW8 - R Markdown Template of Course Project"},{"body":"Projects will be posted here.\n","categories":"","description":"","excerpt":"Projects will be posted here.\n","ref":"/assignments/projects/","tags":"","title":"Projects"},{"body":"\n\nIntroduction During the tutorial sessions of this class all students will perform the basic data analysis of at least two NGS Workflows including RNA-Seq, ChIP-Seq and ATAC-Seq. In addition, every student will work on a Challenge Project addressing a specific data analysis task within one of the general NGS Workflows. Students will also present a scientific paper closely related to their challenge topic (see here). To facilitate teamwork and communication with instructors, each course project will be assigned a private GitHub repository.\nThe results of the Challenge Projects will be presented by each student during the last week of the course (see Slideshow Template here). In addition, each student will write a detailed analysis report for the assigned course project. This report needs to include all analysis steps of the corresponding NGS Workflow (e.g. full RNA-Seq analysis) as well as the code and results of the Challenge Project. The final project reports will be written in R Markdown. A basic tutorial on R Markdown is available here. Both the R Markdown script (.Rmd) along with the rendered HTML or PDF report will be submitted to each student’s private GitHub repository. All helper code used for the challenge project needs to be organized as well documented R functions in each project’s *_Fct.R script. The expected structure of the final project report is outlined below.\nThe reports should be submitted to each student’s private GitHub repository that was used to submit the homework assignments. For the report each student should create in this repository a new directory named ProjectReport and include in it the following files:\n .Rmd source script of project report Report rendered from .Rmd source in HTML or PDF format ._Fct.R file containing all helper functions used for challenge project Submission Deadline for reports: 6:00 PM, June 8th, 2021  Structure of final project report  Abstract Introduction Methods  Short description of methods used by NGS workflow Detailed description of methods used for challenge project   Results and Discussion  Includes all components of NGS workflow as well as challenge project   Conclusions Acknowledgments References Supplement (optional)  ","categories":"","description":"","excerpt":"\n\nIntroduction During the tutorial sessions of this class all students …","ref":"/assignments/projects/project_overview/","tags":"","title":"Overview of Course Projects"},{"body":"\n\nRNA-Seq Workflow  Read quality assessment, filtering and trimming Map reads against reference genome Perform read counting for required ranges (e.g. exonic gene ranges) Normalization of read counts Identification of differentially expressed genes (DEGs) Clustering of gene expression profiles Gene set enrichment analysis  Challenge Project: Comparison of RNA-Seq Aligners  Run workflow from start to finish (steps 1-7) on RNA-Seq data set from Howard et al. (2013) Challenge project tasks  Compare the RNA-Seq aligner HISAT2 with at least 1-2 other aligners, such as Rsubread, Star or Kallisto. Evaluate the impact of the aligner on the downstream analysis results including:  Read counts Differentially expressed genes (DEGs) Generate plots to compare the results efficiently      References  Bray NL, Pimentel H, Melsted P, Pachter L (2016) Near-optimal probabilistic RNA-seq quantification. Nat Biotechnol. doi: 10.1038/nbt.3519 PubMed Howard, B.E. et al., 2013. High-throughput RNA sequencing of pseudomonas-infected Arabidopsis reveals hidden transcriptome complexity and novel splice variants. PloS one, 8(10), p.e74183. PubMed Kim D, Pertea G, Trapnell C, Pimentel H, Kelley R, Salzberg SL (2013) TopHat2: accurate alignment of transcriptomes in the presence of insertions, deletions and gene fusions. Genome Biol. doi: 10.1186/gb-2013-14-4-r36 PubMed Kim D, Langmead B, Salzberg SL (2015) HISAT: a fast spliced aligner with low memory requirements. Nat Methods 12: 357–360 PubMed Liao Y, Smyth GK, Shi W (2013) The Subread aligner: fast, accurate and scalable read mapping by seed-and-vote. Nucleic Acids Res 41: e108 PubMed  ","categories":"","description":"","excerpt":"\n\nRNA-Seq Workflow  Read quality assessment, filtering and trimming …","ref":"/assignments/projects/01_rnaseq_aligners/","tags":"","title":"RNA-Seq - NGS Aligners"},{"body":"\n\nRNA-Seq Workflow  Read quality assessment, filtering and trimming Map reads against reference genome Perform read counting for required ranges (e.g. exonic gene ranges) Normalization of read counts Identification of differentially expressed genes (DEGs) Clustering of gene expression profiles Gene set enrichment analysis  Challenge Projects 1. Comparison of DEG analysis methods  Run workflow from start to finish (steps 1-7) on RNA-Seq data set from Howard et al. (2013) Challenge project tasks  Compare the DEG analysis method chosen for paper presentation with at least 1-2 additional methods (e.g. one student compares edgeR vs. baySeq, and other student DESeq2 vs. limma/voom). Assess the results as follows:  Analyze the similarities and differences in the DEG lists obtained from the two methods using intersect matrices, venn diagrams and/or upset plots. Assess the impact of the DEG method on the downstream gene set enrichment analysis? Plot the performance of the DEG methods in form of ROC curves and/or record their AUC values. A consensus DEG set or the one from the Howard et al. (2013) paper could be used as a ‘pseudo’ ground truth result.      2. Comparison of DEG analysis methods  Similar as above but with different combination of DEG methods and/or performance testing approach.  References  Howard, B.E. et al., 2013. High-throughput RNA sequencing of pseudomonas-infected Arabidopsis reveals hidden transcriptome complexity and novel splice variants. PloS one, 8(10), p.e74183. PubMed Guo Y, Li C-I, Ye F, Shyr Y (2013) Evaluation of read count based RNAseq analysis methods. BMC Genomics 14 Suppl 8: S2 PubMed Hardcastle TJ, Kelly KA (2010) baySeq: empirical Bayesian methods for identifying differential expression in sequence count data. BMC Bioinformatics 11: 422 PubMed Liu R, Holik AZ, Su S, Jansz N, Chen K, Leong HS, Blewitt ME, Asselin-Labat M-L, Smyth GK, Ritchie ME (2015) Why weight? Modelling sample and observational level variability improves power in RNA-seq analyses. Nucleic Acids Res. doi: 10.1093/nar/gkv412. PubMed Love MI, Huber W, Anders S (2014) Moderated estimation of fold change and dispersion for RNA-seq data with DESeq2. Genome Biol 15: 550 PubMed Zhou X, Lindsay H, Robinson MD (2014) Robustly detecting differential expression in RNA sequencing data using observation weights. Nucleic Acids Res 42: e91 PubMed  ","categories":"","description":"","excerpt":"\n\nRNA-Seq Workflow  Read quality assessment, filtering and trimming …","ref":"/assignments/projects/02_rnaseq_deg/","tags":"","title":"RNA-Seq - DEG Analysis Methods"},{"body":"\n\nRNA-Seq Workflow  Read quality assessment, filtering and trimming Map reads against reference genome Perform read counting for required ranges (e.g. exonic gene ranges) Normalization of read counts Identification of differentially expressed genes (DEGs) Clustering of gene expression profiles Gene set enrichment analysis  Challenge Projects 1. Cluster and network analysis methods  Run workflow from start to finish (steps 1-7) on RNA-Seq data set from Howard et al. (2013) Challenge project tasks  Compare at least 2-3 cluster analysis methods (e.g. hierarchical, k-means, Fuzzy C-Means, WGCNA, other) and assess the performance differences as follows:  Analyze the similarities and differences in the cluster groupings obtained from the two methods. Do the differences affect the results of the downstream gene set enrichment analysis? Plot the performance of the clustering methods in form of ROC curves and/or record their AUC values. Functional annotations (e.g. GO, KEGG, Pfam) could be used as a benchmark for defining true results.      2. Cluster and network analysis methods  Similar as above but with different combination of clustering methods and/or performance testing approach.  References  Howard, B.E. et al., 2013. High-throughput RNA sequencing of pseudomonas-infected Arabidopsis reveals hidden transcriptome complexity and novel splice variants. PloS one, 8(10), p.e74183. PubMed Langfelder P, Luo R, Oldham MC, Horvath S (2011) Is my network module preserved and reproducible? PLoS Comput Biol 7: e1001057. PubMed Langfelder P, Horvath S (2008) WGCNA: an R package for weighted correlation network analysis. BMC Bioinformatics 9: 559–559. PubMed Rodriguez MZ, Comin CH, Casanova D, Bruno OM, Amancio DR, Costa L da F, Rodrigues FA (2019) Clustering algorithms: A comparative approach. PLoS One 14: e0210236. PubMed  ","categories":"","description":"","excerpt":"\n\nRNA-Seq Workflow  Read quality assessment, filtering and trimming …","ref":"/assignments/projects/03_cluster_analysis/","tags":"","title":"Cluster and Network Analysis Methods"},{"body":"\n\nRNA-Seq Workflow  Read quality assessment, filtering and trimming Map reads against reference genome Perform read counting for required ranges (e.g. exonic gene ranges) Normalization of read counts Identification of differentially expressed genes (DEGs) Clustering of gene expression profiles Gene set enrichment analysis  Challenge Projects 1. Embedding Methods for scRNA-Seq  Run workflow from start to finish (steps 1-7) on RNA-Seq data set from Howard et al. (2013) Challenge project tasks  Compare the partition performance of at least 3 embedding methods for high-dimensional gene expression data using single cell RNA-Seq data. The dimensionality reduction methods can include PCA, MDS, SC3, isomap, t-SNE, FIt-SNE, UMAP, etc. To obtain meaningful test results, choose an scRNA-Seq data set (here pre-processed count data) where the correct cell clustering is known (ground truth). For simplicity the data could be obtained from the scRNAseq package (Risso and Cole, 2020) or loaded from GEO (e.g. Shulse et al., 2019). For learning purposes, organize the data in a SingleCellExperiment object. Optional: plot the (partitioning) performance in form of ROC curves and/or record their AUC values. Compare your test results with published performance test results, e.g. Sun et al. (2019) or Duò et al. (2018).    2. Embedding Methods for scRNA-Seq  Similar as above but with different combination of embedding methods and/or performance testing approach.  3. Embedding Methods for scRNA-Seq  Similar as above but with different combination of embedding methods and/or performance testing approach.  References  Duò A, Robinson MD, Soneson C (2018) A systematic performance evaluation of clustering methods for single-cell RNA-seq data. F1000Res 7: 1141. PubMed Howard, B.E. et al., 2013. High-throughput RNA sequencing of pseudomonas-infected Arabidopsis reveals hidden transcriptome complexity and novel splice variants. PloS one, 8(10), p.e74183. PubMed Kiselev VY, Kirschner K, Schaub MT, Andrews T, Yiu A, Chandra T, Natarajan KN, Reik W, Barahona M, Green AR, et al (2017) SC3: consensus clustering of single-cell RNA-seq data. Nat Methods 14: 483–486. PubMed L.J.P. van der Maaten and G.E. Hinton. Visualizing High-Dimensional Data Using t-SNE. Journal of Machine Learning Research 9 (Nov) : 2579-2605, 2008. Linderman GC, Rachh M, Hoskins JG, Steinerberger S, Kluger Y (2019) Fast interpolation-based t-SNE for improved visualization of single-cell RNA-seq data. Nat Methods 16: 243–245 PubMed (Note: this could be used as a more recent pub on t-SNE; the speed improved version is also available for R with a C) McInnes L, Healy J, Melville J (2018) UMAP: Uniform Manifold Approximation and Projection for Dimension Reduction. arXiv Risso D, Cole M (2020). scRNAseq: Collection of Public Single-Cell RNA-Seq Datasets. R package version 2.4.0. -\u003e Choose one scRNA-Seq data set from this Bioc data package for testing embedding methods. URL Senabouth A, Lukowski SW, Hernandez JA, Andersen SB, Mei X, Nguyen QH, Powell JE (2019) ascend: R package for analysis of single-cell RNA-seq data. Gigascience. doi: 10.1093/gigascience/giz087. PubMed Shulse CN, Cole BJ, Ciobanu D, Lin J, Yoshinaga Y, Gouran M, Turco GM, Zhu Y, O’Malley RC, Brady SM, et al (2019) High-Throughput Single-Cell Transcriptome Profiling of Plant Cell Types. Cell Rep 27: 2241–2247.e4 PubMed Sun S, Zhu J, Ma Y, Zhou X (2019) Accuracy, robustness and scalability of dimensionality reduction methods for single-cell RNA-seq analysis. Genome Biol 20: 269. PubMed Sun S, Zhu J, Zhou X (2020) Statistical analysis of spatial expression patterns for spatially resolved transcriptomic studies. Nat Methods. doi: 10.1038/s41592-019-0701-7. PubMed  ","categories":"","description":"","excerpt":"\n\nRNA-Seq Workflow  Read quality assessment, filtering and trimming …","ref":"/assignments/projects/04_scrnaseq_embedding/","tags":"","title":"Embedding Methods for scRNA-Seq"},{"body":"\n\nChIP-Seq Workflow  Read quality assessment, filtering and trimming Align reads to reference genome Compute read coverage across genome Peak calling with different methods and consensus peak identification Annotate peaks Differential binding analysis Gene set enrichment analysis Motif prediction to identify putative TF binding sites  Challenge Projects 1. Comparison of peak calling methods  Run workflow from start to finish (steps 1-8) on ChIP-Seq data set from Kaufman et al. (2010) Challenge project tasks  Call peaks with at least 2-3 software tools, such as MACS2, PeakSeq, F-Seq, Homer, ChIPseqR, or CSAR. Compare the results from with peaks identified by Kaufmann et al (2010) Report unique and common peaks among three methods and plot the results as venn diagrams Plot the performance of the peak callers in form of ROC plots. As true result set one can use the intersect of the peaks identified by all methods.    2. Comparison of peak calling methods  Similar as above but with different combination of peak calling methods and/or performance testing approach.  References  Feng J, Liu T, Qin B, Zhang Y, Liu XS (2012) Identifying ChIP-seq enrichment using MACS. Nat Protoc 7: 1728–1740. PubMed Kaufmann, K, F Wellmer, J M Muiño, T Ferrier, S E Wuest, V Kumar, A Serrano-Mislata, et al. 2010. “Orchestration of Floral Initiation by APETALA1.” Science 328 (5974): 85–89. PubMed Landt SG, Marinov GK, Kundaje A, Kheradpour P, Pauli F, Batzoglou S, Bernstein BE, Bickel P, Brown JB, Cayting P, et al (2012) ChIP-seq guidelines and practices of the ENCODE and modENCODE consortia. Genome Res 22: 1813–1831. PubMed Lun ATL, Smyth GK (2014) De novo detection of differentially bound regions for ChIP-seq data using peaks and windows: controlling error rates correctly. Nucleic Acids Res 42: e95. PubMed Muiño JM, Kaufmann K, van Ham RC, Angenent GC, Krajewski P (2011) ChIP-seq Analysis in R (CSAR): An R package for the statistical detection of protein-bound genomic regions. Plant Methods 7: 11. PubMed Wilbanks EG, Facciotti MT (2010) Evaluation of algorithm performance in ChIP-seq peak detection. PLoS One. doi: 10.1371/journal.pone.0011471. PubMed Zhang Y, Liu T, Meyer CA, Eeckhoute J, Johnson DS, Bernstein BE, Nussbaum C, Myers RM, Brown M, Li W, et al (2008) Model-based analysis of ChIP-Seq (MACS). Genome Biol. doi: 10.1186/gb-2008-9-9-r137. PubMed  ","categories":"","description":"","excerpt":"\n\nChIP-Seq Workflow  Read quality assessment, filtering and trimming …","ref":"/assignments/projects/05_chipseq_peakcaller/","tags":"","title":"ChIP-Seq Peak Callers"},{"body":"\n\nChIP-Seq Workflow  Read quality assessment, filtering and trimming Align reads to reference genome Compute read coverage across genome Peak calling with different methods and consensus peak identification Annotate peaks Differential binding analysis Gene set enrichment analysis Motif prediction to identify putative TF binding sites  Challenge Project: Functional enrichment analysis (FEA)  Run workflow from start to finish (steps 1-8) on ChIP-Seq data set from Kaufman et al. (2010) Challenge project tasks  Perform functional enrichment analysis on the genes overlapping or downstream of the peak ranges discovered by the ChIP-Seq workflow. Compare at least 2 functional enrichment methods (e.g. GOCluster_Report, fgsea, chipenrich, goseq, GOstats) using KEGG/Reactome or Gene Ontology as functional annotation systems. Among the FEA methods include one based on the hypergeometric distribution (ORA) and one on the Gene Set Enrichment Analysis (GSEA) algorithm. Assess the results as follows:  Quantify the rank-based similarities of the functional categories among the chosen enrichment methods. Determine whether the enrichment results match the biological expectations of the experiment (e.g. are certain biological processes enriched)? Optional: visualize the results with one of the pathway or GO graph viewing tools.      References  Kaufmann, K, F Wellmer, J M Muiño, T Ferrier, S E Wuest, V Kumar, A Serrano-Mislata, et al. 2010. “Orchestration of Floral Initiation by APETALA1.” Science 328 (5974): 85–89. PubMed Sergushichev A (2016) An algorithm for fast preranked gene set enrichment analysis using cumulative statistic calculation. bioRxiv 060012 Subramanian A, Tamayo P, Mootha VK, Mukherjee S, Ebert BL, Gillette MA, Paulovich A, Pomeroy SL, Golub TR, Lander ES, et al (2005) Gene set enrichment analysis: a knowledge-based approach for interpreting genome-wide expression profiles. Proc Natl Acad Sci U S A 102: 15545–15550. PubMed Welch RP, Lee C, Imbriano PM, Patil S, Weymouth TE, Smith RA, Scott LJ, Sartor MA (2014) ChIP-Enrich: gene set enrichment testing for ChIP-seq data. Nucleic Acids Res 42: e105. PubMed Young MD, Wakefield MJ, Smyth GK, Oshlack A (2010) Gene ontology analysis for RNA-seq: accounting for selection bias. Genome Biol 11: R14. PubMed  ","categories":"","description":"","excerpt":"\n\nChIP-Seq Workflow  Read quality assessment, filtering and trimming …","ref":"/assignments/projects/06_functional_enrichment/","tags":"","title":"Functional enrichment analysis (FEA)"},{"body":"\n\nChIP-Seq Workflow  Read quality assessment, filtering and trimming Align reads to reference genome Compute read coverage across genome Peak calling with different methods and consensus peak identification Annotate peaks Differential binding analysis Gene set enrichment analysis Motif prediction to identify putative TF binding sites  Challenge Projects 1. Functional enrichment analysis (FEA)  Run workflow from start to finish (steps 1-8) on ChIP-Seq data set from Kaufman et al. (2010) Challenge project tasks  Prioritize/rank peaks by FDR from differential binding analysis Parse peak sequences from genome Determine which motifs in the Jaspar database (motifDB) show the highest enrichment in the peak sequences. The motif enrichment tests can be performed with the PWMEnrich package. Basic starter code for accomplishing these tasks is provided here. The motif mapping can be performed with matchPWM or motifmatcher, and motif identification in databases can be performed with MotIV. To have distinct challenge project aspects for each of the two students in this project, one could use different peak ranking approaches, e.g. one ranks by FDR of differential binding analysis, and the other by coverage or p-values of peak caller.    2. Functional enrichment analysis (FEA)  Similar as above but with different combination of enrichment and/or testing methods.  References  Frith, Martin C., Yutao Fu, Liqun Yu, Jiang‐fan Chen, Ulla Hansen, and Zhiping Weng. 2004. “Detection of Functional DNA Motifs via Statistical Over‐representation.” Nucleic Acids Research 32 (4): 1372–81. PubMed Kaufmann, K, F Wellmer, J M Muiño, T Ferrier, S E Wuest, V Kumar, A Serrano-Mislata, et al. 2010. “Orchestration of Floral Initiation by APETALA1.” Science 328 (5974): 85–89. PubMed Machanick P, Bailey TL (2011) MEME-ChIP: motif analysis of large DNA datasets. Bioinformatics 27: 1696–1697. PubMed McLeay, Robert C, and Timothy L Bailey. 2010. “Motif Enrichment Analysis: A Unified Framework and an Evaluation on ChIP Data.” BMC Bioinformatics 11: 165. PubMed Tompa, M, N Li, T L Bailey, G M Church, B De Moor, E Eskin, A V Favorov, et al. 2005. “Assessing Computational Tools for the Discovery of Transcription Factor Binding Sites.” Nature Biotechnology 23 (1): 137–44. PubMed Alipanahi B, Delong A, Weirauch MT, Frey BJ (2015) Predicting the sequence specificities of DNA- and RNA-binding proteins by deep learning. Nat Biotechnol 33: 831–838. PubMed  ","categories":"","description":"","excerpt":"\n\nChIP-Seq Workflow  Read quality assessment, filtering and trimming …","ref":"/assignments/projects/07_motif_enrichment/","tags":"","title":"Motif Enrichment Analysis (MEA)"},{"body":"\n\nChIP-Seq Workflow  Read quality assessment, filtering and trimming Align reads to reference genome Compute read coverage across genome Peak calling with different methods and consensus peak identification Annotate peaks Differential binding analysis Gene set enrichment analysis Motif prediction to identify putative TF binding sites  Challenge Project: Programmable graphics for visualizing genomic features  Run workflow from start to finish (steps 1-8) on ChIP-Seq data set from Kaufman et al. (2010) Challenge project tasks  This project focuses on the visualization of patterns in NGS experiments (e.g. consensus motifs in ChIP-Seq peaks) to discover novel features in genomes. The visualization backend should be based on one of the programmable and extendable R/Bioconductor environments such as ggplot2 (ggplotly), ggbio, Gviz, RCircos, etc. For instance, this could include:  The generation of motif logos (e.g. for ChIP-Seq peaks) for any number of sequence ranges of interest. Integration of the results with functional annotation information (e.g. protein families from Pfam, exonic regions coding for disordered structures), pathways and/or GO. Incorporation of quantitative information such as relative or differential abundance information obtained from the corresponding NGS profiling technology. If there is interest, a Shiny App could be included to run the developed R functions interactively from a web browser.      References  Hahne F, Ivanek R (2016). “Statistical Genomics: Methods and Protocols.” In Mathé E, Davis S (eds.), chapter Visualizing Genomic Data Using Gviz and Bioconductor, 335–351. Springer New York, New York, NY. ISBN 978-1-4939-3578-9, doi: 10.1007/978-1-4939-3578-9_16. PubMed Kaufmann, K, F Wellmer, J M Muiño, T Ferrier, S E Wuest, V Kumar, A Serrano-Mislata, et al. 2010. “Orchestration of Floral Initiation by APETALA1.” Science 328 (5974): 85–89. PubMed Yin T, Cook D, Lawrence M (2012). “ggbio: an R package for extending the grammar of graphics for genomic data.” Genome Biology, 13(8), R77. PubMed Zhang H, Meltzer P, Davis S (2013) RCircos: an R package for Circos 2D track plots. BMC Bioinformatics 14: 244–244. PubMed  ","categories":"","description":"","excerpt":"\n\nChIP-Seq Workflow  Read quality assessment, filtering and trimming …","ref":"/assignments/projects/08_genome_graphics/","tags":"","title":"Genome Summary Graphics"},{"body":"\n\nShared big data space on HPCC All larger data sets of the coure projects will be organized in a big data space under /bigdata/gen242/\u003cuser_name\u003e. Within this space, each student will read and write data to a subdirectory named after their project:\n /bigdata/gen242/\u003cuser_name\u003e/projdata  Within each projdata directory all input files of a workflow (e.g. FASTQ) will be saved to a data directory and all output files will be written to a results directory. To set up the proper directory structure, cd into /bigdata/gen242/\u003cuser_name\u003e, create the directory named projdata and then within this directory create the data and results subdirectories. The full path to these directories should look like this:\n /bigdata/gen242/\u003cuser_name\u003e/projdata/data /bigdata/gen242/\u003cuser_name\u003e/projdata/results  GitHub repositories for projects Students will work on the course projects within GitHub repositories, one for each course project. These project repositories are private and have been shared with each student via GitHub Classroom. To populate a course project with an initial project workflow, please follow the instructions given.\nGenerate workflow environment with project data  Log in to the HPCC cluster and set your working directory to bigdata or (/bigdata/gen242/\u003cuser_name\u003e) Clone the GitHub repository for your project with git clone ... (URLs listed here) and then cd into this directory. Generate the workflow environment for your project on the HPCC cluster with genWorkenvir from systemPipeRdata. Delete the default data and results directories and replace them with symbolic links pointing to the above described data and results directories of your course project. For instance, the project RNA-Seq should create the symbolic links for their data and results directories like this: ln -s /bigdata/gen242/\u003cuser_name\u003e/projdata/data data ln -s /bigdata/gen242/\u003cuser_name\u003e/projdata/results results   Add the workflow directory to the GitHub repository of your project with git add -A and the run commit and push as outlined in the GitHub instructions of this course here. Download the FASTQ files of your project with getSRAfastq (see below) to the data directory of your project, here ‘/bigdata/gen242/\u003cuser_name\u003e/projdata/data’. Generate a proper targets file for your project where the first column(s) point(s) to the downloaded FASTQ files. In addition, provide sample names matching the experimental design (columns: SampleNames and Factor). Inspect and adjust the .param files you will be using. For instance, make sure the software modules you are loading and the path to the reference genome are correct. Every time you start working on your project you cd into the directory of the repository and then run git pull to get the latest change. When you are done, you commit and push your changes back to GitHub with git commit -am \"some edits\"; git push -u origin master.  Download of project data Open R from within the GitHub respository of your project and then run the following code section, but only those that apply to your project.\nFASTQ files from SRA Choose FASTQ data for your project  The FASTQ files for the ChIP-Seq project are from SRA study SRP002174 (Kaufman et al. 2010)  sraidv \u003c- paste(\"SRR0388\", 45:51, sep=\"\")   The FASTQ files for the RNA-Seq project are from SRA study SRP010938 (Howard et al. 2013)  sraidv \u003c- paste(\"SRR4460\", 27:44, sep=\"\")  Load libraries and modules library(systemPipeR) moduleload(\"sratoolkit/2.9.2\") system('fastq-dump --help') # prints help to screen  Redirect cache output of SRA Toolkit Newer versions of the SRA Toolkit create a cache directory (named ncbi) in the highest level of a user’s home directory. To save space in home accounts (limited to 20GB), users need to redirect this output to their project’s data directory via a symbolic link. The following shows how to do this for the data directory of the ChIP-Seq project.\nsystem(\"ln -s /bigdata/gen242/\u003cuser_name\u003e/projdata/data ~/ncbi\")  Define download function The following function downloads and extracts the FASTQ files for each project from SRA. Internally, it uses the fastq-dump utility of the SRA Toolkit from NCBI.\ngetSRAfastq \u003c- function(sraid, targetdir, maxreads=\"1000000000\") { system(paste(\"fastq-dump --split-files --gzip --maxSpotId\", maxreads, sraid, \"--outdir\", targetdir)) }  Run download Note the following performs the download in serialized mode for the chosen data set and saves the extracted FASTQ files to the path specified under targetdir.\nmydir \u003c- getwd(); setwd(\"data\") for(i in sraidv) getSRAfastq(sraid=i, targetdir=\".\") setwd(mydir)  Alternatively, the download can be performed in parallelized mode with BiocParallel. Please run this version only on one of the compute nodes.\nmydir \u003c- getwd(); setwd(\"data\") # bplapply(sraidv, getSRAfastq, targetdir=\".\", BPPARAM = MulticoreParam(workers=4)) setwd(mydir)  Download reference genome and annotation The following downloadRefs function downloads the Arabidopsis thaliana genome sequence and GFF file from the TAIR FTP site. It also assigns consistent chromosome identifiers to make them the same among both the genome sequence and the GFF file. This is important for many analysis routines such as the read counting in the RNA-Seq workflow.\ndownloadRefs \u003c- function(rerun=FALSE) { if(rerun==TRUE) { library(Biostrings) download.file(\"https://www.arabidopsis.org/download_files/Genes/TAIR10_genome_release/TAIR10_chromosome_files/TAIR10_chr_all.fas\", \"./data/tair10.fasta\") dna \u003c- readDNAStringSet(\"./data/tair10.fasta\") names(dna) \u003c- paste(rep(\"Chr\", 7), c(1:5, \"M\", \"C\"), sep=\"\") # Fixes chromomse ids writeXStringSet(dna, \"./data/tair10.fasta\") download.file(\"https://www.arabidopsis.org/download_files/Genes/TAIR10_genome_release/TAIR10_gff3/TAIR10_GFF3_genes.gff\", \"./data/tair10.gff\") download.file(\"https://www.arabidopsis.org/download_files/Genes/TAIR10_genome_release/TAIR10_functional_descriptions\", \"./data/tair10_functional_descriptions\") } }  After importing/sourcing the above function, execute it as follows:\ndownloadRefs(rerun=TRUE)  ","categories":"","description":"","excerpt":"\n\nShared big data space on HPCC All larger data sets of the coure …","ref":"/assignments/projects/project_data/","tags":"","title":"Data Management for Course Projects"},{"body":"Presentation will be posted here.\n","categories":"","description":"","excerpt":"Presentation will be posted here.\n","ref":"/assignments/presentations/","tags":"","title":"Project and Paper Presentations"},{"body":"Overview Each student has been assigned one journal publication to present in class. The expected structure of the paper presentations is outlined in this Slideshow Template. A detailed presentation schedule is available on the internal Course Schedule. The following lists the assigned papers organized by course project topics.\nPublications organized by course projects All references in Paperpile\nRNA-Seq Aligners  Kim D, Langmead B, Salzberg SL (2015) HISAT: a fast spliced aligner with low memory requirements. Nat Methods 12: 357–360. PubMed  DEG Methods Zhou X, Lindsay H, Robinson MD (2014) Robustly detecting differential expression in RNA sequencing data using observation weights. Nucleic Acids Res 42: e91. PubMed Love MI, Huber W, Anders S (2014) Moderated estimation of fold change and dispersion for RNA-seq data with DESeq2. Genome Biol 15: 550. PubMed  Clustering and Network Analysis Langfelder P, Luo R, Oldham MC, Horvath S (2011) Is my network module preserved and reproducible? PLoS Comput Biol 7: e1001057. PubMed Rodriguez MZ, Comin CH, Casanova D, Bruno OM, Amancio DR, Costa L da F, Rodrigues FA (2019) Clustering algorithms: A comparative approach. PLoS One 14: e0210236. PubMed  Embedding of High-dimensional scRNA-Seq Data Shulse CN, Cole BJ, Ciobanu D, Lin J, Yoshinaga Y, Gouran M, Turco GM, Zhu Y, O’Malley RC, Brady SM, et al (2019) High-Throughput Single-Cell Transcriptome Profiling of Plant Cell Types. Cell Rep 27: 2241–2247.e4. PubMed Sun S, Zhu J, Ma Y, Zhou X (2019) Accuracy, robustness and scalability of dimensionality reduction methods for single-cell RNA-seq analysis. Genome Biol 20: 269. PubMed McInnes L, Healy J, Melville J (2018) UMAP: Uniform Manifold Approximation and Projection for Dimension Reduction. arXiv  ChIP-Seq Peak Callers Wilbanks EG, Facciotti MT (2010) Evaluation of algorithm performance in ChIP-seq peak detection. PLoS One. doi: 10.1371/journal.pone.0011471. PubMed Feng J, Liu T, Qin B, Zhang Y, Liu XS (2012) Identifying ChIP-seq enrichment using MACS. Nat Protoc 7: 1728–1740. PubMed  Functional Enrichment Analysis Subramanian A, Tamayo P, Mootha VK, Mukherjee S, Ebert BL, Gillette MA, Paulovich A, Pomeroy SL, Golub TR, Lander ES, et al (2005) Gene set enrichment analysis: a knowledge-based approach for interpreting genome-wide expression profiles. Proc Natl Acad Sci U S A 102: 15545–15550. PubMed  Motif Enrichment Analysis McLeay, Robert C, and Timothy L Bailey. 2010. “Motif Enrichment Analysis: A Unified Framework and an Evaluation on ChIP Data.” BMC Bioinformatics 11: 165. PubMed  Programmable Genome Summary Graphics Zhang H, Meltzer P, Davis S (2013) RCircos: an R package for Circos 2D track plots. BMC Bioinformatics 14: 244–244. PubMed  ","categories":"","description":"","excerpt":"Overview Each student has been assigned one journal publication to …","ref":"/assignments/presentations/paper_presentations/","tags":"","title":"Student Paper Presentations"},{"body":"Suggestions  Single cell profiling (e.g. scRNA-Seq) Comparative genomics (e.g. ortholog assignments and/or assembly) Tool development (e.g. design of Shiny Apps)  ","categories":"","description":"...","excerpt":"...","ref":"/blog/2021/03/11/special-topics/","tags":"","title":"Special Topics"},{"body":"Welcome to GEN242 - Spring 2021  Due to COVID-19 restrictions, this class will be instructed entirely online via Zoom. The Zoom URLs for lectures, discussion sections and office hours will be provided shortly before the class starts. First Lecture: 02:00-03:20 PM, Tue, March 30, 2021  ","categories":"","description":"...","excerpt":"...","ref":"/blog/2021/02/13/first-day-of-instructions/","tags":"","title":"First Day of Instructions"},{"body":"","categories":"","description":"","excerpt":"","ref":"/about/","tags":"","title":"About GEN242"},{"body":"","categories":"","description":"","excerpt":"","ref":"/assignments/","tags":"","title":"Assignments"},{"body":"  #td-cover-block-0 { background-image: url(\"background.jpg\") }  Data Analysis in Genome Biology  --  About Course  Piazza   Instructors     GEN242 is a graduate class taught at the University of California, Riverside         Overview This course introduces algorithms, statistical methods and data analysis programming routines relevant for genome biology. It consists of three main components: lectures, hands-on practicals and student course projects. The lecture topics cover databases, sequence (NGS) analysis, phylogenetics, comparative genomics, genome-wide profiling methods, network biology and more. The hands-on practicals include homework assignments and course projects focusing on data analysis programming of next generation genome data using command-line tools on a computer cluster and the programming environment R. Depending on student interests, one or more specialty topics may be included, such as the analysis of single cell (e.g. scRNA-Seq) experiments, multi-omics data, or the development of web-based analysis tools (e.g. Shiny Apps).  Who should take this class? Students with a strong interest and motivation in acquiring the skills required for mastering the computational aspects of modern genome research. The class is mainly targeting graduate students but senior undergraduate students are welcome to enroll as well. The main audience of this class usually includes students from bioscience, biomedical and bioengineering programs as well as CS and statistics students with interest in computational biology.  Can I audit this class? It is possible to audit this class. However, due to the emphasis on active participation in practicals and course projects, students usually learn much more if they enroll into the class rather than auditing it in a passive manner.      University of California, Riverside    ","categories":"","description":"","excerpt":"  #td-cover-block-0 { background-image: url(\"background.jpg\") }  Data …","ref":"/","tags":"","title":"GEN242"},{"body":"","categories":"","description":"The pages under this _Internal Section_ provide information about internal resources that are mainly relevant for the instructor(s) of this class.","excerpt":"The pages under this _Internal Section_ provide information about …","ref":"/about/internal/","tags":"","title":"Internal Resources"},{"body":"This is the blog section. It has two categories: News and Releases.\nFiles in these directories will be listed in reverse chronological order.\n","categories":"","description":"","excerpt":"This is the blog section. It has two categories: News and Releases. …","ref":"/blog/","tags":"","title":"GEN242 News"},{"body":"This page provides URLs to external resources  Piazza GitHub Repo Bioconductor Hugo, Docsy and R  ","categories":"","description":"","excerpt":"This page provides URLs to external resources  Piazza GitHub Repo …","ref":"/external_resources/","tags":"","title":"Links"},{"body":"","categories":"","description":"","excerpt":"","ref":"/search/","tags":"","title":"Search Results"},{"body":"","categories":"","description":"","excerpt":"","ref":"/slides/","tags":"","title":"Slides"},{"body":"","categories":"","description":"","excerpt":"","ref":"/tutorials/","tags":"","title":"Tutorials"}]