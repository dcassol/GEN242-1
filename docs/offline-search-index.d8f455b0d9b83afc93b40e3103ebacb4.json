



























[{"body":"\nOverview This course introduces algorithms, statistical methods and data analysis programming routines relevant for genome biology. It consists of three main components: lectures, hands-on practicals and student course projects. The lecture topics cover databases, sequence (NGS) analysis, phylogenetics, comparative genomics, genome-wide profiling methods, network biology and more. The hands-on practicals include homework assignments and course projects focusing on data analysis programming of next generation genome data using command-line tools on a computer cluster and the programming environment R.\nWho should take this class? Students with a strong interest and motivation in acquiring the skills required for mastering the computational aspects of modern genome research. The class is mainly targeting graduate students but senior undergraduate students are welcome to enroll as well. The main audience of this class are usually students from bioscience, biomedical and bioengineering programs as well as CS and statistics students with interest in computational biology.\nCan I audit this class? It is possible to audit this class. However, due to the emphasis on active participation in practicals and course projects, students usually learn much more if they enroll into the class rather than auditing it in a passive manner.\n","categories":"","description":"","excerpt":"\nOverview This course introduces algorithms, statistical methods and …","ref":"/about/introduction/","tags":"","title":"Introduction"},{"body":"  GitHub in GEN242  Note, this class will make heavy use of GitHub Homework assignments will be submitted to private GitHub repositories: one repository for each student Course projects will also use private GitHub repositories: one repository for each course project (shared among students of each project) Each student will need a personal GitHub account. They can be created here. GitHub provides an unlimited number of free public repositories to each user. Via GitHub Education students can sign up for free private GitHub accounts (see here). All private GitHub accounts required for this class will be provided by the instructor via GitHub Classroom For beginners this quick guide may be useful  What are Git and GitHub?  Git is a distributed version control system similar to SVN GitHub is an online social coding service based on Git Combined Git/GitHub: environment for version control and social coding  Installing Git  Install on Windows, OS X and Linux When using it from RStudio, it needs to find the Git executable  Git Basics from Command-Line Also try interactive git tutorial.\n  Finding help from command-line\ngit \u003ccommand\u003e --help    Initialize a directory as a Git repository\ngit init    Add specific files to Git repository (staging area)\ngit add myfile    Add all files recursively\nTo ignore specific files (e.g. temp files), list them in a .gitignore file in your repository’s root directory. Regular expressions are supported. See here for more details.\ngit add -A :/    After editing file(s) in your repos, record a snapshot of the staging area\ngit commit -am \"some edits\"    GitHub Basics from Command-Line   Generate a new remote repository on GitHub online or use hub command-line wrapper for this. To avoid errors with the online method, do not initialize the new repository with README, license, or .gitignore files. You can add these files after your project has been pushed to GitHub.\ngit remote add origin https://github.com/\u003cuser_name\u003e/\u003crepos_name\u003e.git    Push updates to remote. Next time one can just use git push\ngit push -u origin master    Clone existing remote repository\ngit clone https://github.com/\u003cuser_name\u003e/\u003crepos_name\u003e.git    Before working on project, update local git repos\ngit pull    Make changes and recommit local to remote\ngit commit -am \"some edits\"; git push -u origin master    Exercise Run the following git/github excercise from the command-line.\ngit clone https://github.com/\u003cuser or org\u003e/\u003crepo name\u003e cd \u003crepo name\u003e git pull touch test # Creates empty file for testing git add -A git commit -am \"some edits\" git push -u origin master ##-\u003e Edit test file online and then run `git pull` to inspect changes  Online file upload This could be useful for new users who want to upload their homework assignments to GitHub but are not familiar enough with the command-line yet.\n Press Create new file button on your repository. Under the file path window add required subdirectory structure and a dummy file name (e.g. Homework/HW1/dummy.txt) After this press Upload files and upload any file (e.g. homework) to the newly create directory. After this the initial dummy file can be deleted. The latter is necessary since empty directories are not visible on GitHub.  Using GitHub from RStudio   After installing Git (see here), set path to Git executable in Rstudio:\n Tools \u003e Global Options \u003e Git/SVN    If needed, log in to GitHub account and create repository. Use option Initialize this repository with a README.\n  Clone repository by copying \u0026 pasting URL from repository into RStudio’s ‘Clone Git Repository’ window:\n File \u003e New Project \u003e Version Control \u003e Git \u003e Provide URL    Now do some work (e.g. add an R script), commit and push changes as follows:\n Tools \u003e Version Control \u003e Commit    Check files in staging area and press Commit Button\n  To commit changes to GitHub, press Push Button\n  Shortcuts to automate above routines are here\n  To resolve password issues, follow instructions here.\n  ","categories":"","description":"","excerpt":"  GitHub in GEN242  Note, this class will make heavy use of GitHub …","ref":"/tutorials/github/github/","tags":"","title":"GitHub Introduction"},{"body":"Course title Data Analysis in Genome Biology GEN242 - Spring 2021\nPrintable syllabus See Google Doc version here.\nInstructor Name: Thomas Girke Email: thomas.girke@ucr.edu Office location: 1207F Genomics Office hours: Tue \u0026 Thu 4:30 - 5:30 PM\nDescription Introduction to algorithms, statistical methods and data analysis programming routines relevant for genome biology. The class consists of three main components: lectures, hands-on practicals and student course projects. The lecture topics cover databases, sequence (NGS) analysis, phylogenetics, comparative genomics, genome-wide profiling methods, network biology and more. The hands-on practicals include homework assignments and course projects focusing on data analysis programming of next generation genome data using command-line tools on a computer cluster and the programming environment R. Credit: 4 units (2x 1.5 hours lectures, 1 hour discussion)\nObjectives of course  Acquire understanding of algorithms used in bioinformatics Obtain hands-on experience in large scale data analysis.  Prerequisites The main prerequisite for this course is a strong interest in acquiring the skills required for mastering the computational aspects of modern genome research.\nStructure of course Two lectures per week (1.5 hours each) plus one discussion section (1 hour). During the first weeks the discussion section will be used for data analysis tutorials using Linux command-line tools and R.\nTime Lecture: Tue/Thu 2:00-3:20 PM Discussion: Thu 3:30-4:20 PM\nLocation Online via video conferencing software\nGrading  Homework assignments: 40% Scientific paper presentation: 20% Course project presentations: 20% Final project report: 20%  Grading policy: Given the diverse educational background of the students in GEN242, all assignments are designed to be solvable by students from both experimental and quantitative disciplines, including those with no or only limited prior experience in programming and/or data modeling. The weight of each of the four gradable components in this class is given above in percent. (1) The homeworks include 8-10 assignments throughout the class. They cover algorithms and data analysis programming problems using the R language. The grading of these assignments is mainly based on correctness, reproducibility and reusability of the analysis code. (2-4) Students will work in groups of 3-5 members on a Challenge Project addressing a specific data analysis problem in genome data sciences. As part of their project, students will present a scientific paper (2) closely related to their project (see reading list for details). The results of the Challenge Projects (3) will be presented and discussed by each student at the end of the course. In addition, each student will write a detailed analysis report (4) of the assigned course project. The latter will be written in the style of a scientific publication and should include a detailed description of the results including all analysis code to fully reproduce the project results followed by a critical discussion of the outcomes. The grading of both the paper and project presentations (2-3) includes anonymous feedback from all students as well as the instructor, where understanding of the material, clarity of the oral presentations and critical thinking are the main grading criteria. The final project reports (4) will be graded by the instructor with an emphasis on scientific and coding accuracy, overall understanding of the topic, as well as reproducibility of the results.\nMaterials needed Students are expected to bring to each class meeting a laptop with a functional wireless connection and a recent internet browser version (e.g. Firefox, Chrome or Safari) preinstalled. Tablet computers with mobile operating systems are not suitable for running the required software. User accounts on a research computer cluster will be provided at the beginning of the course. To log in to the cluster, students also need to install a terminal application for their operating system (e.g. iTerm2 on OS X, and PuTTY or MobaXterm on Windows) as well as a file exchange software such as FileZilla. In addition, a recent version of R and RStudio should be installed on each laptop.\nSchedule    Week Topic     Week 1 Course Introduction    Databases and Software for Genome Biology    Discussion: Introduction to Linux and HPC    Reading: A1, T1, T2   Week 2 Sequencing Technologies    Discussion: Introduction to R    Reading: A2-A4, T3   Week 3 Sequence Alignments and Searching    Multiple Sequence Alignments    Discussion: Programming in R    Reading: A5-A6, T4   Week 4 Short Read Alignment Algorithms    Discussion: Basics of NGS Analysis    Reading: A7-A10, T5   Week 5 Gene Expression Analysis using Microarrays and RNA-Seq    Discussion: NGS Workflow Overview; RNA-Seq Analysis    Reading: A11-A15, T6-T7   Week 6 Analysis of ChIP-Seq and VAR-Seq Experiments    Discussion: ChIP-Seq and VAR-Seq Analysis    Reading: A16-A18, T8-T9   Week 7 Students present publication related to their chosen course project    Discussion: Q\u0026A about papers    Reading: A19-A23   Week 8 Clustering algorithms    Pathway and GO annotation systems    Discussion: Gene Set Enrichment Analysis    Reading: A24-A26, T6 (Sec 3.14-3.15), T10   Week 9 Genome and Transcriptome Assembly Algorithms    Profile HMMs for Protein Family Modeling    Introduction to Phylogenetics    Discussion: Graphics and Data Visualization    Reading: A27-A29, T11   Week 10 Final presentations of student data analysis projects    Discussion: Tips and tricks for efficient data analysis programming    Reading: A30-A31, T3 (Sec 12,13-17)    Reading list Journal articles A1. Huber W, Carey VJ, Gentleman R, Anders S, Carlson M, Carvalho BS, Bravo HC, Davis S, Gatto L, Girke T, et al (2015) Orchestrating high-throughput genomic analysis with Bioconductor. Nat Methods 12: 115–121\nA2. Metzker, M. L., Jan 2010. Sequencing technologies - the next generation. Nat Rev Genet 11 (1), 31–46.\nA3. Needleman SB, Wunsch CD (1970) A general method applicable to the search for similarities in the amino acid sequence of two proteins. J Mol Biol 48, 443-453.\nA4. Smith TF, Waterman MS (1981) Identification of common molecular subsequences. J Mol Biol 147, 195-197.\nA5. Corpet F (1988) Multiple sequence alignment with hierarchical clustering. Nucleic Acids Res 16, 10881-90.\nA6. Altschul, S. F., Gish, W., Miller, W., Myers, E. W., Lipman, D. J., Oct 1990. Basic local alignment search tool. J Mol Biol 215 (3), 403–410.\nA7. Li, H, Durbin, R (2009) Fast and accurate short read alignment with Burrows-Wheeler transform. Bioinformatics, 25: 1754-1760.\nA8. Dobin, A., Davis, C.A., Schlesinger, F., Drenkow, J., Zaleski, C., Jha, S., Batut, P., Chaisson, M., Gingeras, T.R., 2012. STAR: ultrafast universal RNA-seq aligner. Bioinformatics 29, 15–21.\nA9. Langmead, B, Salzberg, S L (2012) Fast gapped-read alignment with Bowtie 2. Nat Methods, 9: 357-359.\nA10. Kim D, Langmead B, Salzberg SL (2015) HISAT: a fast spliced aligner with low memory requirements. Nat Methods 12: 357–360\nA11. Bray NL, Pimentel H, Melsted P, Pachter L (2016) Near-optimal probabilistic RNA-seq quantification. Nat Biotechnol. doi: 10.1038/nbt.3519\nA12. Love MI, Huber W, Anders S (2014) Moderated estimation of fold change and dispersion for RNA-seq data with DESeq2. Genome Biol 15: 550\nA13. Zhou X, Lindsay H, Robinson MD (2014) Robustly detecting differential expression in RNA sequencing data using observation weights. Nucleic Acids Res 42: e91\nA14. Anders, S, Reyes, A, Huber, W (2012) Detecting differential usage of exons from RNA-seq data. Genome Res, 22: 2008-2017.\nA15. Soneson, C, Delorenzi, M (2013) A comparison of methods for differential expression analysis of RNA-seq data. BMC Bioinformatics, 14: 91-91.\nA16. Zhang Y, Liu T, Meyer CA, Eeckhoute J, Johnson DS, Bernstein BE, Nussbaum C, Myers RM, Brown M, Li W, et al (2008) Model-based analysis of ChIP-Seq (MACS). Genome Biol. doi: 10.1186/gb-2008-9-9-r137\nA17. Wilbanks EG, Facciotti MT (2010) Evaluation of algorithm performance in ChIP-seq peak detection. PLoS One. doi: 10.1371/journal.pone.0011471.\nA18. Landt et al. (2012) ChIP-seq guidelines and practices of the ENCODE and modENCODE consortia. Genome Res, 22: 1813-1831.\nA19. McLeay, Robert C, and Timothy L Bailey. 2010. “Motif Enrichment Analysis: A Unified Framework and an Evaluation on ChIP Data.” BMC Bioinformatics 11: 165.\nA20. Machanick, P, Bailey, T L (2011) MEME-ChIP: motif analysis of large DNA datasets. Bioinformatics, 27: 1696-1697.\nA21. Tompa, M, N Li, T L Bailey, G M Church, B De Moor, E Eskin, A V Favorov, et al. 2005. “Assessing Computational Tools for the Discovery of Transcription Factor Binding Sites.” Nature Biotechnology 23 (1): 137–44.\nA22. DePristo MA, Banks E, Poplin R, Garimella KV, Maguire JR, Hartl C, Philippakis AA, del Angel G, Rivas MA, Hanna M, et al (2011) A framework for variation discovery and genotyping using next-generation DNA sequencing data. Nat Genet 43: 491–498.\nA23. Shihab HA, Rogers MF, Gough J, Mort M, Cooper DN, Day INM, Gaunt TR, Campbell C (2015) An integrative approach to predicting the functional effects of non-coding and coding sequence variation. Bioinformatics 31: 1536–1543.\nA24. Raymond JW, Blankley CJ, Willett P (2003) Comparison of chemical clustering methods using graph- and fingerprint-based similarity measures. J Mol Graph Model 21: 421–433.\nA25. Subramanian A, Tamayo P, Mootha VK, Mukherjee S, Ebert BL, Gillette MA, Paulovich A, Pomeroy SL, Golub TR, Lander ES, et al (2005) Gene set enrichment analysis: a knowledge-based approach for interpreting genome-wide expression profiles. Proc Natl Acad Sci U S A 102: 15545–15550.\nA26. Ashburner M, Ball CA, Blake JA, Botstein D, Butler H, Cherry JM, Davis AP, Dolinski K, Dwight SS, Eppig JT, et al (2000) Gene ontology: tool for the unification of biology. The Gene Ontology Consortium. Nat Genet 25: 25–29.\nA27. Alkan, C, Sajjadian, S, Eichler, E E (2011) Limitations of next-generation genome sequence assembly. Nat Methods, 8: 61-65.\nA28. Eddy SR (1998) Profile hidden Markov models. Bioinformatics 14: 755–763.\nA29. Grabherr, M G, Haas, B J, Yassour, M, Levin, J Z, Thompson, D A, Amit, I, Adiconis, X, Fan, L, Raychowdhury, R, Zeng, Q, Chen, Z, Mauceli, E, Hacohen, N, Gnirke, A, Rhind, N, di Palma, F, Birren, B W, Nusbaum, C, Lindblad-Toh, K, Friedman, N, Regev, A (2011) Full-length transcriptome assembly from RNA-Seq data without a reference genome. Nat Biotechnol, 29: 644-652.\nA30. Zeitouni, B, Boeva, V, Janoueix-Lerosey, I, Loeillet, S, Legoix-ne, P, Nicolas, A, Delattre, O, Barillot, E (2010) SVDetect: a tool to identify genomic structural variations from paired-end and mate-pair sequencing data. Bioinformatics, 26: 1895-1896.\nA31. Ronquist F, Teslenko M, van der Mark P, Ayres DL, Darling A, Höhna S, Larget B, Liu L, Suchard MA, Huelsenbeck JP (2012) MrBayes 3.2: efficient Bayesian phylogenetic inference and model choice across a large model space. Syst Biol 61: 539–542.\nTutorials T1. GitHub Introduction\nT2. Introduction to Computer Clusters and Linux\nT3. Introduction to R\nT4. Programming in R\nT5. NGS Analysis Basics\nT6. NGS Workflows\nT7. RNA-Seq Workflow\nT8. ChIP-Seq Workflow\nT9. VAR-Seq Workflow\nT10. Unsupervised Learning\nT11. Data Visualization\nBooks Note: there is no need to purchase any books for this course as most reading material will be based on journal articles!\nGeneral Jonathan Pevsner (2009) Bioinformatics and Functional Genomics. Wiley-Blackwell; 2nd Edition, 992 pages.\nAlgorithms Jones N and Pevzner P (2004) An Introduction to Bioinformatics Algorithms. MIT Press, Massachusetts, 435 pages.\nSequence Analysis Durbin, R, Eddy, S, Krogh, A, Mitchison, G. (1998) Biological Sequence Analysis: Probabilistic Models of Proteins and Nucleic Acids. Cambridge University Press, UK, 356 pages.\nParida L (2008) Pattern Discovery in Bioinformatics: Theory \u0026 Algorithms. CRC Press, London, 526 pages.\nProfiling Bioinformatics Gentleman, R, Carey, V, Dudoit, S, Irizarry, R, Huber, W (2005) Bioinformatics and Computational Biology Solutions Using R and Bioconductor. Springer, New York, 473 pages.\nPhylogenetics Felsenstein, J (2004) Inferring Phylogenies. Sinauer, Massachusetts, 664 pages.\nParadis (2006) Analysis of Phylogenetics and Evolution with R. Springer, New York, 211 pages.\n","categories":"","description":"","excerpt":"Course title Data Analysis in Genome Biology GEN242 - Spring 2021 …","ref":"/about/syllabus/","tags":"","title":"Syllabus - GEN242"},{"body":"  HPCC Cluster Overview The HPCC Cluster (formerly called biocluster) is a shared research computing system available at UCR. The HPCC website is available here.\nWhat Is a Computer Cluster?   A computer cluster is an assembly of CPU units, so called computer nodes that work together to perform many computations in parallel. To achieve this, an internal network (e.g. Infiniband interconnect) connects the nodes to a larger unit, while a head node controls the load and traffic across the entire system.\n  Usually, users log into the head node to submit their computer requests via srun to a queuing system provided by resource management and scheduling software, such as SGE, Slurm or TORQUE/MAUI. The queuing system distributes the processes to the computer nodes in a controlled fashion.\n  Because the head node controls the entire system, users should never run computing jobs on the head node directly!\n  For code testing purposes, one can log into one of the nodes with srun --pty bash -l and run jobs interactively. Alternatively, one can log into the test node owl via ssh.\n  Hardware Infrastructure Computer nodes  Over 4,500 CPU cores 48 AMD computer nodes, each with 64 CPU cores and 512GB RAM 40 Intel computer nodes, each with 32 CPU cores and 512GB RAM 6 high-memory nodes, each 32 CPU cores and 1024GB RAM 12 GPU nodes, each with 5,000 cuda cores  Interconnect  FDR IB @56Gbs  Storage  Parallel GPFS storage system with 2.1 PB usable space Backup of same architecture and similar amount  User traffic  Computing tasks need to be submitted via srun HPCC Cluster headnode only for login, not for computing tasks! Monitor cluster activity: squeue or jobMonitor (qstatMonitor)  Manuals  HPCC Cluster Manual Linux Manual  Linux Basics Log into HPCC Cluster  Login command on OS X or Linux  ssh -XY user@cluster.hpcc.ucr.edu  Type password\n  Windows: provide same information in a terminal application like Putty or MobaXterm.\n Host name: cluster.hpcc.ucr.edu User name: … Password: …    Important Linux Commands Finding help\nman \u003cprogram_name\u003e  List content of current directory\nls  Print current working directory\npwd  Search in files and directories\ngrep  Word count\nwc  Create directory\nmkdir  Delete files and directories\nrm  Move and rename files\nmv  Copy files from internet to pwd\nwget  Viewing files\nless  File Exchange GUI applications\n Windows: WinSCP Mac OS X: CyberDuck Win/OS X/Linux: FileZilla  SCP command-line tool\nscp file user@remotehost:/home/user/ # From local to remote scp user@remotehost:/home/user/file . # From remote to local  STD IN/OUT/ERR, Redirect \u0026 Wildcards Wildcard * to specify many files\nfile.*  Redirect ls output to file\nls \u003e file  Specify file as input to command\ncommand \u003c myfile  Append output of command to file\ncommand \u003e\u003e myfile  Pipe STDOUT of one command to another command\ncommand1 | command2  Turn off progress info\ncommand \u003e /dev/null  Pipe output of grep to wc\ngrep pattern file | wc  Print STDERR to file\ngrep pattern nonexistingfile 2 \u003e mystderr  Homework Assignment (HW2) See HW2 page here.\nPermissions and ownership List directories and files\nls -al  The previous command shows something like this for each file/dir: drwxrwxrwx. The meaning of this syntax is as follows:\n d: directory rwx: read, write and execute permissions, respectively  first triplet: user permissions (u) second triplet: group permissions (g) third triplet: world permissions (o)    Example for assigning write and execute permissions to user, group and world\nchmod ugo+rx my_file   + causes the permissions selected to be added - causes them to be removed = causes them to be the only permissions that the file has.  When performing the same operation on many files with subdirectories then one can use -R for recursive behavior.\nchmod -R ugo+rx my_dir  Since directories have to be executable the capital X option can be useful which applies only to directories but not to files. The following will assign drwxr-xr-x to directories and -rw-r--r-- to files and hidden files.\nchmod -R ugo-x,u+rwX,go+rX,go-w ./* ./.[!.]*  Syntax for changing user \u0026 group ownership\nchown \u003cuser\u003e:\u003cgroup\u003e \u003cfile or dir\u003e  Symbolic Links Symbolic links are short nicknames to files and directories that save typing of their full paths.\nln -s original_filename new_nickname  Software and module system  Over 750 software tools are currently installed on HPCC Cluster Most common research databases used in bioinformatics are available Support of most common programming languages used in research computing A module system is used to facilitate the management of software tools. This includes any number of versions of each software. New software install requests can be sent to support@hpcc.ucr.edu. To use software manged under the module system, users need to learn using some basic commands. The most common commands are listed below.  Print available modules\nmodule avail  Print available modules starting with R\nmodule avail R  Load default module R\nmodule load R  Load specific module R version\nmodule load R/3.2.2  List loaded modules\nmodule list  Unload module R\nmodule unload R  Unload specific module R\nmodule unload R/3.2.3-dev  Big data storage Each user account on HPCC Cluster comes only with 20GB of disk space. Much more disk space is available in a dedicated bigdata directory. How much space depends on the subscription of each user group. The path of bigdata and bigdata-shared is as follows:\n /bigdata/labname/username /bigdata/labname/shared  All lab members share the same bigdata pool. The course number gen242 is used as labname for user accounts adminstered under GEN242.\nThe disk usage of home and bigdata can be monitored on the HPCC Cluster Dashboard.\nQueuing system: Slurm HPCC Cluster uses Slurm as queuing and load balancing system. To control user traffic, any type of compute intensive jobs need to be submitted via the sbatch or srun (see below) to the computer nodes. Much more detailed information on this topic can be found on these sites:\n UCR HPCC Manual Slurm Documentation Torque/Slurm Comparison Switching from Torque to Slurm Slurm Quick Start Tutorial  Job submission with sbatch Print information about queues/partitions available on a cluster.\nsinfo  Compute jobs are submitted with sbatch via a submission script (here script_name.sh).\nsbatch script_name.sh  The following sample submission script (script_name.sh) executes an R script named my_script.R.\n#!/bin/bash -l #SBATCH --nodes=1 #SBATCH --ntasks=1 #SBATCH --cpus-per-task=1 #SBATCH --mem-per-cpu=1G #SBATCH --time=1-00:15:00 # 1 day and 15 minutes #SBATCH --mail-user=useremail@address.com #SBATCH --mail-type=ALL #SBATCH --job-name=\"some_test\" #SBATCH -p batch # Choose queue/parition from: intel, batch, highmem, gpu, short Rscript my_script.R  Interactive session: logs user into node\nsrun --pty bash -l  Interactive session with specific resource requests\nsrun --x11 --partition=short --mem=2gb --cpus-per-task 4 --ntasks 1 --time 1:00:00 --pty bash -l  STDOUT and STDERROR of jobs will be written to files named slurm-\u003cjobid\u003e.out or to custom a file specified under #SBATCH --output in the submission script.\nMonitoring jobs with squeue List all jobs in queue\nsqueue  List jobs of a specific user\nsqueue -u \u003cuser\u003e  Print more detailed information about a job\nscontrol show job \u003cJOBID\u003e  Custom command to summarize and visualize cluster activity\njobMonitor  Deleting and altering jobs Delete a single job\nscancel -i \u003cJOBID\u003e  Delete all jobs of a user\nscancel -u \u003cusername\u003e  Delete all jobs of a certain name\nscancel --name \u003cmyJobName\u003e  Altering jobs with scontrol update. The below example changes the walltime (\u003cNEW_TIME\u003e) of a specific job (\u003cJOBID\u003e).\nscontrol update jobid=\u003cJOBID\u003e TimeLimit=\u003cNEW_TIME\u003e  Resource limits Resourse limits for users can be viewed as follows.\nsacctmgr show account $GROUP format=Account,User,Partition,GrpCPUs,GrpMem,GrpNodes --ass | grep $USER  Similarly, one can view the limits of the group a user belongs to.\nsacctmgr show account $GROUP format=Account,User,Partition,GrpCPUs,GrpMem,GrpNodes,GrpTRES%30 --ass | head -3  Text/code editors The following list includes examples of several widely used code editors.\n Vi/Vim/Neovim: Non-graphical (terminal-based) editor. Vi is guaranteed to be available on any system. Vim and Nvim (Neovim) are the improved versions of vi. Emacs: Non-graphical or window-based editor. You still need to know keystroke commands to use it. Installed on all Linux distributions and on most other Unix systems. Pico: Simple terminal-based editor available on most versions of Unix. Uses keystroke commands, but they are listed in logical fashion at bottom of screen. Nano: A simple terminal-based editor which is default on modern Debian systems. Atom: Modern text editor developed by GitHub project.  Why does it matter? To work efficiently on remote systems like a computer cluster, it is essential to learn how to work in a pure command-line interface. GUI environments like RStudio and similar coding environments are not suitable for this. In addition, there is a lot of value of knowing how to work in an environment that is not restricted to a specific programming language. Therefore, this class embraces RStudio where it is useful, but for working on remote systems like HPCC Cluster, it uses Nvim and Tmux. Both are useful for many programming languages. Combinded with the nvim-r plugin they also provide a powerful command-line working environment for R. The following provides a brief introduction to this environment.\nVim overview The following opens a file (here myfile) with nvim (or vim)\nnvim myfile.txt # for neovim (or 'vim myfile.txt' for vim)  Once you are in Nvim, there are three main modes: normal, insert and command mode. The most important commands for switching between the three modes are:\n i: The i key brings you from the normal mode to the insert mode. The latter is used for typing. Esc: The Esc key brings you from the insert mode back to the normal mode. :: The : key starts the command mode at the bottom of the screen.  Use the arrow keys to move your cursor in the text. Using Fn Up/Down key allows to page through the text quicker. In the following command overview, all commands starting with : need to be typed in the command mode. All other commands are typed in the normal mode after pushing the Esc key.\nImportant modifier keys to control vim/nvim\n :w: save changes to file. If you are in editing mode you have to hit Esc first. :q: quit file that has not been changed :wq: save and quit file :!q: quit file without saving any changes  Useful resources for learning vim/nvim  Interactive Vim Tutorial Official Vim Documentation HPCC Linux Manual  Nvim-R-Tmux essentials Terminal-based Working Environment for R: Nvim-R-Tmux.\n Nvim-R-Tmux IDE for R Basics Tmux is a terminal multiplexer that allows to split terminal windows and to detach/reattach to existing terminal sessions. Combinded with the nvim-r plugin it provides a powerful command-line working environment for R where users can send code from a script to the R console or command-line. Both tmux and the nvim-r plugin need to be installed on a system. On HPCC Cluster both are configured in each user account. If this is not the case then follow the quick configuration instructions given in the following subsection.\nQuick configuration in user accounts of UCR’s HPCC Skip these steps if Nvim-R-Tmux is already configured in your account. Or follow the detailed instructions to install Nvim-R-Tmux from scratch on your own system.\n Log in to your user account on HPCC and execute install_nvimRtmux. Alternatively, follow these step-by-step install commands. To enable the nvim-R-tmux environment, log out and in again. Follow usage instructions of next section.  Basic usage of Nvim-R-Tmux The official and much more detailed user manual for Nvim-R is available here. The following gives a short introduction into the basic usage of Nvim-R-Tmux:\n1. Start tmux session (optional)\nNote, running Nvim from within a tmux session is optional. Skip this step if tmux functionality is not required (e.g. reattaching to sessions on remote systems).\ntmux # starts a new tmux session tmux a # attaches to an existing session  2. Open nvim-connected R session\nOpen a *.R or *.Rmd file with nvim and intialize a connected R session with \\rf. This command can be remapped to other key combinations, e.g. uncommenting lines 10-12 in .config/nvim/init.vim will remap it to the F2 key. Note, the resulting split window among Nvim and R behaves like a split viewport in nvim or vim meaning the usage of Ctrl-w w followed by i and Esc is important for navigation.\nnvim myscript.R # or *.Rmd file  3. Send R code from nvim to the R pane\nSingle lines of code can be sent from nvim to the R console by pressing the space bar. To send several lines at once, one can select them in nvim’s visual mode and then hit the space bar. Please note, the default command for sending code lines in the nvim-r-plugin is \\l. This key binding has been remapped in the provided .config/nvim/init.vim file to the space bar. Most other key bindings (shortcuts) still start with the \\ as LocalLeader, e.g. \\rh opens the help for a function/object where the curser is located in nvim. More details on this are given below.\nImportant keybindings for nvim The main advantages of Neovim compared to Vim are its better performance and its built-in terminal emulator facilitating the communication among Neovim and interactive programming environments such as R. Since the Vim and Neovim environments are managed independently, one can run them in parallel on the same system without interfering with each other. The usage of Neovim is almost identical to Vim.\nNvim commands\n \\rf: opens vim-connected R session. If you do this the first time in your user account, you might be asked to create an R directory under ~/. If so approve this action by pressing y. spacebar: sends code from vim to R; here remapped in init.vim from default \\l :split or :vsplit: splits viewport (similar to pane split in tmux) gz: maximizes size of viewport in normal mode (similar to Tmux’s Ctrl-a z zoom utility) Ctrl-w w: jumps cursor to R viewport and back; toggle between insert (i) and command (Esc) mode is required for navigation and controlling the environment. Ctrl-w r: swaps viewports Ctrl-w =: resizes splits to equal size :resize \u003c+5 or -5\u003e: resizes height by specified value :vertical resize \u003c+5 or -5\u003e: resizes width by specified value Ctrl-w H or Ctrl-w K: toggles between horizontal/vertical splits Ctrl-spacebar: omni completion for R objects/functions when nvim is in insert mode. Note, this has been remapped in init.vim from difficult to type default Ctrl-x Ctrl-o. :h nvim-R: opens nvim-R’s user manual; navigation works the same as for any Vim/Nvim help document :Rhelp fct_name: opens help for a function from nvim’s command mode with text completion support Ctrl-s and Ctrl-x: freezes/unfreezes vim (some systems)  Important keybindings for tmux Pane-level commands\n Ctrl-a %: splits pane vertically Ctrl-a \": splits pane horizontally Ctrl-a o: jumps cursor to next pane Ctrl-a Ctrl-o: swaps panes Ctrl-a \u003cspace bar\u003e: rotates pane arrangement Ctrl-a Alt \u003cleft or right\u003e: resizes to left or right Ctrl-a Esc \u003cup or down\u003e: resizes to left or right  Window-level comands\n Ctrl-a n: switches to next tmux window Ctrl-a Ctrl-a: switches to previous tmux window Ctrl-a c: creates a new tmux window Ctrl-a 1: switches to specific tmux window selected by number  Session-level comands\n Ctrl-a d: detaches from current session Ctrl-a s: switch between available tmux sesssions $ tmux new -s \u003cname\u003e: starts new session with a specific name $ tmux ls: lists available tmux session(s) $ tmux attach -t \u003cid\u003e: attaches to specific tmux session $ tmux attach: reattaches to session $ tmux kill-session -t \u003cid\u003e: kills a specific tmux session Ctrl-a : kill-session: kills a session from tmux command mode that can be initiated with Ctrl-a :  Nvim IDEs for other languages For other languages, such as Bash, Python and Ruby, one can use the vimcmdline plugin for nvim (or vim). To install it, one needs to copy from the vimcmdline resository the directories ftplugin, plugin and syntax and their files to ~/.config/nvim/. For user accounts of UCR’s HPCC, the above install script install_nvimRtmux includes the install of vimcmdline (since 09-Jun-18).\nThe usage of vimcmdline is very similar to nvim-R. To start a connected terminal session, one opens with nvim a code file with the extension of a given language (e.g. *.sh for Bash or *.py for Python), while the corresponding interactive interpreter session is initiated by pressing the key sequence \\s (corresponds to \\rf under nvim-R). Subsequently, code lines can be sent with the space bar. More details are available here.\n","categories":"","description":"","excerpt":"  HPCC Cluster Overview The HPCC Cluster (formerly called biocluster) …","ref":"/tutorials/linux/linux/","tags":"","title":"Introduction to HPCC Cluster and Linux"},{"body":"Detailed course schedule Note: this schedule is preliminary and subject to changes.\n ","categories":"","description":"","excerpt":"Detailed course schedule Note: this schedule is preliminary and …","ref":"/about/schedule/","tags":"","title":"Course Schedule"},{"body":"       document.addEventListener(\"DOMContentLoaded\", function() { document.querySelector(\"h1\").className = \"title\"; });  document.addEventListener(\"DOMContentLoaded\", function() { var links = document.links; for (var i = 0, linksLength = links.length; i Overview What is R? R is a powerful statistical environment and programming language for the analysis and visualization of data. The associated Bioconductor and CRAN package repositories provide many additional R packages for statistical data analysis for a wide array of research areas. The R software is free and runs on all common operating systems.\nWhy Using R?  Complete statistical environment and programming language Efficient functions and data structures for data analysis Powerful graphics Access to fast growing number of analysis packages Most widely used language in bioinformatics Is standard for data mining and biostatistical analysis Technical advantages: free, open-source, available for all OSs  Books and Documentation  simpleR - Using R for Introductory Statistics (John Verzani, 2004) - URL Bioinformatics and Computational Biology Solutions Using R and Bioconductor (Gentleman et al., 2005) - URL More on this see “Finding Help” section in UCR Manual - URL  R Working Environments    R Projects and Interfaces\n Some R working environments with support for syntax highlighting and utilities to send code to the R console:\n RStudio: excellent choice for beginners (Cheat Sheet) Basic R code editors provided by Rguis gedit, Rgedit, RKWard, Eclipse, Tinn-R, Notepad++, NppToR Vim-R-Tmux: R working environment based on vim and tmux Emacs (ESS add-on package)  Example: RStudio New integrated development environment (IDE) for R. Highly functional for both beginners and advanced.\n   RStudio IDE\n Some userful shortcuts: Ctrl+Enter (send code), Ctrl+Shift+C (comment/uncomment), Ctrl+1/2 (switch window focus)\nExample: Nvim-R-Tmux Terminal-based Working Environment for R: Nvim-R-Tmux.\n   Nvim-R-Tmux IDE for R\n R Package Repositories  CRAN (\u003e11,000 packages) general data analysis - URL Bioconductor (\u003e1,100 packages) bioscience data analysis - URL Omegahat (\u003e90 packages) programming interfaces - URL  Installation of R Packages   Install R for your operating system from CRAN.\n  Install RStudio from RStudio.\n  Install CRAN Packages from R console like this:\ninstall.packages(c(\"pkg1\", \"pkg2\")) install.packages(\"pkg.zip\", repos=NULL)    Install Bioconductor packages as follows:\nsource(\"http://www.bioconductor.org/biocLite.R\") #library(BiocInstaller) BiocVersion() biocLite() biocLite(c(\"pkg1\", \"pkg2\"))    For more details consult the Bioc Install page and BiocInstaller package.\n  Getting Around Startup and Closing Behavior   Starting R: The R GUI versions, including RStudio, under Windows and Mac OS X can be opened by double-clicking their icons. Alternatively, one can start it by typing R in a terminal (default under Linux).\n  Startup/Closing Behavior: The R environment is controlled by hidden files in the startup directory: .RData, .Rhistory and .Rprofile (optional).\n  Closing R:\n  q()  Save workspace image? [y/n/c]:   Note: When responding with y, then the entire R workspace will be written to the .RData file which can become very large. Often it is sufficient to just save an analysis protocol in an R source file. This way one can quickly regenerate all data sets and objects.  Navigating directories Create an object with the assignment operator \u003c- or =\nobject \u003c- ...  List objects in current R session\nls()  Return content of current working directory\ndir()  Return path of current working directory\ngetwd()  Change current working directory\nsetwd(\"/home/user\")  Basic Syntax General R command syntax\nobject \u003c- function_name(arguments) object \u003c- object[arguments]  Finding help\n?function_name  Load a library/package\nlibrary(\"my_library\")  List functions defined by a library\nlibrary(help=\"my_library\")  Load library manual (PDF or HTML file)\nvignette(\"my_library\")  Execute an R script from within R\nsource(\"my_script.R\")  Execute an R script from command-line (the first of the three options is preferred)\n$ Rscript my_script.R $ R CMD BATCH my_script.R $ R --slave \u003c my_script.R  Data Types Numeric data Example: 1, 2, 3, ...\nx \u003c- c(1, 2, 3) x  ## [1] 1 2 3  is.numeric(x)  ## [1] TRUE  as.character(x)  ## [1] \"1\" \"2\" \"3\"  Character data Example: \"a\", \"b\", \"c\", ...\nx \u003c- c(\"1\", \"2\", \"3\") x  ## [1] \"1\" \"2\" \"3\"  is.character(x)  ## [1] TRUE  as.numeric(x)  ## [1] 1 2 3  Complex data Example: mix of both\nc(1, \"b\", 3)  ## [1] \"1\" \"b\" \"3\"  Logical data Example: TRUE of FALSE\nx \u003c- 1:10 \u003c 5 x  ## [1] TRUE TRUE TRUE TRUE FALSE FALSE FALSE FALSE FALSE FALSE  !x  ## [1] FALSE FALSE FALSE FALSE TRUE TRUE TRUE TRUE TRUE TRUE  which(x) # Returns index for the 'TRUE' values in logical vector  ## [1] 1 2 3 4  Data Objects Object types Vectors (1D) Definition: numeric or character\nmyVec \u003c- 1:10; names(myVec) \u003c- letters[1:10] myVec[1:5]  ## a b c d e ## 1 2 3 4 5  myVec[c(2,4,6,8)]  ## b d f h ## 2 4 6 8  myVec[c(\"b\", \"d\", \"f\")]  ## b d f ## 2 4 6  Factors (1D) Definition: vectors with grouping information\nfactor(c(\"dog\", \"cat\", \"mouse\", \"dog\", \"dog\", \"cat\"))  ## [1] dog cat mouse dog dog cat ## Levels: cat dog mouse  Matrices (2D) Definition: two dimensional structures with data of same type\nmyMA \u003c- matrix(1:30, 3, 10, byrow = TRUE) class(myMA)  ## [1] \"matrix\" \"array\"  myMA[1:2,]  ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] ## [1,] 1 2 3 4 5 6 7 8 9 10 ## [2,] 11 12 13 14 15 16 17 18 19 20  myMA[1, , drop=FALSE]  ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] ## [1,] 1 2 3 4 5 6 7 8 9 10  Data Frames (2D) Definition: two dimensional objects with data of variable types\nmyDF \u003c- data.frame(Col1=1:10, Col2=10:1) myDF[1:2, ]  ## Col1 Col2 ## 1 1 10 ## 2 2 9  Arrays Definition: data structure with one, two or more dimensions\nLists Definition: containers for any object type\nmyL \u003c- list(name=\"Fred\", wife=\"Mary\", no.children=3, child.ages=c(4,7,9)) myL  ## $name ## [1] \"Fred\" ## ## $wife ## [1] \"Mary\" ## ## $no.children ## [1] 3 ## ## $child.ages ## [1] 4 7 9  myL[[4]][1:2]  ## [1] 4 7  Functions Definition: piece of code\nmyfct \u003c- function(arg1, arg2, ...) { function_body }  Subsetting of data objects (1.) Subsetting by positive or negative index/position numbers\nmyVec \u003c- 1:26; names(myVec) \u003c- LETTERS myVec[1:4]  ## A B C D ## 1 2 3 4  (2.) Subsetting by same length logical vectors\nmyLog \u003c- myVec \u003e 10 myVec[myLog]  ## K L M N O P Q R S T U V W X Y Z ## 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26  (3.) Subsetting by field names\nmyVec[c(\"B\", \"K\", \"M\")]  ## B K M ## 2 11 13  (4.) Subset with $ sign: references a single column or list component by its name\niris$Species[1:8]  ## [1] setosa setosa setosa setosa setosa setosa setosa setosa ## Levels: setosa versicolor virginica  Important Utilities Combining Objects The c function combines vectors and lists\nc(1, 2, 3)  ## [1] 1 2 3  x \u003c- 1:3; y \u003c- 101:103 c(x, y)  ## [1] 1 2 3 101 102 103  iris$Species[1:8]  ## [1] setosa setosa setosa setosa setosa setosa setosa setosa ## Levels: setosa versicolor virginica  The cbind and rbind functions can be used to append columns and rows, respecively.\nma \u003c- cbind(x, y) ma  ## x y ## [1,] 1 101 ## [2,] 2 102 ## [3,] 3 103  rbind(ma, ma)  ## x y ## [1,] 1 101 ## [2,] 2 102 ## [3,] 3 103 ## [4,] 1 101 ## [5,] 2 102 ## [6,] 3 103  Accessing Dimensions of Objects Length and dimension information of objects\nlength(iris$Species)  ## [1] 150  dim(iris)  ## [1] 150 5  Accessing Name Slots of Objects Accessing row and column names of 2D objects\nrownames(iris)[1:8]  ## [1] \"1\" \"2\" \"3\" \"4\" \"5\" \"6\" \"7\" \"8\"  colnames(iris)  ## [1] \"Sepal.Length\" \"Sepal.Width\" \"Petal.Length\" \"Petal.Width\" \"Species\"  Return name field of vectors and lists\nnames(myVec)  ## [1] \"A\" \"B\" \"C\" \"D\" \"E\" \"F\" \"G\" \"H\" \"I\" \"J\" \"K\" \"L\" \"M\" \"N\" \"O\" \"P\" \"Q\" \"R\" \"S\" \"T\" \"U\" \"V\" \"W\" \"X\" ## [25] \"Y\" \"Z\"  names(myL)  ## [1] \"name\" \"wife\" \"no.children\" \"child.ages\"  Sorting Objects The function sort returns a vector in ascending or descending order\nsort(10:1)  ## [1] 1 2 3 4 5 6 7 8 9 10  The function order returns a sorting index for sorting an object\nsortindex \u003c- order(iris[,1], decreasing = FALSE) sortindex[1:12]  ## [1] 14 9 39 43 42 4 7 23 48 3 30 12  iris[sortindex,][1:2,]  ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 14 4.3 3.0 1.1 0.1 setosa ## 9 4.4 2.9 1.4 0.2 setosa  sortindex \u003c- order(-iris[,1]) # Same as decreasing=TRUE  Sorting multiple columns\niris[order(iris$Sepal.Length, iris$Sepal.Width),][1:2,]  ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 14 4.3 3.0 1.1 0.1 setosa ## 9 4.4 2.9 1.4 0.2 setosa  Operators and Calculations Comparison Operators Comparison operators: ==, !=, \u003c, \u003e, \u003c=, \u003e=\n1==1  ## [1] TRUE  Logical operators: AND: \u0026, OR: |, NOT: !\nx \u003c- 1:10; y \u003c- 10:1 x \u003e y \u0026 x \u003e 5  ## [1] FALSE FALSE FALSE FALSE FALSE TRUE TRUE TRUE TRUE TRUE  Basic Calculations To look up math functions, see Function Index here\nx + y  ## [1] 11 11 11 11 11 11 11 11 11 11  sum(x)  ## [1] 55  mean(x)  ## [1] 5.5  apply(iris[1:6,1:3], 1, mean)  ## 1 2 3 4 5 6 ## 3.333333 3.100000 3.066667 3.066667 3.333333 3.666667  Reading and Writing External Data Import of tabular data Import of a tab-delimited tabular file\nmyDF \u003c- read.delim(\"myData.xls\", sep=\"\\t\")  Import of Excel file. Note: working with tab- or comma-delimited files is more flexible and preferred.\nlibrary(gdata) myDF \u003c- read.xls\"myData.xls\")  Import of Google Sheets. The following example imports a sample Google Sheet from here. Detailed instructions for interacting from R with Google Sheets with the required googlesheets package are here.\nlibrary(\"googlesheets\"); library(\"dplyr\"); library(knitr) gs_auth() # Creates authorizaton token (.httr-oauth) in current directory if not present sheetid \u003c-\"1U-32UcwZP1k3saKeaH1mbvEAOfZRdNHNkWK2GI1rpPM\" gap \u003c- gs_key(sheetid) mysheet \u003c- gs_read(gap, skip=4) myDF \u003c- as.data.frame(mysheet) myDF  Export of tabular data write.table(myDF, file=\"myfile.xls\", sep=\"\\t\", quote=FALSE, col.names=NA)  Line-wise import myDF \u003c- readLines(\"myData.txt\")  Line-wise export writeLines(month.name, \"myData.txt\")  Export R object mylist \u003c- list(C1=iris[,1], C2=iris[,2]) # Example to export saveRDS(mylist, \"mylist.rds\")  Import R object mylist \u003c- readRDS(\"mylist.rds\")  Copy and paste into R On Windows/Linux systems\nread.delim(\"clipboard\")  On Mac OS X systems\nread.delim(pipe(\"pbpaste\"))  Copy and paste from R On Windows/Linux systems\nwrite.table(iris, \"clipboard\", sep=\"\\t\", col.names=NA, quote=F)  On Mac OS X systems\nzz \u003c- pipe('pbcopy', 'w') write.table(iris, zz, sep=\"\\t\", col.names=NA, quote=F) close(zz)  Homework 3A Homework 3A: Object Subsetting Routines and Import/Export\nUseful R Functions Unique entries Make vector entries unique with unique\nlength(iris$Sepal.Length)  ## [1] 150  length(unique(iris$Sepal.Length))  ## [1] 35  Count occurrences Count occurrences of entries with table\ntable(iris$Species)  ## ## setosa versicolor virginica ## 50 50 50  Aggregate data Compute aggregate statistics with aggregate\naggregate(iris[,1:4], by=list(iris$Species), FUN=mean, na.rm=TRUE)  ## Group.1 Sepal.Length Sepal.Width Petal.Length Petal.Width ## 1 setosa 5.006 3.428 1.462 0.246 ## 2 versicolor 5.936 2.770 4.260 1.326 ## 3 virginica 6.588 2.974 5.552 2.026  Intersect data Compute intersect between two vectors with %in%\nmonth.name %in% c(\"May\", \"July\")  ## [1] FALSE FALSE FALSE FALSE TRUE FALSE TRUE FALSE FALSE FALSE FALSE FALSE  Merge data frames Join two data frames by common field entries with merge (here row names by.x=0). To obtain only the common rows, change all=TRUE to all=FALSE. To merge on specific columns, refer to them by their position numbers or their column names.\nframe1 \u003c- iris[sample(1:length(iris[,1]), 30), ] frame1[1:2,]  ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 55 6.5 2.8 4.6 1.5 versicolor ## 49 5.3 3.7 1.5 0.2 setosa  dim(frame1)  ## [1] 30 5  my_result \u003c- merge(frame1, iris, by.x = 0, by.y = 0, all = TRUE) dim(my_result)  ## [1] 150 11  dplyr Environment Modern object classes and methods for handling data.frame like structures are provided by the dplyr and data.table packages. The following gives a short introduction to the usage and functionalities of the dplyr package. More detailed tutorials on this topic can be found here:\n dplyr: A Grammar of Data Manipulation Introduction to dplyr Tutorial on dplyr Cheatsheet for Joins from Jenny Bryan Tibbles Intro to data.table package Big data with dplyr and data.table Fast lookups with dplyr and data.table  Installation The dplyr environment has evolved into an ecosystem of packages. To simplify package management, one can install and load the entire collection via the tidyverse package. For more details on tidyverse see here.\ninstall.packages(\"tidyverse\")  Construct a tibble (tibble) library(tidyverse) as_tibble(iris) # coerce data.frame to tibble tbl  ## # A tibble: 150 x 5 ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cfct\u003e ## 1 5.1 3.5 1.4 0.2 setosa ## 2 4.9 3 1.4 0.2 setosa ## 3 4.7 3.2 1.3 0.2 setosa ## 4 4.6 3.1 1.5 0.2 setosa ## 5 5 3.6 1.4 0.2 setosa ## 6 5.4 3.9 1.7 0.4 setosa ## 7 4.6 3.4 1.4 0.3 setosa ## 8 5 3.4 1.5 0.2 setosa ## 9 4.4 2.9 1.4 0.2 setosa ## 10 4.9 3.1 1.5 0.1 setosa ## # … with 140 more rows  Alternative functions producing the same result include as_data_frame and tbl_df:\nas_data_frame(iris) tbl_df(iris)  Reading and writing tabular files While the base R read/write utilities can be used for data.frames, best time performance with the least amount of typing is achieved with the export/import functions from the readr package. For very large files the fread function from the data.table package achieves the best time performance.\nImport with readr Import functions provided by readr include:\n read_csv(): comma separated (CSV) files read_tsv(): tab separated files read_delim(): general delimited files read_fwf(): fixed width files read_table(): tabular files where colums are separated by white-space. read_log(): web log files  Create a sample tab delimited file for import\nwrite_tsv(iris, \"iris.txt\") # Creates sample file  Import with read_tsv\niris_df \u003c- read_tsv(\"iris.txt\") # Import with read_tbv from readr package iris_df  ## # A tibble: 150 x 5 ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cchr\u003e ## 1 5.1 3.5 1.4 0.2 setosa ## 2 4.9 3 1.4 0.2 setosa ## 3 4.7 3.2 1.3 0.2 setosa ## 4 4.6 3.1 1.5 0.2 setosa ## 5 5 3.6 1.4 0.2 setosa ## 6 5.4 3.9 1.7 0.4 setosa ## 7 4.6 3.4 1.4 0.3 setosa ## 8 5 3.4 1.5 0.2 setosa ## 9 4.4 2.9 1.4 0.2 setosa ## 10 4.9 3.1 1.5 0.1 setosa ## # … with 140 more rows  To import Google Sheets directly into R, see here.\nFast table import with fread The fread function from the data.table package provides the best time performance for reading large tabular files into R.\nlibrary(data.table) iris_df \u003c- as_data_frame(fread(\"iris.txt\")) # Import with fread and conversion to tibble iris_df  ## # A tibble: 150 x 5 ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cchr\u003e ## 1 5.1 3.5 1.4 0.2 setosa ## 2 4.9 3 1.4 0.2 setosa ## 3 4.7 3.2 1.3 0.2 setosa ## 4 4.6 3.1 1.5 0.2 setosa ## 5 5 3.6 1.4 0.2 setosa ## 6 5.4 3.9 1.7 0.4 setosa ## 7 4.6 3.4 1.4 0.3 setosa ## 8 5 3.4 1.5 0.2 setosa ## 9 4.4 2.9 1.4 0.2 setosa ## 10 4.9 3.1 1.5 0.1 setosa ## # … with 140 more rows  Note: to ignore lines starting with comment signs, one can pass on to fread a shell command for preprocessing the file. The following example illustrates this option.\nfread(\"grep -v '^#' iris.txt\")  Export with readr Export function provided by readr inlcude\n write_delim(): general delimited files write_csv(): comma separated (CSV) files write_excel_csv(): excel style CSV files write_tsv(): tab separated files  For instance, the write_tsv function writes a data.frame or tibble to a tab delimited file with much nicer default settings than the base R write.table function.\nwrite_tsv(iris_df, \"iris.txt\")  Column and row binds The equivalents to base R’s rbind and cbind are bind_rows and bind_cols, respectively.\nbind_cols(iris_df, iris_df)  ## # A tibble: 150 x 10 ## Sepal.Length...1 Sepal.Width...2 Petal.Length...3 Petal.Width...4 Species...5 Sepal.Length...6 ## \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cchr\u003e \u003cdbl\u003e ## 1 5.1 3.5 1.4 0.2 setosa 5.1 ## 2 4.9 3 1.4 0.2 setosa 4.9 ## 3 4.7 3.2 1.3 0.2 setosa 4.7 ## 4 4.6 3.1 1.5 0.2 setosa 4.6 ## 5 5 3.6 1.4 0.2 setosa 5 ## 6 5.4 3.9 1.7 0.4 setosa 5.4 ## 7 4.6 3.4 1.4 0.3 setosa 4.6 ## 8 5 3.4 1.5 0.2 setosa 5 ## 9 4.4 2.9 1.4 0.2 setosa 4.4 ## 10 4.9 3.1 1.5 0.1 setosa 4.9 ## # … with 140 more rows, and 4 more variables: Sepal.Width...7 \u003cdbl\u003e, Petal.Length...8 \u003cdbl\u003e, ## # Petal.Width...9 \u003cdbl\u003e, Species...10 \u003cchr\u003e  bind_rows(iris_df, iris_df)  ## # A tibble: 300 x 5 ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cchr\u003e ## 1 5.1 3.5 1.4 0.2 setosa ## 2 4.9 3 1.4 0.2 setosa ## 3 4.7 3.2 1.3 0.2 setosa ## 4 4.6 3.1 1.5 0.2 setosa ## 5 5 3.6 1.4 0.2 setosa ## 6 5.4 3.9 1.7 0.4 setosa ## 7 4.6 3.4 1.4 0.3 setosa ## 8 5 3.4 1.5 0.2 setosa ## 9 4.4 2.9 1.4 0.2 setosa ## 10 4.9 3.1 1.5 0.1 setosa ## # … with 290 more rows  Extract column as vector The subsetting operators [[ and $can be used to extract from a tibble single columns as vector.\niris_df[[5]][1:12]  ## [1] \"setosa\" \"setosa\" \"setosa\" \"setosa\" \"setosa\" \"setosa\" \"setosa\" \"setosa\" \"setosa\" \"setosa\" ## [11] \"setosa\" \"setosa\"  iris_df$Species[1:12]  ## [1] \"setosa\" \"setosa\" \"setosa\" \"setosa\" \"setosa\" \"setosa\" \"setosa\" \"setosa\" \"setosa\" \"setosa\" ## [11] \"setosa\" \"setosa\"  Important dplyr functions  filter() and slice() arrange() select() and rename() distinct() mutate() and transmute() summarise() sample_n() and sample_frac()  Slice and filter functions Filter function filter(iris_df, Sepal.Length \u003e 7.5, Species==\"virginica\")  ## # A tibble: 6 x 5 ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cchr\u003e ## 1 7.6 3 6.6 2.1 virginica ## 2 7.7 3.8 6.7 2.2 virginica ## 3 7.7 2.6 6.9 2.3 virginica ## 4 7.7 2.8 6.7 2 virginica ## 5 7.9 3.8 6.4 2 virginica ## 6 7.7 3 6.1 2.3 virginica  Base R code equivalent iris_df[iris_df[, \"Sepal.Length\"] \u003e 7.5 \u0026 iris_df[, \"Species\"]==\"virginica\", ]  ## # A tibble: 6 x 5 ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cchr\u003e ## 1 7.6 3 6.6 2.1 virginica ## 2 7.7 3.8 6.7 2.2 virginica ## 3 7.7 2.6 6.9 2.3 virginica ## 4 7.7 2.8 6.7 2 virginica ## 5 7.9 3.8 6.4 2 virginica ## 6 7.7 3 6.1 2.3 virginica  Including boolean operators filter(iris_df, Sepal.Length \u003e 7.5 | Sepal.Length \u003c 5.5, Species==\"virginica\")  ## # A tibble: 7 x 5 ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cchr\u003e ## 1 7.6 3 6.6 2.1 virginica ## 2 4.9 2.5 4.5 1.7 virginica ## 3 7.7 3.8 6.7 2.2 virginica ## 4 7.7 2.6 6.9 2.3 virginica ## 5 7.7 2.8 6.7 2 virginica ## 6 7.9 3.8 6.4 2 virginica ## 7 7.7 3 6.1 2.3 virginica  Subset rows by position dplyr approach\nslice(iris_df, 1:2)  ## # A tibble: 2 x 5 ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cchr\u003e ## 1 5.1 3.5 1.4 0.2 setosa ## 2 4.9 3 1.4 0.2 setosa  Base R code equivalent\niris_df[1:2,]  ## # A tibble: 2 x 5 ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cchr\u003e ## 1 5.1 3.5 1.4 0.2 setosa ## 2 4.9 3 1.4 0.2 setosa  Subset rows by names Since tibbles do not contain row names, row wise subsetting via the [,] operator cannot be used. However, the corresponding behavior can be achieved by passing to select a row position index obtained by basic R intersect utilities such as match.\nCreate a suitable test tibble\ndf1 \u003c- bind_cols(data_frame(ids1=paste0(\"g\", 1:10)), as_data_frame(matrix(1:40, 10, 4, dimnames=list(1:10, paste0(\"CA\", 1:4))))) df1  ## # A tibble: 10 x 5 ## ids1 CA1 CA2 CA3 CA4 ## \u003cchr\u003e \u003cint\u003e \u003cint\u003e \u003cint\u003e \u003cint\u003e ## 1 g1 1 11 21 31 ## 2 g2 2 12 22 32 ## 3 g3 3 13 23 33 ## 4 g4 4 14 24 34 ## 5 g5 5 15 25 35 ## 6 g6 6 16 26 36 ## 7 g7 7 17 27 37 ## 8 g8 8 18 28 38 ## 9 g9 9 19 29 39 ## 10 g10 10 20 30 40  dplyr approach\nslice(df1, match(c(\"g10\", \"g4\", \"g4\"), df1$ids1))  ## # A tibble: 3 x 5 ## ids1 CA1 CA2 CA3 CA4 ## \u003cchr\u003e \u003cint\u003e \u003cint\u003e \u003cint\u003e \u003cint\u003e ## 1 g10 10 20 30 40 ## 2 g4 4 14 24 34 ## 3 g4 4 14 24 34  Base R equivalent\ndf1_old \u003c- as.data.frame(df1) rownames(df1_old) \u003c- df1_old[,1] df1_old[c(\"g10\", \"g4\", \"g4\"),]  ## ids1 CA1 CA2 CA3 CA4 ## g10 g10 10 20 30 40 ## g4 g4 4 14 24 34 ## g4.1 g4 4 14 24 34  Sorting with arrange Row-wise ordering based on specific columns\ndplyr approach\narrange(iris_df, Species, Sepal.Length, Sepal.Width)  ## # A tibble: 150 x 5 ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cchr\u003e ## 1 4.3 3 1.1 0.1 setosa ## 2 4.4 2.9 1.4 0.2 setosa ## 3 4.4 3 1.3 0.2 setosa ## 4 4.4 3.2 1.3 0.2 setosa ## 5 4.5 2.3 1.3 0.3 setosa ## 6 4.6 3.1 1.5 0.2 setosa ## 7 4.6 3.2 1.4 0.2 setosa ## 8 4.6 3.4 1.4 0.3 setosa ## 9 4.6 3.6 1 0.2 setosa ## 10 4.7 3.2 1.3 0.2 setosa ## # … with 140 more rows  For ordering descendingly use desc() function\narrange(iris_df, desc(Species), Sepal.Length, Sepal.Width)  ## # A tibble: 150 x 5 ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cchr\u003e ## 1 4.9 2.5 4.5 1.7 virginica ## 2 5.6 2.8 4.9 2 virginica ## 3 5.7 2.5 5 2 virginica ## 4 5.8 2.7 5.1 1.9 virginica ## 5 5.8 2.7 5.1 1.9 virginica ## 6 5.8 2.8 5.1 2.4 virginica ## 7 5.9 3 5.1 1.8 virginica ## 8 6 2.2 5 1.5 virginica ## 9 6 3 4.8 1.8 virginica ## 10 6.1 2.6 5.6 1.4 virginica ## # … with 140 more rows  Base R code equivalent\niris_df[order(iris_df$Species, iris_df$Sepal.Length, iris_df$Sepal.Width), ]  ## # A tibble: 150 x 5 ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cchr\u003e ## 1 4.3 3 1.1 0.1 setosa ## 2 4.4 2.9 1.4 0.2 setosa ## 3 4.4 3 1.3 0.2 setosa ## 4 4.4 3.2 1.3 0.2 setosa ## 5 4.5 2.3 1.3 0.3 setosa ## 6 4.6 3.1 1.5 0.2 setosa ## 7 4.6 3.2 1.4 0.2 setosa ## 8 4.6 3.4 1.4 0.3 setosa ## 9 4.6 3.6 1 0.2 setosa ## 10 4.7 3.2 1.3 0.2 setosa ## # … with 140 more rows  iris_df[order(iris_df$Species, decreasing=TRUE), ]  ## # A tibble: 150 x 5 ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cchr\u003e ## 1 6.3 3.3 6 2.5 virginica ## 2 5.8 2.7 5.1 1.9 virginica ## 3 7.1 3 5.9 2.1 virginica ## 4 6.3 2.9 5.6 1.8 virginica ## 5 6.5 3 5.8 2.2 virginica ## 6 7.6 3 6.6 2.1 virginica ## 7 4.9 2.5 4.5 1.7 virginica ## 8 7.3 2.9 6.3 1.8 virginica ## 9 6.7 2.5 5.8 1.8 virginica ## 10 7.2 3.6 6.1 2.5 virginica ## # … with 140 more rows  Select columns with select Select specific columns\nselect(iris_df, Species, Petal.Length, Sepal.Length)  ## # A tibble: 150 x 3 ## Species Petal.Length Sepal.Length ## \u003cchr\u003e \u003cdbl\u003e \u003cdbl\u003e ## 1 setosa 1.4 5.1 ## 2 setosa 1.4 4.9 ## 3 setosa 1.3 4.7 ## 4 setosa 1.5 4.6 ## 5 setosa 1.4 5 ## 6 setosa 1.7 5.4 ## 7 setosa 1.4 4.6 ## 8 setosa 1.5 5 ## 9 setosa 1.4 4.4 ## 10 setosa 1.5 4.9 ## # … with 140 more rows  Select range of columns by name\nselect(iris_df, Sepal.Length : Petal.Width)  ## # A tibble: 150 x 4 ## Sepal.Length Sepal.Width Petal.Length Petal.Width ## \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e ## 1 5.1 3.5 1.4 0.2 ## 2 4.9 3 1.4 0.2 ## 3 4.7 3.2 1.3 0.2 ## 4 4.6 3.1 1.5 0.2 ## 5 5 3.6 1.4 0.2 ## 6 5.4 3.9 1.7 0.4 ## 7 4.6 3.4 1.4 0.3 ## 8 5 3.4 1.5 0.2 ## 9 4.4 2.9 1.4 0.2 ## 10 4.9 3.1 1.5 0.1 ## # … with 140 more rows  Drop specific columns (here range)\nselect(iris_df, -(Sepal.Length : Petal.Width))  ## # A tibble: 150 x 1 ## Species ## \u003cchr\u003e ## 1 setosa ## 2 setosa ## 3 setosa ## 4 setosa ## 5 setosa ## 6 setosa ## 7 setosa ## 8 setosa ## 9 setosa ## 10 setosa ## # … with 140 more rows  Renaming columns with rename dplyr approach\nrename(iris_df, new_col_name = Species)  ## # A tibble: 150 x 5 ## Sepal.Length Sepal.Width Petal.Length Petal.Width new_col_name ## \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cchr\u003e ## 1 5.1 3.5 1.4 0.2 setosa ## 2 4.9 3 1.4 0.2 setosa ## 3 4.7 3.2 1.3 0.2 setosa ## 4 4.6 3.1 1.5 0.2 setosa ## 5 5 3.6 1.4 0.2 setosa ## 6 5.4 3.9 1.7 0.4 setosa ## 7 4.6 3.4 1.4 0.3 setosa ## 8 5 3.4 1.5 0.2 setosa ## 9 4.4 2.9 1.4 0.2 setosa ## 10 4.9 3.1 1.5 0.1 setosa ## # … with 140 more rows  Base R code approach\ncolnames(iris_df)[colnames(iris_df)==\"Species\"] \u003c- \"new_col_names\"  Obtain unique rows with distinct dplyr approach\ndistinct(iris_df, Species, .keep_all=TRUE)  ## # A tibble: 3 x 5 ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cchr\u003e ## 1 5.1 3.5 1.4 0.2 setosa ## 2 7 3.2 4.7 1.4 versicolor ## 3 6.3 3.3 6 2.5 virginica  Base R code approach\niris_df[!duplicated(iris_df$Species),]  ## # A tibble: 3 x 5 ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cchr\u003e ## 1 5.1 3.5 1.4 0.2 setosa ## 2 7 3.2 4.7 1.4 versicolor ## 3 6.3 3.3 6 2.5 virginica  Add columns mutate The mutate function allows to append columns to existing ones.\nmutate(iris_df, Ratio = Sepal.Length / Sepal.Width, Sum = Sepal.Length + Sepal.Width)  ## # A tibble: 150 x 7 ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species Ratio Sum ## \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cchr\u003e \u003cdbl\u003e \u003cdbl\u003e ## 1 5.1 3.5 1.4 0.2 setosa 1.46 8.6 ## 2 4.9 3 1.4 0.2 setosa 1.63 7.9 ## 3 4.7 3.2 1.3 0.2 setosa 1.47 7.9 ## 4 4.6 3.1 1.5 0.2 setosa 1.48 7.7 ## 5 5 3.6 1.4 0.2 setosa 1.39 8.6 ## 6 5.4 3.9 1.7 0.4 setosa 1.38 9.3 ## 7 4.6 3.4 1.4 0.3 setosa 1.35 8 ## 8 5 3.4 1.5 0.2 setosa 1.47 8.4 ## 9 4.4 2.9 1.4 0.2 setosa 1.52 7.3 ## 10 4.9 3.1 1.5 0.1 setosa 1.58 8 ## # … with 140 more rows  transmute The transmute function does the same as mutate but drops existing columns\ntransmute(iris_df, Ratio = Sepal.Length / Sepal.Width, Sum = Sepal.Length + Sepal.Width)  ## # A tibble: 150 x 2 ## Ratio Sum ## \u003cdbl\u003e \u003cdbl\u003e ## 1 1.46 8.6 ## 2 1.63 7.9 ## 3 1.47 7.9 ## 4 1.48 7.7 ## 5 1.39 8.6 ## 6 1.38 9.3 ## 7 1.35 8 ## 8 1.47 8.4 ## 9 1.52 7.3 ## 10 1.58 8 ## # … with 140 more rows  bind_cols The bind_cols function is the equivalent of cbind in base R. To add rows, use the corresponding bind_rows function.\nbind_cols(iris_df, iris_df)  ## # A tibble: 150 x 10 ## Sepal.Length...1 Sepal.Width...2 Petal.Length...3 Petal.Width...4 Species...5 Sepal.Length...6 ## \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cchr\u003e \u003cdbl\u003e ## 1 5.1 3.5 1.4 0.2 setosa 5.1 ## 2 4.9 3 1.4 0.2 setosa 4.9 ## 3 4.7 3.2 1.3 0.2 setosa 4.7 ## 4 4.6 3.1 1.5 0.2 setosa 4.6 ## 5 5 3.6 1.4 0.2 setosa 5 ## 6 5.4 3.9 1.7 0.4 setosa 5.4 ## 7 4.6 3.4 1.4 0.3 setosa 4.6 ## 8 5 3.4 1.5 0.2 setosa 5 ## 9 4.4 2.9 1.4 0.2 setosa 4.4 ## 10 4.9 3.1 1.5 0.1 setosa 4.9 ## # … with 140 more rows, and 4 more variables: Sepal.Width...7 \u003cdbl\u003e, Petal.Length...8 \u003cdbl\u003e, ## # Petal.Width...9 \u003cdbl\u003e, Species...10 \u003cchr\u003e  Summarize data Summary calculation on single column\nsummarize(iris_df, mean(Petal.Length))  ## # A tibble: 1 x 1 ## `mean(Petal.Length)` ## \u003cdbl\u003e ## 1 3.76  Summary calculation on many columns\nsummarize_all(iris_df[,1:4], mean)  ## # A tibble: 1 x 4 ## Sepal.Length Sepal.Width Petal.Length Petal.Width ## \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e ## 1 5.84 3.06 3.76 1.20  Summarize by grouping column\nsummarize(group_by(iris_df, Species), mean(Petal.Length))  ## # A tibble: 3 x 2 ## Species `mean(Petal.Length)` ## \u003cchr\u003e \u003cdbl\u003e ## 1 setosa 1.46 ## 2 versicolor 4.26 ## 3 virginica 5.55  Aggregate summaries\nsummarize_all(group_by(iris_df, Species), mean)  ## # A tibble: 3 x 5 ## Species Sepal.Length Sepal.Width Petal.Length Petal.Width ## \u003cchr\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e ## 1 setosa 5.01 3.43 1.46 0.246 ## 2 versicolor 5.94 2.77 4.26 1.33 ## 3 virginica 6.59 2.97 5.55 2.03  Note: group_by does the looping for the user similar to aggregate or tapply.\nMerging tibbles The dplyr package provides several join functions for merging tibbles by a common key column similar to the merge function in base R. These *_join functions include:\n inner_join(): returns join only for rows matching among both tibbles full_join(): returns join for all (matching and non-matching) rows of two tibbles left_join(): returns join for all rows in first tibble right_join(): returns join for all rows in second tibble anti_join(): returns for first tibble only those rows that have no match in the second one  Sample tibbles to illustrate *.join functions.\ndf1 \u003c- bind_cols(data_frame(ids1=paste0(\"g\", 1:10)), as_data_frame(matrix(1:40, 10, 4, dimnames=list(1:10, paste0(\"CA\", 1:4))))) df1  ## # A tibble: 10 x 5 ## ids1 CA1 CA2 CA3 CA4 ## \u003cchr\u003e \u003cint\u003e \u003cint\u003e \u003cint\u003e \u003cint\u003e ## 1 g1 1 11 21 31 ## 2 g2 2 12 22 32 ## 3 g3 3 13 23 33 ## 4 g4 4 14 24 34 ## 5 g5 5 15 25 35 ## 6 g6 6 16 26 36 ## 7 g7 7 17 27 37 ## 8 g8 8 18 28 38 ## 9 g9 9 19 29 39 ## 10 g10 10 20 30 40  df2 \u003c- bind_cols(data_frame(ids2=paste0(\"g\", c(2,5,11,12))), as_data_frame(matrix(1:16, 4, 4, dimnames=list(1:4, paste0(\"CB\", 1:4))))) df2  ## # A tibble: 4 x 5 ## ids2 CB1 CB2 CB3 CB4 ## \u003cchr\u003e \u003cint\u003e \u003cint\u003e \u003cint\u003e \u003cint\u003e ## 1 g2 1 5 9 13 ## 2 g5 2 6 10 14 ## 3 g11 3 7 11 15 ## 4 g12 4 8 12 16  Inner join inner_join(df1, df2, by=c(\"ids1\"=\"ids2\"))  ## # A tibble: 2 x 9 ## ids1 CA1 CA2 CA3 CA4 CB1 CB2 CB3 CB4 ## \u003cchr\u003e \u003cint\u003e \u003cint\u003e \u003cint\u003e \u003cint\u003e \u003cint\u003e \u003cint\u003e \u003cint\u003e \u003cint\u003e ## 1 g2 2 12 22 32 1 5 9 13 ## 2 g5 5 15 25 35 2 6 10 14  Left join left_join(df1, df2, by=c(\"ids1\"=\"ids2\"))  ## # A tibble: 10 x 9 ## ids1 CA1 CA2 CA3 CA4 CB1 CB2 CB3 CB4 ## \u003cchr\u003e \u003cint\u003e \u003cint\u003e \u003cint\u003e \u003cint\u003e \u003cint\u003e \u003cint\u003e \u003cint\u003e \u003cint\u003e ## 1 g1 1 11 21 31 NA NA NA NA ## 2 g2 2 12 22 32 1 5 9 13 ## 3 g3 3 13 23 33 NA NA NA NA ## 4 g4 4 14 24 34 NA NA NA NA ## 5 g5 5 15 25 35 2 6 10 14 ## 6 g6 6 16 26 36 NA NA NA NA ## 7 g7 7 17 27 37 NA NA NA NA ## 8 g8 8 18 28 38 NA NA NA NA ## 9 g9 9 19 29 39 NA NA NA NA ## 10 g10 10 20 30 40 NA NA NA NA  Right join right_join(df1, df2, by=c(\"ids1\"=\"ids2\"))  ## # A tibble: 4 x 9 ## ids1 CA1 CA2 CA3 CA4 CB1 CB2 CB3 CB4 ## \u003cchr\u003e \u003cint\u003e \u003cint\u003e \u003cint\u003e \u003cint\u003e \u003cint\u003e \u003cint\u003e \u003cint\u003e \u003cint\u003e ## 1 g2 2 12 22 32 1 5 9 13 ## 2 g5 5 15 25 35 2 6 10 14 ## 3 g11 NA NA NA NA 3 7 11 15 ## 4 g12 NA NA NA NA 4 8 12 16  Full join full_join(df1, df2, by=c(\"ids1\"=\"ids2\"))  ## # A tibble: 12 x 9 ## ids1 CA1 CA2 CA3 CA4 CB1 CB2 CB3 CB4 ## \u003cchr\u003e \u003cint\u003e \u003cint\u003e \u003cint\u003e \u003cint\u003e \u003cint\u003e \u003cint\u003e \u003cint\u003e \u003cint\u003e ## 1 g1 1 11 21 31 NA NA NA NA ## 2 g2 2 12 22 32 1 5 9 13 ## 3 g3 3 13 23 33 NA NA NA NA ## 4 g4 4 14 24 34 NA NA NA NA ## 5 g5 5 15 25 35 2 6 10 14 ## 6 g6 6 16 26 36 NA NA NA NA ## 7 g7 7 17 27 37 NA NA NA NA ## 8 g8 8 18 28 38 NA NA NA NA ## 9 g9 9 19 29 39 NA NA NA NA ## 10 g10 10 20 30 40 NA NA NA NA ## 11 g11 NA NA NA NA 3 7 11 15 ## 12 g12 NA NA NA NA 4 8 12 16  Anti join anti_join(df1, df2, by=c(\"ids1\"=\"ids2\"))  ## # A tibble: 8 x 5 ## ids1 CA1 CA2 CA3 CA4 ## \u003cchr\u003e \u003cint\u003e \u003cint\u003e \u003cint\u003e \u003cint\u003e ## 1 g1 1 11 21 31 ## 2 g3 3 13 23 33 ## 3 g4 4 14 24 34 ## 4 g6 6 16 26 36 ## 5 g7 7 17 27 37 ## 6 g8 8 18 28 38 ## 7 g9 9 19 29 39 ## 8 g10 10 20 30 40  For additional join options users want to cosult the *_join help pages.\nChaining To simplify chaining of serveral operations, dplyr provides the %\u003e% operator, where x %\u003e% f(y) turns into f(x, y). This way one can pipe together multiple operations by writing them from left-to-right or top-to-bottom. This makes for easy to type and readable code.\nExample 1 Series of data manipulations and export\nread_tsv(\"iris.txt\") %\u003e% # Import with read_tbv from readr package as_tibble() %\u003e% # Declare tibble to use select(Sepal.Length:Species) %\u003e% # Select columns filter(Species==\"setosa\") %\u003e% # Filter rows by some value arrange(Sepal.Length) %\u003e% # Sort by some column mutate(Subtract=Petal.Length - Petal.Width) # Calculate and append  ## # A tibble: 50 x 6 ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species Subtract ## \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cchr\u003e \u003cdbl\u003e ## 1 4.3 3 1.1 0.1 setosa 1 ## 2 4.4 2.9 1.4 0.2 setosa 1.2 ## 3 4.4 3 1.3 0.2 setosa 1.1 ## 4 4.4 3.2 1.3 0.2 setosa 1.1 ## 5 4.5 2.3 1.3 0.3 setosa 1 ## 6 4.6 3.1 1.5 0.2 setosa 1.3 ## 7 4.6 3.4 1.4 0.3 setosa 1.10 ## 8 4.6 3.6 1 0.2 setosa 0.8 ## 9 4.6 3.2 1.4 0.2 setosa 1.2 ## 10 4.7 3.2 1.3 0.2 setosa 1.1 ## # … with 40 more rows  # write_tsv(\"iris.txt\") # Export to file, omitted here to show result  Example 2 Series of summary calculations for grouped data (group_by)\niris_df %\u003e% # Declare tibble to use group_by(Species) %\u003e% # Group by species summarize(Mean_Sepal.Length=mean(Sepal.Length), Max_Sepal.Length=max(Sepal.Length), Min_Sepal.Length=min(Sepal.Length), SD_Sepal.Length=sd(Sepal.Length), Total=n())  ## # A tibble: 3 x 6 ## Species Mean_Sepal.Length Max_Sepal.Length Min_Sepal.Length SD_Sepal.Length Total ## \u003cchr\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cdbl\u003e \u003cint\u003e ## 1 setosa 5.01 5.8 4.3 0.352 50 ## 2 versicolor 5.94 7 4.9 0.516 50 ## 3 virginica 6.59 7.9 4.9 0.636 50  Example 3 Combining dplyr chaining with ggplot\niris_df %\u003e% group_by(Species) %\u003e% summarize_all(mean) %\u003e% reshape2::melt(id.vars=c(\"Species\"), variable.name = \"Samples\", value.name=\"Values\") %\u003e% ggplot(aes(Samples, Values, fill = Species)) + geom_bar(position=\"dodge\", stat=\"identity\")  SQLite Databases SQLite is a lightweight relational database solution. The RSQLite package provides an easy to use interface to create, manage and query SQLite databases directly from R. Basic instructions for using SQLite from the command-line are available here. A short introduction to RSQLite is available here.\nLoading data into SQLite databases The following loads two data.frames derived from the iris data set (here mydf1 and mydf2) into an SQLite database (here test.db).\nlibrary(RSQLite) unlink(\"test.db\") # Delete any existing test.db mydb \u003c- dbConnect(SQLite(), \"test.db\") # Creates database file test.db mydf1 \u003c- data.frame(ids=paste0(\"id\", seq_along(iris[,1])), iris) mydf2 \u003c- mydf1[sample(seq_along(mydf1[,1]), 10),] dbWriteTable(mydb, \"mydf1\", mydf1) dbWriteTable(mydb, \"mydf2\", mydf2)  List names of tables in database dbListTables(mydb)  ## [1] \"mydf1\" \"mydf2\"  Import table into data.frame dbGetQuery(mydb, 'SELECT * FROM mydf2')  ## ids Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 1 id122 5.6 2.8 4.9 2.0 virginica ## 2 id68 5.8 2.7 4.1 1.0 versicolor ## 3 id26 5.0 3.0 1.6 0.2 setosa ## 4 id150 5.9 3.0 5.1 1.8 virginica ## 5 id77 6.8 2.8 4.8 1.4 versicolor ## 6 id59 6.6 2.9 4.6 1.3 versicolor ## 7 id45 5.1 3.8 1.9 0.4 setosa ## 8 id143 5.8 2.7 5.1 1.9 virginica ## 9 id20 5.1 3.8 1.5 0.3 setosa ## 10 id12 4.8 3.4 1.6 0.2 setosa  Query database dbGetQuery(mydb, 'SELECT * FROM mydf1 WHERE \"Sepal.Length\" \u003c 4.6')  ## ids Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 1 id9 4.4 2.9 1.4 0.2 setosa ## 2 id14 4.3 3.0 1.1 0.1 setosa ## 3 id39 4.4 3.0 1.3 0.2 setosa ## 4 id42 4.5 2.3 1.3 0.3 setosa ## 5 id43 4.4 3.2 1.3 0.2 setosa  Join tables The two tables can be joined on the shared ids column as follows.\ndbGetQuery(mydb, 'SELECT * FROM mydf1, mydf2 WHERE mydf1.ids = mydf2.ids')  ## ids Sepal.Length Sepal.Width Petal.Length Petal.Width Species ids Sepal.Length ## 1 id12 4.8 3.4 1.6 0.2 setosa id12 4.8 ## 2 id20 5.1 3.8 1.5 0.3 setosa id20 5.1 ## 3 id26 5.0 3.0 1.6 0.2 setosa id26 5.0 ## 4 id45 5.1 3.8 1.9 0.4 setosa id45 5.1 ## 5 id59 6.6 2.9 4.6 1.3 versicolor id59 6.6 ## 6 id68 5.8 2.7 4.1 1.0 versicolor id68 5.8 ## 7 id77 6.8 2.8 4.8 1.4 versicolor id77 6.8 ## 8 id122 5.6 2.8 4.9 2.0 virginica id122 5.6 ## 9 id143 5.8 2.7 5.1 1.9 virginica id143 5.8 ## 10 id150 5.9 3.0 5.1 1.8 virginica id150 5.9 ## Sepal.Width Petal.Length Petal.Width Species ## 1 3.4 1.6 0.2 setosa ## 2 3.8 1.5 0.3 setosa ## 3 3.0 1.6 0.2 setosa ## 4 3.8 1.9 0.4 setosa ## 5 2.9 4.6 1.3 versicolor ## 6 2.7 4.1 1.0 versicolor ## 7 2.8 4.8 1.4 versicolor ## 8 2.8 4.9 2.0 virginica ## 9 2.7 5.1 1.9 virginica ## 10 3.0 5.1 1.8 virginica  Graphics in R Advantages  Powerful environment for visualizing scientific data Integrated graphics and statistics infrastructure Publication quality graphics Fully programmable Highly reproducible Full LaTeX and Markdown support via knitr and R markdown Vast number of R packages with graphics utilities  Documentation for R Graphics General\n Graphics Task Page - URL R Graph Gallery - URL R Graphical Manual - URL Paul Murrell’s book R (Grid) Graphics - URL  Interactive graphics\n rggobi` (GGobi) - URL iplots - URL Open GL (rgl) - URL  Graphics Environments Viewing and saving graphics in R\n On-screen graphics postscript, pdf, svg jpeg, png, wmf, tiff, …  Four major graphic environments\n Low-level infrastructure   R Base Graphics (low- and high-level) grid: Manual  High-level infrastructure \\begin{itemize}   lattice: Manual, Intro, Book ggplot2: Manual, Intro, Book  Base Graphics: Overview Important high-level plotting functions\n plot: generic x-y plotting barplot: bar plots boxplot: box-and-whisker plot hist: histograms pie: pie charts dotchart: cleveland dot plots image, heatmap, contour, persp: functions to generate image-like plots qqnorm, qqline, qqplot: distribution comparison plots pairs, coplot: display of multivariant data  Help on graphics functions\n ?myfct ?plot ?par  Preferred Object Types  Matrices and data frames Vectors Named vectors  Scatter Plots Basic Scatter Plot Sample data set for subsequent plots\nset.seed(1410) y \u003c- matrix(runif(30), ncol=3, dimnames=list(letters[1:10], LETTERS[1:3]))  Plot data\nplot(y[,1], y[,2])  All pairs pairs(y)  With labels plot(y[,1], y[,2], pch=20, col=\"red\", main=\"Symbols and Labels\") text(y[,1]+0.03, y[,2], rownames(y))  More examples Print instead of symbols the row names\nplot(y[,1], y[,2], type=\"n\", main=\"Plot of Labels\") text(y[,1], y[,2], rownames(y))  Usage of important plotting parameters\ngrid(5, 5, lwd = 2) op \u003c- par(mar=c(8,8,8,8), bg=\"lightblue\") plot(y[,1], y[,2], type=\"p\", col=\"red\", cex.lab=1.2, cex.axis=1.2, cex.main=1.2, cex.sub=1, lwd=4, pch=20, xlab=\"x label\", ylab=\"y label\", main=\"My Main\", sub=\"My Sub\") par(op)  __Important arguments_\n mar: specifies the margin sizes around the plotting area in order: c(bottom, left, top, right) col: color of symbols pch: type of symbols, samples: example(points) lwd: size of symbols cex.*: control font sizes For details see ?par  Add regression line plot(y[,1], y[,2]) myline \u003c- lm(y[,2]~y[,1]); abline(myline, lwd=2)  summary(myline)  ## ## Call: ## lm(formula = y[, 2] ~ y[, 1]) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.40357 -0.17912 -0.04299 0.22147 0.46623 ## ## Coefficients: ## Estimate Std. Error t value Pr(\u003e|t|) ## (Intercept) 0.5764 0.2110 2.732 0.0258 * ## y[, 1] -0.3647 0.3959 -0.921 0.3839 ## --- ## Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 ## ## Residual standard error: 0.3095 on 8 degrees of freedom ## Multiple R-squared: 0.09589, Adjusted R-squared: -0.01712 ## F-statistic: 0.8485 on 1 and 8 DF, p-value: 0.3839  Log scale Same plot as above, but on log scale\nplot(y[,1], y[,2], log=\"xy\")  Add a mathematical expression plot(y[,1], y[,2]); text(y[1,1], y[1,2], expression(sum(frac(1,sqrt(x^2*pi)))), cex=1.3)  Homework 3B Homework 3B: Scatter Plots\nLine Plots Single data set plot(y[,1], type=\"l\", lwd=2, col=\"blue\")  Many Data Sets Plots line graph for all columns in data frame y. The split.screen function is used in this example in a for loop to overlay several line graphs in the same plot.\nsplit.screen(c(1,1))  ## [1] 1  plot(y[,1], ylim=c(0,1), xlab=\"Measurement\", ylab=\"Intensity\", type=\"l\", lwd=2, col=1) for(i in 2:length(y[1,])) { screen(1, new=FALSE) plot(y[,i], ylim=c(0,1), type=\"l\", lwd=2, col=i, xaxt=\"n\", yaxt=\"n\", ylab=\"\", xlab=\"\", main=\"\", bty=\"n\") }  close.screen(all=TRUE)  Bar Plots Basics barplot(y[1:4,], ylim=c(0, max(y[1:4,])+0.3), beside=TRUE, legend=letters[1:4]) text(labels=round(as.vector(as.matrix(y[1:4,])),2), x=seq(1.5, 13, by=1) + sort(rep(c(0,1,2), 4)), y=as.vector(as.matrix(y[1:4,]))+0.04)  Error Bars bar \u003c- barplot(m \u003c- rowMeans(y) * 10, ylim=c(0, 10)) stdev \u003c- sd(t(y)) arrows(bar, m, bar, m + stdev, length=0.15, angle = 90)  Histograms hist(y, freq=TRUE, breaks=10)  Density Plots plot(density(y), col=\"red\")  Pie Charts pie(y[,1], col=rainbow(length(y[,1]), start=0.1, end=0.8), clockwise=TRUE) legend(\"topright\", legend=row.names(y), cex=1.3, bty=\"n\", pch=15, pt.cex=1.8, col=rainbow(length(y[,1]), start=0.1, end=0.8), ncol=1)  Color Selection Utilities Default color palette and how to change it\npalette()  ## [1] \"black\" \"#DF536B\" \"#61D04F\" \"#2297E6\" \"#28E2E5\" \"#CD0BBC\" \"#F5C710\" \"gray62\"  palette(rainbow(5, start=0.1, end=0.2)) palette()  ## [1] \"#FF9900\" \"#FFBF00\" \"#FFE600\" \"#F2FF00\" \"#CCFF00\"  palette(\"default\")  The gray function allows to select any type of gray shades by providing values from 0 to 1\ngray(seq(0.1, 1, by= 0.2))  ## [1] \"#1A1A1A\" \"#4D4D4D\" \"#808080\" \"#B3B3B3\" \"#E6E6E6\"  Color gradients with colorpanel function from gplots library`\nlibrary(gplots) colorpanel(5, \"darkblue\", \"yellow\", \"white\")  ## [1] \"#00008B\" \"#808046\" \"#FFFF00\" \"#FFFF80\" \"#FFFFFF\"  Much more on colors in R see Earl Glynn’s color chart here\nSaving Graphics to File After the pdf() command all graphs are redirected to file test.pdf. Works for all common formats similarly: jpeg, png, ps, tiff, …\npdf(\"test.pdf\") plot(1:10, 1:10) dev.off()  Generates Scalable Vector Graphics (SVG) files that can be edited in vector graphics programs, such as InkScape.\nlibrary(\"RSvgDevice\") devSVG(\"test.svg\") plot(1:10, 1:10) dev.off()  Homework 3C Homework 3C: Bar Plots\nAnalysis Routine Overview The following exercise introduces a variety of useful data analysis utilities in R.\nAnalysis Routine: Data Import   Step 1: To get started with this exercise, direct your R session to a dedicated workshop directory and download into this directory the following sample tables. Then import the files into Excel and save them as tab delimited text files.\n MolecularWeight_tair7.xls TargetP_analysis_tair7.xls    Import the tables into R\nImport molecular weight table\nmy_mw \u003c- read.delim(file=\"MolecularWeight_tair7.xls\", header=T, sep=\"\\t\") my_mw[1:2,]  Import subcelluar targeting table\nmy_target \u003c- read.delim(file=\"TargetP_analysis_tair7.xls\", header=T, sep=\"\\t\") my_target[1:2,]  Online import of molecular weight table\nmy_mw \u003c- read.delim(file=\"http://faculty.ucr.edu/~tgirke/Documents/R_BioCond/Samples/MolecularWeight_tair7.xls\", header=T, sep=\"\\t\") my_mw[1:2,]  ## Sequence.id Molecular.Weight.Da. Residues ## 1 AT1G08520.1 83285 760 ## 2 AT1G08530.1 27015 257  Online import of subcelluar targeting table\nmy_target \u003c- read.delim(file=\"http://faculty.ucr.edu/~tgirke/Documents/R_BioCond/Samples/TargetP_analysis_tair7.xls\", header=T, sep=\"\\t\") my_target[1:2,]  ## GeneName Loc cTP mTP SP other ## 1 AT1G08520.1 C 0.822 0.137 0.029 0.039 ## 2 AT1G08530.1 C 0.817 0.058 0.010 0.100  Merging Data Frames  Step 2: Assign uniform gene ID column titles  colnames(my_target)[1] \u003c- \"ID\" colnames(my_mw)[1] \u003c- \"ID\"   Step 3: Merge the two tables based on common ID field  my_mw_target \u003c- merge(my_mw, my_target, by.x=\"ID\", by.y=\"ID\", all.x=T)   Step 4: Shorten one table before the merge and then remove the non-matching rows (NAs) in the merged file  my_mw_target2a \u003c- merge(my_mw, my_target[1:40,], by.x=\"ID\", by.y=\"ID\", all.x=T) # To remove non-matching rows, use the argument setting 'all=F'. my_mw_target2 \u003c- na.omit(my_mw_target2a) # Removes rows containing \"NAs\" (non-matching rows).   Homework 3D: How can the merge function in the previous step be executed so that only the common rows among the two data frames are returned? Prove that both methods - the two step version with na.omit and your method - return identical results. Homework 3E: Replace all NAs in the data frame my_mw_target2a with zeros.  Filtering Data  Step 5: Retrieve all records with a value of greater than 100,000 in ‘MW’ column and ‘C’ value in ‘Loc’ column (targeted to chloroplast).  query \u003c- my_mw_target[my_mw_target[, 2] \u003e 100000 \u0026 my_mw_target[, 4] == \"C\", ] query[1:4, ]  ## ID Molecular.Weight.Da. Residues Loc cTP mTP SP other ## 219 AT1G02730.1 132588 1181 C 0.972 0.038 0.008 0.045 ## 243 AT1G02890.1 136825 1252 C 0.748 0.529 0.011 0.013 ## 281 AT1G03160.1 100732 912 C 0.871 0.235 0.011 0.007 ## 547 AT1G05380.1 126360 1138 C 0.740 0.099 0.016 0.358  dim(query)  ## [1] 170 8   Homework 3F: How many protein entries in the my_mw_target data frame have a MW of greater then 4,000 and less then 5,000. Subset the data frame accordingly and sort it by MW to check that your result is correct.  String Substitutions  Step 6: Use a regular expression in a substitute function to generate a separate ID column that lacks the gene model extensions. \u003c\u003clabel=Exercise 4.7, eval=TRUE, echo=TRUE, keep.source=TRUE\u003e\u003e=  my_mw_target3 \u003c- data.frame(loci=gsub(\"\\\\..*\", \"\", as.character(my_mw_target[,1]), perl = TRUE), my_mw_target) my_mw_target3[1:3,1:8]  ## loci ID Molecular.Weight.Da. Residues Loc cTP mTP SP ## 1 AT1G01010 AT1G01010.1 49426 429 _ 0.10 0.090 0.075 ## 2 AT1G01020 AT1G01020.1 28092 245 * 0.01 0.636 0.158 ## 3 AT1G01020 AT1G01020.2 21711 191 * 0.01 0.636 0.158   Homework 3G: Retrieve those rows in my_mw_target3 where the second column contains the following identifiers: c(\"AT5G52930.1\", \"AT4G18950.1\", \"AT1G15385.1\", \"AT4G36500.1\", \"AT1G67530.1\"). Use the %in% function for this query. As an alternative approach, assign the second column to the row index of the data frame and then perform the same query again using the row index. Explain the difference of the two methods.  Calculations on Data Frames  Step 7: Count the number of duplicates in the loci column with the table function and append the result to the data frame with the cbind function.  mycounts \u003c- table(my_mw_target3[,1])[my_mw_target3[,1]] my_mw_target4 \u003c- cbind(my_mw_target3, Freq=mycounts[as.character(my_mw_target3[,1])])   Step 8: Perform a vectorized devision of columns 3 and 4 (average AA weight per protein)  data.frame(my_mw_target4, avg_AA_WT=(my_mw_target4[,3] / my_mw_target4[,4]))[1:2,5:11]  ## Loc cTP mTP SP other Freq.Var1 Freq.Freq ## 1 _ 0.10 0.090 0.075 0.925 AT1G01010 1 ## 2 * 0.01 0.636 0.158 0.448 AT1G01020 2   Step 9: Calculate for each row the mean and standard deviation across several columns  mymean \u003c- apply(my_mw_target4[,6:9], 1, mean) mystdev \u003c- apply(my_mw_target4[,6:9], 1, sd, na.rm=TRUE) data.frame(my_mw_target4, mean=mymean, stdev=mystdev)[1:2,5:12]  ## Loc cTP mTP SP other Freq.Var1 Freq.Freq mean ## 1 _ 0.10 0.090 0.075 0.925 AT1G01010 1 0.2975 ## 2 * 0.01 0.636 0.158 0.448 AT1G01020 2 0.3130  Plotting Example  Step 10: Generate scatter plot columns: ‘MW’ and ‘Residues’  plot(my_mw_target4[1:500,3:4], col=\"red\")  Export Results and Run Entire Exercise as Script  Step 11: Write the data frame my_mw_target4 into a tab-delimited text file and inspect it in Excel.  write.table(my_mw_target4, file=\"my_file.xls\", quote=F, sep=\"\\t\", col.names = NA)   Homework 3H: Write all commands from this exercise into an R script named exerciseRbasics.R, or download it from here. Then execute the script with the source function like this: source(\"exerciseRbasics.R\"). This will run all commands of this exercise and generate the corresponding output files in the current working directory.  source(\"exerciseRbasics.R\")  R Markdown Overview R Markdown combines markdown (an easy to write plain text format) with embedded R code chunks. When compiling R Markdown documents, the code components can be evaluated so that both the code and its output can be included in the final document. This makes analysis reports highly reproducible by allowing to automatically regenerate them when the underlying R code or data changes. R Markdown documents (.Rmd files) can be rendered to various formats including HTML and PDF. The R code in an .Rmd document is processed by knitr, while the resulting .md file is rendered by pandoc to the final output formats (e.g. HTML or PDF). Historically, R Markdown is an extension of the older Sweave/Latex environment. Rendering of mathematical expressions and reference management is also supported by R Markdown using embedded Latex syntax and Bibtex, respectively.\nQuick Start Install R Markdown install.packages(\"rmarkdown\")  Initialize a new R Markdown (Rmd) script To minimize typing, it can be helful to start with an R Markdown template and then modify it as needed. Note the file name of an R Markdown scirpt needs to have the extension .Rmd. Template files for the following examples are available here:\n R Markdown sample script: sample.Rmd Bibtex file for handling citations and reference section: bibtex.bib  Users want to download these files, open the sample.Rmd file with their preferred R IDE (e.g. RStudio, vim or emacs), initilize an R session and then direct their R session to the location of these two files.\nMetadata section The metadata section (YAML header) in an R Markdown script defines how it will be processed and rendered. The metadata section also includes both title, author, and date information as well as options for customizing the output format. For instance, PDF and HTML output can be defined with pdf_document and html_document, respectively. The BiocStyle:: prefix will use the formatting style of the BiocStyle package from Bioconductor.\n --- title: \"My First R Markdown Document\" author: \"Author: First Last\" date: \"Last update: 15 February, 2021\" output: BiocStyle::html_document: toc: true toc_depth: 3 fig_caption: yes fontsize: 14pt bibliography: bibtex.bib ---  Render Rmd script An R Markdown script can be evaluated and rendered with the following render command or by pressing the knit button in RStudio. The output_format argument defines the format of the output (e.g. html_document). The setting output_format=\"all\" will generate all supported output formats. Alternatively, one can specify several output formats in the metadata section as shown in the above example.\nrmarkdown::render(\"sample.Rmd\", clean=TRUE, output_format=\"html_document\")  The following shows two options how to run the rendering from the command-line.\n$ Rscript -e \"rmarkdown::render('sample.Rmd', clean=TRUE)\"  Alternatively, one can use a Makefile to evaluate and render an R Markdown script. A sample Makefile for rendering the above sample.Rmd can be downloaded here. To apply it to a custom Rmd file, one needs open the Makefile in a text editor and change the value assigned to MAIN (line 13) to the base name of the corresponding .Rmd file (e.g. assign systemPipeRNAseq if the file name is systemPipeRNAseq.Rmd). To execute the Makefile, run the following command from the command-line.\n$ make -B  R code chunks R Code Chunks can be embedded in an R Markdown script by using three backticks at the beginning of a new line along with arguments enclosed in curly braces controlling the behavior of the code. The following lines contain the plain R code. A code chunk is terminated by a new line starting with three backticks. The following shows an example of such a code chunk. Note the backslashes are not part of it. They have been added to print the code chunk syntax in this document.\n ```\\{r code_chunk_name, eval=FALSE\\} x \u003c- 1:10 ```  The following lists the most important arguments to control the behavior of R code chunks:\n r: specifies language for code chunk, here R chode_chunk_name: name of code chunk; this name needs to be unique eval: if assigned TRUE the code will be evaluated warning: if assigned FALSE warnings will not be shown message: if assigned FALSE messages will not be shown cache: if assigned TRUE results will be cached to reuse in future rendering instances fig.height: allows to specify height of figures in inches fig.width: allows to specify width of figures in inches  For more details on code chunk options see here.\nLearning Markdown The basic syntax of Markdown and derivatives like kramdown is extremely easy to learn. Rather than providing another introduction on this topic, here are some useful sites for learning Markdown:\n Markdown Intro on GitHub Markdown Cheet Sheet Markdown Basics from RStudio R Markdown Cheat Sheet kramdown Syntax  Tables There are several ways to render tables. First, they can be printed within the R code chunks. Second, much nicer formatted tables can be generated with the functions kable, pander or xtable. The following example uses kable from the knitr package.\nlibrary(knitr) kable(iris[1:12,])     Sepal.Length Sepal.Width Petal.Length Petal.Width Species     5.1 3.5 1.4 0.2 setosa   4.9 3.0 1.4 0.2 setosa   4.7 3.2 1.3 0.2 setosa   4.6 3.1 1.5 0.2 setosa   5.0 3.6 1.4 0.2 setosa   5.4 3.9 1.7 0.4 setosa   4.6 3.4 1.4 0.3 setosa   5.0 3.4 1.5 0.2 setosa   4.4 2.9 1.4 0.2 setosa   4.9 3.1 1.5 0.1 setosa   5.4 3.7 1.5 0.2 setosa   4.8 3.4 1.6 0.2 setosa    A much more elegant and powerful solution is to create fully interactive tables with the DT package. This JavaScirpt based environment provides a wrapper to the DataTables library using jQuery. The resulting tables can be sorted, queried and resized by the user. For an example see here.\nlibrary(DT) datatable(iris, filter = 'top', options = list( pageLength = 100, scrollX = TRUE, scrollY = \"600px\", autoWidth = TRUE ))   {\"x\":{\"filter\":\"top\",\"filterHTML\":\"\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n\",\"data\":[[\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\",\"11\",\"12\",\"13\",\"14\",\"15\",\"16\",\"17\",\"18\",\"19\",\"20\",\"21\",\"22\",\"23\",\"24\",\"25\",\"26\",\"27\",\"28\",\"29\",\"30\",\"31\",\"32\",\"33\",\"34\",\"35\",\"36\",\"37\",\"38\",\"39\",\"40\",\"41\",\"42\",\"43\",\"44\",\"45\",\"46\",\"47\",\"48\",\"49\",\"50\",\"51\",\"52\",\"53\",\"54\",\"55\",\"56\",\"57\",\"58\",\"59\",\"60\",\"61\",\"62\",\"63\",\"64\",\"65\",\"66\",\"67\",\"68\",\"69\",\"70\",\"71\",\"72\",\"73\",\"74\",\"75\",\"76\",\"77\",\"78\",\"79\",\"80\",\"81\",\"82\",\"83\",\"84\",\"85\",\"86\",\"87\",\"88\",\"89\",\"90\",\"91\",\"92\",\"93\",\"94\",\"95\",\"96\",\"97\",\"98\",\"99\",\"100\",\"101\",\"102\",\"103\",\"104\",\"105\",\"106\",\"107\",\"108\",\"109\",\"110\",\"111\",\"112\",\"113\",\"114\",\"115\",\"116\",\"117\",\"118\",\"119\",\"120\",\"121\",\"122\",\"123\",\"124\",\"125\",\"126\",\"127\",\"128\",\"129\",\"130\",\"131\",\"132\",\"133\",\"134\",\"135\",\"136\",\"137\",\"138\",\"139\",\"140\",\"141\",\"142\",\"143\",\"144\",\"145\",\"146\",\"147\",\"148\",\"149\",\"150\"],[5.1,4.9,4.7,4.6,5,5.4,4.6,5,4.4,4.9,5.4,4.8,4.8,4.3,5.8,5.7,5.4,5.1,5.7,5.1,5.4,5.1,4.6,5.1,4.8,5,5,5.2,5.2,4.7,4.8,5.4,5.2,5.5,4.9,5,5.5,4.9,4.4,5.1,5,4.5,4.4,5,5.1,4.8,5.1,4.6,5.3,5,7,6.4,6.9,5.5,6.5,5.7,6.3,4.9,6.6,5.2,5,5.9,6,6.1,5.6,6.7,5.6,5.8,6.2,5.6,5.9,6.1,6.3,6.1,6.4,6.6,6.8,6.7,6,5.7,5.5,5.5,5.8,6,5.4,6,6.7,6.3,5.6,5.5,5.5,6.1,5.8,5,5.6,5.7,5.7,6.2,5.1,5.7,6.3,5.8,7.1,6.3,6.5,7.6,4.9,7.3,6.7,7.2,6.5,6.4,6.8,5.7,5.8,6.4,6.5,7.7,7.7,6,6.9,5.6,7.7,6.3,6.7,7.2,6.2,6.1,6.4,7.2,7.4,7.9,6.4,6.3,6.1,7.7,6.3,6.4,6,6.9,6.7,6.9,5.8,6.8,6.7,6.7,6.3,6.5,6.2,5.9],[3.5,3,3.2,3.1,3.6,3.9,3.4,3.4,2.9,3.1,3.7,3.4,3,3,4,4.4,3.9,3.5,3.8,3.8,3.4,3.7,3.6,3.3,3.4,3,3.4,3.5,3.4,3.2,3.1,3.4,4.1,4.2,3.1,3.2,3.5,3.6,3,3.4,3.5,2.3,3.2,3.5,3.8,3,3.8,3.2,3.7,3.3,3.2,3.2,3.1,2.3,2.8,2.8,3.3,2.4,2.9,2.7,2,3,2.2,2.9,2.9,3.1,3,2.7,2.2,2.5,3.2,2.8,2.5,2.8,2.9,3,2.8,3,2.9,2.6,2.4,2.4,2.7,2.7,3,3.4,3.1,2.3,3,2.5,2.6,3,2.6,2.3,2.7,3,2.9,2.9,2.5,2.8,3.3,2.7,3,2.9,3,3,2.5,2.9,2.5,3.6,3.2,2.7,3,2.5,2.8,3.2,3,3.8,2.6,2.2,3.2,2.8,2.8,2.7,3.3,3.2,2.8,3,2.8,3,2.8,3.8,2.8,2.8,2.6,3,3.4,3.1,3,3.1,3.1,3.1,2.7,3.2,3.3,3,2.5,3,3.4,3],[1.4,1.4,1.3,1.5,1.4,1.7,1.4,1.5,1.4,1.5,1.5,1.6,1.4,1.1,1.2,1.5,1.3,1.4,1.7,1.5,1.7,1.5,1,1.7,1.9,1.6,1.6,1.5,1.4,1.6,1.6,1.5,1.5,1.4,1.5,1.2,1.3,1.4,1.3,1.5,1.3,1.3,1.3,1.6,1.9,1.4,1.6,1.4,1.5,1.4,4.7,4.5,4.9,4,4.6,4.5,4.7,3.3,4.6,3.9,3.5,4.2,4,4.7,3.6,4.4,4.5,4.1,4.5,3.9,4.8,4,4.9,4.7,4.3,4.4,4.8,5,4.5,3.5,3.8,3.7,3.9,5.1,4.5,4.5,4.7,4.4,4.1,4,4.4,4.6,4,3.3,4.2,4.2,4.2,4.3,3,4.1,6,5.1,5.9,5.6,5.8,6.6,4.5,6.3,5.8,6.1,5.1,5.3,5.5,5,5.1,5.3,5.5,6.7,6.9,5,5.7,4.9,6.7,4.9,5.7,6,4.8,4.9,5.6,5.8,6.1,6.4,5.6,5.1,5.6,6.1,5.6,5.5,4.8,5.4,5.6,5.1,5.1,5.9,5.7,5.2,5,5.2,5.4,5.1],[0.2,0.2,0.2,0.2,0.2,0.4,0.3,0.2,0.2,0.1,0.2,0.2,0.1,0.1,0.2,0.4,0.4,0.3,0.3,0.3,0.2,0.4,0.2,0.5,0.2,0.2,0.4,0.2,0.2,0.2,0.2,0.4,0.1,0.2,0.2,0.2,0.2,0.1,0.2,0.2,0.3,0.3,0.2,0.6,0.4,0.3,0.2,0.2,0.2,0.2,1.4,1.5,1.5,1.3,1.5,1.3,1.6,1,1.3,1.4,1,1.5,1,1.4,1.3,1.4,1.5,1,1.5,1.1,1.8,1.3,1.5,1.2,1.3,1.4,1.4,1.7,1.5,1,1.1,1,1.2,1.6,1.5,1.6,1.5,1.3,1.3,1.3,1.2,1.4,1.2,1,1.3,1.2,1.3,1.3,1.1,1.3,2.5,1.9,2.1,1.8,2.2,2.1,1.7,1.8,1.8,2.5,2,1.9,2.1,2,2.4,2.3,1.8,2.2,2.3,1.5,2.3,2,2,1.8,2.1,1.8,1.8,1.8,2.1,1.6,1.9,2,2.2,1.5,1.4,2.3,2.4,1.8,1.8,2.1,2.4,2.3,1.9,2.3,2.5,2.3,1.9,2,2.3,1.8],[\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\"]],\"container\":\"\\n \\n \\n  \\n Sepal.Length\\n Sepal.Width\\n Petal.Length\\n Petal.Width\\n Species\\n \\n \\n\",\"options\":{\"pageLength\":100,\"scrollX\":true,\"scrollY\":\"600px\",\"autoWidth\":true,\"columnDefs\":[{\"className\":\"dt-right\",\"targets\":[1,2,3,4]},{\"orderable\":false,\"targets\":0}],\"order\":[],\"orderClasses\":false,\"orderCellsTop\":true}},\"evals\":[],\"jsHooks\":[]} Figures Plots generated by the R code chunks in an R Markdown document can be automatically inserted in the output file. The size of the figure can be controlled with the fig.height and fig.width arguments.\nlibrary(ggplot2) dsmall \u003c- diamonds[sample(nrow(diamonds), 1000), ] ggplot(dsmall, aes(color, price/carat)) + geom_jitter(alpha = I(1 / 2), aes(color=color))  Sometimes it can be useful to explicitly write an image to a file and then insert that image into the final document by referencing its file name in the R Markdown source. For instance, this can be useful for time consuming analyses. The following code will generate a file named myplot.png. To insert the file in the final document, one can use standard Markdown or HTML syntax, e.g.: \u003cimg src=\"myplot.png\"/\u003e.\npng(\"images/myplot.png\") ggplot(dsmall, aes(color, price/carat)) + geom_jitter(alpha = I(1 / 2), aes(color=color)) dev.off()  ## png ## 2    Inline R code To evaluate R code inline, one can enclose an R expression with a single back-tick followed by r and then the actual expression. For instance, the back-ticked version of ‘r 1 + 1’ evaluates to 2 and ‘r pi’ evaluates to 3.1415927.\nMathematical equations To render mathematical equations, one can use standard Latex syntax. When expressions are enclosed with single $ signs then they will be shown inline, while enclosing them with double $$ signs will show them in display mode. For instance, the following Latex syntax d(X,Y) = \\sqrt[]{ \\sum_{i=1}^{n}{(x_{i}-y_{i})^2} } renders in display mode as follows:\n$$d(X,Y) = \\sqrt[]{ \\sum_{i=1}^{n}{(x_{i}-y_{i})^2} }$$\nCitations and bibliographies Citations and bibliographies can be autogenerated in R Markdown in a similar way as in Latex/Bibtex. Reference collections should be stored in a separate file in Bibtex or other supported formats. To cite a publication in an R Markdown script, one uses the syntax [@\u003cid1\u003e] where \u003cid1\u003e needs to be replaced with a reference identifier present in the Bibtex database listed in the metadata section of the R Markdown script (e.g. bibtex.bib). For instance, to cite Lawrence et al. (2013), one uses its reference identifier (e.g. Lawrence2013-kt) as \u003cid1\u003e (Lawrence et al. 2013). This will place the citation inline in the text and add the corresponding reference to a reference list at the end of the output document. For the latter a special section called References needs to be specified at the end of the R Markdown script. To fine control the formatting of citations and reference lists, users want to consult this the corresponding R Markdown page. Also, for general reference management and outputting references in Bibtex format Paperpile can be very helpful.\nViewing R Markdown report on HPCC cluster R Markdown reports located on UCR’s HPCC Cluster can be viewed locally in a web browser (without moving the source HTML) by creating a symbolic link from a user’s .html directory. This way any updates to the report can be viewed immediately without creating another copy of the HTML file. For instance, if user ttest has generated an R Markdown report under ~/bigdata/today/rmarkdown/sample.html, then the proper symbolic link to this file can be created as follows:\ncd ~/.html ln -s ~/bigdata/today/rmarkdown/sample.html sample.html  After this one can view the report in a web browser using this URL http://biocluster.ucr.edu/~ttest/rmarkdown/sample.html. If necessary access to the URL can be restricted with a password following the instructions here.\nA sample R Markdown report for an RNA-Seq project is given here:\n RNASeq.html{:target=\"_blank\"} RNASeq.Rmd{:target=\"_blank\"}  Shiny Web Apps What is Shiny? Shiny is an R-based environment for building interactive web applications for data analysis and exploration. Since most JavaScript code is autogenerated by the environment, basic R knowledge is sufficient for developing Shiny apps. They can be deployed on local computers or web servers including custom and cloud-based servers ( e.g. AWS, GCP, shinyapp.io service). The basic structure of a Shiny app is an app.R script containing the following components:\n  User interface\nui \u003c- fluidPage()    Server function\nserver \u003c- function(input, output) {}    Statement to run shiny app\nshinyApp(ui = ui, server = server)    Alternatively, the ui and server functions can be organized in two script files, a ui.R and a server.R script, respectively.\nDevelop and test Shiny app locally Open R and set session to parent directory (here myappdir) containing shiny script app.R, and the run it with the runApp() function. A sample app.R script for testing can be downloaded from here.\nlibrary(shiny) runApp(\"myappdir\") # To show code in app, add argument: display.mode=\"showcase\"  This will open the app in a web browser.\nDeploy on web server This can be done on local or cloud systems. An easy solution is to get an account on shinyapps.io and then deploy Shiny apps there. For details, see here.\nsetwd(\"myappdir\") library(rsconnect) deployApp()  Example Shiny app The following Shiny app is hosted on shinyapps.io and embedded into the markdown (or html) source of this page using the following iframe syntax:\n\u003ciframe src=\"https://tgirke.shinyapps.io/diamonds/\" style=\"border: none; width: 880px; height: 900px\"\u003e\u003c/iframe\u003e   Learning Shiny The Shiny section on the Rstudio site contains excellent tutorials. In addition, users may want to explore the example apps included in the shiny package. This can be done by loading the individual examples (see here) or saving the code to a user writable directory like this:\nmydir \u003c- system.file(\"examples\", package=\"shiny\") dir.create('my_shiny_test_dir') file.copy(mydir, \"my_shiny_test_dir\", recursive=TRUE) setwd(\"my_shiny_test_dir/examples\") runApp(\"01_hello\") # Runs first example app in directory dir() # Lists available Shiny examples (directories).  Session Info sessionInfo()  ## R version 4.0.3 (2020-10-10) ## Platform: x86_64-pc-linux-gnu (64-bit) ## Running under: Debian GNU/Linux 10 (buster) ## ## Matrix products: default ## BLAS: /usr/lib/x86_64-linux-gnu/blas/libblas.so.3.8.0 ## LAPACK: /usr/lib/x86_64-linux-gnu/lapack/liblapack.so.3.8.0 ## ## locale: ## [1] LC_CTYPE=en_US.UTF-8 LC_NUMERIC=C LC_TIME=en_US.UTF-8 ## [4] LC_COLLATE=en_US.UTF-8 LC_MONETARY=en_US.UTF-8 LC_MESSAGES=en_US.UTF-8 ## [7] LC_PAPER=en_US.UTF-8 LC_NAME=C LC_ADDRESS=C ## [10] LC_TELEPHONE=C LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C ## ## attached base packages: ## [1] stats graphics grDevices utils datasets methods base ## ## other attached packages: ## [1] knitr_1.30 gplots_3.1.1 RSQLite_2.2.1 data.table_1.13.2 forcats_0.5.0 ## [6] stringr_1.4.0 dplyr_1.0.2 purrr_0.3.4 readr_1.4.0 tidyr_1.1.2 ## [11] tibble_3.0.4 tidyverse_1.3.0 ggplot2_3.3.2 limma_3.46.0 BiocStyle_2.18.0 ## ## loaded via a namespace (and not attached): ## [1] httr_1.4.2 viridisLite_0.3.0 bit64_4.0.5 jsonlite_1.7.1 ## [5] modelr_0.1.8 gtools_3.8.2 assertthat_0.2.1 BiocManager_1.30.10 ## [9] highr_0.8 blob_1.2.1 cellranger_1.1.0 yaml_2.2.1 ## [13] pillar_1.4.7 backports_1.2.0 glue_1.4.2 digest_0.6.27 ## [17] rvest_0.3.6 colorspace_2.0-0 htmltools_0.5.1.1 plyr_1.8.6 ## [21] pkgconfig_2.0.3 broom_0.7.2 haven_2.3.1 bookdown_0.21 ## [25] scales_1.1.1 generics_0.1.0 farver_2.0.3 ellipsis_0.3.1 ## [29] withr_2.3.0 cli_2.2.0 magrittr_2.0.1 crayon_1.3.4 ## [33] readxl_1.3.1 memoise_1.1.0 evaluate_0.14 ps_1.4.0 ## [37] fs_1.5.0 fansi_0.4.1 xml2_1.3.2 blogdown_1.1.7 ## [41] tools_4.0.3 hms_0.5.3 lifecycle_0.2.0 munsell_0.5.0 ## [45] reprex_0.3.0 compiler_4.0.3 caTools_1.18.1 rlang_0.4.8 ## [49] grid_4.0.3 rstudioapi_0.13 bitops_1.0-6 labeling_0.4.2 ## [53] rmarkdown_2.5 gtable_0.3.0 codetools_0.2-16 DBI_1.1.0 ## [57] reshape2_1.4.4 R6_2.5.0 lubridate_1.7.9.2 bit_4.0.4 ## [61] utf8_1.1.4 KernSmooth_2.23-17 stringi_1.5.3 Rcpp_1.0.5 ## [65] vctrs_0.3.5 dbplyr_2.0.0 tidyselect_1.1.0 xfun_0.20  References Lawrence, Michael, Wolfgang Huber, Hervé Pagès, Patrick Aboyoun, Marc Carlson, Robert Gentleman, Martin T Morgan, and Vincent J Carey. 2013. “Software for Computing and Annotating Genomic Ranges.” PLoS Comput. Biol. 9 (8): e1003118. https://doi.org/10.1371/journal.pcbi.1003118.\n  ","categories":"","description":"","excerpt":"       document.addEventListener(\"DOMContentLoaded\", function() { …","ref":"/tutorials/rbasics/rbasics/","tags":"","title":"Introduction to R"},{"body":"Internal  This page provides links to password protected resources that are only accessible to the instructor and/or students enrolled in this class.\n  Course Planning Sheet GitHub: private repositories for course assignments (homework and course projects) GitHub Education: provides free extra benefits to students Piazza: for communication among students and instructor (please avoid email!) How to set up and maintain this site: see here  ","categories":"","description":"","excerpt":"Internal  This page provides links to password protected resources …","ref":"/about/internal/internal_resources/","tags":"","title":"Internal Resources"},{"body":"       R Markdown Overview R Markdown combines markdown (an easy to write plain text format) with embedded R code chunks. When compiling R Markdown documents, the code components can be evaluated so that both the code and its output can be included in the final document. This makes analysis reports highly reproducible by allowing to automatically regenerate them when the underlying R code or data changes. R Markdown documents (.Rmd files) can be rendered to various formats including HTML and PDF. The R code in an .Rmd document is processed by knitr, while the resulting .md file is rendered by pandoc to the final output formats (e.g. HTML or PDF). Historically, R Markdown is an extension of the older Sweave/Latex environment. Rendering of mathematical expressions and reference management is also supported by R Markdown using embedded Latex syntax and Bibtex, respectively.\nQuick Start Install R Markdown install.packages(\"rmarkdown\")  Initialize a new R Markdown (Rmd) script To minimize typing, it can be helful to start with an R Markdown template and then modify it as needed. Note the file name of an R Markdown scirpt needs to have the extension .Rmd. Template files for the following examples are available here:\n R Markdown sample script: sample.Rmd Bibtex file for handling citations and reference section: bibtex.bib  Users want to download these files, open the sample.Rmd file with their preferred R IDE (e.g. RStudio, vim or emacs), initilize an R session and then direct their R session to the location of these two files.\nMetadata section The metadata section (YAML header) in an R Markdown script defines how it will be processed and rendered. The metadata section also includes both title, author, and date information as well as options for customizing the output format. For instance, PDF and HTML output can be defined with pdf_document and html_document, respectively. The BiocStyle:: prefix will use the formatting style of the BiocStyle package from Bioconductor.\n --- title: \"My First R Markdown Document\" author: \"Author: First Last\" date: \"Last update: 15 February, 2021\" output: BiocStyle::html_document: toc: true toc_depth: 3 fig_caption: yes fontsize: 14pt bibliography: bibtex.bib ---  Render Rmd script An R Markdown script can be evaluated and rendered with the following render command or by pressing the knit button in RStudio. The output_format argument defines the format of the output (e.g. html_document). The setting output_format=\"all\" will generate all supported output formats. Alternatively, one can specify several output formats in the metadata section as shown in the above example.\nrmarkdown::render(\"sample.Rmd\", clean=TRUE, output_format=\"html_document\")  The following shows two options how to run the rendering from the command-line.\n$ Rscript -e \"rmarkdown::render('sample.Rmd', clean=TRUE)\"  Alternatively, one can use a Makefile to evaluate and render an R Markdown script. A sample Makefile for rendering the above sample.Rmd can be downloaded here. To apply it to a custom Rmd file, one needs open the Makefile in a text editor and change the value assigned to MAIN (line 13) to the base name of the corresponding .Rmd file (e.g. assign systemPipeRNAseq if the file name is systemPipeRNAseq.Rmd). To execute the Makefile, run the following command from the command-line.\n$ make -B  R code chunks R Code Chunks can be embedded in an R Markdown script by using three backticks at the beginning of a new line along with arguments enclosed in curly braces controlling the behavior of the code. The following lines contain the plain R code. A code chunk is terminated by a new line starting with three backticks. The following shows an example of such a code chunk. Note the backslashes are not part of it. They have been added to print the code chunk syntax in this document.\n ```\\{r code_chunk_name, eval=FALSE\\} x \u003c- 1:10 ```  The following lists the most important arguments to control the behavior of R code chunks:\n r: specifies language for code chunk, here R chode_chunk_name: name of code chunk; this name needs to be unique eval: if assigned TRUE the code will be evaluated warning: if assigned FALSE warnings will not be shown message: if assigned FALSE messages will not be shown cache: if assigned TRUE results will be cached to reuse in future rendering instances fig.height: allows to specify height of figures in inches fig.width: allows to specify width of figures in inches  For more details on code chunk options see here.\nLearning Markdown The basic syntax of Markdown and derivatives like kramdown is extremely easy to learn. Rather than providing another introduction on this topic, here are some useful sites for learning Markdown:\n Markdown Intro on GitHub Markdown Cheet Sheet Markdown Basics from RStudio R Markdown Cheat Sheet kramdown Syntax  Tables There are several ways to render tables. First, they can be printed within the R code chunks. Second, much nicer formatted tables can be generated with the functions kable, pander or xtable. The following example uses kable from the knitr package.\nlibrary(knitr) kable(iris[1:12,])     Sepal.Length Sepal.Width Petal.Length Petal.Width Species     5.1 3.5 1.4 0.2 setosa   4.9 3.0 1.4 0.2 setosa   4.7 3.2 1.3 0.2 setosa   4.6 3.1 1.5 0.2 setosa   5.0 3.6 1.4 0.2 setosa   5.4 3.9 1.7 0.4 setosa   4.6 3.4 1.4 0.3 setosa   5.0 3.4 1.5 0.2 setosa   4.4 2.9 1.4 0.2 setosa   4.9 3.1 1.5 0.1 setosa   5.4 3.7 1.5 0.2 setosa   4.8 3.4 1.6 0.2 setosa    A much more elegant and powerful solution is to create fully interactive tables with the DT package. This JavaScirpt based environment provides a wrapper to the DataTables library using jQuery. The resulting tables can be sorted, queried and resized by the user.\nlibrary(DT) datatable(iris, filter = 'top', options = list( pageLength = 100, scrollX = TRUE, scrollY = \"600px\", autoWidth = TRUE ))   {\"x\":{\"filter\":\"top\",\"filterHTML\":\"\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n\",\"data\":[[\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\",\"11\",\"12\",\"13\",\"14\",\"15\",\"16\",\"17\",\"18\",\"19\",\"20\",\"21\",\"22\",\"23\",\"24\",\"25\",\"26\",\"27\",\"28\",\"29\",\"30\",\"31\",\"32\",\"33\",\"34\",\"35\",\"36\",\"37\",\"38\",\"39\",\"40\",\"41\",\"42\",\"43\",\"44\",\"45\",\"46\",\"47\",\"48\",\"49\",\"50\",\"51\",\"52\",\"53\",\"54\",\"55\",\"56\",\"57\",\"58\",\"59\",\"60\",\"61\",\"62\",\"63\",\"64\",\"65\",\"66\",\"67\",\"68\",\"69\",\"70\",\"71\",\"72\",\"73\",\"74\",\"75\",\"76\",\"77\",\"78\",\"79\",\"80\",\"81\",\"82\",\"83\",\"84\",\"85\",\"86\",\"87\",\"88\",\"89\",\"90\",\"91\",\"92\",\"93\",\"94\",\"95\",\"96\",\"97\",\"98\",\"99\",\"100\",\"101\",\"102\",\"103\",\"104\",\"105\",\"106\",\"107\",\"108\",\"109\",\"110\",\"111\",\"112\",\"113\",\"114\",\"115\",\"116\",\"117\",\"118\",\"119\",\"120\",\"121\",\"122\",\"123\",\"124\",\"125\",\"126\",\"127\",\"128\",\"129\",\"130\",\"131\",\"132\",\"133\",\"134\",\"135\",\"136\",\"137\",\"138\",\"139\",\"140\",\"141\",\"142\",\"143\",\"144\",\"145\",\"146\",\"147\",\"148\",\"149\",\"150\"],[5.1,4.9,4.7,4.6,5,5.4,4.6,5,4.4,4.9,5.4,4.8,4.8,4.3,5.8,5.7,5.4,5.1,5.7,5.1,5.4,5.1,4.6,5.1,4.8,5,5,5.2,5.2,4.7,4.8,5.4,5.2,5.5,4.9,5,5.5,4.9,4.4,5.1,5,4.5,4.4,5,5.1,4.8,5.1,4.6,5.3,5,7,6.4,6.9,5.5,6.5,5.7,6.3,4.9,6.6,5.2,5,5.9,6,6.1,5.6,6.7,5.6,5.8,6.2,5.6,5.9,6.1,6.3,6.1,6.4,6.6,6.8,6.7,6,5.7,5.5,5.5,5.8,6,5.4,6,6.7,6.3,5.6,5.5,5.5,6.1,5.8,5,5.6,5.7,5.7,6.2,5.1,5.7,6.3,5.8,7.1,6.3,6.5,7.6,4.9,7.3,6.7,7.2,6.5,6.4,6.8,5.7,5.8,6.4,6.5,7.7,7.7,6,6.9,5.6,7.7,6.3,6.7,7.2,6.2,6.1,6.4,7.2,7.4,7.9,6.4,6.3,6.1,7.7,6.3,6.4,6,6.9,6.7,6.9,5.8,6.8,6.7,6.7,6.3,6.5,6.2,5.9],[3.5,3,3.2,3.1,3.6,3.9,3.4,3.4,2.9,3.1,3.7,3.4,3,3,4,4.4,3.9,3.5,3.8,3.8,3.4,3.7,3.6,3.3,3.4,3,3.4,3.5,3.4,3.2,3.1,3.4,4.1,4.2,3.1,3.2,3.5,3.6,3,3.4,3.5,2.3,3.2,3.5,3.8,3,3.8,3.2,3.7,3.3,3.2,3.2,3.1,2.3,2.8,2.8,3.3,2.4,2.9,2.7,2,3,2.2,2.9,2.9,3.1,3,2.7,2.2,2.5,3.2,2.8,2.5,2.8,2.9,3,2.8,3,2.9,2.6,2.4,2.4,2.7,2.7,3,3.4,3.1,2.3,3,2.5,2.6,3,2.6,2.3,2.7,3,2.9,2.9,2.5,2.8,3.3,2.7,3,2.9,3,3,2.5,2.9,2.5,3.6,3.2,2.7,3,2.5,2.8,3.2,3,3.8,2.6,2.2,3.2,2.8,2.8,2.7,3.3,3.2,2.8,3,2.8,3,2.8,3.8,2.8,2.8,2.6,3,3.4,3.1,3,3.1,3.1,3.1,2.7,3.2,3.3,3,2.5,3,3.4,3],[1.4,1.4,1.3,1.5,1.4,1.7,1.4,1.5,1.4,1.5,1.5,1.6,1.4,1.1,1.2,1.5,1.3,1.4,1.7,1.5,1.7,1.5,1,1.7,1.9,1.6,1.6,1.5,1.4,1.6,1.6,1.5,1.5,1.4,1.5,1.2,1.3,1.4,1.3,1.5,1.3,1.3,1.3,1.6,1.9,1.4,1.6,1.4,1.5,1.4,4.7,4.5,4.9,4,4.6,4.5,4.7,3.3,4.6,3.9,3.5,4.2,4,4.7,3.6,4.4,4.5,4.1,4.5,3.9,4.8,4,4.9,4.7,4.3,4.4,4.8,5,4.5,3.5,3.8,3.7,3.9,5.1,4.5,4.5,4.7,4.4,4.1,4,4.4,4.6,4,3.3,4.2,4.2,4.2,4.3,3,4.1,6,5.1,5.9,5.6,5.8,6.6,4.5,6.3,5.8,6.1,5.1,5.3,5.5,5,5.1,5.3,5.5,6.7,6.9,5,5.7,4.9,6.7,4.9,5.7,6,4.8,4.9,5.6,5.8,6.1,6.4,5.6,5.1,5.6,6.1,5.6,5.5,4.8,5.4,5.6,5.1,5.1,5.9,5.7,5.2,5,5.2,5.4,5.1],[0.2,0.2,0.2,0.2,0.2,0.4,0.3,0.2,0.2,0.1,0.2,0.2,0.1,0.1,0.2,0.4,0.4,0.3,0.3,0.3,0.2,0.4,0.2,0.5,0.2,0.2,0.4,0.2,0.2,0.2,0.2,0.4,0.1,0.2,0.2,0.2,0.2,0.1,0.2,0.2,0.3,0.3,0.2,0.6,0.4,0.3,0.2,0.2,0.2,0.2,1.4,1.5,1.5,1.3,1.5,1.3,1.6,1,1.3,1.4,1,1.5,1,1.4,1.3,1.4,1.5,1,1.5,1.1,1.8,1.3,1.5,1.2,1.3,1.4,1.4,1.7,1.5,1,1.1,1,1.2,1.6,1.5,1.6,1.5,1.3,1.3,1.3,1.2,1.4,1.2,1,1.3,1.2,1.3,1.3,1.1,1.3,2.5,1.9,2.1,1.8,2.2,2.1,1.7,1.8,1.8,2.5,2,1.9,2.1,2,2.4,2.3,1.8,2.2,2.3,1.5,2.3,2,2,1.8,2.1,1.8,1.8,1.8,2.1,1.6,1.9,2,2.2,1.5,1.4,2.3,2.4,1.8,1.8,2.1,2.4,2.3,1.9,2.3,2.5,2.3,1.9,2,2.3,1.8],[\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"setosa\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"versicolor\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\",\"virginica\"]],\"container\":\"\\n \\n \\n  \\n Sepal.Length\\n Sepal.Width\\n Petal.Length\\n Petal.Width\\n Species\\n \\n \\n\",\"options\":{\"pageLength\":100,\"scrollX\":true,\"scrollY\":\"600px\",\"autoWidth\":true,\"columnDefs\":[{\"className\":\"dt-right\",\"targets\":[1,2,3,4]},{\"orderable\":false,\"targets\":0}],\"order\":[],\"orderClasses\":false,\"orderCellsTop\":true}},\"evals\":[],\"jsHooks\":[]} Figures Plots generated by the R code chunks in an R Markdown document can be automatically inserted in the output file. The size of the figure can be controlled with the fig.height and fig.width arguments.\nlibrary(ggplot2) dsmall \u003c- diamonds[sample(nrow(diamonds), 1000), ] ggplot(dsmall, aes(color, price/carat)) + geom_jitter(alpha = I(1 / 2), aes(color=color))  Sometimes it can be useful to explicitly write an image to a file and then insert that image into the final document by referencing its file name in the R Markdown source. For instance, this can be useful for time consuming analyses. The following code will generate a file named myplot.png. To insert the file in the final document, one can use standard Markdown or HTML syntax, e.g.: \u003cimg src=\"myplot.png\"/\u003e.\npng(\"myplot.png\") ggplot(dsmall, aes(color, price/carat)) + geom_jitter(alpha = I(1 / 2), aes(color=color)) dev.off()  ## png ## 2    Inline R code To evaluate R code inline, one can enclose an R expression with a single back-tick followed by r and then the actual expression. For instance, the back-ticked version of ‘r 1 + 1’ evaluates to 2 and ‘r pi’ evaluates to 3.1415927.\nMathematical equations To render mathematical equations, one can use standard Latex syntax. When expressions are enclosed with single $ signs then they will be shown inline, while enclosing them with double $$ signs will show them in display mode. For instance, the following Latex syntax d(X,Y) = \\sqrt[]{ \\sum_{i=1}^{n}{(x_{i}-y_{i})^2} } renders in display mode as follows:\n$$d(X,Y) = \\sqrt[]{ \\sum_{i=1}^{n}{(x_{i}-y_{i})^2} }$$\nCitations and bibliographies Citations and bibliographies can be autogenerated in R Markdown in a similar way as in Latex/Bibtex. Reference collections should be stored in a separate file in Bibtex or other supported formats. To cite a publication in an R Markdown script, one uses the syntax [@\u003cid1\u003e] where \u003cid1\u003e needs to be replaced with a reference identifier present in the Bibtex database listed in the metadata section of the R Markdown script (e.g. bibtex.bib). For instance, to cite Lawrence et al. (2013), one uses its reference identifier (e.g. Lawrence2013-kt) as \u003cid1\u003e (Lawrence et al. 2013). This will place the citation inline in the text and add the corresponding reference to a reference list at the end of the output document. For the latter a special section called References needs to be specified at the end of the R Markdown script. To fine control the formatting of citations and reference lists, users want to consult this the corresponding R Markdown page. Also, for general reference management and outputting references in Bibtex format Paperpile can be very helpful.\nViewing R Markdown report on HPCC cluster R Markdown reports located on UCR’s HPCC Cluster can be viewed locally in a web browser (without moving the source HTML) by creating a symbolic link from a user’s .html directory. This way any updates to the report will show up immediately without creating another copy of the HTML file. For instance, if user ttest has generated an R Markdown report under ~/bigdata/today/rmarkdown/sample.html, then the symbolic link can be created as follows:\ncd ~/.html ln -s ~/bigdata/today/rmarkdown/sample.html sample.html  After this one can view the report in a web browser using this URL http://biocluster.ucr.edu/~ttest/rmarkdown/sample.html. If necessary access to the URL can be restricted with a password following the instructions here.\nSession Info sessionInfo()  ## R version 4.0.3 (2020-10-10) ## Platform: x86_64-pc-linux-gnu (64-bit) ## Running under: Debian GNU/Linux 10 (buster) ## ## Matrix products: default ## BLAS: /usr/lib/x86_64-linux-gnu/blas/libblas.so.3.8.0 ## LAPACK: /usr/lib/x86_64-linux-gnu/lapack/liblapack.so.3.8.0 ## ## locale: ## [1] LC_CTYPE=en_US.UTF-8 LC_NUMERIC=C ## [3] LC_TIME=en_US.UTF-8 LC_COLLATE=en_US.UTF-8 ## [5] LC_MONETARY=en_US.UTF-8 LC_MESSAGES=en_US.UTF-8 ## [7] LC_PAPER=en_US.UTF-8 LC_NAME=C ## [9] LC_ADDRESS=C LC_TELEPHONE=C ## [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C ## ## attached base packages: ## [1] stats graphics grDevices utils datasets methods base ## ## other attached packages: ## [1] ggplot2_3.3.2 DT_0.16 knitr_1.30 ## ## loaded via a namespace (and not attached): ## [1] compiler_4.0.3 pillar_1.4.7 highr_0.8 tools_4.0.3 ## [5] digest_0.6.27 viridisLite_0.3.0 jsonlite_1.7.1 evaluate_0.14 ## [9] lifecycle_0.2.0 tibble_3.0.4 gtable_0.3.0 pkgconfig_2.0.3 ## [13] rlang_0.4.8 crosstalk_1.1.0.1 yaml_2.2.1 blogdown_1.1.7 ## [17] xfun_0.20 withr_2.3.0 stringr_1.4.0 dplyr_1.0.2 ## [21] generics_0.1.0 htmlwidgets_1.5.2 vctrs_0.3.5 grid_4.0.3 ## [25] tidyselect_1.1.0 glue_1.4.2 R6_2.5.0 rmarkdown_2.5 ## [29] bookdown_0.21 farver_2.0.3 purrr_0.3.4 magrittr_2.0.1 ## [33] scales_1.1.1 htmltools_0.5.1.1 ellipsis_0.3.1 colorspace_2.0-0 ## [37] labeling_0.4.2 stringi_1.5.3 munsell_0.5.0 crayon_1.3.4  References Lawrence, Michael, Wolfgang Huber, Hervé Pagès, Patrick Aboyoun, Marc Carlson, Robert Gentleman, Martin T Morgan, and Vincent J Carey. 2013. “Software for Computing and Annotating Genomic Ranges.” PLoS Comput. Biol. 9 (8): e1003118. https://doi.org/10.1371/journal.pcbi.1003118.\n  ","categories":"","description":"","excerpt":"       R Markdown Overview R Markdown combines markdown (an easy to …","ref":"/tutorials/rbasics/sample/","tags":"","title":"Sample R Markdown"},{"body":"   This page provides instructions how to create new deployment instances of this teaching site, and how to configure and customize it. It uses the Docsy theme of the Hugo framework for building content driven websites.\n Quick start  Click on the Use this Template button. Choose a Repository Name Click on the Create repository from template button.  Usage locally  Go to your new repository that created from our template https://github.com/\u003cusername\u003e/\u003crepository_name\u003e Click on the Code button. Copy the URL https://github.com/\u003cusername\u003e/\u003crepository_name\u003e.git Open terminal  git clone --recurse-submodules --depth 1 https://github.com/\u003cusername\u003e/\u003crepository_name\u003e.git cd \u003crepository_name\u003e   Run the website locally  hugo server   Run the website locally with blogdown  blogdown::serve_site()  Prerequisites and Installation Install {blogdown} and Hugo blogdown installed.packages(\"rstudio/blogdown\") # If anything wrong try develop version remotes::install_github(\"rstudio/blogdown\")  Hugo You need a recent extended version (we recommend version 0.79.0 or later) of Hugo to do local builds and previews of sites that use Docsy.\nIt is recommended to install Hugo from R for working with {blogdown}\nblogdown::install_hugo(extended = TRUE)  or from commandline\nwget https://github.com/gohugoio/hugo/releases/download/v0.79.0/hugo_extended_0.79.0_Linux-64bit.deb sudo dpkg -i hugo_extended_0.79.0_Linux-64bit.deb hugo version  For Windows and macOS please see instructions here.\nInstall PostCSS To build or update your site’s CSS resources, you also need PostCSS to create the final assets. If you need to install it, you must have a recent version of NodeJS installed on your machine so you can use npm, the Node package manager. By default npm installs tools under the directory where you run npm install:\nsudo npm install -D autoprefixer sudo npm install -D postcss-cli # Starting in version 8 of postcss-cli, you must also separately install postcss: sudo npm install -D postcss # go to your website directory cd \u003crepository_name\u003e npm audit fix  Run the website locally with {blogdown}  Open R in console or Rstudio  This repo contains a .Rprofile file that will automatically serve the site for you R starting directory is this newly cloned repository. Otherwise, change working directory to the repository and run:\nblogdown::serve_site()  You should see a website is opened in your local browser or Rstudio viewer.\nRun the website locally on the terminal cd YOUR_NEW_REPO_PATH hugo server  ","categories":"","description":"","excerpt":"   This page provides instructions how to create new deployment …","ref":"/about/internal/install/","tags":"","title":"Deployment and Maintenance of this Site"},{"body":"document.addEventListener(\"DOMContentLoaded\", function() { document.querySelector(\"h1\").className = \"title\"; });  document.addEventListener(\"DOMContentLoaded\", function() { var links = document.links; for (var i = 0, linksLength = links.length; i Overview One of the main attractions of using the R (http://cran.at.r-project.org) environment is the ease with which users can write their own programs and custom functions. The R programming syntax is extremely easy to learn, even for users with no previous programming experience. Once the basic R programming control structures are understood, users can use the R language as a powerful environment to perform complex custom analyses of almost any type of data (Gentleman 2008).\nWhy Programming in R?  Powerful statistical environment and programming language Facilitates reproducible research Efficient data structures make programming very easy Ease of implementing custom functions Powerful graphics Access to fast growing number of analysis packages Most widely used language in bioinformatics Is standard for data mining and biostatistical analysis Technical advantages: free, open-source, available for all OSs  R Basics The previous Rbasics tutorial provides a general introduction to the usage of the R environment and its basic command syntax. More details can be found in the R \u0026 BioConductor manual here.\nCode Editors for R Several excellent code editors are available that provide functionalities like R syntax highlighting, auto code indenting and utilities to send code/functions to the R console.\n RStudio: GUI-based IDE for R Vim-R-Tmux: R working environment based on vim and tmux Emacs (ESS add-on package) gedit and Rgedit RKWard Eclipse Tinn-R Notepad++ (NppToR)   Programming in R using RStudio\n    Programming in R using Vim or Emacs\n   Finding Help Reference list on R programming (selection)\n Advanced R, by Hadley Wickham R Programming for Bioinformatics, by Robert Gentleman S Programming, by W. N. Venables and B. D. Ripley Programming with Data, by John M. Chambers R Help \u0026 R Coding Conventions, Henrik Bengtsson, Lund University Programming in R (Vincent Zoonekynd) Peter’s R Programming Pages, University of Warwick Rtips, Paul Johnsson, University of Kansas R for Programmers, Norm Matloff, UC Davis High-Performance R, Dirk Eddelbuettel tutorial presented at useR-2008 C/C++ level programming for R, Gopi Goswami  Control Structures Important Operators Comparison operators  == (equal) != (not equal) \u003e (greater than) \u003e= (greater than or equal) \u003c (less than) \u003c= (less than or equal)  Logical operators  \u0026 (and) | (or) ! (not)  Conditional Executions: if Statements An if statement operates on length-one logical vectors.\nSyntax\nif(TRUE) { statements_1 } else { statements_2 }  Example\nif(1==0) { print(1) } else { print(2) }  ## [1] 2  Conditional Executions: ifelse Statements The ifelse statement operates on vectors.\nSyntax\nifelse(test, true_value, false_value)  Example\nx \u003c- 1:10 ifelse(x\u003c5, x, 0)  ## [1] 1 2 3 4 0 0 0 0 0 0  Loops for loop for loops iterate over elements of a looping vector.\nSyntax\nfor(variable in sequence) { statements }  Example\nmydf \u003c- iris myve \u003c- NULL for(i in seq(along=mydf[,1])) { myve \u003c- c(myve, mean(as.numeric(mydf[i,1:3]))) } myve[1:8]  ## [1] 3.333333 3.100000 3.066667 3.066667 3.333333 3.666667 3.133333 3.300000  Note: Inject into objecs is much faster than append approach with c, cbind, etc.\nExample\nmyve \u003c- numeric(length(mydf[,1])) for(i in seq(along=myve)) { myve[i] \u003c- mean(as.numeric(mydf[i,1:3])) } myve[1:8]  ## [1] 3.333333 3.100000 3.066667 3.066667 3.333333 3.666667 3.133333 3.300000  Conditional Stop of Loops The stop function can be used to break out of a loop (or a function) when a condition becomes TRUE. In addition, an error message will be printed.\nExample\nx \u003c- 1:10 z \u003c- NULL for(i in seq(along=x)) { if(x[i] \u003c 5) { z \u003c- c(z, x[i]-1) } else { stop(\"values need to be \u003c 5\") } }  while loop Iterates as long as a condition is true.\nSyntax\nwhile(condition) { statements }  Example\nz \u003c- 0 while(z\u003c5) { z \u003c- z + 2 print(z) }  ## [1] 2 ## [1] 4 ## [1] 6  The apply Function Family apply Syntax\napply(X, MARGIN, FUN, ARGs)  Arguments\n X: array, matrix or data.frame MARGIN: 1 for rows, 2 for columns FUN: one or more functions ARGs: possible arguments for functions  Example\napply(iris[1:8,1:3], 1, mean)  ## 1 2 3 4 5 6 7 8 ## 3.333333 3.100000 3.066667 3.066667 3.333333 3.666667 3.133333 3.300000  tapply Applies a function to vector components that are defined by a factor.\nSyntax\ntapply(vector, factor, FUN)  Example\niris[1:2,]  ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 1 5.1 3.5 1.4 0.2 setosa ## 2 4.9 3.0 1.4 0.2 setosa  tapply(iris$Sepal.Length, iris$Species, mean)  ## setosa versicolor virginica ## 5.006 5.936 6.588  sapply and lapply Both apply a function to vector or list objects. The lapply function always returns a list object, while sapply returns vector or matrix objects when it is possible.\nExamples\nl \u003c- list(a = 1:10, beta = exp(-3:3), logic = c(TRUE,FALSE,FALSE,TRUE)) lapply(l, mean)  ## $a ## [1] 5.5 ## ## $beta ## [1] 4.535125 ## ## $logic ## [1] 0.5  sapply(l, mean)  ## a beta logic ## 5.500000 4.535125 0.500000  Often used in combination with a function definition:\nlapply(names(l), function(x) mean(l[[x]])) sapply(names(l), function(x) mean(l[[x]]))  Functions Function Overview A very useful feature of the R environment is the possibility to expand existing functions and to easily write custom functions. In fact, most of the R software can be viewed as a series of R functions.\nSyntax to define function\nmyfct \u003c- function(arg1, arg2, ...) { function_body }  Syntax to call functions\nmyfct(arg1=..., arg2=...)  The value returned by a function is the value of the function body, which is usually an unassigned final expression, e.g.: return()\nFunction Syntax Rules General\n Functions are defined by  The assignment with the keyword function The declaration of arguments/variables (arg1, arg2, ...) The definition of operations (function_body) that perform computations on the provided arguments. A function name needs to be assigned to call the function.    Naming\n Function names can be almost anything. However, the usage of names of existing functions should be avoided.  Arguments\n It is often useful to provide default values for arguments (e.g.: arg1=1:10). This way they don’t need to be provided in a function call. The argument list can also be left empty (myfct \u003c- function() { fct_body }) if a function is expected to return always the same value(s). The argument ... can be used to allow one function to pass on argument settings to another.  Body\n The actual expressions (commands/operations) are defined in the function body which should be enclosed by braces. The individual commands are separated by semicolons or new lines (preferred).  Usage\n Functions are called by their name followed by parentheses containing possible argument names. Empty parenthesis after the function name will result in an error message when a function requires certain arguments to be provided by the user. The function name alone will print the definition of a function.  Scope\n Variables created inside a function exist only for the life time of a function. Thus, they are not accessible outside of the function. To force variables in functions to exist globally, one can use the double assignment operator: \u003c\u003c-  Examples Define sample function\nmyfct \u003c- function(x1, x2=5) { z1 \u003c- x1 / x1 z2 \u003c- x2 * x2 myvec \u003c- c(z1, z2) return(myvec) }  Function usage\nApply function to values 2 and 5\nmyfct(x1=2, x2=5)  ## [1] 1 25  Run without argument names\nmyfct(2, 5)  ## [1] 1 25  Makes use of default value 5\nmyfct(x1=2)  ## [1] 1 25  Print function definition (often unintended)\nmyfct  ## function(x1, x2=5) { ## z1 \u003c- x1 / x1 ## z2 \u003c- x2 * x2 ## myvec \u003c- c(z1, z2) ## return(myvec) ## } ## \u003cbytecode: 0x5865ccde4df0\u003e  Useful Utilities Debugging Utilities Several debugging utilities are available for R. They include:\n traceback browser options(error=recover) options(error=NULL) debug  The Debugging in R page provides an overview of the available resources.\nRegular Expressions R’s regular expression utilities work similar as in other languages. To learn how to use them in R, one can consult the main help page on this topic with ?regexp.\nString matching with grep The grep function can be used for finding patterns in strings, here letter A in vector month.name.\nmonth.name[grep(\"A\", month.name)]  ## [1] \"April\" \"August\"  String substitution with gsub Example for using regular expressions to substitute a pattern by another one using a back reference. Remember: single escapes \\ need to be double escaped \\\\ in R.\ngsub('(i.*a)', 'xxx_\\\\1', \"virginica\", perl = TRUE)  ## [1] \"vxxx_irginica\"  Interpreting a Character String as Expression Some useful examples\nGenerates vector of object names in session\nmylist \u003c- ls() mylist[1]  ## [1] \"i\"  Executes 1st entry as expression\nget(mylist[1])  ## [1] 150  Alternative approach\neval(parse(text=mylist[1]))  ## [1] 150  Replacement, Split and Paste Functions for Strings Selected examples\nSubstitution with back reference which inserts in this example _ character\nx \u003c- gsub(\"(a)\",\"\\\\1_\", month.name[1], perl=T) x  ## [1] \"Ja_nua_ry\"  Split string on inserted character from above\nstrsplit(x,\"_\")  ## [[1]] ## [1] \"Ja\" \"nua\" \"ry\"  Reverse a character string by splitting first all characters into vector fields\npaste(rev(unlist(strsplit(x, NULL))), collapse=\"\")  ## [1] \"yr_aun_aJ\"  Time, Date and Sleep Selected examples\nReturn CPU (and other) times that an expression used (here ls)\nsystem.time(ls())  ## user system elapsed ## 0 0 0  Return the current system date and time\ndate()  ## [1] \"Sat Feb 13 18:30:39 2021\"  Pause execution of R expressions for a given number of seconds (e.g. in loop)\nSys.sleep(1)  Example Import of Specific File Lines with Regular Expression The following example demonstrates the retrieval of specific lines from an external file with a regular expression. First, an external file is created with the cat function, all lines of this file are imported into a vector with readLines, the specific elements (lines) are then retieved with the grep function, and the resulting lines are split into vector fields with strsplit.\ncat(month.name, file=\"zzz.txt\", sep=\"\\n\") x \u003c- readLines(\"zzz.txt\") x[1:6]  ## [1] \"January\" \"February\" \"March\" \"April\" \"May\" \"June\"  x \u003c- x[c(grep(\"^J\", as.character(x), perl = TRUE))] t(as.data.frame(strsplit(x, \"u\")))  ## [,1] [,2] ## c..Jan....ary.. \"Jan\" \"ary\" ## c..J....ne.. \"J\" \"ne\" ## c..J....ly.. \"J\" \"ly\"  Calling External Software External command-line software can be called with system. The following example calls blastall from R\nsystem(\"blastall -p blastp -i seq.fasta -d uniprot -o seq.blastp\")  ## Warning in system(\"blastall -p blastp -i seq.fasta -d uniprot -o seq.blastp\"): error in running ## command  Running R Scripts Possibilities for Executing R Scripts R console source(\"my_script.R\")  Command-line Rscript my_script.R # or just ./myscript.R after making it executable R CMD BATCH my_script.R # Alternative way 1 R --slave \u003c my_script.R # Alternative way 2  Passing arguments from command-line to R Create an R script named test.R with the following content:\nmyarg \u003c- commandArgs() print(iris[1:myarg[6], ])  Then run it from the command-line like this:\nRscript test.R 10  In the given example the number 10 is passed on from the command-line as an argument to the R script which is used to return to STDOUT the first 10 rows of the iris sample data. If several arguments are provided, they will be interpreted as one string and need to be split in R with the strsplit function. A more detailed example can be found here.\nBuilding R Packages Short Overview of Package Building Process R packages can be built with the package.skeleton function. The given example will create a directory named mypackage containing the skeleton of the package for all functions, methods and classes defined in the R script(s) passed on to the code_files argument. The basic structure of the package directory is described here. The package directory will also contain a file named Read-and-delete-me with instructions for completing the package:\npackage.skeleton(name=\"mypackage\", code_files=c(\"script1.R\", \"script2.R\"))  Once a package skeleton is available one can build the package from the command-line (Linux/OS X). This will create a tarball of the package with its version number encoded in the file name. Subequently, the package tarball needs to be checked for errors with:\nR CMD build mypackage R CMD check mypackage_1.0.tar.gz  Install package from source\ninstall.packages(\"mypackage_1.0.tar.gz\", repos=NULL)  For more details see here\nProgramming Exercises Exercise 1 for loop Task 1.1: Compute the mean of each row in myMA by applying the mean function in a for loop.\nmyMA \u003c- matrix(rnorm(500), 100, 5, dimnames=list(1:100, paste(\"C\", 1:5, sep=\"\"))) myve_for \u003c- NULL for(i in seq(along=myMA[,1])) { myve_for \u003c- c(myve_for, mean(as.numeric(myMA[i, ]))) } myResult \u003c- cbind(myMA, mean_for=myve_for) myResult[1:4, ]  ## C1 C2 C3 C4 C5 mean_for ## 1 1.7988703 0.785864023 1.2763288 0.2950553 0.9858471 1.02839310 ## 2 -0.9683694 2.724133446 -0.8274809 -0.3208423 -0.4600894 0.02947028 ## 3 -1.1476365 -0.002864923 1.2573494 0.9574395 1.0390970 0.42067691 ## 4 -0.3476123 0.639676778 -1.4706145 -1.3904486 -0.1612300 -0.54604574  while loop Task 1.2: Compute the mean of each row in myMA by applying the mean function in a while loop.\nz \u003c- 1 myve_while \u003c- NULL while(z \u003c= length(myMA[,1])) { myve_while \u003c- c(myve_while, mean(as.numeric(myMA[z, ]))) z \u003c- z + 1 } myResult \u003c- cbind(myMA, mean_for=myve_for, mean_while=myve_while) myResult[1:4, -c(1,2)]  ## C3 C4 C5 mean_for mean_while ## 1 1.2763288 0.2950553 0.9858471 1.02839310 1.02839310 ## 2 -0.8274809 -0.3208423 -0.4600894 0.02947028 0.02947028 ## 3 1.2573494 0.9574395 1.0390970 0.42067691 0.42067691 ## 4 -1.4706145 -1.3904486 -0.1612300 -0.54604574 -0.54604574  Task 1.3: Confirm that the results from both mean calculations are identical\nall(myResult[,6] == myResult[,7])  ## [1] TRUE  apply loop Task 1.4: Compute the mean of each row in myMA by applying the mean function in an apply loop\nmyve_apply \u003c- apply(myMA, 1, mean) myResult \u003c- cbind(myMA, mean_for=myve_for, mean_while=myve_while, mean_apply=myve_apply) myResult[1:4, -c(1,2)]  ## C3 C4 C5 mean_for mean_while mean_apply ## 1 1.2763288 0.2950553 0.9858471 1.02839310 1.02839310 1.02839310 ## 2 -0.8274809 -0.3208423 -0.4600894 0.02947028 0.02947028 0.02947028 ## 3 1.2573494 0.9574395 1.0390970 0.42067691 0.42067691 0.42067691 ## 4 -1.4706145 -1.3904486 -0.1612300 -0.54604574 -0.54604574 -0.54604574  Avoiding loops Task 1.5: When operating on large data sets it is much faster to use the rowMeans function\nmymean \u003c- rowMeans(myMA) myResult \u003c- cbind(myMA, mean_for=myve_for, mean_while=myve_while, mean_apply=myve_apply, mean_int=mymean) myResult[1:4, -c(1,2,3)]  ## C4 C5 mean_for mean_while mean_apply mean_int ## 1 0.2950553 0.9858471 1.02839310 1.02839310 1.02839310 1.02839310 ## 2 -0.3208423 -0.4600894 0.02947028 0.02947028 0.02947028 0.02947028 ## 3 0.9574395 1.0390970 0.42067691 0.42067691 0.42067691 0.42067691 ## 4 -1.3904486 -0.1612300 -0.54604574 -0.54604574 -0.54604574 -0.54604574  Exercise 2 Custom functions Task 2.1: Use the following code as basis to implement a function that allows the user to compute the mean for any combination of columns in a matrix or data frame. The first argument of this function should specify the input data set, the second the mathematical function to be passed on (e.g. mean, sd, max) and the third one should allow the selection of the columns by providing a grouping vector.\nmyMA \u003c- matrix(rnorm(100000), 10000, 10, dimnames=list(1:10000, paste(\"C\", 1:10, sep=\"\"))) myMA[1:2,]  ## C1 C2 C3 C4 C5 C6 C7 C8 C9 ## 1 0.2457294 1.0377898 -0.1467638 -0.3248598 0.6157826 -1.4879414 2.0392123 -0.08362708 0.5044756 ## 2 -0.8500019 -0.7396865 -0.2914722 1.0449035 0.4690041 -0.2100562 0.7917301 0.17614233 0.3136505 ## C10 ## 1 -0.6699119 ## 2 -0.6938574  myList \u003c- tapply(colnames(myMA), c(1,1,1,2,2,2,3,3,4,4), list) names(myList) \u003c- sapply(myList, paste, collapse=\"_\") myMAmean \u003c- sapply(myList, function(x) apply(myMA[,x], 1, mean)) myMAmean[1:4,]  ## C1_C2_C3 C4_C5_C6 C7_C8 C9_C10 ## 1 0.37891844 -0.39900621 0.9777926 -0.08271812 ## 2 -0.62705354 0.43461709 0.4839362 -0.19010345 ## 3 0.44567197 -0.03322511 -0.1556891 -0.56857498 ## 4 -0.07690464 0.66825754 -0.3142668 -0.43291652  Exercise 3 Nested loops to generate similarity matrices Task 3.1: Create a sample list populated with character vectors of different lengths\nsetlist \u003c- lapply(11:30, function(x) sample(letters, x, replace=TRUE)) names(setlist) \u003c- paste(\"S\", seq(along=setlist), sep=\"\") setlist[1:6]  ## $S1 ## [1] \"t\" \"y\" \"l\" \"w\" \"x\" \"c\" \"w\" \"i\" \"n\" \"v\" \"v\" ## ## $S2 ## [1] \"t\" \"f\" \"q\" \"z\" \"e\" \"g\" \"u\" \"m\" \"q\" \"t\" \"l\" \"f\" ## ## $S3 ## [1] \"j\" \"g\" \"t\" \"z\" \"l\" \"q\" \"p\" \"k\" \"a\" \"k\" \"s\" \"q\" \"y\" ## ## $S4 ## [1] \"y\" \"g\" \"j\" \"n\" \"a\" \"x\" \"h\" \"a\" \"t\" \"q\" \"f\" \"u\" \"p\" \"n\" ## ## $S5 ## [1] \"i\" \"c\" \"y\" \"e\" \"k\" \"u\" \"j\" \"v\" \"t\" \"u\" \"q\" \"w\" \"b\" \"q\" \"s\" ## ## $S6 ## [1] \"w\" \"i\" \"d\" \"u\" \"w\" \"m\" \"o\" \"u\" \"v\" \"k\" \"m\" \"t\" \"b\" \"h\" \"h\" \"v\"  Task 3.2: Compute the length for all pairwise intersects of the vectors stored in setlist. The intersects can be determined with the %in% function like this: sum(setlist[[1]] %in% setlist[[2]])\nsetlist \u003c- sapply(setlist, unique) olMA \u003c- sapply(names(setlist), function(x) sapply(names(setlist), function(y) sum(setlist[[x]] %in% setlist[[y]]))) olMA[1:12,]  ## S1 S2 S3 S4 S5 S6 S7 S8 S9 S10 S11 S12 S13 S14 S15 S16 S17 S18 S19 S20 ## S1 9 2 3 4 6 4 4 4 5 5 6 5 5 3 5 5 4 6 7 7 ## S2 2 9 5 5 4 3 4 5 4 6 4 6 5 7 5 4 5 7 5 7 ## S3 3 5 11 7 6 2 4 6 5 3 7 7 5 8 6 5 7 5 6 10 ## S4 4 5 7 12 5 3 6 6 3 6 5 6 6 8 7 6 8 6 7 9 ## S5 6 4 6 5 13 7 4 3 5 6 9 7 7 7 9 4 8 8 8 11 ## S6 4 3 2 3 7 11 3 3 4 7 6 8 4 6 6 6 8 9 7 8 ## S7 4 4 4 6 4 3 12 6 5 7 6 6 8 7 7 7 9 8 9 9 ## S8 4 5 6 6 3 3 6 10 7 5 5 5 6 7 4 7 6 5 7 9 ## S9 5 4 5 3 5 4 5 7 11 5 6 7 6 6 7 7 5 6 7 9 ## S10 5 6 3 6 6 7 7 5 5 14 6 8 6 8 7 9 8 8 11 9 ## S11 6 4 7 5 9 6 6 5 6 6 13 7 4 8 10 6 10 9 10 10 ## S12 5 6 7 6 7 8 6 5 7 8 7 15 6 10 8 9 10 10 7 11  Task 3.3 Plot the resulting intersect matrix as heat map. The image or the heatmap.2 function from the gplots library can be used for this.\nimage(olMA)  Exercise 4 Build your own R package Task 4.1: Save one or more of your functions to a file called script.R and build the package with the package.skeleton function.\npackage.skeleton(name=\"mypackage\", code_files=c(\"script1.R\"))  Task 4.2: Build tarball of the package\nsystem(\"R CMD build mypackage\")  Task 4.3: Install and use package\ninstall.packages(\"mypackage_1.0.tar.gz\", repos=NULL, type=\"source\") library(mypackage) ?myMAcomp # Opens help for function defined by mypackage  Homework 5 Reverse and complement of DNA Task 1: Write a RevComp function that returns the reverse and complement of a DNA sequence string. Include an argument that will allow to return only the reversed sequence, the complemented sequence or the reversed and complemented sequence. The following R functions will be useful for the implementation:\nx \u003c- c(\"ATGCATTGGACGTTAG\") x  ## [1] \"ATGCATTGGACGTTAG\"  x \u003c- substring(x, 1:nchar(x), 1:nchar(x)) x  ## [1] \"A\" \"T\" \"G\" \"C\" \"A\" \"T\" \"T\" \"G\" \"G\" \"A\" \"C\" \"G\" \"T\" \"T\" \"A\" \"G\"  x \u003c- rev(x) x  ## [1] \"G\" \"A\" \"T\" \"T\" \"G\" \"C\" \"A\" \"G\" \"G\" \"T\" \"T\" \"A\" \"C\" \"G\" \"T\" \"A\"  x \u003c- paste(x, collapse=\"\") x  ## [1] \"GATTGCAGGTTACGTA\"  chartr(\"ATGC\", \"TACG\", x)  ## [1] \"CTAACGTCCAATGCAT\"  Task 2: Write a function that applies the RevComp function to many sequences stored in a vector.\nTranslate DNA into Protein Task 3: Write a function that will translate one or many DNA sequences in all three reading frames into proteins. The following commands will simplify this task:\nAAdf \u003c- read.table(file=\"http://faculty.ucr.edu/~tgirke/Documents/R_BioCond/My_R_Scripts/AA.txt\", header=TRUE, sep=\"\\t\") AAdf[1:4,]  ## Codon AA_1 AA_3 AA_Full AntiCodon ## 1 TCA S Ser Serine TGA ## 2 TCG S Ser Serine CGA ## 3 TCC S Ser Serine GGA ## 4 TCT S Ser Serine AGA  AAv \u003c- as.character(AAdf[,2]) names(AAv) \u003c- AAdf[,1] AAv  ## TCA TCG TCC TCT TTT TTC TTA TTG TAT TAC TAA TAG TGT TGC TGA TGG CTA CTG CTC CTT CCA CCG CCC CCT CAT ## \"S\" \"S\" \"S\" \"S\" \"F\" \"F\" \"L\" \"L\" \"Y\" \"Y\" \"*\" \"*\" \"C\" \"C\" \"*\" \"W\" \"L\" \"L\" \"L\" \"L\" \"P\" \"P\" \"P\" \"P\" \"H\" ## CAC CAA CAG CGA CGG CGC CGT ATT ATC ATA ATG ACA ACG ACC ACT AAT AAC AAA AAG AGT AGC AGA AGG GTA GTG ## \"H\" \"Q\" \"Q\" \"R\" \"R\" \"R\" \"R\" \"I\" \"I\" \"I\" \"M\" \"T\" \"T\" \"T\" \"T\" \"N\" \"N\" \"K\" \"K\" \"S\" \"S\" \"R\" \"R\" \"V\" \"V\" ## GTC GTT GCA GCG GCC GCT GAT GAC GAA GAG GGA GGG GGC GGT ## \"V\" \"V\" \"A\" \"A\" \"A\" \"A\" \"D\" \"D\" \"E\" \"E\" \"G\" \"G\" \"G\" \"G\"  y \u003c- gsub(\"(...)\", \"\\\\1_\", x) y \u003c- unlist(strsplit(y, \"_\")) y \u003c- y[grep(\"^...$\", y)] AAv[y]  ## GAT TGC AGG TTA CGT ## \"D\" \"C\" \"R\" \"L\" \"R\"  Homework submission Submit the 3 functions in one well structured and annotated R script to the instructor. The script should include instructions on how to use the functions.\nDue date This homework is due on Thu, April 26th at 6:00 PM.\nHomework Solutions See here\nSession Info sessionInfo()  ## R version 4.0.3 (2020-10-10) ## Platform: x86_64-pc-linux-gnu (64-bit) ## Running under: Debian GNU/Linux 10 (buster) ## ## Matrix products: default ## BLAS: /usr/lib/x86_64-linux-gnu/blas/libblas.so.3.8.0 ## LAPACK: /usr/lib/x86_64-linux-gnu/lapack/liblapack.so.3.8.0 ## ## locale: ## [1] LC_CTYPE=en_US.UTF-8 LC_NUMERIC=C LC_TIME=en_US.UTF-8 ## [4] LC_COLLATE=en_US.UTF-8 LC_MONETARY=en_US.UTF-8 LC_MESSAGES=en_US.UTF-8 ## [7] LC_PAPER=en_US.UTF-8 LC_NAME=C LC_ADDRESS=C ## [10] LC_TELEPHONE=C LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C ## ## attached base packages: ## [1] stats graphics grDevices utils datasets methods base ## ## other attached packages: ## [1] ggplot2_3.3.2 limma_3.46.0 BiocStyle_2.18.0 ## ## loaded via a namespace (and not attached): ## [1] knitr_1.30 magrittr_2.0.1 tidyselect_1.1.0 munsell_0.5.0 ## [5] colorspace_2.0-0 R6_2.5.0 rlang_0.4.8 dplyr_1.0.2 ## [9] stringr_1.4.0 tools_4.0.3 grid_4.0.3 gtable_0.3.0 ## [13] xfun_0.20 withr_2.3.0 ellipsis_0.3.1 htmltools_0.5.1.1 ## [17] yaml_2.2.1 digest_0.6.27 tibble_3.0.4 lifecycle_0.2.0 ## [21] crayon_1.3.4 bookdown_0.21 purrr_0.3.4 BiocManager_1.30.10 ## [25] codetools_0.2-16 vctrs_0.3.5 glue_1.4.2 evaluate_0.14 ## [29] rmarkdown_2.5 blogdown_1.1.7 stringi_1.5.3 pillar_1.4.7 ## [33] compiler_4.0.3 generics_0.1.0 scales_1.1.1 pkgconfig_2.0.3  References Gentleman, Robert. 2008. R Programming for Bioinformatics (Chapman \u0026 Hall/CRC Computer Science \u0026 Data Analysis). 1 edition. Chapman; Hall/CRC. http://www.amazon.com/Programming-Bioinformatics-Chapman-Computer-Analysis/dp/1420063677.\n  ","categories":"","description":"","excerpt":"document.addEventListener(\"DOMContentLoaded\", function() { …","ref":"/tutorials/rprogramming/rprogramming/","tags":"","title":"Programming in R"},{"body":" This is a placeholder page that shows you how to use this template site.\n For Rmarkdown integrations and new features, read Rmarkdown section This template is provided by docsy. You can use this similar structure to build to docs.   This section is where the user documentation for your project lives - all the information your users need to understand and successfully use your project.\nFor large documentation sets we recommend adding content under the headings in this section, though if some or all of them don’t apply to your project feel free to remove them or add your own. You can see an example of a smaller Docsy documentation site in the Docsy User Guide, which lives in the Docsy theme repo if you’d like to copy its docs section.\nOther content such as marketing material, case studies, and community updates should live in the About and Community pages.\nFind out how to use the Docsy theme in the Docsy User Guide. You can learn more about how to organize your documentation (and how we organized this site) in Organizing Your Content.\n","categories":"","description":"","excerpt":" This is a placeholder page that shows you how to use this template …","ref":"/assignments/","tags":"","title":"Assignments"},{"body":" This is a placeholder page that shows you how to use this template site.\n For Rmarkdown integrations and new features, read Rmarkdown section This template is provided by docsy. You can use this similar structure to build to docs.   This section is where the user documentation for your project lives - all the information your users need to understand and successfully use your project.\nFor large documentation sets we recommend adding content under the headings in this section, though if some or all of them don’t apply to your project feel free to remove them or add your own. You can see an example of a smaller Docsy documentation site in the Docsy User Guide, which lives in the Docsy theme repo if you’d like to copy its docs section.\nOther content such as marketing material, case studies, and community updates should live in the About and Community pages.\nFind out how to use the Docsy theme in the Docsy User Guide. You can learn more about how to organize your documentation (and how we organized this site) in Organizing Your Content.\n","categories":"","description":"","excerpt":" This is a placeholder page that shows you how to use this template …","ref":"/assignments/homework/","tags":"","title":"Homework"},{"body":"","categories":"","description":"","excerpt":"","ref":"/blog/news/","tags":"","title":"News"},{"body":" This is a placeholder page that shows you how to use this template site.\n For Rmarkdown integrations and new features, read Rmarkdown section This template is provided by docsy. You can use this similar structure to build to docs.   This section is where the user documentation for your project lives - all the information your users need to understand and successfully use your project.\nFor large documentation sets we recommend adding content under the headings in this section, though if some or all of them don’t apply to your project feel free to remove them or add your own. You can see an example of a smaller Docsy documentation site in the Docsy User Guide, which lives in the Docsy theme repo if you’d like to copy its docs section.\nOther content such as marketing material, case studies, and community updates should live in the About and Community pages.\nFind out how to use the Docsy theme in the Docsy User Guide. You can learn more about how to organize your documentation (and how we organized this site) in Organizing Your Content.\n","categories":"","description":"","excerpt":" This is a placeholder page that shows you how to use this template …","ref":"/assignments/projects/","tags":"","title":"Projects"},{"body":"","categories":"","description":"","excerpt":"","ref":"/tutorials/","tags":"","title":"Tutorials"},{"body":"Welcome to GEN242, Spring 2021: The first meeting of this course will be on March 30, 2021\n","categories":"","description":"...","excerpt":"...","ref":"/blog/2021/02/13/first-day-of-instructions/","tags":"","title":"First Day of Instructions"},{"body":"","categories":"","description":"","excerpt":"","ref":"/about/","tags":"","title":"About GEN242"},{"body":"\n\n Teaching material will be posted one day before each class meeting.\n  [ Download ]\n","categories":"","description":"","excerpt":"\n\n Teaching material will be posted one day before each class meeting. …","ref":"/lectures/slides/slides_01/","tags":"","title":"Course Introduction"},{"body":"\n\nSlide show to be posted.\n[ Download ]\n","categories":"","description":"","excerpt":"\n\nSlide show to be posted.\n[ Download ]\n","ref":"/lectures/slides/slides_03/","tags":"","title":"Databases and Software"},{"body":" Data Analysis in Genome Biology   About Course  GitHub   Instructors     GEN242 is a graduate class taught at the University of California, Riverside         Overview This course introduces algorithms, statistical methods and data analysis programming routines relevant for genome biology. It consists of three main components: lectures, hands-on practicals and student course projects. The lecture topics cover databases, sequence (NGS) analysis, phylogenetics, comparative genomics, genome-wide profiling methods, network biology and more. The hands-on practicals include homework assignments and course projects focusing on data analysis programming of next generation genome data using command-line tools on a computer cluster and the programming environment R.  Who should take this class? Students with a strong interest and motivation in acquiring the skills required for mastering the computational aspects of modern genome research. The class is mainly targeting graduate students but senior undergraduate students are welcome to enroll as well. The main audience of this class are usually students from bioscience, biomedical and bioengineering programs as well as CS and statistics students with interest in computational biology.  Can I audit this class? It is possible to audit this class. However, due to the emphasis on active participation in practicals and course projects, students usually learn much more if they enroll into the class rather than auditing it in a passive manner.      University of California, Riverside    ","categories":"","description":"","excerpt":" Data Analysis in Genome Biology   About Course  GitHub   Instructors …","ref":"/","tags":"","title":"GEN242"},{"body":"\n\nSlide show to be posted.\n[ Download ]\n","categories":"","description":"","excerpt":"\n\nSlide show to be posted.\n[ Download ]\n","ref":"/lectures/slides/slides_02/","tags":"","title":"Genome Basics"},{"body":"","categories":"","description":"The pages under this _Internal Section_ provide information about internal resources that are mainly relevant for the instructor(s) of this class.","excerpt":"The pages under this _Internal Section_ provide information about …","ref":"/about/internal/","tags":"","title":"Internal Resources"},{"body":"","categories":"","description":"","excerpt":"","ref":"/lectures/","tags":"","title":"Lectures"},{"body":"This is the blog section. It has two categories: News and Releases.\nFiles in these directories will be listed in reverse chronological order.\n","categories":"","description":"","excerpt":"This is the blog section. It has two categories: News and Releases. …","ref":"/blog/","tags":"","title":"GEN242 News"},{"body":"This page provides URLs to external resources  Piazza GitHub Repo Bioconductor Hugo, Docsy and R  ","categories":"","description":"","excerpt":"This page provides URLs to external resources  Piazza GitHub Repo …","ref":"/external_resources/","tags":"","title":"Links"},{"body":"","categories":"","description":"","excerpt":"","ref":"/search/","tags":"","title":"Search Results"},{"body":"","categories":"","description":"","excerpt":"","ref":"/lectures/slides/","tags":"","title":"Slides"},{"body":" Teaching material will be posted one day before each class meeting.\n GitHub  … …  Linux and HPC  … …  Introduction to R  … …  Programming in R  … …  NGS Analysis Basics  … …  NGS Workflows - Overview  … …  Graphics and Visualization  … …  Cluster Analysis and Data Mining  … …  ","categories":"","description":"","excerpt":" Teaching material will be posted one day before each class meeting. …","ref":"/tutorials/tutorials/","tags":"","title":"Tutorials"}]